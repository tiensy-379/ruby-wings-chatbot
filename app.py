"""
RUBY WINGS CHATBOT v5.0 - C·∫¨P NH·∫¨T KNOWLEDGE.JSON
C·∫•u tr√∫c ho√†n ch·ªânh theo ƒë·ªÅ c∆∞∆°ng chu·∫©n h√≥a
"""

# ==================== PH·∫¶N 1: IMPORTS & CONFIG ====================
import json
import logging
import re
import hashlib
import time
import os
import threading
import traceback
import unicodedata
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, asdict, field
from enum import Enum
from datetime import datetime
from functools import lru_cache
from collections import defaultdict, deque
from difflib import SequenceMatcher
import requests
import logging
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)
import numpy as np
from flask import Flask, request, jsonify, Response, stream_with_context
app = Flask(__name__)

from flask_cors import CORS

# Try to import FAISS with fallback
try:
    import faiss
    HAS_FAISS = True
except ImportError:
    HAS_FAISS = False
    logger.warning("‚ö†Ô∏è FAISS not available, using fallback")

# C√°c bi·∫øn config
LLM_URL = "http://localhost:11434/api/generate"
EMBEDDING_MODEL = "nomic-embed-text"
KNOWLEDGE_PATH = "knowledge.json"
CAPI_ENABLED = True
CAPI_URL = "https://graph.facebook.com/v18.0/me/messages"
SESSION_TIMEOUT = 1800
CACHE_TTL = 300
MAX_TOURS_RETURN = 10
SEMANTIC_MIN_SCORE = 0.75
TOP_K = 10

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ruby_wings.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==================== PH·∫¶N 2: DATACLASSES & ENUMS ====================

class QuestionType(Enum):
    """C√°c lo·∫°i c√¢u h·ªèi - GI·ªÆ NGUY√äN t·ª´ app g·ªëc"""
    LIST_TOURS = "list_tours"
    TOUR_DETAIL = "tour_detail"
    COMPARISON = "comparison"
    RECOMMENDATION = "recommendation"
    GREETING = "greeting"
    FAREWELL = "farewell"
    GENERAL_INFO = "general_info"
    UNKNOWN = "unknown"

class ConversationState(Enum):
    """Tr·∫°ng th√°i h·ªôi tho·∫°i - GI·ªÆ NGUY√äN"""
    INITIAL = "initial"
    FILTERING = "filtering"
    DETAIL_VIEW = "detail_view"
    COMPARISON = "comparison"
    RECOMMENDING = "recommending"
    CLOSING = "closing"

@dataclass
class Tour:
    """
    TOUR OBJECT M·ªöI - T∆Ø∆†NG TH√çCH KNOWLEDGE.JSON
    K·∫ø th·ª´a t·∫•t c·∫£ field t·ª´ knowledge.json + th√™m computed fields
    """
    # Primary fields t·ª´ knowledge.json
    id: int
    tour_name: str
    summary: str
    location: str
    duration: str  # Gi·ªØ nguy√™n string format
    price: str     # Gi·ªØ nguy√™n string format
    includes: List[str]
    notes: str
    style: str
    transport: str
    accommodation: str
    meals: str
    event_support: str
    
    # Computed fields ƒë·ªÉ h·ªó tr·ª£ filter/search
    price_numeric: Optional[float] = None    # Gi√° ƒë√£ parse sang s·ªë
    duration_numeric: Optional[int] = None   # Th·ªùi gian ƒë√£ parse sang s·ªë ng√†y
    category: Optional[str] = None          # Lo·∫°i tour (auto-categorized)
    rating: Optional[float] = 4.5           # Rating m·∫∑c ƒë·ªãnh
    
    # Backward compatibility fields
    description: str = ""                   # Map t·ª´ summary
    highlights: List[str] = field(default_factory=list)  # Map t·ª´ includes
    name: str = ""                          # Alias cho tour_name
    tags: List[str] = field(default_factory=list)       # Auto-generated tags

@dataclass
class FilterSet:
    """B·ªô l·ªçc - TH√äM field style ƒë·ªÉ filter theo knowledge.json"""
    min_price: Optional[float] = None
    max_price: Optional[float] = None
    location: Optional[str] = None
    duration_min: Optional[int] = None
    duration_max: Optional[int] = None
    style: Optional[str] = None            # NEW: Filter theo field style
    category: Optional[str] = None
    include_keywords: Optional[List[str]] = None  # T√¨m trong includes
    group_type: Optional[str] = None
    
    def is_empty(self) -> bool:
        """Check if filter set is empty"""
        return all(
            value is None or (isinstance(value, list) and not value)
            for value in [
                self.min_price, self.max_price, self.location,
                self.duration_min, self.duration_max, self.style,
                self.category, self.include_keywords, self.group_type
            ]
        )

@dataclass
class ConversationContext:
    """Context h·ªôi tho·∫°i - GI·ªÆ NGUY√äN t·ª´ app g·ªëc"""
    session_id: str
    last_tours_mentioned: List[int] = field(default_factory=list)
    user_preferences: Dict[str, Any] = field(default_factory=dict)
    conversation_history: List[Dict] = field(default_factory=list)
    last_question_type: Optional[QuestionType] = None
    current_state: ConversationState = ConversationState.INITIAL
    active_filters: Optional[FilterSet] = None
    created_at: float = field(default_factory=time.time)
    last_activity: float = field(default_factory=time.time)
    
    # Additional fields for backward compatibility
    current_tours: List[int] = field(default_factory=list)
    last_successful_tours: List[int] = field(default_factory=list)
    mentioned_tours: List[int] = field(default_factory=list)
    
    def update(self, user_message: str, bot_response: str, tour_indices: List[int] = None):
        """Update conversation context"""
        self.last_activity = time.time()
        self.conversation_history.append({
            'timestamp': time.time(),
            'user': user_message,
            'bot': bot_response,
            'tours': tour_indices
        })
        
        if tour_indices:
            self.last_successful_tours = tour_indices
            self.current_tours = tour_indices
            self.mentioned_tours.extend(tour_indices)
            
            # Keep only recent tours
            if len(self.mentioned_tours) > 20:
                self.mentioned_tours = self.mentioned_tours[-20:]

@dataclass
class ChatResponse:
    """Response format - GI·ªÆ NGUY√äN t·ª´ app g·ªëc"""
    reply: str
    tour_name: Optional[str] = None
    tour_indices: Optional[List[int]] = None
    action: str = "continue"
    context: Optional[Dict] = None
    warnings: Optional[List[str]] = None
    metadata: Optional[Dict] = None

@dataclass  
class CacheEntry:
    """Cache entry - GI·ªÆ NGUY√äN t·ª´ app g·ªëc"""
    value: Any
    expiry: float
    created_at: float = field(default_factory=time.time)
    
    def is_expired(self) -> bool:
        """Check if cache entry is expired"""
        return time.time() > self.expiry

@dataclass
class LLMRequest:
    """LLM request - GI·ªÆ NGUY√äN t·ª´ app g·ªëc"""
    prompt: str
    model: str = "llama2"
    stream: bool = False
    temperature: float = 0.7
    max_tokens: int = 500

# ==================== PH·∫¶N 3: KNOWLEDGE PROCESSING ====================

class KnowledgeLoader:
    """H·ªá th·ªëng load v√† parse knowledge.json"""
    
    @staticmethod
    def load_knowledge_file(file_path: str = KNOWLEDGE_PATH) -> Dict:
        """Load raw JSON data t·ª´ knowledge.json"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Failed to load knowledge file: {e}")
            return {"tours": []}
    
    @staticmethod
    def parse_tour_data(raw_tour: Dict, tour_id: int) -> Tour:
        """Parse m·ªôt tour t·ª´ raw JSON data sang Tour object"""
        
        # Parse numeric values
        price_numeric = KnowledgeParser.parse_price_string(raw_tour.get('price', ''))
        duration_numeric = KnowledgeParser.parse_duration_string(raw_tour.get('duration', ''))
        
        # Auto-categorize
        category = KnowledgeParser.categorize_tour(raw_tour)
        
        # Create Tour object
        tour = Tour(
            id=tour_id,
            tour_name=raw_tour.get('tour_name', ''),
            summary=raw_tour.get('summary', ''),
            location=raw_tour.get('location', ''),
            duration=raw_tour.get('duration', ''),
            price=raw_tour.get('price', ''),
            includes=raw_tour.get('includes', []),
            notes=raw_tour.get('notes', ''),
            style=raw_tour.get('style', ''),
            transport=raw_tour.get('transport', ''),
            accommodation=raw_tour.get('accommodation', ''),
            meals=raw_tour.get('meals', ''),
            event_support=raw_tour.get('event_support', ''),
            price_numeric=price_numeric,
            duration_numeric=duration_numeric,
            category=category,
            description=raw_tour.get('summary', ''),
            highlights=raw_tour.get('includes', [])[:3],
            name=raw_tour.get('tour_name', ''),
            tags=KnowledgeParser.generate_tags(raw_tour)
        )
        
        return tour
    
    @classmethod
    def build_tours_database(cls) -> Dict[int, Tour]:
        """X√¢y d·ª±ng database tours t·ª´ knowledge.json"""
        knowledge_data = cls.load_knowledge_file()
        tours_db = {}
        
        for idx, tour_data in enumerate(knowledge_data.get('tours', [])):
            tour = cls.parse_tour_data(tour_data, idx)
            tours_db[idx] = tour
        
        logger.info(f"Loaded {len(tours_db)} tours from knowledge.json")
        return tours_db

class KnowledgeParser:
    """Parser utilities cho knowledge.json fields"""
    
    @staticmethod
    def parse_price_string(price_str: str) -> Optional[float]:
        """Parse chu·ªói gi√° sang s·ªë"""
        if not price_str or not isinstance(price_str, str):
            return None
        
        # T√¨m t·∫•t c·∫£ s·ªë trong chu·ªói (h·ªó tr·ª£ c·∫£ d·∫•u ph·∫©y v√† ch·∫•m)
        numbers = re.findall(r'(\d+(?:[.,]\d+)?)', price_str.replace(',', '.'))
        if numbers:
            try:
                value = float(numbers[0])
                # Gi·∫£ ƒë·ªãnh gi√° t√≠nh theo tri·ªáu VND
                return value * 1000000
            except ValueError:
                pass
        
        return None
    
    @staticmethod
    def parse_duration_string(duration_str: str) -> Optional[int]:
        """Parse chu·ªói th·ªùi gian sang s·ªë ng√†y"""
        if not duration_str or not isinstance(duration_str, str):
            return None
        
        numbers = re.findall(r'\d+', duration_str)
        if numbers:
            try:
                return int(numbers[0])
            except ValueError:
                pass
        
        return None
    
    @staticmethod
    def categorize_tour(tour_data: Dict) -> str:
        """Ph√¢n lo·∫°i tour t·ª± ƒë·ªông d·ª±a tr√™n style v√† location"""
        style = (tour_data.get('style') or '').lower()
        location = (tour_data.get('location') or '').lower()
        
        category_keywords = {
            'adventure': ['m·∫°o hi·ªÉm', 'kh√°m ph√°', 'trekking', 'leo n√∫i', 'ph∆∞·ª£t'],
            'relaxation': ['ngh·ªâ d∆∞·ª°ng', 'th∆∞ gi√£n', 'bi·ªÉn', 'spa', 'resort'],
            'cultural': ['vƒÉn h√≥a', 'l·ªãch s·ª≠', 'di s·∫£n', 'di t√≠ch', 'truy·ªÅn th·ªëng'],
            'culinary': ['·∫©m th·ª±c', 'ƒÉn u·ªëng', 'ƒë·∫∑c s·∫£n', 'food tour'],
            'event': ['s·ª± ki·ªán', 'team building', 'h·ªôi ngh·ªã', 't·ªï ch·ª©c'],
            'family': ['gia ƒë√¨nh', 'tr·∫ª em', 'tr·∫£i nghi·ªám gia ƒë√¨nh'],
            'luxury': ['cao c·∫•p', 'sang tr·ªçng', '5 sao', 'VIP']
        }
        
        for category, keywords in category_keywords.items():
            for keyword in keywords:
                if keyword in style or keyword in location:
                    return category
        
        return 'general'
    
    @staticmethod
    def generate_tags(tour_data: Dict) -> List[str]:
        """T·∫°o tags cho tour d·ª±a tr√™n d·ªØ li·ªáu"""
        tags = []
        
        # Location tags
        location = (tour_data.get('location') or '').lower()
        if location:
            for loc in ['hu·∫ø', 'qu·∫£ng tr·ªã', 'b·∫°ch m√£', 'tr∆∞·ªùng s∆°n']:
                if loc in location:
                    tags.append(f"location:{loc}")
        
        # Style tags
        style = (tour_data.get('style') or '').lower()
        if style:
            for st in ['thi·ªÅn', 'kh√≠ c√¥ng', 'retreat', 'l·ªãch s·ª≠', 'vƒÉn h√≥a']:
                if st in style:
                    tags.append(f"style:{st}")
        
        # Duration tags
        duration = (tour_data.get('duration') or '').lower()
        if '1 ng√†y' in duration:
            tags.append("duration:1day")
        elif '2 ng√†y' in duration:
            tags.append("duration:2day")
        elif '3 ng√†y' in duration:
            tags.append("duration:3day")
        
        # Price tags (if price available)
        price = tour_data.get('price', '')
        price_numeric = KnowledgeParser.parse_price_string(price)
        if price_numeric:
            if price_numeric < 1000000:
                tags.append("price:budget")
            elif price_numeric < 3000000:
                tags.append("price:midrange")
            else:
                tags.append("price:premium")
        
        return list(set(tags))

# ==================== PH·∫¶N 4: 10 UPGRADES SYSTEMS ====================

class MandatoryFilterSystemV2:
    """
    Upgrade 1: Mandatory Filter System
    C·∫¨P NH·∫¨T: H·ªó tr·ª£ c√°c field m·ªõi t·ª´ knowledge.json
    """
    
    @staticmethod
    def extract_filters(message: str) -> FilterSet:
        """Tr√≠ch xu·∫•t filter t·ª´ message v·ªõi knowledge.json fields"""
        filters = FilterSet()
        msg_lower = message.lower()
        
        # 1. Price filter
        price_patterns = [
            (r'gi√°\s*(?:d∆∞·ªõi|d∆∞·ªõi\s*)?\s*(\d+(?:[.,]\d+)?)\s*tr?i?·ªá?u?', 'max'),
            (r'gi√°\s*(?:tr√™n|tr√™n\s*)?\s*(\d+(?:[.,]\d+)?)\s*tr?i?·ªá?u?', 'min'),
            (r'(\d+(?:[.,]\d+)?)\s*-\s*(\d+(?:[.,]\d+)?)\s*tr?i?·ªá?u?', 'range'),
            (r'kho·∫£ng\s*(\d+(?:[.,]\d+)?)\s*tr?i?·ªá?u?', 'approx')
        ]
        
        for pattern, ptype in price_patterns:
            matches = re.findall(pattern, msg_lower)
            if matches:
                if ptype == 'max':
                    filters.max_price = float(matches[0].replace(',', '.')) * 1000000
                elif ptype == 'min':
                    filters.min_price = float(matches[0].replace(',', '.')) * 1000000
                elif ptype == 'range':
                    filters.min_price = float(matches[0][0].replace(',', '.')) * 1000000
                    filters.max_price = float(matches[0][1].replace(',', '.')) * 1000000
                elif ptype == 'approx':
                    price = float(matches[0].replace(',', '.')) * 1000000
                    filters.min_price = price * 0.8
                    filters.max_price = price * 1.2
                break
        
        # 2. Location filter
        common_locations = [
            'h√† n·ªôi', 'hanoi', 'sapa', 'h·∫° long', 'halong', 'nha trang',
            'ƒë√† n·∫µng', 'danang', 'h·ªôi an', 'hoian', 'ph√∫ qu·ªëc', 'phuquoc',
            'c·∫ßn th∆°', 'cantho', 'mi·ªÅn b·∫Øc', 'mi·ªÅn nam', 'mi·ªÅn trung',
            'hu·∫ø', 'qu·∫£ng tr·ªã', 'b·∫°ch m√£', 'tr∆∞·ªùng s∆°n', 'ƒë√¥ng h√†'
        ]
        for loc in common_locations:
            if loc in msg_lower:
                filters.location = loc
                break
        
        # 3. Duration filter
        duration_patterns = [
            r'(\d+)\s*ng√†y',
            r'(\d+)\s*-\s*(\d+)\s*ng√†y',
            r'kho·∫£ng\s*(\d+)\s*ng√†y'
        ]
        
        for pattern in duration_patterns:
            matches = re.findall(pattern, msg_lower)
            if matches:
                if isinstance(matches[0], tuple):
                    filters.duration_min = int(matches[0][0])
                    filters.duration_max = int(matches[0][1])
                else:
                    dur = int(matches[0])
                    filters.duration_min = dur
                    filters.duration_max = dur
                break
        
        # 4. NEW: Style filter (t·ª´ knowledge.json field "style")
        style_keywords = [
            'vƒÉn h√≥a', '·∫©m th·ª±c', 'ngh·ªâ d∆∞·ª°ng', 'm·∫°o hi·ªÉm', 'kh√°m ph√°',
            'gia ƒë√¨nh', 'c√° nh√¢n', 'nh√≥m', 'team building', 's·ª± ki·ªán',
            'thi·ªÅn', 'kh√≠ c√¥ng', 'retreat', 'ch·ªØa l√†nh'
        ]
        for style in style_keywords:
            if style in msg_lower:
                filters.style = style
                break
        
        # 5. Include keywords filter (t√¨m trong field "includes")
        include_keywords = ['ƒÉn s√°ng', 'v√© m√°y bay', 'kh√°ch s·∫°n', 'h∆∞·ªõng d·∫´n vi√™n', 'b·∫£o hi·ªÉm']
        found_includes = []
        for keyword in include_keywords:
            if keyword in msg_lower:
                found_includes.append(keyword)
        if found_includes:
            filters.include_keywords = found_includes
        
        # 6. Group type filter
        group_keywords = {
            'family': ['gia ƒë√¨nh', 'tr·∫ª em', 'con n√≠t', 'b·ªë m·∫π'],
            'friends': ['nh√≥m b·∫°n', 'b·∫°n b√®', 'b·∫°n tr·∫ª'],
            'corporate': ['c√¥ng ty', 'team building', 'doanh nghi·ªáp'],
            'solo': ['m·ªôt m√¨nh', 'ƒëi l·∫ª', 'solo'],
            'couple': ['c·∫∑p ƒë√¥i', 'ƒë√¥i l·ª©a', 'ng∆∞·ªùi y√™u']
        }
        
        for group_type, keywords in group_keywords.items():
            for keyword in keywords:
                if keyword in msg_lower:
                    filters.group_type = group_type
                    break
            if filters.group_type:
                break
        
        return filters
    
    @staticmethod
    def apply_filters(tours_db: Dict[int, Tour], filters: FilterSet) -> List[int]:
        """√Åp d·ª•ng filter l√™n tours database (h·ªó tr·ª£ knowledge.json fields)"""
        if filters.is_empty():
            return list(tours_db.keys())
        
        filtered_tours = []
        
        for tour_id, tour in tours_db.items():
            # 1. Price filter (s·ª≠ d·ª•ng price_numeric ƒë√£ parse)
            if filters.min_price is not None and tour.price_numeric is not None:
                if tour.price_numeric < filters.min_price:
                    continue
            
            if filters.max_price is not None and tour.price_numeric is not None:
                if tour.price_numeric > filters.max_price:
                    continue
            
            # 2. Location filter
            if filters.location:
                if filters.location.lower() not in tour.location.lower():
                    continue
            
            # 3. Duration filter (s·ª≠ d·ª•ng duration_numeric ƒë√£ parse)
            if filters.duration_min is not None and tour.duration_numeric is not None:
                if tour.duration_numeric < filters.duration_min:
                    continue
            
            if filters.duration_max is not None and tour.duration_numeric is not None:
                if tour.duration_numeric > filters.duration_max:
                    continue
            
            # 4. NEW: Style filter
            if filters.style and tour.style:
                if filters.style.lower() not in tour.style.lower():
                    continue
            
            # 5. NEW: Include keywords filter
            if filters.include_keywords:
                includes_lower = [inc.lower() for inc in tour.includes]
                found_all = all(
                    any(keyword in inc for inc in includes_lower)
                    for keyword in filters.include_keywords
                )
                if not found_all:
                    continue
            
            # 6. Category filter
            if filters.category and tour.category:
                if filters.category.lower() != tour.category.lower():
                    continue
            
            # 7. Group type filter
            if filters.group_type:
                if filters.group_type == 'family':
                    if not any(tag.startswith('style:') for tag in tour.tags):
                        continue
                elif filters.group_type == 'solo':
                    # Solo travelers might prefer certain styles
                    if tour.style and 'nh√≥m' in tour.style.lower():
                        continue
            
            filtered_tours.append(tour_id)
        
        return filtered_tours

class DeduplicationEngine:
    """
    Upgrade 2: Deduplication Engine - GI·ªÆ NGUY√äN
    """
    
    SIMILARITY_THRESHOLD = 0.85
    MIN_TEXT_LENGTH = 20
    
    @staticmethod
    def calculate_similarity(text1: str, text2: str) -> float:
        """Calculate text similarity using multiple methods"""
        if not text1 or not text2:
            return 0.0
        
        text1_norm = DeduplicationEngine._normalize_text(text1)
        text2_norm = DeduplicationEngine._normalize_text(text2)
        
        if len(text1_norm) < DeduplicationEngine.MIN_TEXT_LENGTH or len(text2_norm) < DeduplicationEngine.MIN_TEXT_LENGTH:
            return 0.0
        
        seq_ratio = SequenceMatcher(None, text1_norm, text2_norm).ratio()
        
        words1 = set(text1_norm.split())
        words2 = set(text2_norm.split())
        
        if not words1 or not words2:
            jaccard = 0.0
        else:
            intersection = words1.intersection(words2)
            union = words1.union(words2)
            jaccard = len(intersection) / len(union)
        
        prefix_len = min(50, min(len(text1_norm), len(text2_norm)))
        prefix1 = text1_norm[:prefix_len]
        prefix2 = text2_norm[:prefix_len]
        prefix_sim = SequenceMatcher(None, prefix1, prefix2).ratio()
        
        similarity = (seq_ratio * 0.5) + (jaccard * 0.3) + (prefix_sim * 0.2)
        
        return similarity
    
    @staticmethod
    def _normalize_text(text: str) -> str:
        """Normalize text for comparison"""
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        stopwords = {'v√†', 'c·ªßa', 'cho', 'v·ªõi', 't·∫°i', '·ªü', 'n√†y', 'ƒë√≥', 'kia', 'v·ªÅ', 'trong'}
        words = [word for word in text.split() if word not in stopwords]
        
        return ' '.join(words)
    
    @staticmethod
    def deduplicate_passages(passages: List[Tuple[float, Dict]], 
                            similarity_threshold: float = None) -> List[Tuple[float, Dict]]:
        """
        Remove duplicate passages from results
        """
        if len(passages) <= 1:
            return passages
        
        threshold = similarity_threshold or DeduplicationEngine.SIMILARITY_THRESHOLD
        unique_passages = []
        seen_passages = []
        
        sorted_passages = sorted(passages, key=lambda x: x[0], reverse=True)
        
        for score, passage in sorted_passages:
            text = passage.get('text', '').strip()
            path = passage.get('path', '')
            
            if not text or len(text) < DeduplicationEngine.MIN_TEXT_LENGTH:
                unique_passages.append((score, passage))
                continue
            
            is_duplicate = False
            for seen_text, seen_path in seen_passages:
                tour_match1 = re.search(r'tours\[(\d+)\]', path)
                tour_match2 = re.search(r'tours\[(\d+)\]', seen_path)
                
                if tour_match1 and tour_match2:
                    if tour_match1.group(1) == tour_match2.group(1):
                        field1 = path.split('.')[-1] if '.' in path else ''
                        field2 = seen_path.split('.')[-1] if '.' in seen_path else ''
                        if field1 == field2:
                            is_duplicate = True
                            break
                
                similarity = DeduplicationEngine.calculate_similarity(text, seen_text)
                if similarity > threshold:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_passages.append((score, passage))
                seen_passages.append((text, path))
        
        logger.info(f"üîÑ Deduplication: {len(passages)} ‚Üí {len(unique_passages)} passages")
        return unique_passages
    
    @staticmethod
    def merge_similar_tours(tour_indices: List[int], tours_db: Dict[int, Tour]) -> List[int]:
        """Merge tours that are essentially the same"""
        if len(tour_indices) <= 1:
            return tour_indices
        
        tour_groups = []
        processed = set()
        
        for i, idx1 in enumerate(tour_indices):
            if idx1 in processed:
                continue
            
            group = [idx1]
            tour1 = tours_db.get(idx1)
            name1 = (tour1.tour_name if tour1 else "").strip()
            
            if not name1:
                processed.add(idx1)
                tour_groups.append(group)
                continue
            
            for j, idx2 in enumerate(tour_indices[i+1:], i+1):
                if idx2 in processed:
                    continue
                
                tour2 = tours_db.get(idx2)
                name2 = (tour2.tour_name if tour2 else "").strip()
                
                if not name2:
                    continue
                
                similarity = DeduplicationEngine.calculate_similarity(name1, name2)
                if similarity > 0.9:
                    group.append(idx2)
                    processed.add(idx2)
            
            processed.add(idx1)
            tour_groups.append(group)
        
        best_tours = []
        for group in tour_groups:
            if not group:
                continue
            
            if len(group) == 1:
                best_tours.append(group[0])
                continue
            
            best_score = -1
            best_idx = group[0]
            
            for idx in group:
                tour = tours_db.get(idx)
                if not tour:
                    continue
                
                score = 0
                
                if tour.tour_name:
                    score += 2
                if tour.duration:
                    score += 2
                if tour.location:
                    score += 2
                if tour.price:
                    score += 3
                if tour.includes:
                    score += 2
                if tour.summary:
                    score += 1
                
                for field in [tour.includes, tour.summary, tour.notes]:
                    if isinstance(field, str) and len(field) > 50:
                        score += 1
                    elif isinstance(field, list) and field:
                        score += len(field)
                
                if score > best_score:
                    best_score = score
                    best_idx = idx
            
            best_tours.append(best_idx)
        
        logger.info(f"üîÑ Tour merging: {len(tour_indices)} ‚Üí {len(best_tours)} unique tours")
        return best_tours

class EnhancedFieldDetectorV2:
    """
    Upgrade 3: Enhanced Field Detector
    C·∫¨P NH·∫¨T: Detect c√°c field m·ªõi t·ª´ knowledge.json
    """
    
    @staticmethod
    def detect_field_with_confidence(message: str) -> Tuple[Optional[str], float, Dict]:
        """Ph√°t hi·ªán field ƒë∆∞·ª£c h·ªèi v·ªõi knowledge.json structure"""
        msg_lower = message.lower()
        
        # Field mapping: t·ª´ kh√≥a -> field trong knowledge.json
        field_mappings = {
            'tour_name': {
                'keywords': ['t√™n tour', 'tour n√†o', 'tour g√¨', 'tour t√™n l√†'],
                'weight': 1.0
            },
            'price': {
                'keywords': ['gi√°', 'gi√° c·∫£', 'chi ph√≠', 'bao nhi√™u ti·ªÅn', 'gi√° tour'],
                'weight': 1.0
            },
            'duration': {
                'keywords': ['th·ªùi gian', 'bao l√¢u', 'm·∫•y ng√†y', 'k√©o d√†i', 'duration'],
                'weight': 0.9
            },
            'location': {
                'keywords': ['ƒë·ªãa ƒëi·ªÉm', '·ªü ƒë√¢u', 'n∆°i n√†o', 'ƒëi·ªÉm ƒë·∫øn', 'location'],
                'weight': 0.9
            },
            'includes': {
                'keywords': ['bao g·ªìm', 'c√≥ g√¨', 'd·ªãch v·ª•', 'ti·ªán √≠ch', 'included'],
                'weight': 0.8
            },
            'style': {
                'keywords': ['phong c√°ch', 'lo·∫°i h√¨nh', 'd·∫°ng tour', 'ki·ªÉu tour', 'style'],
                'weight': 0.7
            },
            'transport': {
                'keywords': ['ph∆∞∆°ng ti·ªán', 'di chuy·ªÉn', 'xe c·ªô', 'v·∫≠n chuy·ªÉn', 'transport'],
                'weight': 0.6
            },
            'accommodation': {
                'keywords': ['ch·ªó ·ªü', 'kh√°ch s·∫°n', 'n∆°i ·ªü', 'l∆∞u tr√∫', 'accommodation'],
                'weight': 0.6
            },
            'meals': {
                'keywords': ['ƒÉn u·ªëng', 'b·ªØa ƒÉn', '·∫©m th·ª±c', 'ƒë·ªì ƒÉn', 'meals'],
                'weight': 0.6
            },
            'event_support': {
                'keywords': ['h·ªó tr·ª£ s·ª± ki·ªán', 't·ªï ch·ª©c event', 's·ª± ki·ªán', 'event support'],
                'weight': 0.5
            },
            'summary': {
                'keywords': ['t√≥m t·∫Øt', 'm√¥ t·∫£', 'gi·ªõi thi·ªáu', 'summary', 'overview'],
                'weight': 0.7
            },
            'notes': {
                'keywords': ['l∆∞u √Ω', 'ch√∫ √Ω', 'c·∫ßn bi·∫øt', 'notes', 'ghi ch√∫'],
                'weight': 0.5
            }
        }
        
        field_scores = {}
        for field, config in field_mappings.items():
            score = 0
            for keyword in config['keywords']:
                if keyword in msg_lower:
                    score += 1
            
            if score > 0:
                # T√≠nh confidence d·ª±a tr√™n s·ªë keyword match v√† weight
                base_confidence = min(0.3 + (score * 0.15), 0.9)
                weighted_confidence = base_confidence * config['weight']
                field_scores[field] = weighted_confidence
        
        if not field_scores:
            return None, 0.3, {}
        
        # T√¨m field c√≥ confidence cao nh·∫•t
        best_field = max(field_scores.items(), key=lambda x: x[1])
        return best_field[0], best_field[1], field_scores
    
    @staticmethod
    def get_field_value(tour: Tour, field_name: str) -> Any:
        """L·∫•y gi√° tr·ªã field t·ª´ Tour object"""
        if field_name == 'tour_name':
            return tour.tour_name
        elif field_name == 'price':
            return tour.price
        elif field_name == 'duration':
            return tour.duration
        elif field_name == 'location':
            return tour.location
        elif field_name == 'includes':
            return tour.includes
        elif field_name == 'style':
            return tour.style
        elif field_name == 'transport':
            return tour.transport
        elif field_name == 'accommodation':
            return tour.accommodation
        elif field_name == 'meals':
            return tour.meals
        elif field_name == 'event_support':
            return tour.event_support
        elif field_name == 'summary':
            return tour.summary
        elif field_name == 'notes':
            return tour.notes
        else:
            return None

class KnowledgeAwareQuestionPipeline:
    """
    Upgrade 4: Question Pipeline
    C·∫¨P NH·∫¨T: Hi·ªÉu c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn knowledge.json fields
    """
    
    @staticmethod
    def classify_question(message: str) -> Tuple[QuestionType, float, Dict]:
        """Ph√¢n lo·∫°i c√¢u h·ªèi v·ªõi knowledge.json context"""
        msg_lower = message.lower()
        
        # Ki·ªÉm tra greeting
        greetings = ['xin ch√†o', 'hello', 'hi', 'ch√†o b·∫°n', 'ch√†o']
        if any(g in msg_lower for g in greetings):
            return QuestionType.GREETING, 0.95, {'greeting_type': 'standard'}
        
        # Ki·ªÉm tra farewell
        farewells = ['t·∫°m bi·ªát', 'bye', 'c·∫£m ∆°n', 'thanks', 'k·∫øt th√∫c']
        if any(f in msg_lower for f in farewells):
            return QuestionType.FAREWELL, 0.95, {'farewell_type': 'standard'}
        
        # C√¢u h·ªèi li·ªát k√™ tour
        list_keywords = ['danh s√°ch', 'li·ªát k√™', 'c√≥ nh·ªØng tour n√†o', 'tour n√†o c√≥', 'c√°c tour']
        list_count = sum(1 for kw in list_keywords if kw in msg_lower)
        if list_count > 0:
            confidence = min(0.7 + (list_count * 0.1), 0.95)
            return QuestionType.LIST_TOURS, confidence, {'list_type': 'general'}
        
        # C√¢u h·ªèi chi ti·∫øt tour
        detail_keywords = ['chi ti·∫øt', 'th√¥ng tin', 'gi·ªõi thi·ªáu', 'm√¥ t·∫£', 'tour n√†y']
        detail_count = sum(1 for kw in detail_keywords if kw in msg_lower)
        if detail_count > 0:
            confidence = min(0.65 + (detail_count * 0.1), 0.9)
            return QuestionType.TOUR_DETAIL, confidence, {'detail_type': 'general'}
        
        # C√¢u h·ªèi so s√°nh
        compare_keywords = ['so s√°nh', 'kh√°c nhau', 'n√™n ch·ªçn', 'c√°i n√†o t·ªët', 'c√°i n√†o hay']
        compare_count = sum(1 for kw in compare_keywords if kw in msg_lower)
        if compare_count > 0:
            confidence = min(0.6 + (compare_count * 0.15), 0.9)
            return QuestionType.COMPARISON, confidence, {'compare_type': 'general'}
        
        # C√¢u h·ªèi ƒë·ªÅ xu·∫•t
        recommend_keywords = ['ƒë·ªÅ xu·∫•t', 'g·ª£i √Ω', 'n√™n ƒëi', 'ph√π h·ª£p', 't∆∞ v·∫•n']
        recommend_count = sum(1 for kw in recommend_keywords if kw in msg_lower)
        if recommend_count > 0:
            confidence = min(0.7 + (recommend_count * 0.1), 0.95)
            return QuestionType.RECOMMENDATION, confidence, {'recommend_type': 'general'}
        
        # C√¢u h·ªèi v·ªÅ field c·ª• th·ªÉ trong knowledge.json
        field_detector = EnhancedFieldDetectorV2()
        field_name, field_confidence, _ = field_detector.detect_field_with_confidence(message)
        if field_confidence > 0.6:
            return QuestionType.GENERAL_INFO, field_confidence, {'field_name': field_name}
        
        return QuestionType.UNKNOWN, 0.5, {'reason': 'no_keywords_matched'}

class ComplexQueryProcessor:
    """Upgrade 5: Complex Query Processor - GI·ªÆ NGUY√äN"""
    
    @staticmethod
    def split_query(query: str) -> List[Dict[str, Any]]:
        """Split complex query into sub-queries"""
        sub_queries = []
        
        # Simple implementation - can be enhanced
        if ' v√† ' in query or ',' in query:
            parts = re.split(r' v√† |,', query)
            for part in parts:
                if part.strip():
                    sub_queries.append({
                        'query': part.strip(),
                        'priority': 0.8,
                        'filters': {},
                        'focus': 'general'
                    })
        else:
            sub_queries.append({
                'query': query,
                'priority': 1.0,
                'filters': {},
                'focus': 'general'
            })
        
        return sub_queries

class FuzzyMatcher:
    """Upgrade 6: Fuzzy Matcher - GI·ªÆ NGUY√äN"""
    
    def __init__(self, tours_db: Dict[int, Tour]):
        self.tours_db = tours_db
    
    def find_similar_tours(self, query: str, tour_names: Dict[str, int]) -> List[Tuple[int, float]]:
        """Find tours with similar names"""
        matches = []
        query_norm = self.normalize_text(query)
        
        for name, idx in tour_names.items():
            name_norm = self.normalize_text(name)
            similarity = SequenceMatcher(None, query_norm, name_norm).ratio()
            
            if similarity > 0.6:
                matches.append((idx, similarity))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        return matches[:5]
    
    def find_tour_by_partial_name(self, partial_name: str) -> List[int]:
        """Find tours by partial name match"""
        partial_norm = self.normalize_text(partial_name)
        matches = []
        
        for idx, tour in self.tours_db.items():
            tour_name_norm = self.normalize_text(tour.tour_name)
            if partial_norm in tour_name_norm:
                matches.append(idx)
        
        return matches
    
    @staticmethod
    def normalize_text(text: str) -> str:
        """Normalize text for fuzzy matching"""
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text

class ConversationStateMachine:
    """Upgrade 7: Conversation State Machine - GI·ªÆ NGUY√äN"""
    
    def __init__(self, initial_state: ConversationState = ConversationState.INITIAL):
        self.current_state = initial_state
        self.state_history = []
    
    def update(self, user_message: str, bot_response: str, tour_indices: List[int] = None):
        """Update state based on interaction"""
        # Simple state transitions based on message content
        msg_lower = user_message.lower()
        
        if 'so s√°nh' in msg_lower:
            self.current_state = ConversationState.COMPARISON
        elif 'chi ti·∫øt' in msg_lower or 'th√¥ng tin' in msg_lower:
            self.current_state = ConversationState.DETAIL_VIEW
        elif 'ƒë·ªÅ xu·∫•t' in msg_lower or 'g·ª£i √Ω' in msg_lower:
            self.current_state = ConversationState.RECOMMENDING
        elif 't·∫°m bi·ªát' in msg_lower or 'bye' in msg_lower:
            self.current_state = ConversationState.CLOSING
        
        self.state_history.append({
            'timestamp': time.time(),
            'state': self.current_state.value,
            'message': user_message[:100]
        })
    
    def extract_reference(self, message: str) -> List[int]:
        """Extract tour reference from message"""
        # Simple implementation - look for tour names
        msg_lower = message.lower()
        references = []
        
        for idx, tour in tours_db.items():
            tour_name_lower = tour.tour_name.lower()
            if tour_name_lower in msg_lower:
                references.append(idx)
        
        return references

class SemanticAnalyzer:
    """Upgrade 8: Semantic Analyzer - GI·ªÆ NGUY√äN"""
    
    @staticmethod
    def analyze_user_profile(message: str, current_context: ConversationContext) -> Dict:
        """Analyze user profile from message"""
        profile = {
            'interests': [],
            'budget': None,
            'group_type': None,
            'preferred_duration': None
        }
        
        msg_lower = message.lower()
        
        # Detect interests
        interest_keywords = {
            'history': ['l·ªãch s·ª≠', 'chi·∫øn tranh', 'di t√≠ch'],
            'nature': ['thi√™n nhi√™n', 'r·ª´ng', 'n√∫i'],
            'wellness': ['thi·ªÅn', 'kh√≠ c√¥ng', 'ch·ªØa l√†nh'],
            'culture': ['vƒÉn h√≥a', '·∫©m th·ª±c', 'truy·ªÅn th·ªëng']
        }
        
        for interest, keywords in interest_keywords.items():
            for keyword in keywords:
                if keyword in msg_lower:
                    profile['interests'].append(interest)
                    break
        
        return profile
    
    @staticmethod
    def match_tours_to_profile(profile: Dict, tours_db: Dict[int, Tour]) -> List[Tuple]:
        """Match tours to user profile"""
        matches = []
        
        for idx, tour in tours_db.items():
            score = 0
            
            # Match interests with tour style
            if profile.get('interests') and tour.style:
                tour_style_lower = tour.style.lower()
                for interest in profile['interests']:
                    interest_keywords = {
                        'history': ['l·ªãch s·ª≠', 'chi·∫øn tranh'],
                        'nature': ['thi√™n nhi√™n', 'r·ª´ng'],
                        'wellness': ['thi·ªÅn', 'kh√≠ c√¥ng'],
                        'culture': ['vƒÉn h√≥a', '·∫©m th·ª±c']
                    }
                    
                    if any(keyword in tour_style_lower for keyword in interest_keywords.get(interest, [])):
                        score += 1
            
            # Match budget
            if profile.get('budget') and tour.price_numeric:
                if tour.price_numeric <= profile['budget']:
                    score += 1
            
            if score > 0:
                matches.append((idx, score))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        return matches

class AutoValidator:
    """Upgrade 9: Auto Validator - GI·ªÆ NGUY√äN"""
    
    @staticmethod
    def validate_response(response: str) -> str:
        """Validate and correct response"""
        # Simple validation - ensure hotline is included
        if '0332510486' not in response:
            response += "\n\nüìû Li√™n h·ªá hotline 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt!"
        
        return response
    
    @staticmethod
    def safe_validate(reply: dict) -> dict:
        """Safe validation wrapper"""
        try:
            if not isinstance(reply, dict):
                return reply
            
            if 'reply' in reply:
                reply['reply'] = AutoValidator.validate_response(reply['reply'])
            
            return reply
        except Exception as e:
            logger.error(f"Validation error: {e}")
            return reply

class KnowledgeTemplateSystem:
    """
    Upgrade 10: Template System
    C·∫¨P NH·∫¨T: Templates cho knowledge.json fields
    """
    
    TEMPLATES = {
        # General templates
        'greeting': """Xin ch√†o! üëã T√¥i l√† tr·ª£ l√Ω du l·ªãch c·ªßa Ruby Wings.

T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:
‚Ä¢ T√¨m ki·∫øm tour theo y√™u c·∫ßu
‚Ä¢ Cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ tour
‚Ä¢ So s√°nh c√°c tour v·ªõi nhau
‚Ä¢ ƒê·ªÅ xu·∫•t tour ph√π h·ª£p v·ªõi nhu c·∫ßu

B·∫°n ƒëang t√¨m ki·∫øm tour nh∆∞ th·∫ø n√†o?""",
        
        'farewell': """C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng d·ªãch v·ª• c·ªßa Ruby Wings! üåü

N·∫øu b·∫°n c·∫ßn th√™m th√¥ng tin v·ªÅ b·∫•t k·ª≥ tour n√†o, ƒë·ª´ng ng·∫ßn ng·∫°i quay l·∫°i.

Ch√∫c b·∫°n c√≥ m·ªôt chuy·∫øn ƒëi tuy·ªát v·ªùi! ‚úàÔ∏è""",
        
        # Tour list template
        'tour_list': """üéØ **T√¥i t√¨m th·∫•y {count} tour ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n:**

{tour_items}

üí° **G·ª£i √Ω:**
‚Ä¢ G√µ s·ªë th·ª© t·ª± ƒë·ªÉ xem chi ti·∫øt tour
‚Ä¢ Ho·∫∑c h·ªèi th√™m v·ªÅ ti√™u ch√≠ c·ª• th·ªÉ (gi√°, th·ªùi gian, ƒë·ªãa ƒëi·ªÉm)""",
        
        'tour_item': """{idx}. **{tour_name}**
   üìç {location} | ‚è± {duration} | üí∞ {price}
   üéØ {summary}""",
        
        # Tour detail template v·ªõi knowledge.json fields
        'tour_detail_full': """üåü **{tour_name}**

üìã **T√≥m t·∫Øt:** {summary}
üìç **ƒê·ªãa ƒëi·ªÉm:** {location}
‚è± **Th·ªùi gian:** {duration}
üí∞ **Gi√°:** {price}
üé® **Phong c√°ch:** {style}

üöå **Ph∆∞∆°ng ti·ªán di chuy·ªÉn:** {transport}
üè® **Ch·ªó ·ªü:** {accommodation}
üçΩ **ƒÇn u·ªëng:** {meals}

‚úÖ **D·ªãch v·ª• bao g·ªìm:**
{includes_formatted}

üìù **L∆∞u √Ω quan tr·ªçng:** {notes}

üé™ **H·ªó tr·ª£ s·ª± ki·ªán:** {event_support}

üíé **Lo·∫°i tour:** {category} | ‚≠ê **ƒê√°nh gi√°:** {rating}/5""",
        
        # Field-specific templates
        'field_price': """üí∞ **Gi√° tour {tour_name}:**
{price}

üí° *Gi√° ƒë√£ bao g·ªìm thu·∫ø v√† ph√≠ d·ªãch v·ª•*""",
        
        'field_includes': """‚úÖ **Tour {tour_name} bao g·ªìm:**

{includes_formatted}

üí° *T·∫•t c·∫£ d·ªãch v·ª• ƒë√£ ƒë∆∞·ª£c ki·ªÉm duy·ªát v√† ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng*""",
        
        'field_duration': """‚è± **Th·ªùi gian tour {tour_name}:**
{duration}

üìÖ *L·ªãch tr√¨nh chi ti·∫øt c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh theo y√™u c·∫ßu*""",
        
        'field_location': """üìç **ƒê·ªãa ƒëi·ªÉm tour {tour_name}:**
{location}

üó∫Ô∏è *B·∫£n ƒë·ªì v√† h∆∞·ªõng d·∫´n di chuy·ªÉn s·∫Ω ƒë∆∞·ª£c cung c·∫•p ƒë·∫ßy ƒë·ªß*""",
        
        # Comparison template
        'comparison': """üîÑ **So s√°nh {count} tour:**

{comparison_table}

üìä **T√≥m t·∫Øt:**
{summary}

üí° **G·ª£i √Ω:** {suggestion}""",
        
        # Recommendation template
        'recommendation': """üéØ **ƒê·ªÅ xu·∫•t ph√π h·ª£p v·ªõi b·∫°n:**

{recommended_tour}

üìà **L√Ω do ƒë·ªÅ xu·∫•t:**
{reasons}

ü§î **Tour kh√°c c√≥ th·ªÉ xem x√©t:**
{alternatives}""",
        
        # Error/fallback templates
        'no_results': """üòï **Kh√¥ng t√¨m th·∫•y tour ph√π h·ª£p**

T√¥i kh√¥ng t√¨m th·∫•y tour n√†o ƒë√°p ·ª©ng y√™u c·∫ßu c·ªßa b·∫°n. B·∫°n c√≥ th·ªÉ:

1. **M·ªü r·ªông ti√™u ch√≠ t√¨m ki·∫øm**
2. **Thay ƒë·ªïi ng√¢n s√°ch ho·∫∑c th·ªùi gian**
3. **Xem danh s√°ch t·∫•t c·∫£ tour c√≥ s·∫µn**

B·∫°n mu·ªën th·ª≠ c√°ch n√†o?""",
        
        'general_fallback': """ü§î **T√¥i hi·ªÉu b·∫°n ƒëang h·ªèi v·ªÅ:**
_{user_message}_

Hi·ªán t√¥i c√≥ th·ªÉ gi√∫p b·∫°n v·ªõi:
‚Ä¢ Th√¥ng tin v·ªÅ {available_fields}
‚Ä¢ So s√°nh c√°c tour
‚Ä¢ ƒê·ªÅ xu·∫•t tour ph√π h·ª£p

B·∫°n mu·ªën t√¨m hi·ªÉu c·ª• th·ªÉ v·ªÅ ƒëi·ªÅu g√¨?"""
    }
    
    @classmethod
    def render(cls, template_name: str, **kwargs) -> str:
        """Render template v·ªõi data"""
        template = cls.TEMPLATES.get(template_name)
        if not template:
            return f"Template '{template_name}' not found"
        
        try:
            # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho includes (chuy·ªÉn list -> string)
            if 'includes' in kwargs and isinstance(kwargs['includes'], list):
                includes_items = [f"‚Ä¢ {item}" for item in kwargs['includes']]
                kwargs['includes_formatted'] = "\n".join(includes_items)
            
            return template.format(**kwargs)
        except KeyError as e:
            logger.error(f"Template rendering error: {e}")
            return template

# ==================== PH·∫¶N 5: SUPPORT FUNCTIONS ====================

class CacheSystem:
    """Cache System"""
    
    def __init__(self):
        self.cache = {}
    
    def get_cache_key(self, query: str, context_hash: str = "") -> str:
        """Generate cache key"""
        key_parts = [query]
        if context_hash:
            key_parts.append(context_hash)
        return hashlib.md5("|".join(key_parts).encode()).hexdigest()
    
    def get(self, key: str) -> Optional[Any]:
        """Get item from cache"""
        if key in self.cache:
            entry = self.cache[key]
            if not entry.is_expired():
                logger.debug(f"üíæ Cache hit for key: {key[:20]}...")
                return entry.value
            else:
                del self.cache[key]
        return None
    
    def set(self, key: str, value: Any, expiry: int = None):
        """Set item in cache"""
        ttl = expiry or CACHE_TTL
        cache_entry = CacheEntry(
            value=value,
            expiry=time.time() + ttl
        )
        self.cache[key] = cache_entry
        
        # Clean up expired entries occasionally
        if len(self.cache) > 100:
            self._cleanup()
    
    def _cleanup(self):
        """Clean up expired cache entries"""
        expired_keys = []
        for key, entry in self.cache.items():
            if entry.is_expired():
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.cache[key]
        
        if expired_keys:
            logger.debug(f"üßπ Cleaned up {len(expired_keys)} expired cache entries")

def get_session_context(session_id: str) -> ConversationContext:
    """L·∫•y context t·ª´ session"""
    with SESSION_LOCK:
        if session_id in sessions:
            context = sessions[session_id]
            # Check if session has expired
            if time.time() - context.last_activity > SESSION_TIMEOUT:
                logger.info(f"Session {session_id} expired, creating new")
                context = ConversationContext(session_id=session_id)
                sessions[session_id] = context
            return context
        else:
            context = ConversationContext(session_id=session_id)
            sessions[session_id] = context
            return context

def save_session_context(session_id: str, context: ConversationContext):
    """L∆∞u context v√†o session"""
    with SESSION_LOCK:
        sessions[session_id] = context

def extract_session_id(request_data: Dict, remote_addr: str) -> str:
    """Extract session ID"""
    session_id = request_data.get("session_id")
    if not session_id:
        ip = remote_addr or "0.0.0.0"
        current_hour = datetime.now().strftime("%Y%m%d%H")
        unique_str = f"{ip}_{current_hour}"
        session_id = hashlib.md5(unique_str.encode()).hexdigest()[:12]
    return f"session_{session_id}"

def llm_request(request_data: LLMRequest) -> str:
    """G·ª≠i request ƒë·∫øn LLM"""
    try:
        import requests
        response = requests.post(
            LLM_URL,
            json={
                "model": request_data.model,
                "prompt": request_data.prompt,
                "stream": request_data.stream,
                "temperature": request_data.temperature,
                "max_tokens": request_data.max_tokens
            },
            timeout=30
        )
        
        if response.status_code == 200:
            if request_data.stream:
                return response.text
            else:
                data = response.json()
                return data.get("response", "")
        else:
            logger.error(f"LLM request failed: {response.status_code}")
            return ""
    except Exception as e:
        logger.error(f"LLM request error: {e}")
        return ""

def parse_llm_response(llm_response: str) -> Dict:
    """Parse LLM response"""
    # Simple parsing - can be enhanced
    return {"reply": llm_response}

@lru_cache(maxsize=100)
def embed_text(text: str) -> Tuple[List[float], int]:
    """T·∫°o embedding cho text"""
    # Fallback embedding - can be replaced with actual embedding model
    if not text:
        return [], 0
    
    # Simple hash-based embedding for fallback
    h = hash(text) % (10 ** 12)
    dim = 1536  # OpenAI embedding dimension
    embedding = [(float((h >> (i % 32)) & 0xFF) + (i % 7)) / 255.0 
                 for i in range(dim)]
    
    return embedding, dim

class NumpyIndex:
    """Simple numpy-based index"""
    
    def __init__(self, mat=None):
        if mat is None:
            self.mat = np.empty((0, 0), dtype="float32")
        else:
            self.mat = np.asarray(mat, dtype="float32")
            if self.mat.ndim == 1:
                self.mat = self.mat.reshape(1, -1)
        
        if self.mat.shape[0] > 0 and self.mat.ndim == 2:
            self.dim = int(self.mat.shape[1])
        else:
            self.dim = 0
        self.size = int(self.mat.shape[0])
    
    def is_empty(self):
        return self.mat.shape[0] == 0
    
    def search(self, query_vec, k=5):
        if self.is_empty():
            return [], []
        
        q = np.asarray(query_vec, dtype="float32").reshape(1, -1)
        # Normalize for cosine similarity
        q_norm = q / (np.linalg.norm(q) + 1e-12)
        mat_norm = self.mat / (np.linalg.norm(self.mat, axis=1, keepdims=True) + 1e-12)
        
        sims = np.dot(mat_norm, q_norm.T).reshape(-1)
        topk = np.argsort(-sims)[:k]
        
        return sims[topk].tolist(), topk.tolist()
    
    def save(self, path):
        np.savez_compressed(path, mat=self.mat)
    
    @classmethod
    def load(cls, path):
        try:
            arr = np.load(path)
            return cls(arr['mat'])
        except Exception as e:
            logger.error(f"Failed to load numpy index: {e}")
            return cls()

def query_index(query: str, top_k: int = 5, min_score: float = SEMANTIC_MIN_SCORE) -> List[Tuple[float, Dict]]:
    """Semantic search"""
    if search_index is None:
        return []
    
    try:
        embedding, _ = embed_text(query)
        if not embedding:
            return []
        
        scores, indices = search_index.search(embedding, k=top_k)
        
        results = []
        for score, idx in zip(scores, indices):
            if score < min_score:
                continue
            
            if idx < len(MAPPING):
                passage = MAPPING[idx]
                results.append((float(score), passage))
        
        return results
    except Exception as e:
        logger.error(f"Search error: {e}")
        return []

def build_index(force_rebuild: bool = False) -> bool:
    """Build search index"""
    global search_index
    
    try:
        if not FLAT_TEXTS:
            logger.warning("No texts to index")
            return False
        
        logger.info(f"üî® Building index for {len(FLAT_TEXTS)} passages...")
        
        # Generate embeddings
        vectors = []
        for text in FLAT_TEXTS:
            emb, _ = embed_text(text)
            if emb:
                vectors.append(np.array(emb, dtype="float32"))
        
        if not vectors:
            logger.error("No embeddings generated")
            return False
        
        # Create index
        mat = np.vstack(vectors)
        mat = mat / (np.linalg.norm(mat, axis=1, keepdims=True) + 1e-12)
        
        if HAS_FAISS:
            import faiss
            index = faiss.IndexFlatIP(mat.shape[1])
            index.add(mat)
            search_index = index
            logger.info("‚úÖ Built FAISS index")
        else:
            search_index = NumpyIndex(mat)
            logger.info("‚úÖ Built numpy index")
        
        return True
    except Exception as e:
        logger.error(f"Index building error: {e}")
        return False

def send_capi_event(session_id: str, user_message: str, bot_response: str):
    """G·ª≠i event ƒë·∫øn CAPI"""
    if not CAPI_ENABLED:
        return
    
    try:
        # Implement CAPI sending logic here
        pass
    except Exception as e:
        logger.error(f"CAPI error: {e}")

def generate_session_id() -> str:
    """Generate session ID"""
    import uuid
    return f"session_{uuid.uuid4().hex[:12]}"

def cleanup_expired_sessions():
    """D·ªçn d·∫πp session h·∫øt h·∫°n"""
    with SESSION_LOCK:
        expired_keys = []
        current_time = time.time()
        
        for session_id, context in sessions.items():
            if current_time - context.last_activity > SESSION_TIMEOUT:
                expired_keys.append(session_id)
        
        for key in expired_keys:
            del sessions[key]
        
        if expired_keys:
            logger.info(f"üßπ Cleaned up {len(expired_keys)} expired sessions")

def _prepare_llm_prompt(user_message: str, search_results: List, context: Dict) -> str:
    """Chu·∫©n b·ªã prompt cho LLM"""
    prompt_parts = [
        "B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n du l·ªãch Ruby Wings - CHUY√äN NGHI·ªÜP, TH√îNG MINH, NHI·ªÜT T√åNH.",
        "",
        "‚ö†Ô∏è QUY T·∫ÆC NGHI√äM NG·∫∂T:",
        "1. LU√îN tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát",
        "2. Gi·ªØ th√°i ƒë·ªô nhi·ªát t√¨nh, th√¢n thi·ªán",
        "3. KH√îNG b·ªãa th√¥ng tin n·∫øu kh√¥ng bi·∫øt",
        "4. LU√îN ƒë·ªÅ c·∫≠p hotline 0332510486 khi k·∫øt th√∫c",
        "",
        "üìö TH√îNG TIN NG·ªÆ C·∫¢NH:",
    ]
    
    # Add context info
    if context.get('user_preferences'):
        prefs = context['user_preferences']
        prompt_parts.append(f"- S·ªü th√≠ch ng∆∞·ªùi d√πng: {prefs}")
    
    if context.get('current_tours'):
        tours_info = context['current_tours']
        prompt_parts.append(f"- Tour ƒëang n√≥i ƒë·∫øn: {tours_info}")
    
    # Add search results
    prompt_parts.append("")
    prompt_parts.append("üìù D·ªÆ LI·ªÜU T√åM TH·∫§Y:")
    
    if search_results:
        for i, (score, passage) in enumerate(search_results[:5], 1):
            text = passage.get('text', '')[:200]
            prompt_parts.append(f"[{i}] {text}")
    else:
        prompt_parts.append("(Kh√¥ng c√≥ d·ªØ li·ªáu c·ª• th·ªÉ)")
    
    # Add user message
    prompt_parts.append("")
    prompt_parts.append("üí¨ C√ÇU H·ªéI C·ª¶A KH√ÅCH:")
    prompt_parts.append(user_message)
    
    # Add instructions
    prompt_parts.append("")
    prompt_parts.append("üéØ H√ÉY TR·∫¢ L·ªúI:")
    prompt_parts.append("1. D·ª±a tr√™n d·ªØ li·ªáu c√≥ s·∫µn")
    prompt_parts.append("2. Ng·∫Øn g·ªçn, r√µ r√†ng")
    prompt_parts.append("3. K·∫øt th√∫c b·∫±ng hotline 0332510486")
    
    return "\n".join(prompt_parts)

def _generate_fallback_response(user_message: str, search_results: List, tour_indices: List[int] = None) -> str:
    """Generate fallback response"""
    # Use template system for fallback
    if tour_indices and tours_db:
        tour_list = []
        for idx in tour_indices[:3]:
            tour = tours_db.get(idx)
            if tour:
                tour_list.append(tour)
        
        if tour_list:
            tour_items = []
            for i, tour in enumerate(tour_list, 1):
                tour_items.append(
                    KnowledgeTemplateSystem.TEMPLATES['tour_item'].format(
                        idx=i,
                        tour_name=tour.tour_name,
                        location=tour.location,
                        duration=tour.duration,
                        price=tour.price,
                        summary=tour.summary[:100] + "..."
                    )
                )
            
            return KnowledgeTemplateSystem.TEMPLATES['tour_list'].format(
                count=len(tour_list),
                tour_items="\n\n".join(tour_items)
            )
    
    return KnowledgeTemplateSystem.TEMPLATES['general_fallback'].format(
        user_message=user_message,
        available_fields="gi√° c·∫£, th·ªùi gian, ƒë·ªãa ƒëi·ªÉm, d·ªãch v·ª• bao g·ªìm"
    )

# ==================== PH·∫¶N 6: GLOBAL VARIABLES & INITIALIZATION ====================

# Global variables
tours_db: Dict[int, Tour] = {}
tour_name_index: Dict[str, int] = {}
search_index = None
sessions: Dict[str, ConversationContext] = {}
SESSION_LOCK = threading.Lock()
cache_system = CacheSystem()

# Knowledge base state
KNOW: Dict = {}
FLAT_TEXTS: List[str] = []
MAPPING: List[Dict] = []

def initialize_system():
    """Kh·ªüi t·∫°o h·ªá th·ªëng - C·∫¨P NH·∫¨T v·ªõi knowledge.json"""
    global tours_db, tour_name_index, KNOW, FLAT_TEXTS, MAPPING
    
    # Load tours t·ª´ knowledge.json
    tours_db = KnowledgeLoader.build_tours_database()
    
    # Build tour name index
    tour_name_index = {}
    for tid, tour in tours_db.items():
        normalized_name = tour.tour_name.lower().strip()
        if normalized_name:
            tour_name_index[normalized_name] = tid
    
    # Load knowledge for indexing
    KNOW = KnowledgeLoader.load_knowledge_file()
    
    # Flatten knowledge for indexing
    def scan(obj, prefix="root"):
        if isinstance(obj, dict):
            for k, v in obj.items():
                scan(v, f"{prefix}.{k}")
        elif isinstance(obj, list):
            for i, v in enumerate(obj):
                scan(v, f"{prefix}[{i}]")
        elif isinstance(obj, str):
            t = obj.strip()
            if t:
                FLAT_TEXTS.append(t)
                MAPPING.append({"path": prefix, "text": t})
        else:
            try:
                s = str(obj).strip()
                if s:
                    FLAT_TEXTS.append(s)
                    MAPPING.append({"path": prefix, "text": s})
            except Exception:
                pass
    
    scan(KNOW)
    
    # Build search index
    build_index(force_rebuild=False)
    
    logger.info(f"‚úÖ System initialized with {len(tours_db)} tours, {len(FLAT_TEXTS)} passages")

# G·ªçi kh·ªüi t·∫°o
initialize_system()

# ==================== PH·∫¶N 7: FLASK APP ====================

app = Flask(__name__)
CORS(app)

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "chatbot": "running",
            "tours_db": len(tours_db),
            "knowledge_base": len(KNOW.get('tours', [])),
            "sessions": len(sessions)
        }
    })

@app.route('/api/tours', methods=['GET'])
def get_tours():
    """Get all tours"""
    try:
        tours_list = []
        for idx, tour in tours_db.items():
            tours_list.append({
                "id": idx,
                "tour_name": tour.tour_name,
                "summary": tour.summary,
                "location": tour.location,
                "duration": tour.duration,
                "price": tour.price,
                "category": tour.category,
                "style": tour.style
            })
        
        return jsonify({
            "success": True,
            "count": len(tours_list),
            "tours": tours_list
        })
    except Exception as e:
        logger.error(f"Error getting tours: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/tours/<int:tour_id>', methods=['GET'])
def get_tour_detail(tour_id: int):
    """Get tour details by ID"""
    try:
        tour = tours_db.get(tour_id)
        if not tour:
            return jsonify({"error": "Tour not found"}), 404
        
        return jsonify({
            "success": True,
            "tour": asdict(tour)
        })
    except Exception as e:
        logger.error(f"Error getting tour {tour_id}: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/search', methods=['POST'])
def search_tours():
    """Search tours by query"""
    try:
        data = request.get_json() or {}
        query = data.get('query', '').strip()
        
        if not query:
            return jsonify({"error": "Query is required"}), 400
        
        # Apply filters if provided
        filters_data = data.get('filters', {})
        filters = FilterSet(
            min_price=filters_data.get('min_price'),
            max_price=filters_data.get('max_price'),
            location=filters_data.get('location'),
            duration_min=filters_data.get('duration_min'),
            duration_max=filters_data.get('duration_max'),
            style=filters_data.get('style'),
            category=filters_data.get('category')
        )
        
        # First apply mandatory filters
        filtered_indices = MandatoryFilterSystemV2.apply_filters(tours_db, filters)
        
        # Then apply fuzzy matching if needed
        if query and filtered_indices:
            fuzzy_matcher = FuzzyMatcher(tours_db)
            filtered_tours_db = {idx: tours_db[idx] for idx in filtered_indices}
            
            # Create tour name index for filtered tours
            filtered_tour_names = {}
            for idx in filtered_indices:
                tour = tours_db[idx]
                normalized_name = tour.tour_name.lower().strip()
                if normalized_name:
                    filtered_tour_names[normalized_name] = idx
            
            # Find similar tours
            fuzzy_matches = fuzzy_matcher.find_similar_tours(query, filtered_tour_names)
            if fuzzy_matches:
                filtered_indices = [idx for idx, _ in fuzzy_matches]
        
        # Prepare results
        results = []
        for idx in filtered_indices[:MAX_TOURS_RETURN]:
            tour = tours_db[idx]
            results.append({
                "id": idx,
                "tour_name": tour.tour_name,
                "summary": tour.summary,
                "location": tour.location,
                "duration": tour.duration,
                "price": tour.price,
                "category": tour.category,
                "style": tour.style,
                "rating": tour.rating
            })
        
        return jsonify({
            "success": True,
            "count": len(results),
            "tours": results,
            "total_matches": len(filtered_indices)
        })
    except Exception as e:
        logger.error(f"Search error: {e}")
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

# ==================== PH·∫¶N 8: CHAT ENDPOINT (ƒê·ªÇ CH√àN TH·ª¶ C√îNG) ====================

# ==================== PH·∫¶N 8: CHAT ENDPOINT - KNOWLEDGE.JSON INTEGRATION ====================

@app.route("/chat", methods=["POST"])
def chat_endpoint_knowledge():
    """
    Main chat endpoint v·ªõi full knowledge.json integration
    Version: Knowledge-Aware Chatbot V1.0
    """
    start_time = time.time()
    
    try:
        # ================== 1. NH·∫¨N REQUEST & PARSE ==================
        data = request.get_json() or {}
        user_message = (data.get("message") or "").strip()
        session_id = extract_session_id(data, request.remote_addr)
        
        if not user_message:
            return jsonify(asdict(ChatResponse(
                reply=KnowledgeTemplateSystem.render('greeting'),
                tour_indices=[],
                action="continue",
                context={"session_id": session_id},
                metadata={"processing_time_ms": 0}
            )))
        
        logger.info(f"üì© Received message from {session_id}: {user_message[:100]}...")
        
        # ================== 2. KH·ªûI T·∫†O & LOAD D·ªÆ LI·ªÜU ==================
        # 2.1 L·∫•y context t·ª´ session
        context = get_session_context(session_id)
        context.last_activity = time.time()
        
        # 2.2 Th√™m user message v√†o history
        context.conversation_history.append({
            'role': 'user',
            'message': user_message,
            'timestamp': datetime.utcnow().isoformat()
        })
        
        # 2.3 Check cache
        cache_key = None
        if UpgradeFlags.is_enabled("CACHE_SYSTEM"):
            context_hash = hashlib.md5(json.dumps({
                'last_tours': context.last_tours_mentioned[-3:] if context.last_tours_mentioned else [],
                'state': context.current_state.value,
                'filters': context.active_filters.to_dict() if context.active_filters else {}
            }, sort_keys=True).encode()).hexdigest()
            
            cache_key = cache_system.get_cache_key(user_message, context_hash)
            cached_response = cache_system.get(cache_key)
            
            if cached_response:
                logger.info(f"üíæ Cache hit for key: {cache_key[:50]}...")
                cached_response['metadata']['from_cache'] = True
                cached_response['metadata']['processing_time_ms'] = int((time.time() - start_time) * 1000)
                return jsonify(cached_response)
        
        # ================== 3. PH√ÇN T√çCH C√ÇU H·ªéI V·ªöI KNOWLEDGE.JSON ==================
        # 3.1 Ph√¢n lo·∫°i c√¢u h·ªèi v·ªõi knowledge context
        question_type, confidence, type_details = KnowledgeAwareQuestionPipeline.classify_question(user_message)
        context.last_question_type = question_type
        
        logger.info(f"üéØ Question type: {question_type.value} (confidence: {confidence:.2f})")
        
        # 3.2 Tr√≠ch xu·∫•t filter v·ªõi knowledge.json fields
        mandatory_filters = MandatoryFilterSystemV2.extract_filters(user_message)
        if not mandatory_filters.is_empty():
            context.active_filters = mandatory_filters
            logger.info(f"üîç Filters extracted: {mandatory_filters}")
        
        # 3.3 Ph√°t hi·ªán field ƒë∆∞·ª£c h·ªèi t·ª´ knowledge.json
        field_name, field_confidence, field_scores = EnhancedFieldDetectorV2.detect_field_with_confidence(user_message)
        if field_name:
            logger.info(f"üìä Field detected: {field_name} (confidence: {field_confidence:.2f})")
        
        # 3.4 Ph√¢n t√≠ch semantic user profile
        user_profile = {}
        if UpgradeFlags.is_enabled("8_SEMANTIC_ANALYSIS"):
            user_profile = SemanticAnalyzer.analyze_user_profile(user_message, context)
            if user_profile:
                context.user_preferences.update(user_profile)
                logger.info(f"üë§ User profile updated: {user_profile}")
        
        # ================== 4. T√åM KI·∫æM TOUR T·ª™ KNOWLEDGE.JSON ==================
        tour_indices = []
        resolved_tours = []
        
        # 4.1 DIRECT TOUR NAME MATCHING v·ªõi knowledge.json
        message_lower = user_message.lower()
        for tour_id, tour in tours_db.items():
            # Ki·ªÉm tra t√™n tour
            if tour.tour_name and tour.tour_name.lower() in message_lower:
                if tour_id not in tour_indices:
                    tour_indices.append(tour_id)
                    resolved_tours.append(tour)
            
            # Ki·ªÉm tra trong c√°c field kh√°c c·ªßa knowledge.json
            search_text = f"{tour.summary} {tour.location} {tour.style} {' '.join(tour.includes)}".lower()
            important_keywords = ['b·∫°ch m√£', 'tr∆∞·ªùng s∆°n', 'hu·∫ø', 'qu·∫£ng tr·ªã', 'thi·ªÅn', 'retreat']
            
            for keyword in important_keywords:
                if keyword in message_lower and keyword in search_text:
                    if tour_id not in tour_indices:
                        tour_indices.append(tour_id)
                        resolved_tours.append(tour)
                    break
        
        # 4.2 √Åp d·ª•ng MANDATORY FILTERS v·ªõi knowledge.json fields
        if not mandatory_filters.is_empty():
            filtered_indices = MandatoryFilterSystemV2.apply_filters(tours_db, mandatory_filters)
            
            if filtered_indices:
                if tour_indices:
                    # K·∫øt h·ª£p v·ªõi logic AND: tour ph·∫£i th·ªèa c·∫£ t√¨m ki·∫øm v√† filter
                    combined = list(set(tour_indices) & set(filtered_indices))
                    if combined:
                        tour_indices = combined
                        logger.info(f"‚úÖ Combined search and filter results: {len(tour_indices)} tours")
                    else:
                        # N·∫øu kh√¥ng c√≥ tour n√†o th·ªèa c·∫£ hai, ∆∞u ti√™n filter
                        tour_indices = filtered_indices
                        logger.info(f"‚ö†Ô∏è No tours match both search and filter, using filter results: {len(tour_indices)} tours")
                else:
                    tour_indices = filtered_indices
                    logger.info(f"üîç Using filter-only results: {len(tour_indices)} tours")
        
        # 4.3 FUZZY MATCHING n·∫øu ch∆∞a ƒë·ªß k·∫øt qu·∫£
        if len(tour_indices) < 3 and UpgradeFlags.is_enabled("6_FUZZY_MATCHING"):
            try:
                fuzzy_matcher = FuzzyMatcher(tours_db)
                fuzzy_results = fuzzy_matcher.find_tour_by_partial_name(user_message)
                
                for tour_id in fuzzy_results:
                    if tour_id not in tour_indices:
                        tour_indices.append(tour_id)
                        tour = tours_db.get(tour_id)
                        if tour:
                            resolved_tours.append(tour)
                
                if fuzzy_results:
                    logger.info(f"üîç Added {len(fuzzy_results)} tours from fuzzy matching")
            except Exception as e:
                logger.error(f"Fuzzy matching error: {e}")
        
        # 4.4 SEMANTIC SEARCH v·ªõi FAISS index
        if len(tour_indices) < 5 and UpgradeFlags.is_enabled("8_SEMANTIC_ANALYSIS") and search_index is not None:
            try:
                semantic_results = query_index(user_message, top_k=7, min_score=SEMANTIC_MIN_SCORE)
                
                for score, passage in semantic_results:
                    if 'tour_id' in passage:
                        tour_id = passage['tour_id']
                        if tour_id not in tour_indices:
                            tour_indices.append(tour_id)
                            tour = tours_db.get(tour_id)
                            if tour:
                                resolved_tours.append(tour)
                
                if semantic_results:
                    logger.info(f"üß† Added {len(semantic_results)} tours from semantic search")
            except Exception as e:
                logger.error(f"Semantic search error: {e}")
        
        # 4.5 PROFILE-BASED RECOMMENDATION
        if len(tour_indices) < 3 and user_profile and UpgradeFlags.is_enabled("8_SEMANTIC_ANALYSIS"):
            try:
                profile_matches = SemanticAnalyzer.match_tours_to_profile(user_profile, tours_db)
                for tour_id, score in profile_matches:
                    if score > 0.7 and tour_id not in tour_indices:
                        tour_indices.append(tour_id)
                        tour = tours_db.get(tour_id)
                        if tour:
                            resolved_tours.append(tour)
                
                if profile_matches:
                    logger.info(f"üë§ Added {len(profile_matches)} tours from profile matching")
            except Exception as e:
                logger.error(f"Profile matching error: {e}")
        
        # 4.6 DEDUPLICATION
        if UpgradeFlags.is_enabled("2_DEDUPLICATION"):
            try:
                original_count = len(tour_indices)
                tour_indices = DeduplicationEngine.merge_similar_tours(tour_indices, tours_db)
                if original_count != len(tour_indices):
                    logger.info(f"üîÑ Deduplication: {original_count} -> {len(tour_indices)} tours")
            except Exception as e:
                logger.error(f"Deduplication error: {e}")
        
        # 4.7 S·∫Øp x·∫øp theo relevance v·ªõi knowledge.json fields
        def calculate_relevance_score(tour_id: int) -> float:
            """T√≠nh ƒëi·ªÉm relevance d·ª±a tr√™n knowledge.json fields"""
            tour = tours_db.get(tour_id)
            if not tour:
                return 0
            
            score = 0
            
            # 1. Direct name match (cao nh·∫•t)
            if tour.tour_name and tour.tour_name.lower() in message_lower:
                score += 100
            
            # 2. Field match
            if field_name:
                field_value = EnhancedFieldDetectorV2.get_field_value(tour, field_name)
                if field_value:
                    if isinstance(field_value, str) and field_value.lower() in message_lower:
                        score += 50
                    elif isinstance(field_value, list):
                        for item in field_value:
                            if item.lower() in message_lower:
                                score += 20
                                break
            
            # 3. Location match
            if tour.location and any(loc in message_lower for loc in ['hu·∫ø', 'qu·∫£ng tr·ªã', 'b·∫°ch m√£', 'tr∆∞·ªùng s∆°n']):
                for loc in ['hu·∫ø', 'qu·∫£ng tr·ªã', 'b·∫°ch m√£', 'tr∆∞·ªùng s∆°n']:
                    if loc in message_lower and loc in tour.location.lower():
                        score += 30
                        break
            
            # 4. Style match
            if tour.style and 'style' in type_details.get('field_name', ''):
                score += 15
            
            # 5. Price range match (n·∫øu c√≥ filter)
            if mandatory_filters and (mandatory_filters.min_price or mandatory_filters.max_price):
                if tour.price_numeric:
                    if mandatory_filters.min_price and tour.price_numeric >= mandatory_filters.min_price:
                        score += 10
                    if mandatory_filters.max_price and tour.price_numeric <= mandatory_filters.max_price:
                        score += 10
            
            # 6. Rating bonus
            if tour.rating:
                score += tour.rating * 5
            
            return score
        
        # S·∫Øp x·∫øp theo relevance score
        tour_indices.sort(key=lambda x: calculate_relevance_score(x), reverse=True)
        
        # 4.8 Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng
        tour_indices = tour_indices[:MAX_TOURS_RETURN]
        
        # C·∫≠p nh·∫≠t resolved_tours
        resolved_tours = [tours_db.get(idx) for idx in tour_indices if tours_db.get(idx)]
        
        logger.info(f"‚úÖ Found {len(tour_indices)} tours: {tour_indices}")
        
        # ================== 5. X√ÇY D·ª∞NG RESPONSE V·ªöI KNOWLEDGE.JSON TEMPLATES ==================
        reply = ""
        warnings = []
        metadata = {
            "tour_count": len(tour_indices),
            "question_type": question_type.value,
            "confidence": confidence,
            "field_detected": field_name,
            "filters_applied": not mandatory_filters.is_empty() if mandatory_filters else False
        }
        
        # 5.1 X·ª¨ L√ù THEO QUESTION TYPE V·ªöI KNOWLEDGE.JSON TEMPLATES
        if question_type == QuestionType.GREETING:
            reply = KnowledgeTemplateSystem.render('greeting')
            context.current_state = ConversationState.INITIAL
            
        elif question_type == QuestionType.FAREWELL:
            reply = KnowledgeTemplateSystem.render('farewell')
            context.current_state = ConversationState.CLOSING
            
        elif question_type == QuestionType.LIST_TOURS:
            if tour_indices:
                # Nh√≥m tour theo category t·ª´ knowledge.json
                tours_by_category = {}
                for tour in resolved_tours:
                    category = tour.category or 'general'
                    if category not in tours_by_category:
                        tours_by_category[category] = []
                    tours_by_category[category].append(tour)
                
                # T·∫°o danh s√°ch tour c√≥ nh√≥m
                tour_items_by_category = []
                for category, tours in tours_by_category.items():
                    category_tours = []
                    for idx, tour in enumerate(tours[:4], 1):
                        tour_item = KnowledgeTemplateSystem.render('tour_item',
                            idx=idx,
                            tour_name=tour.tour_name,
                            location=tour.location,
                            duration=tour.duration,
                            price=tour.price,
                            summary=(tour.summary[:120] + '...') if tour.summary and len(tour.summary) > 120 else (tour.summary or "Kh√¥ng c√≥ m√¥ t·∫£")
                        )
                        category_tours.append(tour_item)
                    
                    if category_tours:
                        category_name = {
                            'adventure': 'üèîÔ∏è M·∫†O HI·ªÇM & KH√ÅM PH√Å',
                            'relaxation': 'üåø NGH·ªà D∆Ø·ª†NG & TH∆Ø GI√ÉN',
                            'cultural': 'üèõÔ∏è VƒÇN H√ìA & L·ªäCH S·ª¨',
                            'culinary': 'üçú ·∫®M TH·ª∞C & ƒê·∫∂C S·∫¢N',
                            'event': 'üé™ S·ª∞ KI·ªÜN & TEAM BUILDING',
                            'family': 'üë®‚Äçüë©‚Äçüëß‚Äçüë¶ GIA ƒê√åNH & NH√ìM',
                            'luxury': 'üíé CAO C·∫§P & SANG TR·ªåNG',
                            'general': '‚ú® T·ªîNG H·ª¢P'
                        }.get(category, category.upper())
                        
                        tour_items_by_category.append(f"**{category_name}**\n" + "\n".join(category_tours))
                
                tour_items_str = "\n\n".join(tour_items_by_category)
                
                reply = KnowledgeTemplateSystem.render('tour_list',
                    count=len(tour_indices),
                    tour_items=tour_items_str
                )
                
                # Th√™m filter info n·∫øu c√≥
                if mandatory_filters and not mandatory_filters.is_empty():
                    filter_info = []
                    if mandatory_filters.location:
                        filter_info.append(f"üìç ƒê·ªãa ƒëi·ªÉm: {mandatory_filters.location}")
                    if mandatory_filters.style:
                        filter_info.append(f"üé® Phong c√°ch: {mandatory_filters.style}")
                    if mandatory_filters.min_price or mandatory_filters.max_price:
                        price_range = []
                        if mandatory_filters.min_price:
                            price_range.append(f"t·ª´ {mandatory_filters.min_price:,.0f} VNƒê")
                        if mandatory_filters.max_price:
                            price_range.append(f"ƒë·∫øn {mandatory_filters.max_price:,.0f} VNƒê")
                        filter_info.append(f"üí∞ Gi√°: {' '.join(price_range)}")
                    
                    if filter_info:
                        reply += f"\n\nüîç **ƒêang √°p d·ª•ng b·ªô l·ªçc:**\n" + "\n".join([f"‚Ä¢ {info}" for info in filter_info])
            else:
                reply = KnowledgeTemplateSystem.render('no_results')
                warnings.append("Kh√¥ng t√¨m th·∫•y tour n√†o ph√π h·ª£p v·ªõi y√™u c·∫ßu")
            
            context.current_state = ConversationState.FILTERING
            
        elif question_type == QuestionType.TOUR_DETAIL:
            if tour_indices:
                # Hi·ªÉn th·ªã chi ti·∫øt ƒë·∫ßy ƒë·ªß t·ª´ knowledge.json
                tour = resolved_tours[0] if resolved_tours else None
                if tour:
                    reply = KnowledgeTemplateSystem.render('tour_detail_full',
                        tour_name=tour.tour_name,
                        summary=tour.summary,
                        location=tour.location,
                        duration=tour.duration,
                        price=tour.price,
                        style=tour.style,
                        transport=tour.transport,
                        accommodation=tour.accommodation,
                        meals=tour.meals,
                        includes=tour.includes,
                        notes=tour.notes,
                        event_support=tour.event_support,
                        category=tour.category or 'general',
                        rating=tour.rating or 4.5
                    )
                    
                    # G·ª£i √Ω c√°c tour t∆∞∆°ng t·ª± d·ª±a tr√™n style v√† category
                    similar_tours = []
                    for other_tour in resolved_tours[1:5]:
                        if other_tour and other_tour.style == tour.style or other_tour.category == tour.category:
                            similar_tours.append(f"‚Ä¢ {other_tour.tour_name} ({other_tour.duration}, {other_tour.price})")
                    
                    if similar_tours:
                        reply += f"\n\nüîç **Tour t∆∞∆°ng t·ª± c√πng phong c√°ch:**\n" + "\n".join(similar_tours)
                else:
                    reply = "Kh√¥ng t√¨m th·∫•y th√¥ng tin chi ti·∫øt cho tour n√†y."
            else:
                reply = "Kh√¥ng t√¨m th·∫•y tour n√†o. Vui l√≤ng cung c·∫•p t√™n tour ho·∫∑c m√¥ t·∫£ chi ti·∫øt h∆°n."
            
            context.current_state = ConversationState.DETAIL_VIEW
            
        elif question_type == QuestionType.GENERAL_INFO and field_name:
            # C√¢u h·ªèi v·ªÅ field c·ª• th·ªÉ t·ª´ knowledge.json
            if tour_indices:
                if len(tour_indices) == 1:
                    # M·ªôt tour c·ª• th·ªÉ
                    tour = resolved_tours[0]
                    if tour:
                        field_value = EnhancedFieldDetectorV2.get_field_value(tour, field_name)
                        if field_value:
                            # S·ª≠ d·ª•ng template c·ª• th·ªÉ n·∫øu c√≥
                            template_name = f'field_{field_name}'
                            if template_name in KnowledgeTemplateSystem.TEMPLATES:
                                if field_name == 'includes':
                                    includes_formatted = "\n".join([f"‚Ä¢ {item}" for item in field_value])
                                    reply = KnowledgeTemplateSystem.render(template_name,
                                        tour_name=tour.tour_name,
                                        includes_formatted=includes_formatted
                                    )
                                else:
                                    reply = KnowledgeTemplateSystem.render(template_name,
                                        tour_name=tour.tour_name,
                                        **{field_name: field_value}
                                    )
                            else:
                                # Format chung
                                if isinstance(field_value, list):
                                    field_display = "\n".join([f"‚Ä¢ {item}" for item in field_value])
                                else:
                                    field_display = str(field_value)
                                
                                field_display_name = {
                                    'tour_name': 'T√™n tour',
                                    'price': 'Gi√°',
                                    'duration': 'Th·ªùi gian',
                                    'location': 'ƒê·ªãa ƒëi·ªÉm',
                                    'includes': 'D·ªãch v·ª• bao g·ªìm',
                                    'style': 'Phong c√°ch',
                                    'transport': 'Ph∆∞∆°ng ti·ªán',
                                    'accommodation': 'Ch·ªó ·ªü',
                                    'meals': 'ƒÇn u·ªëng',
                                    'event_support': 'H·ªó tr·ª£ s·ª± ki·ªán',
                                    'summary': 'T√≥m t·∫Øt',
                                    'notes': 'L∆∞u √Ω'
                                }.get(field_name, field_name.replace('_', ' ').upper())
                                
                                reply = f"**{field_display_name} c·ªßa tour {tour.tour_name}:**\n{field_display}"
                        else:
                            reply = f"Tour {tour.tour_name} kh√¥ng c√≥ th√¥ng tin v·ªÅ {field_name.replace('_', ' ')}."
                    else:
                        reply = "Kh√¥ng t√¨m th·∫•y tour."
                else:
                    # Nhi·ªÅu tour - t·ªïng h·ª£p th√¥ng tin field
                    reply = f"**TH√îNG TIN {field_name.replace('_', ' ').upper()} CHO C√ÅC TOUR:**\n\n"
                    for tour in resolved_tours[:5]:
                        field_value = EnhancedFieldDetectorV2.get_field_value(tour, field_name)
                        if field_value:
                            if isinstance(field_value, list):
                                field_display = ", ".join(field_value[:3]) + ("..." if len(field_value) > 3 else "")
                            else:
                                field_display = str(field_value)[:80] + ("..." if len(str(field_value)) > 80 else "")
                            
                            reply += f"‚Ä¢ **{tour.tour_name}**: {field_display}\n"
                        else:
                            reply += f"‚Ä¢ **{tour.tour_name}**: Kh√¥ng c√≥ th√¥ng tin\n"
                    
                    reply += f"\nüí° C√≥ {len(tour_indices)} tour ph√π h·ª£p. ƒê·ªÉ bi·∫øt chi ti·∫øt v·ªÅ m·ªôt tour c·ª• th·ªÉ, vui l√≤ng ch·ªçn t√™n tour."
            else:
                reply = f"Kh√¥ng t√¨m th·∫•y tour n√†o ƒë·ªÉ cung c·∫•p th√¥ng tin v·ªÅ {field_name.replace('_', ' ')}."
            
            context.current_state = ConversationState.DETAIL_VIEW
            
        elif question_type == QuestionType.COMPARISON:
            if len(tour_indices) >= 2:
                # So s√°nh t·ªëi ƒëa 3 tour t·ª´ knowledge.json
                tours_to_compare = resolved_tours[:3]
                
                # T·∫°o b·∫£ng so s√°nh v·ªõi c√°c field quan tr·ªçng
                comparison_rows = []
                
                # C√°c field so s√°nh t·ª´ knowledge.json
                comparison_fields = [
                    ('tour_name', 'T√™n tour'),
                    ('price', 'Gi√°'),
                    ('duration', 'Th·ªùi gian'),
                    ('location', 'ƒê·ªãa ƒëi·ªÉm'),
                    ('style', 'Phong c√°ch'),
                    ('transport', 'Ph∆∞∆°ng ti·ªán'),
                    ('accommodation', 'Ch·ªó ·ªü'),
                    ('includes', 'D·ªãch v·ª• ch√≠nh'),
                    ('rating', 'ƒê√°nh gi√°')
                ]
                
                for field_key, display_name in comparison_fields:
                    row = f"**{display_name}**: "
                    values = []
                    for tour in tours_to_compare:
                        val = EnhancedFieldDetectorV2.get_field_value(tour, field_key)
                        if val:
                            if isinstance(val, list):
                                val = ", ".join(val[:2]) if len(val) > 2 else ", ".join(val)
                            elif field_key == 'price' and len(str(val)) > 40:
                                val = str(val)[:40] + "..."
                            values.append(str(val))
                        else:
                            values.append("N/A")
                    row += " | ".join(values)
                    comparison_rows.append(row)
                
                comparison_table = "\n".join(comparison_rows)
                
                # T·∫°o summary v√† suggestion
                tour_names = [t.tour_name for t in tours_to_compare]
                summary = f"So s√°nh {len(tours_to_compare)} tour: {', '.join(tour_names)}"
                
                # Ph√¢n t√≠ch ƒëi·ªÉm m·∫°nh c·ªßa t·ª´ng tour
                strengths = []
                for tour in tours_to_compare:
                    if tour.style:
                        strengths.append(f"‚Ä¢ {tour.tour_name}: M·∫°nh v·ªÅ {tour.style}")
                    elif tour.category:
                        strengths.append(f"‚Ä¢ {tour.tour_name}: Thu·ªôc lo·∫°i {tour.category}")
                
                suggestion = "ƒê·ªÉ ch·ªçn tour ph√π h·ª£p nh·∫•t:\n"
                if strengths:
                    suggestion += "\n".join(strengths)
                suggestion += "\n\nüìû Li√™n h·ªá hotline 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt."
                
                reply = KnowledgeTemplateSystem.render('comparison',
                    count=len(tours_to_compare),
                    comparison_table=comparison_table,
                    summary=summary,
                    suggestion=suggestion
                )
            else:
                reply = "C·∫ßn √≠t nh·∫•t 2 tour ƒë·ªÉ so s√°nh. Vui l√≤ng cung c·∫•p t√™n c√°c tour c·∫ßn so s√°nh."
            
            context.current_state = ConversationState.COMPARISON
            
        elif question_type == QuestionType.RECOMMENDATION:
            if tour_indices:
                # T√≠nh ƒëi·ªÉm recommendation d·ª±a tr√™n knowledge.json fields
                scored_tours = []
                for tour in resolved_tours:
                    score = 0
                    reasons = []
                    
                    # ƒêi·ªÉm cho filter match
                    if mandatory_filters and not mandatory_filters.is_empty():
                        if mandatory_filters.location and mandatory_filters.location.lower() in tour.location.lower():
                            score += 3
                            reasons.append(f"ƒê√∫ng ƒë·ªãa ƒëi·ªÉm: {mandatory_filters.location}")
                        
                        if mandatory_filters.style and mandatory_filters.style.lower() in tour.style.lower():
                            score += 3
                            reasons.append(f"ƒê√∫ng phong c√°ch: {mandatory_filters.style}")
                        
                        if mandatory_filters.include_keywords:
                            matches = 0
                            for keyword in mandatory_filters.include_keywords:
                                if any(keyword in inc.lower() for inc in tour.includes):
                                    matches += 1
                            if matches > 0:
                                score += matches * 2
                                reasons.append(f"C√≥ {matches} d·ªãch v·ª• b·∫°n c·∫ßn")
                    
                    # ƒêi·ªÉm cho field match
                    if field_name:
                        field_value = EnhancedFieldDetectorV2.get_field_value(tour, field_name)
                        if field_value:
                            score += 2
                            reasons.append(f"C√≥ th√¥ng tin v·ªÅ {field_name.replace('_', ' ')}")
                    
                    # ƒêi·ªÉm cho rating
                    if tour.rating:
                        score += tour.rating
                        reasons.append(f"ƒê√°nh gi√° {tour.rating}/5")
                    
                    # ƒêi·ªÉm cho duration ph√π h·ª£p
                    if mandatory_filters and (mandatory_filters.duration_min or mandatory_filters.duration_max):
                        if tour.duration_numeric:
                            if mandatory_filters.duration_min and tour.duration_numeric >= mandatory_filters.duration_min:
                                score += 1
                            if mandatory_filters.duration_max and tour.duration_numeric <= mandatory_filters.duration_max:
                                score += 1
                    
                    scored_tours.append({
                        'tour': tour,
                        'score': score,
                        'reasons': reasons[:3]
                    })
                
                # S·∫Øp x·∫øp theo ƒëi·ªÉm
                scored_tours.sort(key=lambda x: x['score'], reverse=True)
                
                if scored_tours:
                    # L·∫•y tour t·ªët nh·∫•t
                    best_tour = scored_tours[0]['tour']
                    best_reasons = scored_tours[0]['reasons']
                    
                    # T·∫°o alternatives
                    alternatives = []
                    for item in scored_tours[1:4]:
                        tour = item['tour']
                        alt_text = f"‚Ä¢ {tour.tour_name}"
                        if tour.duration:
                            alt_text += f" ({tour.duration})"
                        if tour.price:
                            price_short = tour.price[:40] + "..." if len(tour.price) > 40 else tour.price
                            alt_text += f" - {price_short}"
                        alternatives.append(alt_text)
                    
                    # Format reasons
                    if not best_reasons:
                        best_reasons = ["Ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n", "ƒê∆∞·ª£c nhi·ªÅu kh√°ch h√†ng l·ª±a ch·ªçn"]
                    
                    reasons_text = "\n".join([f"‚Ä¢ {r}" for r in best_reasons])
                    alternatives_text = "\n".join(alternatives) if alternatives else "Kh√¥ng c√≥ tour kh√°c ph√π h·ª£p"
                    
                    reply = KnowledgeTemplateSystem.render('recommendation',
                        recommended_tour=best_tour.tour_name,
                        reasons=reasons_text,
                        alternatives=alternatives_text
                    )
                else:
                    reply = "Kh√¥ng t√¨m th·∫•y tour ph√π h·ª£p ƒë·ªÉ ƒë·ªÅ xu·∫•t."
            else:
                reply = KnowledgeTemplateSystem.render('no_results')
            
            context.current_state = ConversationState.RECOMMENDING
            
        elif question_type == QuestionType.UNKNOWN:
            # Fallback v·ªõi LLM v√† knowledge context
            try:
                # Chu·∫©n b·ªã knowledge context
                knowledge_context = []
                for tour in resolved_tours[:3]:
                    knowledge_context.append({
                        'name': tour.tour_name,
                        'summary': tour.summary,
                        'location': tour.location,
                        'price': tour.price,
                        'style': tour.style,
                        'includes': tour.includes[:3]
                    })
                
                # T·∫°o prompt v·ªõi knowledge context
                prompt = _prepare_llm_prompt_with_knowledge(
                    user_message, 
                    knowledge_context,
                    {
                        'question_type': question_type.value,
                        'filters': mandatory_filters,
                        'field_name': field_name
                    }
                )
                
                # G·ªçi LLM
                llm_request_obj = LLMRequest(
                    prompt=prompt,
                    model="llama2",
                    temperature=0.7,
                    max_tokens=500
                )
                
                llm_response_text = llm_request(llm_request_obj)
                llm_response_parsed = parse_llm_response(llm_response_text)
                
                reply = llm_response_parsed.get('reply', '')
                
                if not reply:
                    reply = _generate_fallback_response_with_knowledge(user_message, resolved_tours)
                
                # Th√™m th√¥ng tin tour n·∫øu c√≥
                if resolved_tours and 'tour' not in reply.lower():
                    tour_names = [t.tour_name for t in resolved_tours[:3]]
                    reply += f"\n\nüîç **M·ªôt s·ªë tour Ruby Wings c√≥ th·ªÉ b·∫°n quan t√¢m:** {', '.join(tour_names)}"
                
            except Exception as e:
                logger.error(f"LLM fallback error: {e}")
                reply = _generate_fallback_response_with_knowledge(user_message, resolved_tours)
            
            context.current_state = ConversationState.INITIAL
        
        # 5.2 AUTO-VALIDATION v·ªõi knowledge.json context
        if UpgradeFlags.is_enabled("9_AUTO_VALIDATION"):
            try:
                validation_context = {
                    'tours': [t.tour_name for t in resolved_tours[:3]],
                    'field_name': field_name,
                    'question_type': question_type.value
                }
                
                validated_reply = AutoValidator.safe_validate({'reply': reply, 'context': validation_context})
                if 'reply' in validated_reply and validated_reply['reply'] != reply:
                    reply = validated_reply['reply']
                    warnings.append("Ph·∫£n h·ªìi ƒë√£ ƒë∆∞·ª£c t·ª± ƒë·ªông ki·ªÉm tra v√† ƒëi·ªÅu ch·ªânh")
            except Exception as e:
                logger.warning(f"Auto-validation error: {e}")
        
        # 5.3 ƒê·∫£m b·∫£o c√≥ th√¥ng tin li√™n h·ªá
        if '0332510486' not in reply:
            reply += "\n\nüìû **Hotline t∆∞ v·∫•n 24/7:** 0332510486"
        
        if 'www.rubywings.vn' not in reply and 'rubywings.vn' not in reply:
            reply += "\nüåê **Website:** www.rubywings.vn"
        
        # 5.4 Formatting cu·ªëi c√πng
        reply = reply.strip()
        
        # ================== 6. H·∫¨U X·ª¨ L√ù ==================
        # 6.1 C·∫≠p nh·∫≠t conversation state
        state_machine = ConversationStateMachine(context.current_state)
        state_machine.update(user_message, reply[:100], tour_indices)
        context.current_state = state_machine.current_state
        
        # 6.2 C·∫≠p nh·∫≠t last_tours_mentioned
        if tour_indices:
            for tour_id in tour_indices:
                if tour_id not in context.last_tours_mentioned:
                    context.last_tours_mentioned.append(tour_id)
            
            # Gi·ªõi h·∫°n 10 tour
            if len(context.last_tours_mentioned) > 10:
                context.last_tours_mentioned = context.last_tours_mentioned[-10:]
        
        # 6.3 Th√™m bot response v√†o conversation history
        context.conversation_history.append({
            'role': 'assistant',
            'message': reply[:500],
            'timestamp': datetime.utcnow().isoformat(),
            'tour_indices': tour_indices[:5],
            'question_type': question_type.value,
            'field_name': field_name
        })
        
        # 6.4 L∆∞u cache
        if cache_key and UpgradeFlags.is_enabled("CACHE_SYSTEM"):
            cache_entry = CacheEntry(
                value={
                    'reply': reply,
                    'tour_indices': tour_indices,
                    'warnings': warnings,
                    'metadata': metadata
                },
                expiry=time.time() + CACHE_TTL
            )
            cache_system.set(cache_key, cache_entry)
            logger.info(f"üíæ Cached response for key: {cache_key[:50]}...")
        
        # 6.5 L∆∞u session context
        save_session_context(session_id, context)
        
        # 6.6 G·ª≠i CAPI event
        if CAPI_ENABLED:
            try:
                send_capi_event(session_id, user_message[:100], reply[:100])
            except Exception as e:
                logger.error(f"CAPI error: {e}")
        
        # ================== 7. TR·∫¢ RESPONSE ==================
        processing_time = time.time() - start_time
        metadata['processing_time_ms'] = int(processing_time * 1000)
        metadata['from_cache'] = False
        
        # T·∫°o ChatResponse
        chat_response = ChatResponse(
            reply=reply,
            tour_indices=tour_indices,
            action="continue",
            context={
                "session_id": session_id,
                "question_type": question_type.value,
                "field_name": field_name,
                "confidence": confidence,
                "filters_applied": not mandatory_filters.is_empty() if mandatory_filters else False,
                "state": context.current_state.value,
                "tour_count": len(tour_indices)
            },
            warnings=warnings if warnings else None,
            metadata=metadata
        )
        
        logger.info(f"‚úÖ Request processed in {processing_time:.2f}s | "
                   f"Tours: {len(tour_indices)} | "
                   f"Type: {question_type.value} | "
                   f"Confidence: {confidence:.2f}")
        
        return jsonify(asdict(chat_response))
        
    except Exception as e:
        logger.error(f"‚ùå Critical error in chat endpoint: {e}", exc_info=True)
        
        processing_time = time.time() - start_time
        
        # T·∫°o error response
        error_response = ChatResponse(
            reply="Xin l·ªói, ƒë√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c li√™n h·ªá hotline 0332510486.",
            tour_indices=[],
            action="error",
            context={
                "error": str(e)[:100],
                "processing_time_ms": int(processing_time * 1000)
            },
            warnings=["H·ªá th·ªëng g·∫∑p s·ª± c·ªë, vui l√≤ng th·ª≠ l·∫°i sau."],
            metadata={
                "error_type": type(e).__name__,
                "processing_time_ms": int(processing_time * 1000)
            }
        )
        
        return jsonify(asdict(error_response)), 500


# ==================== KNOWLEDGE-AWARE HELPER FUNCTIONS ====================

def _prepare_llm_prompt_with_knowledge(user_message: str, knowledge_context: List[Dict], extra_context: Dict) -> str:
    """
    Chu·∫©n b·ªã prompt cho LLM v·ªõi knowledge.json context
    """
    prompt = f"""B·∫°n l√† tr·ª£ l√Ω AI c·ªßa Ruby Wings Travel, chuy√™n v·ªÅ c√°c tour tr·∫£i nghi·ªám t·∫°i mi·ªÅn Trung Vi·ªát Nam.

TH√îNG TIN TOUR HI·ªÜN C√ì (t·ª´ knowledge.json):
{json.dumps(knowledge_context, indent=2, ensure_ascii=False)}

NG·ªÆ C·∫¢NH CU·ªòC H·ªòI THO·∫†I:
- Lo·∫°i c√¢u h·ªèi: {extra_context.get('question_type', 'unknown')}
- Field ƒë∆∞·ª£c h·ªèi: {extra_context.get('field_name', 'none')}
- B·ªô l·ªçc: {extra_context.get('filters', 'none')}

C√ÇU H·ªéI C·ª¶A KH√ÅCH H√ÄNG: "{user_message}"

Y√äU C·∫¶U TR·∫¢ L·ªúI:
1. S·ª≠ d·ª•ng th√¥ng tin t·ª´ knowledge.json ·ªü tr√™n
2. Tr·∫£ l·ªùi th√¢n thi·ªán, chuy√™n nghi·ªáp
3. N·∫øu kh√¥ng c√≥ th√¥ng tin, ƒë·ªÅ ngh·ªã li√™n h·ªá hotline
4. Lu√¥n nh·∫Øc ƒë·∫øn hotline 0332510486 v√† website www.rubywings.vn
5. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát

TR·∫¢ L·ªúI:"""
    
    return prompt


def _generate_fallback_response_with_knowledge(user_message: str, tours: List[Tour]) -> str:
    """
    T·∫°o fallback response v·ªõi knowledge context
    """
    if tours:
        reply = f"C·∫£m ∆°n c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ: '{user_message}'\n\n"
        reply += "D·ª±a tr√™n th√¥ng tin hi·ªán c√≥, ƒë√¢y l√† c√°c tour Ruby Wings c√≥ th·ªÉ ph√π h·ª£p:\n\n"
        
        for i, tour in enumerate(tours[:4], 1):
            reply += f"{i}. **{tour.tour_name}**\n"
            if tour.duration:
                reply += f"   ‚è±Ô∏è {tour.duration}\n"
            if tour.location:
                reply += f"   üìç {tour.location[:50]}...\n" if len(tour.location) > 50 else f"   üìç {tour.location}\n"
            if tour.summary:
                summary_short = tour.summary[:100] + "..." if len(tour.summary) > 100 else tour.summary
                reply += f"   üìù {summary_short}\n"
            reply += "\n"
        
        reply += "ƒê·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt v√† ch√≠nh x√°c h∆°n, vui l√≤ng:\n"
        reply += "‚Ä¢ Cung c·∫•p th√™m th√¥ng tin v·ªÅ nhu c·∫ßu c·ªßa b·∫°n\n"
        reply += "‚Ä¢ G·ªçi tr·ª±c ti·∫øp hotline 0332510486\n"
        reply += "‚Ä¢ Truy c·∫≠p website www.rubywings.vn\n\n"
        reply += "Ruby Wings c√≥ h∆°n 32 tour tr·∫£i nghi·ªám ƒë·∫∑c s·∫Øc t·∫°i Hu·∫ø, Qu·∫£ng Tr·ªã, B·∫°ch M√£ v√† Tr∆∞·ªùng S∆°n!"
    else:
        reply = f"C·∫£m ∆°n c√¢u h·ªèi c·ªßa b·∫°n: '{user_message}'\n\n"
        reply += "Hi·ªán Ruby Wings c√≥ c√°c lo·∫°i tour ch√≠nh:\n\n"
        reply += "üèîÔ∏è **TOUR M·∫†O HI·ªÇM & KH√ÅM PH√Å:**\n"
        reply += "‚Ä¢ Trekking B·∫°ch M√£, kh√°m ph√° r·ª´ng nguy√™n sinh\n"
        reply += "‚Ä¢ Kh√°m ph√° Tr∆∞·ªùng S∆°n, di t√≠ch l·ªãch s·ª≠\n\n"
        
        reply += "üïâÔ∏è **TOUR RETREAT & CH·ªÆA L√ÄNH:**\n"
        reply += "‚Ä¢ Thi·ªÅn ƒë·ªãnh, yoga t·∫°i B·∫°ch M√£\n"
        reply += "‚Ä¢ Retreat tƒ©nh t√¢m, ch·ªØa l√†nh nƒÉng l∆∞·ª£ng\n\n"
        
        reply += "üèõÔ∏è **TOUR VƒÇN H√ìA & L·ªäCH S·ª¨:**\n"
        reply += "‚Ä¢ Di s·∫£n Hu·∫ø, ·∫©m th·ª±c cung ƒë√¨nh\n"
        reply += "‚Ä¢ Di t√≠ch chi·∫øn tranh t·∫°i Qu·∫£ng Tr·ªã\n\n"
        
        reply += "üë• **TOUR NH√ìM & TEAM BUILDING:**\n"
        reply += "‚Ä¢ Team building c√¥ng ty, nh√≥m b·∫°n\n"
        reply += "‚Ä¢ Tour gia ƒë√¨nh, ƒëa th·∫ø h·ªá\n\n"
        
        reply += "üìû **ƒê·ªÉ bi·∫øt th√™m chi ti·∫øt v√† ƒë∆∞·ª£c t∆∞ v·∫•n tour ph√π h·ª£p nh·∫•t:**\n"
        reply += "‚Ä¢ Hotline: 0332510486 (24/7)\n"
        reply += "‚Ä¢ Website: www.rubywings.vn\n"
        reply += "‚Ä¢ Email: rubywingslsa@gmail.com"
    
    return reply


# ==================== FLAG MANAGEMENT ====================

class UpgradeFlags:
    """Qu·∫£n l√Ω c√°c t√≠nh nƒÉng n√¢ng cao"""
    
    _flags = {
        "1_MANDATORY_FILTER": True,
        "2_DEDUPLICATION": True,
        "3_FIELD_DETECTION": True,
        "4_QUESTION_PIPELINE": True,
        "5_COMPLEX_QUERY": False,  # T·∫°m t·∫Øt
        "6_FUZZY_MATCHING": True,
        "7_STATE_MACHINE": True,
        "8_SEMANTIC_ANALYSIS": True,
        "9_AUTO_VALIDATION": True,
        "10_TEMPLATE_SYSTEM": True,
        "CACHE_SYSTEM": True,
        "LLM_FALLBACK": True
    }
    
    @classmethod
    def is_enabled(cls, flag_name: str) -> bool:
        return cls._flags.get(flag_name, False)
    
    @classmethod
    def enable(cls, flag_name: str):
        cls._flags[flag_name] = True
    
    @classmethod
    def disable(cls, flag_name: str):
        cls._flags[flag_name] = False
    
    @classmethod
    def get_all_flags(cls) -> Dict:
        return cls._flags.copy()


# ==================== BACKWARD COMPATIBILITY FUNCTIONS ====================

def get_session_context(session_id: str) -> ConversationContext:
    """L·∫•y context t·ª´ session - T∆∞∆°ng th√≠ch v·ªõi knowledge.json"""
    if session_id not in sessions:
        sessions[session_id] = ConversationContext(session_id=session_id)
    
    # Ki·ªÉm tra session timeout
    context = sessions[session_id]
    if time.time() - context.last_activity > SESSION_TIMEOUT:
        logger.info(f"Session {session_id} expired, creating new one")
        sessions[session_id] = ConversationContext(session_id=session_id)
    
    return sessions[session_id]


def save_session_context(session_id: str, context: ConversationContext):
    """L∆∞u context v√†o session"""
    sessions[session_id] = context


def extract_session_id(request_data: Dict, remote_addr: str) -> str:
    """Extract session ID t·ª´ request"""
    session_id = request_data.get("session_id")
    if not session_id:
        # T·∫°o session ID m·ªõi t·ª´ IP v√† timestamp
        session_hash = hashlib.md5(f"{remote_addr}_{time.time()}".encode()).hexdigest()[:16]
        session_id = f"session_{session_hash}"
    
    return session_id


def llm_request(request_data: LLMRequest) -> str:
    """G·ª≠i request ƒë·∫øn LLM"""
    try:
        response = requests.post(
            LLM_URL,
            json=asdict(request_data),
            timeout=30
        )
        response.raise_for_status()
        return response.text
    except Exception as e:
        logger.error(f"LLM request error: {e}")
        return ""


def parse_llm_response(llm_response: str) -> Dict:
    """Parse LLM response"""
    try:
        # ƒê∆°n gi·∫£n: tr·∫£ v·ªÅ to√†n b·ªô response
        return {"reply": llm_response}
    except:
        return {"reply": "Xin l·ªói, kh√¥ng th·ªÉ x·ª≠ l√Ω ph·∫£n h·ªìi t·ª´ AI."}


# ==================== INITIALIZATION ====================

def initialize_app():
    """Kh·ªüi t·∫°o ·ª©ng d·ª•ng v·ªõi knowledge.json"""
    global tours_db, tour_name_index, search_index
    
    try:
        # Load tours t·ª´ knowledge.json
        tours_db = KnowledgeLoader.build_tours_database()
        
        # Build tour name index
        tour_name_index = {tour.tour_name.lower(): tour_id for tour_id, tour in tours_db.items()}
        
        # Build search index
        build_index(force_rebuild=False)
        
        logger.info(f"‚úÖ App initialized with {len(tours_db)} tours from knowledge.json")
        
        # Log s·ªë l∆∞·ª£ng tour theo category
        categories = {}
        for tour in tours_db.values():
            cat = tour.category or 'unknown'
            categories[cat] = categories.get(cat, 0) + 1
        
        logger.info(f"üìä Tour categories: {categories}")
        
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize app: {e}")
        tours_db = {}
        tour_name_index = {}


# Ch·∫°y kh·ªüi t·∫°o khi import
initialize_app()

# ==================== PH·∫¶N 9: ADDITIONAL ENDPOINTS ====================

@app.route('/api/filters/extract', methods=['POST'])
def extract_filters():
    """Extract filters from message"""
    try:
        data = request.get_json() or {}
        message = data.get('message', '').strip()
        
        if not message:
            return jsonify({"error": "Message is required"}), 400
        
        filters = MandatoryFilterSystemV2.extract_filters(message)
        
        return jsonify({
            "success": True,
            "filters": asdict(filters)
        })
    except Exception as e:
        logger.error(f"Filter extraction error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/question/classify', methods=['POST'])
def classify_question():
    """Classify question type"""
    try:
        data = request.get_json() or {}
        message = data.get('message', '').strip()
        
        if not message:
            return jsonify({"error": "Message is required"}), 400
        
        qtype, confidence, metadata = KnowledgeAwareQuestionPipeline.classify_question(message)
        
        return jsonify({
            "success": True,
            "question_type": qtype.value,
            "confidence": confidence,
            "metadata": metadata
        })
    except Exception as e:
        logger.error(f"Question classification error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/cleanup', methods=['POST'])
def cleanup():
    """Cleanup expired sessions and cache"""
    try:
        cleanup_expired_sessions()
        cache_system._cleanup()
        
        return jsonify({
            "success": True,
            "message": f"Cleanup completed. Sessions: {len(sessions)}"
        })
    except Exception as e:
        logger.error(f"Cleanup error: {e}")
        return jsonify({"error": str(e)}), 500

# ==================== PH·∫¶N 10: ERROR HANDLERS ====================

@app.errorhandler(404)
def not_found(error):
    return jsonify({"error": "Not found"}), 404

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"Internal server error: {error}")
    return jsonify({"error": "Internal server error"}), 500

# ==================== MAIN ====================

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    debug = os.environ.get('DEBUG', 'False').lower() == 'true'
    
    logger.info(f"üöÄ Starting Ruby Wings Chatbot v5.0 on port {port}")
    logger.info(f"üìä Loaded {len(tours_db)} tours from knowledge.json")
    logger.info(f"üîç Search index ready: {search_index is not None}")
    
    # Start cleanup thread
    def cleanup_thread():
        while True:
            time.sleep(300)  # 5 minutes
            cleanup_expired_sessions()
            cache_system._cleanup()
    
    threading.Thread(target=cleanup_thread, daemon=True).start()
    
    app.run(host='0.0.0.0', port=port, debug=debug)