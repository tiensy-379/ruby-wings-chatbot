def safe_validate(reply):
    try:
        if not isinstance(reply, dict):
            return reply
        # Only validate when tour is selected
        if not reply.get("tour_name"):
            return reply
        return AutoValidator.validate_response(reply)
    except Exception as e:
        try:
            reply.setdefault("warnings", []).append(str(e))
        except:
            pass
        return reply


# app.py - Ruby Wings Chatbot v4.0 (Complete Rewrite with Dataclasses)
# =========== IMPORTS ===========
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("ruby-wings")
import os
import sys
import json
import threading
import logging
import re
import unicodedata
import traceback
import hashlib
import time
import random
from functools import lru_cache, wraps
from typing import List, Tuple, Dict, Optional, Any, Set, Union, Callable
from datetime import datetime, timedelta
from collections import defaultdict, deque
from difflib import SequenceMatcher
from enum import Enum
# Try to import numpy with detailed error handling
try:
    
    import numpy as np
    NUMPY_AVAILABLE = True
    logger.info("âœ… NumPy available")
except ImportError as e:
    logger.error(f"âŒ NumPy import failed: {e}")
    # Create a minimal numpy-like fallback for basic operations
    class NumpyFallback:
        def __init__(self):
            self.float32 = float
            self.int64 = int
            
        def array(self, data, dtype=None):
            # Simple list wrapper
            class SimpleArray:
                def __init__(self, data):
                    self.data = list(data)
                    self.shape = (len(data),) if isinstance(data[0], (int, float)) else (len(data), len(data[0]))
                
                def astype(self, dtype):
                    return self
                
                def reshape(self, shape):
                    return self
                
                def __getitem__(self, idx):
                    return self.data[idx]
                
                def __len__(self):
                    return len(self.data)
            
            return SimpleArray(data)
        
        def empty(self, shape, dtype):
            if len(shape) == 1:
                return [0.0] * shape[0]
            else:
                return [[0.0] * shape[1] for _ in range(shape[0])]
        
        def vstack(self, arrays):
            result = []
            for arr in arrays:
                if hasattr(arr, 'data'):
                    result.extend(arr.data)
                else:
                    result.extend(arr)
            return result
        
        def load(self, path):
            # Mock load function
            class MockNpz:
                def __init__(self):
                    self.files = ['mat']
                
                def __getitem__(self, key):
                    if key == 'mat':
                        # Return empty array
                        return self.array([[0.0]])
                    return None
            
            return MockNpz()
        
        def savez_compressed(self, path, **kwargs):
            # Mock save function
            logger.warning(f"âš ï¸ NumPy fallback: Mock saving to {path}")
            return None
    
    np = NumpyFallback()
    NUMPY_AVAILABLE = False
    logger.warning("âš ï¸ Using NumPy fallback - limited functionality")
from flask import Flask, request, jsonify, g
from flask_cors import CORS

# =========== ENTITY IMPORTS ===========
from entities import (
    QuestionType,
    ConversationState,
    PriceLevel,
    DurationType,
    Tour,
    UserProfile,
    SearchResult,
    ConversationContext,
    FilterSet,
    LLMRequest,
    ChatResponse,
    LeadData,
    CacheEntry,
    EnhancedJSONEncoder
)

# =========== CONFIGURATION ===========
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ruby_wings.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("rbw_v4")

# =========== IMPORTS WITH FALLBACKS ===========
HAS_FAISS = False
try:
    import faiss
    HAS_FAISS = True
    logger.info("âœ… FAISS available")
except ImportError:
    logger.warning("âš ï¸ FAISS not available, using numpy fallback")

HAS_OPENAI = False
client = None
try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    logger.warning("âš ï¸ OpenAI not available, using fallback responses")

# Google Sheets
try:
    import gspread
    from google.oauth2.service_account import Credentials
    from google.auth.exceptions import GoogleAuthError
    from gspread.exceptions import APIError, SpreadsheetNotFound, WorksheetNotFound
    HAS_GOOGLE_SHEETS = True
except ImportError:
    HAS_GOOGLE_SHEETS = False
    logger.warning("âš ï¸ Google Sheets not available")

# Meta CAPI
try:
    from meta_capi import send_meta_pageview, send_meta_lead, send_meta_call_button
    HAS_META_CAPI = True
    logger.info("âœ… Meta CAPI available")
except ImportError:
    HAS_META_CAPI = False
    logger.warning("âš ï¸ Meta CAPI not available")

# =========== ENVIRONMENT VARIABLES ===========
# Memory Profile
RAM_PROFILE = os.environ.get("RAM_PROFILE", "512").strip()
IS_LOW_RAM = RAM_PROFILE == "512"
IS_HIGH_RAM = RAM_PROFILE == "2048"

# Core API Keys
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "").strip()
OPENAI_BASE_URL = os.environ.get("OPENAI_BASE_URL", "").strip()
GOOGLE_SERVICE_ACCOUNT_JSON = os.environ.get("GOOGLE_SERVICE_ACCOUNT_JSON", "").strip()

# Knowledge & Index
KNOWLEDGE_PATH = os.environ.get("KNOWLEDGE_PATH", "knowledge.json")
FAISS_INDEX_PATH = os.environ.get("FAISS_INDEX_PATH", "faiss_index.bin")
FAISS_MAPPING_PATH = os.environ.get("FAISS_MAPPING_PATH", "faiss_mapping.json")
FALLBACK_VECTORS_PATH = os.environ.get("FALLBACK_VECTORS_PATH", "vectors.npz")

# Models
EMBEDDING_MODEL = os.environ.get("EMBEDDING_MODEL", "text-embedding-3-small")
CHAT_MODEL = os.environ.get("CHAT_MODEL", "gpt-4o-mini")
TOP_K = int(os.environ.get("TOP_K", "5"))

# FAISS
FAISS_ENABLED = os.environ.get("FAISS_ENABLED", "true").lower() in ("1", "true", "yes") and not IS_LOW_RAM

# Google Sheets
GOOGLE_SHEET_ID = os.environ.get("GOOGLE_SHEET_ID", "1SdVbwkuxb8l1meEW--ddyfh4WmUvSXXMOPQ5bCyPkdk")
GOOGLE_SHEET_NAME = os.environ.get("GOOGLE_SHEET_NAME", "RBW_Lead_Raw_Inbox")
ENABLE_GOOGLE_SHEETS = os.environ.get("ENABLE_GOOGLE_SHEETS", "true").lower() in ("1", "true", "yes")

# Storage
ENABLE_FALLBACK_STORAGE = os.environ.get("ENABLE_FALLBACK_STORAGE", "true").lower() in ("1", "true", "yes")
FALLBACK_STORAGE_PATH = os.environ.get("FALLBACK_STORAGE_PATH", "leads_fallback.json")

# Meta CAPI
META_CAPI_TOKEN = os.environ.get("META_CAPI_TOKEN", "").strip()
META_PIXEL_ID = os.environ.get("META_PIXEL_ID", "").strip()
META_CAPI_ENDPOINT = os.environ.get("META_CAPI_ENDPOINT", "https://graph.facebook.com/v17.0/")
ENABLE_META_CAPI_CALL = os.environ.get("ENABLE_META_CAPI_CALL", "true").lower() in ("1", "true", "yes")

# Server
FLASK_ENV = os.environ.get("FLASK_ENV", "production")
DEBUG = os.environ.get("DEBUG", "false").lower() in ("1", "true", "yes")
SECRET_KEY = os.environ.get("SECRET_KEY", "ruby-wings-secret-key-2024")
CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "https://www.rubywings.vn,http://localhost:3000").split(",")
HOST = os.environ.get("HOST", "0.0.0.0")
PORT = int(os.environ.get("PORT", "10000"))

# =========== STATS TRACKING (FIX Lá»–I STATE) ===========
# ThÃªm global stats tracking system
STATS_LOCK = threading.Lock()
GLOBAL_STATS = {
    'meta_capi_calls': 0,
    'meta_capi_errors': 0,
    'leads': 0,
    'errors': 0,
    'total_requests': 0
}

def increment_stat(stat_name: str, amount: int = 1):
    """Thread-safe stat increment"""
    with STATS_LOCK:
        if stat_name in GLOBAL_STATS:
            GLOBAL_STATS[stat_name] += amount
        else:
            GLOBAL_STATS[stat_name] = amount

def get_stats() -> dict:
    """Get current stats"""
    with STATS_LOCK:
        return GLOBAL_STATS.copy()

# =========== UPGRADE FEATURE FLAGS ===========
class UpgradeFlags:
    """Control all 10 upgrades with environment variables"""
    
    @staticmethod
    def get_all_flags():
        return {
            # CORE UPGRADES (Essential fixes)
            "UPGRADE_1_MANDATORY_FILTER": os.environ.get("UPGRADE_1_MANDATORY_FILTER", "true").lower() == "true",
            "UPGRADE_2_DEDUPLICATION": os.environ.get("UPGRADE_2_DEDUPLICATION", "true").lower() == "true",
            "UPGRADE_3_ENHANCED_FIELDS": os.environ.get("UPGRADE_3_ENHANCED_FIELDS", "true").lower() == "true",
            "UPGRADE_4_QUESTION_PIPELINE": os.environ.get("UPGRADE_4_QUESTION_PIPELINE", "true").lower() == "true",
            
            # ADVANCED UPGRADES
            "UPGRADE_5_QUERY_SPLITTER": os.environ.get("UPGRADE_5_QUERY_SPLITTER", "true").lower() == "true",
            "UPGRADE_6_FUZZY_MATCHING": os.environ.get("UPGRADE_6_FUZZY_MATCHING", "true").lower() == "true",
            "UPGRADE_7_STATE_MACHINE": os.environ.get("UPGRADE_7_STATE_MACHINE", "true").lower() == "true",
            "UPGRADE_8_SEMANTIC_ANALYSIS": os.environ.get("UPGRADE_8_SEMANTIC_ANALYSIS", "true").lower() == "true",
            "UPGRADE_9_AUTO_VALIDATION": os.environ.get("UPGRADE_9_AUTO_VALIDATION", "true").lower() == "true",
            "UPGRADE_10_TEMPLATE_SYSTEM": os.environ.get("UPGRADE_10_TEMPLATE_SYSTEM", "true").lower() == "true",
            
            # PERFORMANCE OPTIONS
            "ENABLE_CACHING": os.environ.get("ENABLE_CACHING", "true").lower() == "true",
            "CACHE_TTL_SECONDS": int(os.environ.get("CACHE_TTL_SECONDS", "300")),
            "ENABLE_QUERY_LOGGING": os.environ.get("ENABLE_QUERY_LOGGING", "true").lower() == "true",
            
            # MEMORY OPTIMIZATION
            "EMBEDDING_CACHE_SIZE": 100 if IS_LOW_RAM else 1000,
            "TOUR_CACHE_ENABLED": not IS_LOW_RAM,
            "PRELOAD_EMBEDDINGS": not IS_LOW_RAM,
        }
    
    @staticmethod
    def is_enabled(upgrade_name: str) -> bool:
        flags = UpgradeFlags.get_all_flags()
        return flags.get(f"UPGRADE_{upgrade_name}", False)

# =========== FLASK APP CONFIG ===========
app = Flask(__name__)
app.json_encoder = EnhancedJSONEncoder  # Use custom JSON encoder
CORS(app, origins=CORS_ORIGINS, supports_credentials=True)

# =========== GLOBAL STATE (USING DATACLASSES) ===========
# Initialize OpenAI client
# ==== OpenAI client (SDK 1.x safe, Render compatible) ====
from openai import OpenAI
import httpx
import os

def create_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY is not set")

    # Render-safe HTTP client (no proxies param in OpenAI 1.x)
    http_client = httpx.Client(
        timeout=60.0,
        follow_redirects=True
    )

    return OpenAI(
        api_key=api_key,
        http_client=http_client
    )

# Create global OpenAI client
client = create_openai_client()


# Knowledge base state
KNOW: Dict = {}                      # Raw knowledge.json data
FLAT_TEXTS: List[str] = []           # All text passages for indexing
MAPPING: List[Dict] = []             # Mapping from text to original path
INDEX = None                         # FAISS or numpy index
INDEX_LOCK = threading.Lock()        # Thread safety for index operations

# Tour databases (USING Tour DATACLASS)
TOUR_NAME_TO_INDEX: Dict[str, int] = {}      # Normalized tour name â†’ index
TOURS_DB: Dict[int, Tour] = {}               # Structured tour database using Tour objects
TOUR_TAGS: Dict[int, List[str]] = {}         # Auto-generated tags for filtering

# Session management (USING ConversationContext DATACLASS)
SESSION_CONTEXTS: Dict[str, ConversationContext] = {}
SESSION_LOCK = threading.Lock()
SESSION_TIMEOUT = 1800  # 30 minutes

# Cache system
_response_cache: Dict[str, CacheEntry] = {}
_cache_lock = threading.Lock()

# Embedding cache (memory optimized)
_embedding_cache: Dict[str, Tuple[List[float], int]] = {}
_embedding_cache_lock = threading.Lock()
MAX_EMBEDDING_CACHE_SIZE = UpgradeFlags.get_all_flags()["EMBEDDING_CACHE_SIZE"]

# =========== MEMORY OPTIMIZATION FUNCTIONS ===========
def optimize_for_memory_profile():
    """Apply memory optimizations based on RAM profile"""
    flags = UpgradeFlags.get_all_flags()
    
    if IS_LOW_RAM:
        logger.info("ðŸ§  Low RAM mode (512MB) - optimizing memory usage")
        # Disable heavy preloading
        global FAISS_ENABLED
        FAISS_ENABLED = False
        
        # Reduce cache sizes
        import functools
        functools.lru_cache(maxsize=128)(embed_text)
        
        # Limit tour loading
        global MAX_TOURS_TO_LOAD
        MAX_TOURS_TO_LOAD = 50
        
    elif IS_HIGH_RAM:
        logger.info("ðŸš€ High RAM mode (2GB) - enabling all features")
        # Enable all features
        FAISS_ENABLED = HAS_FAISS
        MAX_TOURS_TO_LOAD = 1000
        
        # Increase cache sizes
        import functools
        functools.lru_cache(maxsize=flags["EMBEDDING_CACHE_SIZE"])(embed_text)

# =========== UPGRADE 1: MANDATORY FILTER SYSTEM (DATACLASS COMPATIBLE) ===========
class MandatoryFilterSystem:
    """
    UPGRADE 1: Extract and apply mandatory filters BEFORE semantic search
    """
    
    FILTER_PATTERNS = {
        'duration': [
            (r'(?:thá»i gian|máº¥y ngÃ y|bao lÃ¢u|kÃ©o dÃ i)\s*(?:lÃ \s*)?(\d+)\s*(?:ngÃ y|Ä‘Ãªm)', 'exact_duration'),
            (r'(\d+)\s*ngÃ y\s*(?:vÃ \s*)?(\d+)?\s*Ä‘Ãªm', 'days_nights'),
            (r'(\d+)\s*ngÃ y\s*(?:trá»Ÿ lÃªn|trá»Ÿ xuá»‘ng)', 'duration_range'),
            (r'(?:tour|hÃ nh trÃ¬nh)\s*(?:khoáº£ng|táº§m|khoáº£ng)?\s*(\d+)\s*ngÃ y', 'approx_duration'),
        ],
        
        'price': [
            (r'dÆ°á»›i\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'max_price'),
            (r'trÃªn\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'min_price'),
            (r'khoáº£ng\s*(\d[\d,\.]*)\s*(?:Ä‘áº¿n|-)\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'price_range'),
            (r'giÃ¡\s*(?:tá»«\s*)?(\d[\d,\.]*)\s*(?:Ä‘áº¿n|-|tá»›i)\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'price_range'),
            (r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)\s*trá»Ÿ xuá»‘ng', 'max_price'),
            (r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)\s*trá»Ÿ lÃªn', 'min_price'),
        ],
        
        'location': [
            (r'(?:á»Ÿ|táº¡i|vá»|Ä‘áº¿n|thÄƒm)\s+([^.,!?\n]+?)(?:\s|$|\.|,|!|\?)', 'location'),
            (r'(?:Ä‘iá»ƒm Ä‘áº¿n|Ä‘á»‹a Ä‘iá»ƒm|nÆ¡i|vÃ¹ng)\s+(?:lÃ \s*)?([^.,!?\n]+)', 'location'),
            (r'(?:quanh|gáº§n|khu vá»±c)\s+([^.,!?\n]+)', 'near_location'),
        ],
        
        'date_time': [
            (r'(?:thÃ¡ng|vÃ o)\s*(\d{1,2})', 'month'),
            (r'(?:cuá»‘i tuáº§n|weekend)', 'weekend'),
            (r'(?:dá»‹p|lá»…|táº¿t)\s+([^.,!?\n]+)', 'holiday'),
        ],
        
        'group_type': [
            (r'(?:gia Ä‘Ã¬nh|family)', 'family'),
            (r'(?:cáº·p Ä‘Ã´i|couple|Ä‘Ã´i lá»©a)', 'couple'),
            (r'(?:nhÃ³m báº¡n|báº¡n bÃ¨|friends)', 'friends'),
            (r'(?:cÃ´ng ty|doanh nghiá»‡p|team building)', 'corporate'),
            (r'(?:má»™t mÃ¬nh|Ä‘i láº»|solo)', 'solo'),
        ],
    }
    
    @staticmethod
    def extract_filters(message: str) -> FilterSet:
        """
        Extract ALL mandatory filters from user message
        """
        filters = FilterSet()
        
        if not message:
            return filters
        
        message_lower = message.lower()
        
        # 1. DURATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['duration']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'exact_duration':
                    try:
                        days = int(match.group(1))
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'days_nights':
                    try:
                        days = int(match.group(1))
                        nights = int(match.group(2)) if match.group(2) else days
                        # Store in appropriate fields
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass
        
        # 2. PRICE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['price']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                try:
                    if filter_type == 'max_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_max = amount
                            logger.info(f"ðŸ’° Extracted MAX price filter: {amount} VND")
                    
                    elif filter_type == 'min_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_min = amount
                            logger.info(f"ðŸ’° Extracted MIN price filter: {amount} VND")
                    
                    elif filter_type == 'price_range':
                        min_amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(3))
                        max_amount = MandatoryFilterSystem._parse_price(match.group(2), match.group(3))
                        if min_amount and max_amount:
                            filters.price_min = min_amount
                            filters.price_max = max_amount
                            logger.info(f"ðŸ’° Extracted PRICE RANGE: {min_amount} - {max_amount} VND")
                
                except (ValueError, IndexError, AttributeError):
                    continue
        
        # 3. LOCATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['location']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                location = match.group(1).strip()
                if location and len(location) > 1:
                    if filter_type == 'location':
                        filters.location = location
                    elif filter_type == 'near_location':
                        filters.near_location = location
        
        # 4. DATE/TIME FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['date_time']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'month':
                    try:
                        filters.month = int(match.group(1))
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'weekend':
                    filters.weekend = True
                elif filter_type == 'holiday':
                    filters.holiday = match.group(1).strip()
        
        # 5. GROUP TYPE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['group_type']:
            if re.search(pattern, message_lower):
                filters.group_type = filter_type
        
        # 6. SPECIAL KEYWORDS
        special_keywords = {
            'ráº»': ('price_max', 1500000),
            'giÃ¡ ráº»': ('price_max', 1500000),
            'tiáº¿t kiá»‡m': ('price_max', 1500000),
            'cao cáº¥p': ('price_min', 3000000),
            'sang trá»ng': ('price_min', 3000000),
            'premium': ('price_min', 3000000),
            'ngáº¯n ngÃ y': ('duration_max', 2),
            'dÃ i ngÃ y': ('duration_min', 3),
        }
        
        for keyword, (filter_key, value) in special_keywords.items():
            if keyword in message_lower:
                if filter_key == 'price_max':
                    filters.price_max = value
                elif filter_key == 'price_min':
                    filters.price_min = value
                elif filter_key == 'duration_max':
                    filters.duration_max = value
                elif filter_key == 'duration_min':
                    filters.duration_min = value
        
        logger.info(f"ðŸŽ¯ Extracted filters: {filters}")
        return filters
    
    @staticmethod
    def _parse_price(amount_str: str, unit: str) -> Optional[int]:
        """Parse price string like '1.5 triá»‡u' to integer VND"""
        if not amount_str:
            return None
        
        try:
            amount_str = amount_str.replace(',', '').replace('.', '')
            if not amount_str.isdigit():
                return None
            
            amount = int(amount_str)
            
            if unit in ['triá»‡u', 'tr']:
                return amount * 1000000
            elif unit == 'k':
                return amount * 1000
            elif unit == 'nghÃ¬n':
                return amount * 1000
            else:
                return amount if amount > 1000 else amount * 1000
        
        except (ValueError, AttributeError):
            return None
    
    @staticmethod
    def apply_filters(tours_db: Dict[int, Tour], filters: FilterSet) -> List[int]:
        """
        Apply mandatory filters to tour database
        Returns list of tour indices that pass ALL filters
        """
        if filters.is_empty() or not tours_db:
            return list(tours_db.keys())
        
        passing_tours = []
        
        try:
            for tour_idx, tour in tours_db.items():
                passes_all = True
                
                # PRICE FILTERING
                if passes_all and (filters.price_max is not None or filters.price_min is not None):
                    tour_price_text = tour.price or ""
                    if not tour_price_text:
                        if filters.price_max is not None or filters.price_min is not None:
                            passes_all = False
                    else:
                        tour_prices = MandatoryFilterSystem._extract_tour_prices(tour_price_text)
                        if not tour_prices:
                            passes_all = False
                        else:
                            min_tour_price = min(tour_prices)
                            max_tour_price = max(tour_prices)
                            
                            if filters.price_max is not None and min_tour_price > filters.price_max:
                                passes_all = False
                            if filters.price_min is not None and max_tour_price < filters.price_min:
                                passes_all = False
                
                # DURATION FILTERING
                if passes_all and (filters.duration_min is not None or filters.duration_max is not None):
                    duration_text = (tour.duration or "").lower()
                    tour_duration = MandatoryFilterSystem._extract_duration_days(duration_text)
                    
                    if tour_duration is not None:
                        if filters.duration_min is not None and tour_duration < filters.duration_min:
                            passes_all = False
                        if filters.duration_max is not None and tour_duration > filters.duration_max:
                            passes_all = False
                    else:
                        if filters.duration_min is not None or filters.duration_max is not None:
                            passes_all = False
                
                # LOCATION FILTERING
                if passes_all and (filters.location is not None or filters.near_location is not None):
                    tour_location = (tour.location or "").lower()
                    if filters.location is not None:
                        filter_location = filters.location.lower()
                        if filter_location not in tour_location:
                            passes_all = False
                    if filters.near_location is not None:
                        near_location = filters.near_location.lower()
                        if near_location not in tour_location:
                            passes_all = False
                
                if passes_all:
                    passing_tours.append(tour_idx)
            
            logger.info(f"ðŸ” After mandatory filtering: {len(passing_tours)}/{len(tours_db)} tours pass")
        except Exception as e:
            logger.error(f"âŒ Error in apply_filters: {e}")
            passing_tours = list(tours_db.keys())
        
        return passing_tours
    
    @staticmethod
    def _extract_tour_prices(price_text: str) -> List[int]:
        """Extract price numbers from tour price text"""
        prices = []
        
        number_patterns = [
            r'(\d[\d,\.]+)\s*(?:triá»‡u|tr)',
            r'(\d[\d,\.]+)\s*(?:k|nghÃ¬n)',
            r'(\d[\d,\.]+)\s*(?:Ä‘á»“ng|vnÄ‘|vnd)',
            r'(\d[\d,\.]+)\s*-\s*(\d[\d,\.]+)',
        ]
        
        for pattern in number_patterns:
            matches = re.finditer(pattern, price_text, re.IGNORECASE)
            for match in matches:
                try:
                    for i in range(1, 3):
                        if match.group(i):
                            num_str = match.group(i).replace(',', '').replace('.', '')
                            if num_str.isdigit():
                                num = int(num_str)
                                
                                if 'triá»‡u' in match.group(0).lower() or 'tr' in match.group(0).lower():
                                    num = num * 1000000
                                elif 'k' in match.group(0).lower() or 'nghÃ¬n' in match.group(0).lower():
                                    num = num * 1000
                                
                                prices.append(num)
                except (ValueError, AttributeError):
                    continue
        
        if not prices:
            raw_numbers = re.findall(r'\d[\d,\.]+', price_text)
            for num_str in raw_numbers[:2]:
                try:
                    num_str = num_str.replace(',', '').replace('.', '')
                    if num_str.isdigit():
                        num = int(num_str)
                        if 100 <= num <= 10000:
                            num = num * 1000
                        prices.append(num)
                except ValueError:
                    continue
        
        return prices
    
    @staticmethod
    def _extract_duration_days(duration_text: str) -> Optional[int]:
        """Extract duration in days from text"""
        if not duration_text:
            return None
        
        patterns = [
            r'(\d+)\s*ngÃ y',
            r'(\d+)\s*ngÃ y\s*\d*\s*Ä‘Ãªm',
            r'(\d+)\s*Ä‘Ãªm',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, duration_text)
            if match:
                try:
                    return int(match.group(1))
                except (ValueError, IndexError):
                    continue
        
        return None

# =========== UPGRADE 2: DEDUPLICATION ENGINE (DATACLASS COMPATIBLE) ===========
class DeduplicationEngine:
    """
    UPGRADE 2: Remove duplicate and highly similar results
    """
    
    SIMILARITY_THRESHOLD = 0.85
    MIN_TEXT_LENGTH = 20
    
    @staticmethod
    def calculate_similarity(text1: str, text2: str) -> float:
        """Calculate text similarity using multiple methods"""
        if not text1 or not text2:
            return 0.0
        
        text1_norm = DeduplicationEngine._normalize_text(text1)
        text2_norm = DeduplicationEngine._normalize_text(text2)
        
        if len(text1_norm) < DeduplicationEngine.MIN_TEXT_LENGTH or len(text2_norm) < DeduplicationEngine.MIN_TEXT_LENGTH:
            return 0.0
        
        seq_ratio = SequenceMatcher(None, text1_norm, text2_norm).ratio()
        
        words1 = set(text1_norm.split())
        words2 = set(text2_norm.split())
        
        if not words1 or not words2:
            jaccard = 0.0
        else:
            intersection = words1.intersection(words2)
            union = words1.union(words2)
            jaccard = len(intersection) / len(union)
        
        prefix_len = min(50, min(len(text1_norm), len(text2_norm)))
        prefix1 = text1_norm[:prefix_len]
        prefix2 = text2_norm[:prefix_len]
        prefix_sim = SequenceMatcher(None, prefix1, prefix2).ratio()
        
        similarity = (seq_ratio * 0.5) + (jaccard * 0.3) + (prefix_sim * 0.2)
        
        return similarity
    
    @staticmethod
    def _normalize_text(text: str) -> str:
        """Normalize text for comparison"""
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        stopwords = {'vÃ ', 'cá»§a', 'cho', 'vá»›i', 'táº¡i', 'á»Ÿ', 'nÃ y', 'Ä‘Ã³', 'kia', 'vá»', 'trong'}
        words = [word for word in text.split() if word not in stopwords]
        
        return ' '.join(words)
    
    @staticmethod
    def deduplicate_passages(passages: List[Tuple[float, Dict]], 
                            similarity_threshold: float = None) -> List[Tuple[float, Dict]]:
        """
        Remove duplicate passages from results
        """
        if len(passages) <= 1:
            return passages
        
        threshold = similarity_threshold or DeduplicationEngine.SIMILARITY_THRESHOLD
        unique_passages = []
        seen_passages = []
        
        sorted_passages = sorted(passages, key=lambda x: x[0], reverse=True)
        
        for score, passage in sorted_passages:
            text = passage.get('text', '').strip()
            path = passage.get('path', '')
            
            if not text or len(text) < DeduplicationEngine.MIN_TEXT_LENGTH:
                unique_passages.append((score, passage))
                continue
            
            is_duplicate = False
            for seen_text, seen_path in seen_passages:
                tour_match1 = re.search(r'tours\[(\d+)\]', path)
                tour_match2 = re.search(r'tours\[(\d+)\]', seen_path)
                
                if tour_match1 and tour_match2:
                    if tour_match1.group(1) == tour_match2.group(1):
                        field1 = path.split('.')[-1] if '.' in path else ''
                        field2 = seen_path.split('.')[-1] if '.' in seen_path else ''
                        if field1 == field2:
                            is_duplicate = True
                            break
                
                similarity = DeduplicationEngine.calculate_similarity(text, seen_text)
                if similarity > threshold:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_passages.append((score, passage))
                seen_passages.append((text, path))
        
        logger.info(f"ðŸ”„ Deduplication: {len(passages)} â†’ {len(unique_passages)} passages")
        return unique_passages
    
    @staticmethod
    def merge_similar_tours(tour_indices: List[int], tours_db: Dict[int, Tour]) -> List[int]:
        """Merge tours that are essentially the same"""
        if len(tour_indices) <= 1:
            return tour_indices
        
        tour_groups = []
        processed = set()
        
        for i, idx1 in enumerate(tour_indices):
            if idx1 in processed:
                continue
            
            group = [idx1]
            tour1 = tours_db.get(idx1)
            name1 = (tour1.name if tour1 else "").strip()
            
            if not name1:
                processed.add(idx1)
                tour_groups.append(group)
                continue
            
            for j, idx2 in enumerate(tour_indices[i+1:], i+1):
                if idx2 in processed:
                    continue
                
                tour2 = tours_db.get(idx2)
                name2 = (tour2.name if tour2 else "").strip()
                
                if not name2:
                    continue
                
                similarity = DeduplicationEngine.calculate_similarity(name1, name2)
                if similarity > 0.9:
                    group.append(idx2)
                    processed.add(idx2)
            
            processed.add(idx1)
            tour_groups.append(group)
        
        best_tours = []
        for group in tour_groups:
            if not group:
                continue
            
            if len(group) == 1:
                best_tours.append(group[0])
                continue
            
            best_score = -1
            best_idx = group[0]
            
            for idx in group:
                tour = tours_db.get(idx)
                if not tour:
                    continue
                
                score = 0
                
                if tour.name:
                    score += 2
                if tour.duration:
                    score += 2
                if tour.location:
                    score += 2
                if tour.price:
                    score += 3
                if tour.includes:
                    score += 2
                if tour.summary:
                    score += 1
                
                for field in [tour.includes, tour.summary, tour.notes]:
                    if isinstance(field, str) and len(field) > 50:
                        score += 1
                    elif isinstance(field, list) and field:
                        score += len(field)
                
                if score > best_score:
                    best_score = score
                    best_idx = idx
            
            best_tours.append(best_idx)
        
        logger.info(f"ðŸ”„ Tour merging: {len(tour_indices)} â†’ {len(best_tours)} unique tours")
        return best_tours

# =========== UPGRADE 3: ENHANCED FIELD DETECTION (DATACLASS COMPATIBLE) ===========
class EnhancedFieldDetector:
    """
    UPGRADE 3: Better detection of what user is asking for
    """
    
    FIELD_DETECTION_RULES = [
        # TOUR LIST
        {
            "field": "tour_name",
            "patterns": [
                (r'liá»‡t kÃª.*tour|danh sÃ¡ch.*tour|cÃ¡c tour|cÃ³ nhá»¯ng tour nÃ o', 1.0),
                (r'tour nÃ o.*cÃ³|tour nÃ o.*hiá»‡n|tour nÃ o.*Ä‘ang', 0.9),
                (r'ká»ƒ tÃªn.*tour|nÃªu tÃªn.*tour|tÃªn cÃ¡c tour', 0.9),
                (r'cÃ³ máº¥y.*tour|bao nhiÃªu.*tour|sá»‘ lÆ°á»£ng.*tour', 0.8),
                (r'list tour|show tour|all tour|every tour', 0.8),
            ],
            "keywords": [
                ("liá»‡t kÃª", 0.9), ("danh sÃ¡ch", 0.9), ("cÃ¡c", 0.7),
                ("táº¥t cáº£", 0.8), ("má»i", 0.7), ("máº¥y", 0.6),
                ("bao nhiÃªu", 0.7), ("sá»‘ lÆ°á»£ng", 0.7),
            ]
        },
        
        # PRICE
        {
            "field": "price",
            "patterns": [
                (r'giÃ¡.*bao nhiÃªu|bao nhiÃªu tiá»n|chi phÃ­.*bao nhiÃªu', 1.0),
                (r'giÃ¡ tour|giÃ¡ cáº£|giÃ¡ thÃ nh|chi phÃ­ tour', 0.9),
                (r'tour.*giÃ¡.*bao nhiÃªu|tour.*bao nhiÃªu tiá»n', 0.95),
                (r'pháº£i tráº£.*bao nhiÃªu|tá»‘n.*bao nhiÃªu|máº¥t.*bao nhiÃªu', 0.8),
                (r'Ä‘Ã³ng.*bao nhiÃªu|thanh toÃ¡n.*bao nhiÃªu', 0.8),
            ],
            "keywords": [
                ("giÃ¡", 0.8), ("tiá»n", 0.7), ("chi phÃ­", 0.8),
                ("Ä‘Ã³ng", 0.6), ("tráº£", 0.6), ("tá»‘n", 0.6),
                ("phÃ­", 0.7), ("kinh phÃ­", 0.7), ("tá»•ng chi", 0.7),
            ]
        },
        
        # DURATION
        {
            "field": "duration",
            "patterns": [
                (r'thá»i gian.*bao lÃ¢u|máº¥y ngÃ y.*Ä‘i|bao lÃ¢u.*tour', 1.0),
                (r'tour.*bao nhiÃªu ngÃ y|máº¥y ngÃ y.*tour', 0.9),
                (r'Ä‘i trong.*bao lÃ¢u|kÃ©o dÃ i.*bao lÃ¢u', 0.9),
                (r'thá»i lÆ°á»£ng.*bao nhiÃªu|thá»i gian.*dÃ i bao lÃ¢u', 0.8),
            ],
            "keywords": [
                ("bao lÃ¢u", 0.9), ("máº¥y ngÃ y", 0.9), ("thá»i gian", 0.8),
                ("kÃ©o dÃ i", 0.7), ("thá»i lÆ°á»£ng", 0.8), ("ngÃ y", 0.6),
                ("Ä‘Ãªm", 0.6), ("thá»i háº¡n", 0.7),
            ]
        },
        
        # LOCATION
        {
            "field": "location",
            "patterns": [
                (r'á»Ÿ Ä‘Ã¢u|Ä‘i Ä‘Ã¢u|Ä‘áº¿n Ä‘Ã¢u|tá»›i Ä‘Ã¢u|thÄƒm quan Ä‘Ã¢u', 1.0),
                (r'Ä‘á»‹a Ä‘iá»ƒm.*nÃ o|nÆ¡i nÃ o|vÃ¹ng nÃ o|khu vá»±c nÃ o', 0.9),
                (r'tour.*á»Ÿ.*Ä‘Ã¢u|hÃ nh trÃ¬nh.*Ä‘i.*Ä‘Ã¢u', 0.9),
                (r'khÃ¡m phÃ¡.*Ä‘Ã¢u|thÄƒm.*Ä‘Ã¢u|ghÃ©.*Ä‘Ã¢u', 0.8),
            ],
            "keywords": [
                ("á»Ÿ Ä‘Ã¢u", 1.0), ("Ä‘i Ä‘Ã¢u", 1.0), ("Ä‘áº¿n Ä‘Ã¢u", 0.9),
                ("tá»›i Ä‘Ã¢u", 0.9), ("Ä‘á»‹a Ä‘iá»ƒm", 0.8), ("nÆ¡i", 0.7),
                ("vÃ¹ng", 0.7), ("khu vá»±c", 0.7),
            ]
        },
        
        # SUMMARY
        {
            "field": "summary",
            "patterns": [
                (r'cÃ³ gÃ¬ hay|cÃ³ gÃ¬ Ä‘áº·c biá»‡t|cÃ³ gÃ¬ thÃº vá»‹', 0.9),
                (r'tour nÃ y tháº¿ nÃ o|hÃ nh trÃ¬nh ra sao|chuyáº¿n Ä‘i nhÆ° nÃ o', 0.8),
                (r'giá»›i thiá»‡u.*tour|mÃ´ táº£.*tour|nÃ³i vá».*tour', 0.8),
                (r'tour.*cÃ³ gÃ¬|Ä‘i.*Ä‘Æ°á»£c gÃ¬|tráº£i nghiá»‡m.*gÃ¬', 0.7),
                (r'Ä‘iá»ƒm nháº¥n.*tour|ná»•i báº­t.*gÃ¬|Ä‘áº·c sáº¯c.*gÃ¬', 0.7),
            ],
            "keywords": [
                ("cÃ³ gÃ¬", 0.7), ("tháº¿ nÃ o", 0.6), ("ra sao", 0.6),
                ("giá»›i thiá»‡u", 0.7), ("mÃ´ táº£", 0.7), ("nÃ³i vá»", 0.6),
                ("Ä‘iá»ƒm nháº¥n", 0.7), ("ná»•i báº­t", 0.7), ("Ä‘áº·c sáº¯c", 0.7),
            ]
        },
        
        # INCLUDES
        {
            "field": "includes",
            "patterns": [
                (r'lá»‹ch trÃ¬nh.*chi tiáº¿t|chÆ°Æ¡ng trÃ¬nh.*chi tiáº¿t', 0.9),
                (r'lÃ m gÃ¬.*tour|hoáº¡t Ä‘á»™ng.*gÃ¬|sinh hoáº¡t.*gÃ¬', 0.8),
                (r'tour.*gá»“m.*gÃ¬|bao gá»“m.*gÃ¬|gá»“m nhá»¯ng gÃ¬', 0.8),
                (r'Ä‘i Ä‘Ã¢u.*lÃ m gÃ¬|thÄƒm quan.*gÃ¬|khÃ¡m phÃ¡.*gÃ¬', 0.7),
            ],
            "keywords": [
                ("lá»‹ch trÃ¬nh", 0.8), ("chÆ°Æ¡ng trÃ¬nh", 0.8), ("lÃ m gÃ¬", 0.7),
                ("hoáº¡t Ä‘á»™ng", 0.7), ("sinh hoáº¡t", 0.6), ("gá»“m", 0.6),
                ("bao gá»“m", 0.7), ("gá»“m nhá»¯ng", 0.7),
            ]
        },
    ]
    
    @staticmethod
    def detect_field_with_confidence(message: str) -> Tuple[Optional[str], float, Dict[str, float]]:
        """
        Detect which field user is asking about with confidence scores
        """
        if not message:
            return None, 0.0, {}
        
        message_lower = message.lower()
        scores = {}
        
        for rule in EnhancedFieldDetector.FIELD_DETECTION_RULES:
            field = rule["field"]
            field_score = 0.0
            
            for pattern, weight in rule["patterns"]:
                if re.search(pattern, message_lower):
                    field_score = max(field_score, weight)
            
            for keyword, weight in rule["keywords"]:
                if keyword in message_lower:
                    position = message_lower.find(keyword)
                    position_factor = 1.0 - (position / max(len(message_lower), 1))
                    adjusted_weight = weight * (0.7 + 0.3 * position_factor)
                    field_score = max(field_score, adjusted_weight)
            
            if field_score > 0:
                field_score = min(field_score * 1.1, 1.0)
            
            scores[field] = field_score
        
        best_field = None
        best_score = 0.0
        
        for field, score in scores.items():
            if score > best_score:
                best_score = score
                best_field = field
        
        if (best_score < 0.3 and 
            ("cÃ³ gÃ¬" in message_lower or "tháº¿ nÃ o" in message_lower) and
            "tour" in message_lower):
            best_field = "summary"
            best_score = 0.6
        
        logger.info(f"ðŸ” Field detection: '{message}' â†’ {best_field} (confidence: {best_score:.2f})")
        return best_field, best_score, scores

# =========== UPGRADE 4: QUESTION PIPELINE (DATACLASS COMPATIBLE) ===========
class QuestionPipeline:
    """
    UPGRADE 4: Process different types of questions differently
    """
    
    @staticmethod
    def classify_question(message: str) -> Tuple[QuestionType, float, Dict]:
        """
        Classify question type with confidence and metadata
        """
        message_lower = message.lower()
        type_scores = defaultdict(float)
        metadata = {}
        
        # LISTING detection - CHá»ˆ khi yÃªu cáº§u rÃµ rÃ ng liá»‡t kÃª DANH SÃCH
        listing_patterns = [
            (r'liá»‡t kÃª.*táº¥t cáº£.*tour|danh sÃ¡ch.*táº¥t cáº£.*tour|táº¥t cáº£.*tour', 0.95),
            (r'liá»‡t kÃª.*tour|danh sÃ¡ch.*tour|list.*tour', 0.9),
            (r'ká»ƒ tÃªn.*tour|nÃªu tÃªn.*tour', 0.9),
            (r'cÃ³ nhá»¯ng.*tour nÃ o|cÃ³ máº¥y.*tour|máº¥y.*tour', 0.7),
            (r'bÃªn báº¡n.*cÃ³.*tour|hiá»‡n cÃ³.*tour', 0.75),
        ]
        
        for pattern, weight in listing_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.LISTING] = max(
                    type_scores[QuestionType.LISTING], weight
                )
        
        # COMPARISON detection
        comparison_patterns = [
            (r'so sÃ¡nh.*vÃ |Ä‘á»‘i chiáº¿u.*vÃ ', 0.95),
            (r'khÃ¡c nhau.*nÃ o|giá»‘ng nhau.*nÃ o', 0.9),
            (r'nÃªn chá»n.*nÃ o|tá»‘t hÆ¡n.*nÃ o|hÆ¡n kÃ©m.*nÃ o', 0.85),
            (r'tour.*vÃ .*tour', 0.8),
            (r'sÃ¡nh.*vá»›i|Ä‘á»‘i chiáº¿u.*vá»›i', 0.8),
        ]
        
        for pattern, weight in comparison_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.COMPARISON] = max(
                    type_scores[QuestionType.COMPARISON], weight
                )
                metadata['comparison_type'] = 'direct'
        
        # RECOMMENDATION detection
        recommendation_patterns = [
            (r'phÃ¹ há»£p.*vá»›i|nÃªn Ä‘i.*nÃ o|gá»£i Ã½.*tour', 0.95),
            (r'tour nÃ o.*phÃ¹ há»£p|phÃ¹ há»£p.*tour nÃ o', 0.95),
            (r'tour.*tá»‘t.*nháº¥t|hÃ nh trÃ¬nh.*hay nháº¥t|tour.*lÃ½ tÆ°á»Ÿng', 0.9),
            (r'Ä‘á» xuáº¥t.*tour|tÆ° váº¥n.*tour|chá»n.*tour nÃ o', 0.9),
            (r'tour nÃ o.*cho.*gia Ä‘Ã¬nh|tour.*gia Ä‘Ã¬nh|gia Ä‘Ã¬nh.*tour', 0.9),
            (r'tour nÃ o.*cho|dÃ nh cho.*tour|tour.*dÃ nh cho', 0.85),
            (r'nÃªn.*tour nÃ o|nÃªn chá»n.*tour|tour.*nÃªn', 0.85),
            (r'tour.*nháº¹ nhÃ ng|tour.*dá»…|tour.*phÃ¹ há»£p.*ngÆ°á»i', 0.85),
            (r'tour.*tráº» em|tour.*con nÃ­t|tour.*bÃ©', 0.85),
            (r'tour.*ngÆ°á»i lá»›n tuá»•i|tour.*cao tuá»•i|tour.*nghá»‰ dÆ°á»¡ng', 0.85),
            (r'chi phÃ­.*vá»«a pháº£i|giÃ¡.*phÃ¹ há»£p|giÃ¡.*há»£p lÃ½', 0.8),
            (r'cho.*tÃ´i|dÃ nh cho.*tÃ´i|há»£p vá»›i.*tÃ´i', 0.75),
            (r'náº¿u.*thÃ¬.*nÃªn.*tour|nÃªn chá»n.*tour', 0.8),
        ]
        
        for pattern, weight in recommendation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.RECOMMENDATION] = max(
                    type_scores[QuestionType.RECOMMENDATION], weight
                )
        
        # GREETING detection
        greeting_words = ['xin chÃ o', 'chÃ o', 'hello', 'hi', 'helo', 'chao']
        greeting_score = 0.0
        for word in greeting_words:
            if word in message_lower:
                if message_lower.startswith(word) or f" {word} " in message_lower or message_lower.endswith(f" {word}"):
                    greeting_score += 0.3
        
        other_intent_score = max([score for qtype, score in type_scores.items() 
                                 if qtype != QuestionType.GREETING], default=0.0)
        
        if greeting_score > 0.8 and other_intent_score < 0.3:
            type_scores[QuestionType.GREETING] = min(greeting_score, 1.0)
        
        # FAREWELL detection
        farewell_words = ['táº¡m biá»‡t', 'cáº£m Æ¡n', 'thanks', 'thank you', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            type_scores[QuestionType.FAREWELL] = 0.95
        
        # CALCULATION detection
        calculation_patterns = [
            (r'tÃ­nh toÃ¡n|tÃ­nh.*bao nhiÃªu|tá»•ng.*bao nhiÃªu', 0.9),
            (r'cá»™ng.*láº¡i|nhÃ¢n.*lÃªn|chia.*ra', 0.8),
            (r'bao nhiÃªu.*ngÆ°á»i|máº¥y.*ngÆ°á»i|sá»‘ lÆ°á»£ng.*ngÆ°á»i', 0.7),
        ]
        
        for pattern, weight in calculation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.CALCULATION] = max(
                    type_scores[QuestionType.CALCULATION], weight
                )
        
        # COMPLEX question detection
        complex_indicators = [
            ('vÃ ', 0.3), ('rá»“i', 0.4), ('sau Ä‘Ã³', 0.5),
            ('tiáº¿p theo', 0.5), ('ngoÃ i ra', 0.4), ('thÃªm ná»¯a', 0.4),
        ]
        
        complex_score = 0.0
        for indicator, weight in complex_indicators:
            if indicator in message_lower:
                complex_score += weight
        
        if complex_score > 0.8:
            type_scores[QuestionType.COMPLEX] = min(complex_score / 2, 1.0)
            metadata['complex_parts'] = QuestionPipeline._split_complex_question(message)
        
        # DEFAULT: INFORMATION request
        if not type_scores:
            type_scores[QuestionType.INFORMATION] = 0.6
        else:
            info_keywords = ['lÃ  gÃ¬', 'bao nhiÃªu', 'á»Ÿ Ä‘Ã¢u', 'khi nÃ o', 'tháº¿ nÃ o', 'ai', 'táº¡i sao']
            if any(keyword in message_lower for keyword in info_keywords):
                type_scores[QuestionType.INFORMATION] = max(
                    type_scores.get(QuestionType.INFORMATION, 0),
                    0.5
                )
        
        # Determine best type
        best_type = QuestionType.INFORMATION
        best_score = 0.0
        
        for qtype, score in type_scores.items():
            if score > best_score:
                best_score = score
                best_type = qtype
        
        if best_score < 0.5:
            best_type = QuestionType.INFORMATION
            best_score = 0.5
        
        logger.info(f"ðŸŽ¯ Question classification: '{message}' â†’ {best_type.value} (score: {best_score:.2f})")
        return best_type, best_score, metadata
    
    @staticmethod
    def _split_complex_question(message: str) -> List[str]:
        """Split complex multi-part question into simpler parts"""
        split_patterns = [
            r'\s+vÃ \s+',
            r'\s+rá»“i\s+',
            r'\s+sau Ä‘Ã³\s+',
            r'\s+tiáº¿p theo\s+',
            r'\s+ngoÃ i ra\s+',
            r'\s+thÃªm ná»¯a\s+',
            r'\s+Ä‘á»“ng thá»i\s+',
            r'\s+cuá»‘i cÃ¹ng\s+',
        ]
        
        parts = [message]
        
        for pattern in split_patterns:
            new_parts = []
            for part in parts:
                split_result = re.split(pattern, part, flags=re.IGNORECASE)
                new_parts.extend([p.strip() for p in split_result if p.strip()])
            parts = new_parts
        
        return parts
    
    @staticmethod
    def process_comparison_question(tour_indices: List[int], tours_db: Dict[int, Tour], 
                                  aspect: str = "", context: Dict = None) -> str:
        """
        Process comparison question between tours
        """
        if len(tour_indices) < 2:
            return "Cáº§n Ã­t nháº¥t 2 tour Ä‘á»ƒ so sÃ¡nh."
        
        tours_to_compare = []
        for idx in tour_indices[:3]:
            tour = tours_db.get(idx)
            if tour:
                tours_to_compare.append((idx, tour))
        
        if len(tours_to_compare) < 2:
            return "KhÃ´ng tÃ¬m tháº¥y Ä‘á»§ thÃ´ng tin tour Ä‘á»ƒ so sÃ¡nh."
        
        if not aspect:
            aspect = 'price'
        
        result_lines = []
        
        headers = ["TIÃŠU CHÃ"]
        for idx, tour in tours_to_compare:
            tour_name = tour.name or f'Tour #{idx}'
            headers.append(tour_name[:25])
        
        result_lines.append(" | ".join(headers))
        result_lines.append("-" * (len(headers) * 30))
        
        comparison_fields = [
            ('duration', 'â±ï¸ Thá»i gian'),
            ('location', 'ðŸ“ Äá»‹a Ä‘iá»ƒm'),
            ('price', 'ðŸ’° GiÃ¡ tour'),
            ('accommodation', 'ðŸ¨ Chá»— á»Ÿ'),
            ('meals', 'ðŸ½ï¸ Ä‚n uá»‘ng'),
            ('transport', 'ðŸš— Di chuyá»ƒn'),
            ('summary', 'ðŸ“ MÃ´ táº£'),
        ]
        
        for field, display_name in comparison_fields:
            if aspect and field != aspect and aspect not in ['all', 'táº¥t cáº£']:
                continue
            
            row = [display_name]
            all_values = []
            
            for idx, tour in tours_to_compare:
                value = getattr(tour, field, 'N/A')
                if isinstance(value, list):
                    value = ', '.join(value[:2])
                row.append(str(value)[:30])
                all_values.append(str(value).lower())
            
            if len(set(all_values)) > 1 or aspect == field:
                result_lines.append(" | ".join(row))
        
        result_lines.append("\n" + "="*50)
        result_lines.append("**ÄÃNH GIÃ & Gá»¢I Ã:**")
        
        durations = [tour.duration for _, tour in tours_to_compare]
        if any('1 ngÃ y' in d for d in durations) and any('2 ngÃ y' in d for d in durations):
            result_lines.append("â€¢ Náº¿u báº¡n cÃ³ Ã­t thá»i gian: Chá»n tour 1 ngÃ y")
            result_lines.append("â€¢ Náº¿u muá»‘n tráº£i nghiá»‡m sÃ¢u: Chá»n tour 2 ngÃ y")
        
        prices = []
        for _, tour in tours_to_compare:
            price_text = tour.price or ''
            price_nums = re.findall(r'\d[\d,\.]+', price_text)
            if price_nums:
                try:
                    price = int(price_nums[0].replace(',', '').replace('.', ''))
                    prices.append(price)
                except:
                    pass
        
        if len(prices) >= 2:
            min_price_idx = prices.index(min(prices))
            max_price_idx = prices.index(max(prices))
            
            if prices[max_price_idx] > prices[min_price_idx] * 1.5:
                result_lines.append(f"â€¢ Tiáº¿t kiá»‡m chi phÃ­: {headers[min_price_idx + 1]}")
                result_lines.append(f"â€¢ Tráº£i nghiá»‡m cao cáº¥p: {headers[max_price_idx + 1]}")
        
        result_lines.append("\nðŸ’¡ *LiÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t*")
        
        return "\n".join(result_lines)

# =========== UPGRADE 5: COMPLEX QUERY SPLITTER (DATACLASS COMPATIBLE) ===========
class ComplexQueryProcessor:
    """
    UPGRADE 5: Handle complex multi-condition queries
    """
    
    @staticmethod
    def split_query(query: str) -> List[Dict[str, Any]]:
        """
        Split complex query into sub-queries with priorities
        """
        sub_queries = []
        
        complexity_score = ComplexQueryProcessor._calculate_complexity(query)
        if complexity_score < 1.5:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': {},
                'focus': 'general'
            }]
        
        conditions = ComplexQueryProcessor._extract_conditions(query)
        
        if len(conditions) <= 1:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': conditions[0] if conditions else {},
                'focus': 'general'
            }]
        
        sub_queries.append({
            'query': query,
            'priority': 1.0,
            'filters': ComplexQueryProcessor._merge_conditions(conditions),
            'focus': 'specific'
        })
        
        location_conds = [c for c in conditions if 'location' in c]
        other_conds = [c for c in conditions if 'location' not in c]
        
        if location_conds and other_conds:
            for other_cond in other_conds[:2]:
                merged = ComplexQueryProcessor._merge_conditions(location_conds + [other_cond])
                sub_queries.append({
                    'query': f"{query} (focus on location + {list(other_cond.keys())[0]})",
                    'priority': 0.8,
                    'filters': merged,
                    'focus': list(other_cond.keys())[0]
                })
        
        important_conds = ['price', 'duration', 'location']
        for cond_type in important_conds:
            conds_of_type = [c for c in conditions if cond_type in c]
            if conds_of_type:
                sub_queries.append({
                    'query': f"{query} (focus on {cond_type})",
                    'priority': 0.6,
                    'filters': conds_of_type[0],
                    'focus': cond_type
                })
        
        sub_queries.sort(key=lambda x: x['priority'], reverse=True)
        
        logger.info(f"ðŸ”€ Split query into {len(sub_queries)} sub-queries")
        return sub_queries[:3]
    
    @staticmethod
    def _calculate_complexity(query: str) -> float:
        """Calculate how complex a query is"""
        complexity = 0.0
        
        aspects = {
            'price': ['giÃ¡', 'tiá»n', 'chi phÃ­', 'Ä‘áº¯t', 'ráº»'],
            'duration': ['ngÃ y', 'Ä‘Ãªm', 'bao lÃ¢u', 'thá»i gian'],
            'location': ['á»Ÿ', 'táº¡i', 'Ä‘áº¿n', 'vá»', 'Ä‘á»‹a Ä‘iá»ƒm'],
            'quality': ['tá»‘t', 'hay', 'Ä‘áº¹p', 'háº¥p dáº«n', 'thÃº vá»‹'],
            'type': ['thiá»n', 'khÃ­ cÃ´ng', 'retreat', 'chá»¯a lÃ nh'],
        }
        
        query_lower = query.lower()
        
        distinct_aspects = 0
        for aspect, keywords in aspects.items():
            if any(keyword in query_lower for keyword in keywords):
                distinct_aspects += 1
        
        complexity += distinct_aspects * 0.5
        complexity += min(len(query.split()) / 10, 1.0)
        
        conjunctions = ['vÃ ', 'vá»›i', 'cÃ³', 'cho', 'mÃ ', 'nhÆ°ng']
        for conj in conjunctions:
            if conj in query_lower:
                complexity += 0.3
        
        return complexity
    
    @staticmethod
    def _extract_conditions(query: str) -> List[Dict[str, Any]]:
        """Extract individual conditions from query"""
        conditions = []
        
        filters = MandatoryFilterSystem.extract_filters(query)
        
        if filters.price_min is not None or filters.price_max is not None:
            price_cond = {'price': {}}
            if filters.price_min is not None:
                price_cond['price']['min'] = filters.price_min
            if filters.price_max is not None:
                price_cond['price']['max'] = filters.price_max
            conditions.append(price_cond)
        
        if filters.duration_min is not None or filters.duration_max is not None:
            duration_cond = {'duration': {}}
            if filters.duration_min is not None:
                duration_cond['duration']['min'] = filters.duration_min
            if filters.duration_max is not None:
                duration_cond['duration']['max'] = filters.duration_max
            conditions.append(duration_cond)
        
        if filters.location:
            conditions.append({'location': filters.location})
        if filters.near_location:
            conditions.append({'near_location': filters.near_location})
        
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['ráº»', 'giÃ¡ ráº»', 'tiáº¿t kiá»‡m']):
            conditions.append({'price_quality': 'budget'})
        if any(word in query_lower for word in ['cao cáº¥p', 'sang', 'premium']):
            conditions.append({'price_quality': 'premium'})
        
        if 'thiá»n' in query_lower:
            conditions.append({'activity_type': 'meditation'})
        if 'khÃ­ cÃ´ng' in query_lower:
            conditions.append({'activity_type': 'qigong'})
        if 'retreat' in query_lower:
            conditions.append({'activity_type': 'retreat'})
        if 'chá»¯a lÃ nh' in query_lower:
            conditions.append({'activity_type': 'healing'})
        
        tour_name_patterns = [
            r'tour\s+([^vÃ \s,]+)\s+vÃ \s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+vá»›i\s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+.*tour\s+([^\s,]+)',
        ]
        
        for pattern in tour_name_patterns:
            matches = re.finditer(pattern, query_lower)
            for match in matches:
                for i in range(1, 3):
                    if match.group(i):
                        tour_name = match.group(i).strip()
                        normalized_name = FuzzyMatcher.normalize_vietnamese(tour_name)
                        for name, idx in TOUR_NAME_TO_INDEX.items():
                            if normalized_name in name or name in normalized_name:
                                conditions.append({'specific_tour': idx})
                                logger.info(f"ðŸ” Extracted tour name from complex query: {tour_name} â†’ index {idx}")
        
        return conditions
    
    @staticmethod
    def _merge_conditions(conditions: List[Dict]) -> Dict[str, Any]:
        """Merge multiple conditions into one filter dict"""
        merged = {}
        
        for condition in conditions:
            for key, value in condition.items():
                if key in merged:
                    if isinstance(merged[key], dict) and isinstance(value, dict):
                        merged[key].update(value)
                    elif isinstance(merged[key], list) and isinstance(value, list):
                        merged[key].extend(value)
                    else:
                        if isinstance(value, dict) or (isinstance(value, str) and len(value) > len(str(merged[key]))):
                            merged[key] = value
                else:
                    merged[key] = value
        
        return merged

# =========== UPGRADE 6: FUZZY MATCHING (DATACLASS COMPATIBLE) ===========
class FuzzyMatcher:
    """
    UPGRADE 6: Handle misspellings and variations in tour names
    """
    
    SIMILARITY_THRESHOLD = 0.75
    
    @staticmethod
    def normalize_vietnamese(text: str) -> str:
        """
        Normalize Vietnamese text for fuzzy matching
        """
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        
        replacements = {
            'Ä‘': 'd',
            'khÃ´ng': 'ko',
            'khong': 'ko',
            'rá»“i': 'roi',
            'vá»›i': 'voi',
            'Ä‘Æ°á»£c': 'duoc',
            'má»™t': 'mot',
            'hai': '2',
            'ba': '3',
            'bá»‘n': '4',
            'nÄƒm': '5',
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    @staticmethod
    def find_similar_tours(query: str, tour_names: Dict[str, int]) -> List[Tuple[int, float]]:
        """
        Find tours with names similar to query
        """
        if not query or not tour_names:
            return []
        
        query_norm = FuzzyMatcher.normalize_vietnamese(query)
        if not query_norm:
            return []
        
        matches = []
        
        for tour_name, tour_idx in tour_names.items():
            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name)
            if not tour_norm:
                continue
            
            similarity = SequenceMatcher(None, query_norm, tour_norm).ratio()
            
            if query_norm in tour_norm or tour_norm in query_norm:
                similarity = min(similarity + 0.2, 1.0)
            
            query_words = set(query_norm.split())
            tour_words = set(tour_norm.split())
            common_words = query_words.intersection(tour_words)
            
            if common_words:
                word_boost = len(common_words) * 0.1
                similarity = min(similarity + word_boost, 1.0)
            
            if similarity >= FuzzyMatcher.SIMILARITY_THRESHOLD:
                matches.append((tour_idx, similarity))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        logger.info(f"ðŸ” Fuzzy matching: '{query}' â†’ {len(matches)} matches")
        return matches
    
    @staticmethod
    def find_tour_by_partial_name(partial_name: str, tours_db: Dict[int, Tour]) -> List[int]:
        """
        Find tours by partial name match
        """
        if not partial_name or not tours_db:
            return []
        
        partial_norm = FuzzyMatcher.normalize_vietnamese(partial_name)
        matches = []
        
        for tour_idx, tour in tours_db.items():
            tour_name = tour.name or ""
            if not tour_name:
                continue
            
            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name)
            
            if partial_norm in tour_norm:
                match_ratio = len(partial_norm) / len(tour_norm) if tour_norm else 0
                matches.append((tour_idx, match_ratio))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        return [idx for idx, _ in matches[:3]]

# =========== UPGRADE 7: STATE MACHINE (DATACLASS COMPATIBLE) ===========
class ConversationStateMachine:
    """
    UPGRADE 7: Track conversation state for better context
    """
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.state = ConversationState.INITIAL
        self.context = ConversationContext(session_id=session_id)
        self.transitions = []
        self.created_at = datetime.utcnow()
        self.last_updated = datetime.utcnow()
    
    def update(self, user_message: str, bot_response: str, tour_indices: List[int] = None):
        """Update state based on new interaction"""
        self.last_updated = datetime.utcnow()
        self.context.update(user_message, bot_response, tour_indices)
        
        new_state = self._determine_state(user_message, bot_response)
        
        self.transitions.append({
            'timestamp': datetime.utcnow().isoformat(),
            'from': self.state.value,
            'to': new_state.value,
            'message': user_message[:100]
        })
        
        self.state = new_state
        
        logger.info(f"ðŸ”„ State update: {self.state.value} for session {self.session_id}")
    
    def _determine_state(self, user_message: str, bot_response: str) -> ConversationState:
        """Determine new state based on current interaction"""
        message_lower = user_message.lower()
        
        farewell_words = ['táº¡m biá»‡t', 'cáº£m Æ¡n', 'thanks', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            return ConversationState.FAREWELL
        
        tour_ref_patterns = [
            r'tour nÃ y', r'tour Ä‘Ã³', r'tour Ä‘ang nÃ³i', r'cÃ¡i tour',
            r'nÃ³', r'cÃ¡i Ä‘Ã³', r'cÃ¡i nÃ y', r'Ä‘áº¥y'
        ]
        
        if any(re.search(pattern, message_lower) for pattern in tour_ref_patterns):
            if self.context.current_tours:
                return ConversationState.TOUR_SELECTED
            elif self.context.last_successful_tours:
                self.context.current_tours = self.context.last_successful_tours
                return ConversationState.TOUR_SELECTED
        
        if 'so sÃ¡nh' in message_lower or 'sÃ¡nh' in message_lower:
            return ConversationState.COMPARING
        
        if any(word in message_lower for word in ['phÃ¹ há»£p', 'gá»£i Ã½', 'Ä‘á» xuáº¥t', 'tÆ° váº¥n', 'nÃªn chá»n']):
            return ConversationState.RECOMMENDATION
        
        if any(word in message_lower for word in ['Ä‘áº·t', 'booking', 'Ä‘Äƒng kÃ½', 'giá»¯ chá»—']):
            return ConversationState.BOOKING
        
        if self.context.current_tours:
            return ConversationState.ASKING_DETAILS
        
        return ConversationState.INITIAL
    
    def get_context_hint(self) -> str:
        """Get hint about current context for LLM prompt"""
        hints = []
        
        if self.state == ConversationState.TOUR_SELECTED and self.context.current_tours:
            tour_indices = self.context.current_tours
            if len(tour_indices) == 1:
                hints.append(f"User is asking about tour index {tour_indices[0]}")
            else:
                hints.append(f"User is asking about tours {tour_indices}")
        
        if self.context.user_preferences:
            prefs = []
            for key, value in self.context.user_preferences.items():
                prefs.append(f"{key}: {value}")
            if prefs:
                hints.append(f"User preferences: {', '.join(prefs)}")
        
        return "; ".join(hints) if hints else "No specific context"
    
    def extract_reference(self, message: str) -> List[int]:
        """Extract tour reference from message using conversation context"""
        message_lower = message.lower()
        
        if self.context.current_tours:
            for tour_idx in self.context.current_tours:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"ðŸ”„ State machine: Using current tour {tour_idx}")
                        return self.context.current_tours
        
        ref_patterns = [
            (r'tour nÃ y', 1.0),
            (r'tour Ä‘Ã³', 0.9),
            (r'tour Ä‘ang nÃ³i', 0.9),
            (r'cÃ¡i tour', 0.8),
            (r'nÃ³', 0.7),
            (r'Ä‘áº¥y', 0.7),
            (r'cÃ¡i Ä‘Ã³', 0.7),
        ]
        
        for pattern, confidence in ref_patterns:
            if re.search(pattern, message_lower):
                if self.context.current_tours:
                    logger.info(f"ðŸ”„ State machine: Resolved reference to {self.context.current_tours}")
                    return self.context.current_tours
                elif self.context.last_successful_tours:
                    logger.info(f"ðŸ”„ State machine: Using last successful tours {self.context.last_successful_tours}")
                    return self.context.last_successful_tours
        
        if self.context.mentioned_tours:
            recent_tours = list(self.context.mentioned_tours)
            for tour_idx in recent_tours[-3:]:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"ðŸ”„ State machine: Matched to recently mentioned tour {tour_idx}")
                        return [tour_idx]
        
        return []

# =========== UPGRADE 8: DEEP SEMANTIC ANALYSIS (DATACLASS COMPATIBLE) ===========
class SemanticAnalyzer:
    """
    UPGRADE 8: Deep understanding of user intent beyond keywords
    """
    
    USER_PROFILE_PATTERNS = {
        'age_group': [
            (r'ngÆ°á»i giÃ |ngÆ°á»i lá»›n tuá»•i|cao tuá»•i', 'senior'),
            (r'thanh niÃªn|tráº»|sinh viÃªn|há»c sinh', 'young'),
            (r'trung niÃªn|trung tuá»•i', 'middle_aged'),
            (r'gia Ä‘Ã¬nh.*tráº» em|tráº» nhá»|con nÃ­t', 'family_with_kids'),
        ],
        
        'group_type': [
            (r'má»™t mÃ¬nh|Ä‘i láº»|solo', 'solo'),
            (r'cáº·p Ä‘Ã´i|Ä‘Ã´i lá»©a|ngÆ°á»i yÃªu', 'couple'),
            (r'gia Ä‘Ã¬nh|bá»‘ máº¹ con', 'family'),
            (r'báº¡n bÃ¨|nhÃ³m báº¡n|há»™i báº¡n', 'friends'),
            (r'cÃ´ng ty|doanh nghiá»‡p|Ä‘á»“ng nghiá»‡p', 'corporate'),
        ],
        
        'interest_type': [
            (r'thiÃªn nhiÃªn|rá»«ng|cÃ¢y|cáº£nh quan', 'nature'),
            (r'lá»‹ch sá»­|di tÃ­ch|chiáº¿n tranh|tri Ã¢n', 'history'),
            (r'vÄƒn hÃ³a|cá»™ng Ä‘á»“ng|dÃ¢n tá»™c|truyá»n thá»‘ng', 'culture'),
            (r'thiá»n|tÃ¢m linh|tÄ©nh tÃ¢m|yoga', 'spiritual'),
            (r'khÃ­ cÃ´ng|sá»©c khá»e|chá»¯a lÃ nh|wellness', 'wellness'),
            (r'áº©m thá»±c|Ä‘á»“ Äƒn|mÃ³n ngon|Ä‘áº·c sáº£n', 'food'),
            (r'phiÃªu lÆ°u|máº¡o hiá»ƒm|khÃ¡m phÃ¡|tráº£i nghiá»‡m', 'adventure'),
        ],
        
        'budget_level': [
            (r'kinh táº¿|tiáº¿t kiá»‡m|ráº»|giÃ¡ tháº¥p', 'budget'),
            (r'trung bÃ¬nh|vá»«a pháº£i|pháº£i chÄƒng', 'midrange'),
            (r'cao cáº¥p|sang trá»ng|premium|Ä‘áº¯t', 'premium'),
        ],
        
        'physical_level': [
            (r'nháº¹ nhÃ ng|dá»… dÃ ng|khÃ´ng má»‡t', 'easy'),
            (r'vá»«a pháº£i|trung bÃ¬nh|bÃ¬nh thÆ°á»ng', 'moderate'),
            (r'thá»­ thÃ¡ch|khÃ³|má»‡t|leo nÃºi', 'challenging'),
        ],
    }
    
    @staticmethod
    def analyze_user_profile(message: str, current_context: ConversationContext = None) -> UserProfile:
        """
        Analyze message to build user profile
        """
        if current_context and hasattr(current_context, 'user_profile') and current_context.user_profile:
            profile = current_context.user_profile
        else:
            profile = UserProfile()
        
        message_lower = message.lower()
        
        for category, patterns in SemanticAnalyzer.USER_PROFILE_PATTERNS.items():
            for pattern, value in patterns:
                if re.search(pattern, message_lower):
                    if category == 'interests':
                        if value not in profile.interests:
                            profile.interests.append(value)
                            profile.confidence_scores[f'interest_{value}'] = 0.8
                    else:
                        setattr(profile, category, value)
                        profile.confidence_scores[category] = 0.8
        
        SemanticAnalyzer._infer_attributes(profile, message_lower)
        profile.overall_confidence = SemanticAnalyzer._calculate_confidence(profile)
        
        logger.info(f"ðŸ‘¤ User profile analysis: {profile}")
        return profile
    
    @staticmethod
    def _infer_attributes(profile: UserProfile, message_lower: str):
        """Infer additional attributes from context"""
        if not profile.age_group:
            if profile.group_type and 'family_with_kids' in profile.group_type:
                profile.age_group = 'middle_aged'
                profile.confidence_scores['age_group'] = 0.6
            elif 'senior' in message_lower or 'giÃ ' in message_lower:
                profile.age_group = 'senior'
                profile.confidence_scores['age_group'] = 0.7
        
        if not profile.physical_level:
            if 'adventure' in profile.interests:
                profile.physical_level = 'challenging'
                profile.confidence_scores['physical_level'] = 0.6
            elif 'spiritual' in profile.interests or 'wellness' in profile.interests:
                profile.physical_level = 'easy'
                profile.confidence_scores['physical_level'] = 0.6
        
        if not profile.budget_level:
            budget_keywords = {
                'budget': ['ráº»', 'tiáº¿t kiá»‡m', 'Ã­t tiá»n', 'kinh táº¿'],
                'premium': ['cao cáº¥p', 'sang', 'Ä‘áº¯t', 'premium']
            }
            
            for level, keywords in budget_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    profile.budget_level = level
                    profile.confidence_scores['budget_level'] = 0.7
                    break
    
    @staticmethod
    def _calculate_confidence(profile: UserProfile) -> float:
        """Calculate overall confidence in user profile"""
        if not profile.confidence_scores:
            return 0.0
        
        total = 0.0
        count = 0
        
        for key, score in profile.confidence_scores.items():
            total += score
            count += 1
        
        return total / max(count, 1)
    
    @staticmethod
    def match_tours_to_profile(profile: UserProfile, tours_db: Dict[int, Tour], 
                              max_results: int = 5) -> List[Tuple[int, float, List[str]]]:
        """
        Match tours to user profile with explanation
        """
        matches = []
        
        for tour_idx, tour in tours_db.items():
            score = 0.0
            reasons = []
            
            tour_tags = tour.tags or []
            
            if profile.age_group:
                if profile.age_group == 'senior':
                    if any('easy' in tag for tag in tour_tags):
                        score += 0.3
                        reasons.append("phÃ¹ há»£p ngÆ°á»i lá»›n tuá»•i")
                    if any('nature' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("thiÃªn nhiÃªn nháº¹ nhÃ ng")
            
            if profile.interests:
                for interest in profile.interests:
                    tour_summary = (tour.summary or "").lower()
                    if (interest in tour_summary or 
                        any(interest in tag for tag in tour_tags)):
                        score += 0.4
                        reasons.append(f"cÃ³ yáº¿u tá»‘ {interest}")
            
            if profile.budget_level:
                tour_price = tour.price or ""
                price_nums = re.findall(r'\d[\d,\.]+', tour_price)
                
                if price_nums:
                    try:
                        first_price = int(price_nums[0].replace(',', '').replace('.', ''))
                        
                        if profile.budget_level == 'budget' and first_price < 2000000:
                            score += 0.3
                            reasons.append("giÃ¡ há»£p lÃ½")
                        elif profile.budget_level == 'premium' and first_price > 2500000:
                            score += 0.3
                            reasons.append("cao cáº¥p")
                        elif profile.budget_level == 'midrange' and 1500000 <= first_price <= 3000000:
                            score += 0.3
                            reasons.append("giÃ¡ vá»«a pháº£i")
                    except:
                        pass
            
            if profile.physical_level:
                if profile.physical_level == 'easy':
                    if any('easy' in tag or 'meditation' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng")
            
            if score > 0:
                matches.append((tour_idx, score, reasons))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        return matches[:max_results]

# =========== UPGRADE 9: AUTO-VALIDATION SYSTEM (DATACLASS COMPATIBLE) ===========
class AutoValidator:
    """
    UPGRADE 9: Validate and correct information before returning
    """
    
    VALIDATION_RULES = {
        'duration': {
            'patterns': [
                r'(\d+)\s*ngÃ y\s*(\d+)\s*Ä‘Ãªm',
                r'(\d+)\s*ngÃ y',
                r'(\d+)\s*Ä‘Ãªm',
            ],
            'constraints': {
                'max_days': 7,
                'max_nights': 7,
                'valid_day_night_combos': [(1,0), (1,1), (2,1), (2,2), (3,2), (3,3)],
                'common_durations': ['1 ngÃ y', '2 ngÃ y 1 Ä‘Ãªm', '3 ngÃ y 2 Ä‘Ãªm']
            }
        },
        
        'price': {
            'patterns': [
                r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)',
                r'(\d[\d,\.]*)\s*-\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)?',
                r'(\d[\d,\.]*)\s*(Ä‘á»“ng|vnÄ‘|vnd)',
            ],
            'constraints': {
                'min_tour_price': 500000,
                'max_tour_price': 10000000,
                'common_ranges': [
                    (800000, 1500000),
                    (1500000, 2500000),
                    (2500000, 4000000),
                ]
            }
        },
        
        'location': {
            'patterns': [
                r'á»Ÿ\s+([^.,!?]+)',
                r'táº¡i\s+([^.,!?]+)',
                r'Ä‘áº¿n\s+([^.,!?]+)',
            ],
            'constraints': {
                'valid_locations': ['Huáº¿', 'Quáº£ng Trá»‹', 'Báº¡ch MÃ£', 'TrÆ°á»ng SÆ¡n', 'ÄÃ´ng HÃ ', 'Khe Sanh'],
                'max_length': 100
            }
        },
    }
    
    @staticmethod
    def validate_response(response: str) -> str:
        """
        Validate and correct response content
        """
        if not response:
            return response
        
        validated = response
        
        validated = AutoValidator._validate_duration(validated)
        validated = AutoValidator._validate_price(validated)
        validated = AutoValidator._validate_locations(validated)
        validated = AutoValidator._check_unrealistic_info(validated)
        
        if validated != response:
            validated = AutoValidator._add_validation_note(validated)
        
        return validated
    
    @staticmethod
    def _validate_duration(text: str) -> str:
        """Validate and correct duration information"""
        for pattern in AutoValidator.VALIDATION_RULES['duration']['patterns']:
            matches = list(re.finditer(pattern, text))
            for match in matches:
                try:
                    if match.lastindex == 2:
                        days = int(match.group(1))
                        nights = int(match.group(2))
                        
                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']
                        
                        valid_combos = constraints['valid_day_night_combos']
                        is_valid_combo = any(d == d2 and n == n2 for d2, n2 in valid_combos)
                        
                        if days > constraints['max_days'] or nights > constraints['max_nights']:
                            replacement = random.choice(constraints['common_durations'])
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"âš ï¸ Corrected unrealistic duration: {days} ngÃ y {nights} Ä‘Ãªm â†’ {replacement}")
                        
                        elif not is_valid_combo:
                            valid_days = min(days, constraints['max_days'])
                            valid_nights = min(nights, constraints['max_nights'])
                            if abs(valid_days - valid_nights) > 1:
                                valid_nights = valid_days
                            
                            replacement = f"{valid_days} ngÃ y {valid_nights} Ä‘Ãªm"
                            text = text.replace(match.group(0), replacement)
                            logger.info(f"ðŸ”„ Fixed duration combo: {replacement}")
                    
                    elif match.lastindex == 1:
                        num = int(match.group(1))
                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']
                        
                        if num > constraints['max_days']:
                            replacement = f"{constraints['max_days']} ngÃ y"
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"âš ï¸ Capped long duration: {num} â†’ {constraints['max_days']}")
                
                except (ValueError, IndexError):
                    continue
        
        return text
    
    @staticmethod
    def _validate_price(text: str) -> str:
        """Validate and correct price information"""
        for pattern in AutoValidator.VALIDATION_RULES['price']['patterns']:
            matches = list(re.finditer(pattern, text, re.IGNORECASE))
            for match in matches:
                try:
                    amount_str = match.group(1).replace(',', '').replace('.', '')
                    if not amount_str.isdigit():
                        continue
                    
                    amount = int(amount_str)
                    
                    unit = match.group(2).lower() if match.lastindex >= 2 else ''
                    
                    if unit in ['triá»‡u', 'tr']:
                        amount = amount * 1000000
                    elif unit in ['k', 'nghÃ¬n']:
                        amount = amount * 1000
                    
                    constraints = AutoValidator.VALIDATION_RULES['price']['constraints']
                    
                    if amount < constraints['min_tour_price']:
                        replacement = "giÃ¡ há»£p lÃ½"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"âš ï¸ Corrected too-low price: {amount} â†’ {replacement}")
                    
                    elif amount > constraints['max_tour_price']:
                        replacement = "giÃ¡ cao cáº¥p"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"âš ï¸ Corrected too-high price: {amount} â†’ {replacement}")
                
                except (ValueError, IndexError, AttributeError):
                    continue
        
        return text
    
    @staticmethod
    def _validate_locations(text: str) -> str:
        """Validate location names"""
        wrong_locations = {
            'hÃ  ná»™i': 'Huáº¿',
            'há»“ chÃ­ minh': 'Quáº£ng Trá»‹',
            'Ä‘Ã  náºµng': 'Báº¡ch MÃ£',
            'nha trang': 'TrÆ°á»ng SÆ¡n',
        }
        
        for wrong, correct in wrong_locations.items():
            if wrong in text.lower():
                text = text.replace(wrong, correct)
                text = text.replace(wrong.capitalize(), correct)
                logger.info(f"ðŸ”„ Corrected location: {wrong} â†’ {correct}")
        
        return text
    
    @staticmethod
    def _check_unrealistic_info(text: str) -> str:
        """Check for other unrealistic information"""
        unrealistic_patterns = [
            (r'\d+\s*giá»\s*bay', "thá»i gian di chuyá»ƒn"),
            (r'\d+\s*sao', "cháº¥t lÆ°á»£ng dá»‹ch vá»¥"),
            (r'\d+\s*táº§ng', "chá»— á»Ÿ"),
            (r'\d+\s*m\s*cao', "Ä‘á»‹a hÃ¬nh"),
        ]
        
        for pattern, replacement in unrealistic_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
                logger.info(f"ðŸ”„ Replaced unrealistic info with: {replacement}")
        
        return text
    
    @staticmethod
    def _add_validation_note(text: str) -> str:
        """Add note about information validation"""
        note = "\n\n*ThÃ´ng tin Ä‘Æ°á»£c cung cáº¥p dá»±a trÃªn dá»¯ liá»‡u hiá»‡n cÃ³. " \
               "Vui lÃ²ng liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ xÃ¡c nháº­n chi tiáº¿t chÃ­nh xÃ¡c nháº¥t.*"
        
        if note not in text:
            text += note
        
        return text

# =========== UPGRADE 10: TEMPLATE SYSTEM (DATACLASS COMPATIBLE) ===========
class TemplateSystem:
    """
    UPGRADE 10: Beautiful, structured responses for different question types
    """
    
    TEMPLATES = {
        'tour_list': {
            'header': "âœ¨ **DANH SÃCH TOUR RUBY WINGS** âœ¨\n\n",
            'item': "**{index}. {tour_name}** {emoji}\n"
                   "   ðŸ“… {duration}\n"
                   "   ðŸ“ {location}\n"
                   "   ðŸ’° {price}\n"
                   "   {summary}\n",
            'footer': "\nðŸ“ž **LiÃªn há»‡ Ä‘áº·t tour:** 0332510486\n"
                     "ðŸ“ **Ruby Wings Travel** - HÃ nh trÃ¬nh tráº£i nghiá»‡m Ä‘áº·c sáº¯c\n"
                     "ðŸ’¡ *Há»i chi tiáº¿t vá» báº¥t ká»³ tour nÃ o báº±ng cÃ¡ch nháº­p tÃªn tour*",
            'emoji_map': {
                '1 ngÃ y': 'ðŸŒ…',
                '2 ngÃ y': 'ðŸŒ„',
                '3 ngÃ y': 'ðŸ”ï¸',
                'default': 'âœ¨'
            }
        },
        
        'tour_detail': {
            'header': "ðŸŽ¯ **{tour_name}**\n\n",
            'sections': {
                'overview': "ðŸ“‹ **THÃ”NG TIN CHÃNH:**\n"
                          "   â±ï¸ Thá»i gian: {duration}\n"
                          "   ðŸ“ Äá»‹a Ä‘iá»ƒm: {location}\n"
                          "   ðŸ’° GiÃ¡ tour: {price}\n\n",
                'description': "ðŸ“– **MÃ” Táº¢ TOUR:**\n{summary}\n\n",
                'includes': "ðŸŽª **Lá»ŠCH TRÃŒNH & Dá»ŠCH Vá»¤:**\n{includes}\n\n",
                'accommodation': "ðŸ¨ **CHá»– á»ž:**\n{accommodation}\n\n",
                'meals': "ðŸ½ï¸ **Ä‚N Uá»NG:**\n{meals}\n\n",
                'transport': "ðŸš— **DI CHUYá»‚N:**\n{transport}\n\n",
                'notes': "ðŸ“ **GHI CHÃš:**\n{notes}\n\n",
            },
            'footer': "ðŸ“ž **Äáº¶T TOUR & TÆ¯ Váº¾N:** 0332510486\n"
                     "â­ *Tour phÃ¹ há»£p cho: {suitable_for}*",
            'default_values': {
                'duration': 'Äang cáº­p nháº­t',
                'location': 'Äang cáº­p nháº­t',
                'price': 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡',
                'summary': 'HÃ nh trÃ¬nh tráº£i nghiá»‡m Ä‘áº·c sáº¯c cá»§a Ruby Wings',
                'includes': 'Chi tiáº¿t lá»‹ch trÃ¬nh liÃªn há»‡ tÆ° váº¥n',
                'accommodation': 'Äang cáº­p nháº­t',
                'meals': 'Äang cáº­p nháº­t',
                'transport': 'Äang cáº­p nháº­t',
                'notes': 'Vui lÃ²ng liÃªn há»‡ Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t',
                'suitable_for': 'má»i Ä‘á»‘i tÆ°á»£ng',
            }
        },
        
        'comparison': {
            'header': "ðŸ“Š **SO SÃNH TOUR**\n\n",
            'table_header': "| TiÃªu chÃ­ | {tour1} | {tour2} |\n|----------|----------|----------|\n",
            'table_row': "| {criterion} | {value1} | {value2} |\n",
            'recommendation': "\nðŸ’¡ **Gá»¢I Ã Lá»°A CHá»ŒN:**\n{recommendations}\n",
            'footer': "\nðŸ“ž **TÆ° váº¥n chi tiáº¿t:** 0332510486\n"
                     "ðŸ¤” *Cáº§n so sÃ¡nh thÃªm tiÃªu chÃ­ nÃ o?*",
        },
        
        'recommendation': {
            'header': "ðŸŽ¯ **Äá»€ XUáº¤T TOUR PHÃ™ Há»¢P**\n\n",
            'top_recommendation': "ðŸ† **PHÃ™ Há»¢P NHáº¤T ({score}%)**\n"
                                "**{tour_name}**\n"
                                "   âœ… {reasons}\n"
                                "   ðŸ“… {duration} | ðŸ“ {location} | ðŸ’° {price}\n\n",
            'other_recommendations': "ðŸ“‹ **Lá»°A CHá»ŒN KHÃC:**\n",
            'other_item': "   â€¢ **{tour_name}** ({score}%)\n"
                         "     ðŸ“… {duration} | ðŸ“ {location}\n",
            'criteria': "\nðŸ” **TIÃŠU CHÃ Äá»€ XUáº¤T:**\n{criteria}\n",
            'footer': "\nðŸ“ž **LiÃªn há»‡ tÆ° váº¥n cÃ¡ nhÃ¢n hÃ³a:** 0332510486\n"
                     "ðŸ’¬ *Cho tÃ´i biáº¿t thÃªm sá»Ÿ thÃ­ch cá»§a báº¡n Ä‘á»ƒ Ä‘á» xuáº¥t chÃ­nh xÃ¡c hÆ¡n*",
        },
        
        'information': {
            'header': "â„¹ï¸ **THÃ”NG TIN:**\n\n",
            'content': "{content}\n",
            'sources': "\nðŸ“š *Nguá»“n thÃ´ng tin tá»« dá»¯ liá»‡u Ruby Wings*",
            'footer': "\nðŸ“ž **Hotline há»— trá»£:** 0332510486",
        },
        
        'greeting': {
            'template': "ðŸ‘‹ **Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI cá»§a Ruby Wings**\n\n"
                       "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:\n"
                       "â€¢ TÃ¬m hiá»ƒu vá» cÃ¡c tour tráº£i nghiá»‡m\n"
                       "â€¢ So sÃ¡nh cÃ¡c hÃ nh trÃ¬nh\n"
                       "â€¢ Äá» xuáº¥t tour phÃ¹ há»£p vá»›i báº¡n\n"
                       "â€¢ Cung cáº¥p thÃ´ng tin chi tiáº¿t vá» tour\n\n"
                       "ðŸ’¡ **VÃ­ dá»¥ báº¡n cÃ³ thá»ƒ há»i:**\n"
                       "- 'CÃ³ nhá»¯ng tour nÃ o?'\n"
                       "- 'Tour Báº¡ch MÃ£ giÃ¡ bao nhiÃªu?'\n"
                       "- 'Tour nÃ o phÃ¹ há»£p cho gia Ä‘Ã¬nh?'\n\n"
                       "HÃ£y cho tÃ´i biáº¿t báº¡n cáº§n gÃ¬ nhÃ©! ðŸ˜Š",
        },
        
        'farewell': {
            'template': "ðŸ™ **Cáº£m Æ¡n báº¡n Ä‘Ã£ trÃ² chuyá»‡n cÃ¹ng Ruby Wings!**\n\n"
                       "ChÃºc báº¡n má»™t ngÃ y trÃ n Ä‘áº§y nÄƒng lÆ°á»£ng vÃ  bÃ¬nh an.\n"
                       "Hy vá»ng sá»›m Ä‘Æ°á»£c Ä‘á»“ng hÃ nh cÃ¹ng báº¡n trong hÃ nh trÃ¬nh tráº£i nghiá»‡m sáº¯p tá»›i!\n\n"
                       "ðŸ“ž **LiÃªn há»‡ Ä‘áº·t tour:** 0332510486\n"
                       "ðŸŒ **Website:** rubywings.vn\n\n"
                       "Háº¹n gáº·p láº¡i! âœ¨",
        },
    }
    
    @staticmethod
    def render(template_name: str, **kwargs) -> str:
        """Render template with provided variables"""
        template_data = TemplateSystem.TEMPLATES.get(template_name)
        if not template_data:
            return kwargs.get('content', '')
        
        if template_name in ['greeting', 'farewell']:
            return template_data['template']
        
        response_parts = []
        
        if 'header' in template_data:
            header = template_data['header']
            for key, value in kwargs.items():
                header = header.replace(f'{{{key}}}', str(value))
            response_parts.append(header)
        
        if template_name == 'tour_list':
            response_parts.append(TemplateSystem._render_tour_list(template_data, kwargs))
        
        elif template_name == 'tour_detail':
            response_parts.append(TemplateSystem._render_tour_detail(template_data, kwargs))
        
        elif template_name == 'comparison':
            response_parts.append(TemplateSystem._render_comparison(template_data, kwargs))
        
        elif template_name == 'recommendation':
            response_parts.append(TemplateSystem._render_recommendation(template_data, kwargs))
        
        elif template_name == 'information':
            response_parts.append(TemplateSystem._render_information(template_data, kwargs))
        
        if 'footer' in template_data:
            footer = template_data['footer']
            for key, value in kwargs.items():
                footer = footer.replace(f'{{{key}}}', str(value))
            response_parts.append(footer)
        
        return '\n'.join(response_parts)
    
    @staticmethod
    def _render_tour_list(template_data: Dict, kwargs: Dict) -> str:
        """Render tour list template"""
        tours = kwargs.get('tours', [])
        if not tours:
            return "Hiá»‡n chÆ°a cÃ³ thÃ´ng tin tour."
        
        items = []
        for i, tour in enumerate(tours[:10], 1):
            duration = tour.duration or ''
            emoji = template_data['emoji_map'].get('default')
            for dur_pattern, dur_emoji in template_data['emoji_map'].items():
                if dur_pattern in duration.lower():
                    emoji = dur_emoji
                    break
            
            item_template = template_data['item']
            item = item_template.format(
                index=i,
                tour_name=tour.name or f'Tour #{i}',
                emoji=emoji or 'âœ¨',
                duration=duration or 'Äang cáº­p nháº­t',
                location=tour.location or 'Äang cáº­p nháº­t',
                price=tour.price or 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡',
                summary=(tour.summary or 'Tour tráº£i nghiá»‡m Ä‘áº·c sáº¯c')[:100] + '...'
            )
            items.append(item)
        
        return '\n'.join(items)
    
    @staticmethod
    def _render_tour_detail(template_data: Dict, kwargs: Dict) -> str:
        """Render tour detail template"""
        sections = []
        
        for section_name, section_template in template_data['sections'].items():
            value = kwargs.get(section_name, template_data['default_values'].get(section_name, ''))
            
            if value and value != template_data['default_values'].get(section_name):
                if isinstance(value, list):
                    if section_name == 'includes':
                        value = '\n'.join([f'   â€¢ {item}' for item in value[:5]])
                    else:
                        value = ', '.join(value[:3])
                
                section = section_template.format(**{section_name: value})
                sections.append(section)
        
        return '\n'.join(sections)
    
    @staticmethod
    def _render_comparison(template_data: Dict, kwargs: Dict) -> str:
        """Render comparison template"""
        comparison_table = []
        
        tour1_name = kwargs.get('tour1_name', 'Tour 1')[:20]
        tour2_name = kwargs.get('tour2_name', 'Tour 2')[:20]
        table_header = template_data['table_header'].format(tour1=tour1_name, tour2=tour2_name)
        comparison_table.append(table_header)
        
        criteria = kwargs.get('criteria', [])
        for criterion in criteria[:8]:
            row = template_data['table_row'].format(
                criterion=criterion.get('name', ''),
                value1=criterion.get('value1', 'N/A')[:20],
                value2=criterion.get('value2', 'N/A')[:20]
            )
            comparison_table.append(row)
        
        return '\n'.join(comparison_table)
    
    @staticmethod
    def _render_recommendation(template_data: Dict, kwargs: Dict) -> str:
        """Render recommendation template"""
        recommendation_text = []
        
        top_tour = kwargs.get('top_tour')
        if top_tour:
            top_text = template_data['top_recommendation'].format(
                score=int(top_tour.get('score', 0) * 100),
                tour_name=top_tour.get('name', ''),
                reasons=', '.join(top_tour.get('reasons', ['phÃ¹ há»£p'])[:3]),
                duration=top_tour.get('duration', ''),
                location=top_tour.get('location', ''),
                price=top_tour.get('price', 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡')
            )
            recommendation_text.append(top_text)
        
        other_tours = kwargs.get('other_tours', [])
        if other_tours:
            recommendation_text.append(template_data['other_recommendations'])
            
            for tour in other_tours[:2]:
                other_item = template_data['other_item'].format(
                    tour_name=tour.get('name', ''),
                    score=int(tour.get('score', 0) * 100),
                    duration=tour.get('duration', ''),
                    location=tour.get('location', '')
                )
                recommendation_text.append(other_item)
        
        return '\n'.join(recommendation_text)
    
    @staticmethod
    def _render_information(template_data: Dict, kwargs: Dict) -> str:
        """Render information template"""
        content = kwargs.get('content', '')
        if not content:
            return ""
        
        info_text = template_data['content'].format(content=content)
        
        if kwargs.get('has_sources'):
            info_text += template_data['sources']
        
        return info_text

# =========== TOUR DATABASE BUILDER (USING Tour DATACLASS) ===========
def load_knowledge(path: str = KNOWLEDGE_PATH):
    """Load knowledge base from JSON file"""
    global KNOW, FLAT_TEXTS, MAPPING
    
    try:
        with open(path, "r", encoding="utf-8") as f:
            KNOW = json.load(f)
        logger.info(f"âœ… Loaded knowledge from {path}")
    except Exception as e:
        logger.error(f"âŒ Could not open {path}: {e}")
        KNOW = {}
    
    FLAT_TEXTS = []
    MAPPING = []
    
    def scan(obj, prefix="root"):
        if isinstance(obj, dict):
            for k, v in obj.items():
                scan(v, f"{prefix}.{k}")
        elif isinstance(obj, list):
            for i, v in enumerate(obj):
                scan(v, f"{prefix}[{i}]")
        elif isinstance(obj, str):
            t = obj.strip()
            if t:
                FLAT_TEXTS.append(t)
                MAPPING.append({"path": prefix, "text": t})
        else:
            try:
                s = str(obj).strip()
                if s:
                    FLAT_TEXTS.append(s)
                    MAPPING.append({"path": prefix, "text": s})
            except Exception:
                pass
    
    scan(KNOW)
    logger.info(f"ðŸ“Š Knowledge scanned: {len(FLAT_TEXTS)} passages")

def index_tour_names():
    """Build tour name to index mapping"""
    global TOUR_NAME_TO_INDEX
    TOUR_NAME_TO_INDEX = {}
    
    for m in MAPPING:
        path = m.get("path", "")
        if path.endswith(".tour_name"):
            txt = m.get("text", "") or ""
            norm = normalize_text_simple(txt)
            if not norm:
                continue
            
            match = re.search(r"\[(\d+)\]", path)
            if match:
                idx = int(match.group(1))
                prev = TOUR_NAME_TO_INDEX.get(norm)
                if prev is None:
                    TOUR_NAME_TO_INDEX[norm] = idx
                else:
                    existing_txt = MAPPING[next(
                        i for i, m2 in enumerate(MAPPING) 
                        if re.search(rf"\[{prev}\]", m2.get('path','')) and ".tour_name" in m2.get('path','')
                    )].get("text","")
                    if len(txt) > len(existing_txt):
                        TOUR_NAME_TO_INDEX[norm] = idx
    
    logger.info(f"ðŸ“ Indexed {len(TOUR_NAME_TO_INDEX)} tour names")

def build_tours_db():
    """Build structured tour database from MAPPING using Tour dataclass"""
    global TOURS_DB, TOUR_TAGS
    
    TOURS_DB.clear()
    TOUR_TAGS.clear()
    
    # First pass: collect all fields for each tour
    for m in MAPPING:
        path = m.get("path", "")
        text = m.get("text", "")
        
        if not path or not text:
            continue
        
        tour_match = re.search(r'tours\[(\d+)\]', path)
        if not tour_match:
            continue
        
        tour_idx = int(tour_match.group(1))
        
        field_match = re.search(r'tours\[\d+\]\.(\w+)(?:\[\d+\])?', path)
        if not field_match:
            continue
        
        field_name = field_match.group(1)
        
        # Initialize tour entry
        if tour_idx not in TOURS_DB:
            TOURS_DB[tour_idx] = Tour(index=tour_idx)
        
        # Update field in Tour object
        tour_obj = TOURS_DB[tour_idx]
        if field_name == 'tour_name':
            tour_obj.name = text
        elif field_name == 'duration':
            tour_obj.duration = text
        elif field_name == 'location':
            tour_obj.location = text
        elif field_name == 'price':
            tour_obj.price = text
        elif field_name == 'summary':
            tour_obj.summary = text
        elif field_name == 'includes':
            if isinstance(tour_obj.includes, list):
                tour_obj.includes.append(text)
            else:
                tour_obj.includes = [text]
        elif field_name == 'accommodation':
            tour_obj.accommodation = text
        elif field_name == 'meals':
            tour_obj.meals = text
        elif field_name == 'transport':
            tour_obj.transport = text
        elif field_name == 'notes':
            tour_obj.notes = text
        elif field_name == 'style':
            tour_obj.style = text
    
    # Second pass: generate tags and metadata
    for tour_idx, tour_obj in TOURS_DB.items():
        tags = []
        
        # Location tags
        if tour_obj.location:
            locations = [loc.strip() for loc in tour_obj.location.split(",") if loc.strip()]
            tags.extend([f"location:{loc}" for loc in locations[:2]])
        
        # Duration tags
        if tour_obj.duration:
            duration_lower = tour_obj.duration.lower()
            if "1 ngÃ y" in duration_lower:
                tags.append("duration:1day")
            elif "2 ngÃ y" in duration_lower:
                tags.append("duration:2day")
            elif "3 ngÃ y" in duration_lower:
                tags.append("duration:3day")
            else:
                day_match = re.search(r'(\d+)\s*ngÃ y', duration_lower)
                if day_match:
                    days = int(day_match.group(1))
                    tags.append(f"duration:{days}day")
        
        # Price tags
        if tour_obj.price:
            price_nums = re.findall(r'[\d,\.]+', tour_obj.price)
            if price_nums:
                try:
                    clean_nums = []
                    for p in price_nums[:2]:
                        p_clean = p.replace(',', '').replace('.', '')
                        if p_clean.isdigit():
                            clean_nums.append(int(p_clean))
                    
                    if clean_nums:
                        avg_price = sum(clean_nums) / len(clean_nums)
                        if avg_price < 1000000:
                            tags.append("price:budget")
                        elif avg_price < 2000000:
                            tags.append("price:midrange")
                        else:
                            tags.append("price:premium")
                except:
                    pass
        
        # Style/theme tags
        text_to_check = (tour_obj.style + " " + (tour_obj.summary or '')).lower()
        
        theme_keywords = {
            'meditation': ['thiá»n', 'chÃ¡nh niá»‡m', 'tÃ¢m linh'],
            'history': ['lá»‹ch sá»­', 'di tÃ­ch', 'chiáº¿n tranh', 'tri Ã¢n'],
            'nature': ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi', 'cÃ¢y'],
            'culture': ['vÄƒn hÃ³a', 'cá»™ng Ä‘á»“ng', 'dÃ¢n tá»™c'],
            'wellness': ['khÃ­ cÃ´ng', 'sá»©c khá»e', 'chá»¯a lÃ nh'],
            'adventure': ['phiÃªu lÆ°u', 'máº¡o hiá»ƒm', 'khÃ¡m phÃ¡'],
        }
        
        for theme, keywords in theme_keywords.items():
            if any(keyword in text_to_check for keyword in keywords):
                tags.append(f"theme:{theme}")
        
        # Destination tags from tour name
        if tour_obj.name:
            name_lower = tour_obj.name.lower()
            if "báº¡ch mÃ£" in name_lower:
                tags.append("destination:bachma")
            if "trÆ°á»ng sÆ¡n" in name_lower:
                tags.append("destination:truongson")
            if "quáº£ng trá»‹" in name_lower:
                tags.append("destination:quangtri")
            if "huáº¿" in name_lower:
                tags.append("destination:hue")
        
        # Update Tour object tags
        tour_obj.tags = list(set(tags))
        TOUR_TAGS[tour_idx] = tour_obj.tags
        
        # Calculate completeness score
        completeness = 0
        important_fields = ['name', 'duration', 'location', 'price', 'summary']
        for field in important_fields:
            if getattr(tour_obj, field, None):
                completeness += 1
        
        tour_obj.completeness_score = completeness / len(important_fields)
    
    logger.info(f"âœ… Built tours database: {len(TOURS_DB)} tours with tags")

def get_passages_by_field(field_name: str, limit: int = 50, 
                         tour_indices: Optional[List[int]] = None) -> List[Tuple[float, Dict]]:
    """
    Get passages for a specific field
    """
    exact_matches = []
    global_matches = []
    
    for m in MAPPING:
        path = m.get("path", "")
        if path.endswith(f".{field_name}") or f".{field_name}" in path:
            is_exact_match = False
            if tour_indices:
                for ti in tour_indices:
                    if f"[{ti}]" in path:
                        is_exact_match = True
                        break
            
            if is_exact_match:
                exact_matches.append((2.0, m))
            elif not tour_indices:
                global_matches.append((1.0, m))
    
    all_results = exact_matches + global_matches
    all_results.sort(key=lambda x: x[0], reverse=True)
    return all_results[:limit]

# =========== CACHE SYSTEM (DATACLASS COMPATIBLE) ===========
class CacheSystem:
    """Simple caching system for responses"""
    
    @staticmethod
    def get_cache_key(query: str, context_hash: str = "") -> str:
        """Generate cache key"""
        key_parts = [query]
        if context_hash:
            key_parts.append(context_hash)
        return hashlib.md5("|".join(key_parts).encode()).hexdigest()
    
    @staticmethod
    def get(key: str, ttl_seconds: int = 300):
        """Get item from cache"""
        with _cache_lock:
            if key in _response_cache:
                cache_entry = _response_cache[key]
                if not cache_entry.is_expired():
                    logger.info(f"ðŸ’¾ Cache hit for key: {key[:20]}...")
                    return cache_entry.value
                else:
                    del _response_cache[key]
            return None
    
    @staticmethod
    def set(key: str, value: Any):
        """Set item in cache"""
        with _cache_lock:
            cache_entry = CacheEntry(
                key=key,
                value=value,
                created_at=datetime.utcnow(),
                ttl_seconds=UpgradeFlags.get_all_flags().get("CACHE_TTL_SECONDS", 300)
            )
            _response_cache[key] = cache_entry
            
            if len(_response_cache) > 1000:
                sorted_items = sorted(_response_cache.items(), 
                                     key=lambda x: x[1].created_at)
                for old_key in [k for k, _ in sorted_items[:200]]:
                    if old_key in _response_cache:
                        del _response_cache[old_key]

# =========== EMBEDDING FUNCTIONS (MEMORY OPTIMIZED) ===========
@lru_cache(maxsize=128 if IS_LOW_RAM else 1000)
def embed_text(text: str) -> Tuple[List[float], int]:
    """Embed text using OpenAI or fallback (with memory optimization)"""
    if not text:
        return [], 0
    
    text = text[:2000]
    
    if client:
        try:
            response = client.embeddings.create(
                model=EMBEDDING_MODEL,
                input=text
            )
            if response.data:
                embedding = response.data[0].embedding
                return embedding, len(embedding)
        except Exception as e:
            logger.error(f"OpenAI embedding error: {e}")
    
    # Fallback: deterministic hash-based embedding
    h = hash(text) % (10 ** 12)
    dim = 1536
    embedding = [(float((h >> (i % 32)) & 0xFF) + (i % 7)) / 255.0 
                 for i in range(dim)]
    
    return embedding, dim

def query_index(query: str, top_k: int = TOP_K) -> List[Tuple[float, Dict]]:
    """Query the index"""
    if not query or INDEX is None:
        return []
    
    emb, _ = embed_text(query)
    if not emb:
        return []
    
    vec = np.array(emb, dtype="float32").reshape(1, -1)
    vec = vec / (np.linalg.norm(vec) + 1e-12)
    
    try:
        if HAS_FAISS and isinstance(INDEX, faiss.Index):
            D, I = INDEX.search(vec, top_k)
        else:
            D, I = INDEX.search(vec, top_k)
        
        results = []
        for score, idx in zip(D[0], I[0]):
            if 0 <= idx < len(MAPPING):
                results.append((float(score), MAPPING[idx]))
        
        return results
    except Exception as e:
        logger.error(f"Index search error: {e}")
        return []

class NumpyIndex:
    """Simple numpy-based index with safe numpy handling"""

    def __init__(self, mat=None):
        if NUMPY_AVAILABLE:
            if mat is None:
                self.mat = np.empty((0, 0), dtype="float32")
            else:
                # Force numpy float32 2D
                self.mat = np.asarray(mat, dtype="float32")
                if self.mat.ndim == 1:
                    self.mat = self.mat.reshape(1, -1)
        else:
            self.mat = mat if mat is not None else []

        # SAFE dimension detection (no numpy truth check)
        if NUMPY_AVAILABLE:
            if self.mat.shape[0] > 0 and self.mat.ndim == 2:
                self.dim = int(self.mat.shape[1])
            else:
                self.dim = 0
            self.size = int(self.mat.shape[0])
        else:
            self.size = len(self.mat)
            self.dim = len(self.mat[0]) if self.size > 0 else 0

    def is_empty(self):
        if NUMPY_AVAILABLE:
            return self.mat.shape[0] == 0
        return len(self.mat) == 0

    def search(self, query_vec, k=5):
        if self.is_empty():
            return [], []

        if NUMPY_AVAILABLE:
            q = np.asarray(query_vec, dtype="float32").reshape(1, -1)
            sims = np.dot(self.mat, q.T).reshape(-1)
            topk = np.argsort(-sims)[:k]
            return sims[topk].tolist(), topk.tolist()
        else:
            return [], []

    
    def search(self, qvec, k):
        if not self.mat or (NUMPY_AVAILABLE and self.mat.shape[0] == 0) or (not NUMPY_AVAILABLE and len(self.mat) == 0):
            # Return empty results
            return np.array([[]]), np.array([[]], dtype=np.int64)
        
        q = np.array(qvec).flatten()
        
        if NUMPY_AVAILABLE:
            # Use numpy if available
            q = q / (np.linalg.norm(q) + 1e-12)
            m = self.mat / (np.linalg.norm(self.mat, axis=1, keepdims=True) + 1e-12)
            sims = np.dot(q, m.T)
            idx = np.argsort(-sims)[:k]
            scores = sims[idx]
        else:
            # Fallback calculation
            q_norm = q / (sum(x*x for x in q)**0.5 + 1e-12)
            scores = []
            for i, row in enumerate(self.mat):
                row_norm = row / (sum(x*x for x in row)**0.5 + 1e-12)
                sim = sum(q_norm[j] * row_norm[j] for j in range(min(len(q_norm), len(row_norm))))
                scores.append((sim, i))
            
            scores.sort(key=lambda x: x[0], reverse=True)
            top_k = scores[:k]
            if top_k:
                scores_arr = np.array([s[0] for s in top_k])
                idx_arr = np.array([s[1] for s in top_k])
            else:
                scores_arr = np.array([])
                idx_arr = np.array([], dtype=np.int64)
            
            return scores_arr.reshape(1, -1), idx_arr.reshape(1, -1)
        
        return scores.reshape(1, -1), idx.reshape(1, -1)
    
    def save(self, path):
        if NUMPY_AVAILABLE:
            np.savez_compressed(path, mat=self.mat)
        else:
            logger.warning(f"âš ï¸ Cannot save index without NumPy: {path}")
    
    @classmethod
    def load(cls, path):
        if NUMPY_AVAILABLE:
            try:
                arr = np.load(path)
                return cls(arr['mat'])
            except Exception as e:
                logger.error(f"Failed to load numpy index: {e}")
                return cls()
        else:
            logger.warning(f"âš ï¸ Cannot load index without NumPy: {path}")
            return cls()

def build_index(force_rebuild: bool = False) -> bool:
    """Build or load FAISS/numpy index"""
    global INDEX, EMBEDDING_MODEL
    
    with INDEX_LOCK:
        # Try to load existing index
        if not force_rebuild:
            if FAISS_ENABLED and HAS_FAISS and os.path.exists(FAISS_INDEX_PATH):
                try:
                    INDEX = faiss.read_index(FAISS_INDEX_PATH)
                    logger.info(f"âœ… Loaded FAISS index from {FAISS_INDEX_PATH}")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load FAISS index: {e}")
            
            # Try numpy fallback
            if os.path.exists(FALLBACK_VECTORS_PATH):
                try:
                    arr = np.load(FALLBACK_VECTORS_PATH)
                    INDEX = NumpyIndex(arr['mat'])
                    logger.info("âœ… Loaded numpy index")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load numpy index: {e}")
        
        # Build new index
        if not FLAT_TEXTS:
            logger.warning("No texts to index")
            return False
        
        logger.info(f"ðŸ”¨ Building index for {len(FLAT_TEXTS)} passages...")
        
        # Generate embeddings
        vectors = []
        dims = None
        
        for text in FLAT_TEXTS:
            emb, d = embed_text(text)
            if emb:
                if dims is None:
                    dims = len(emb)
                vectors.append(np.array(emb, dtype="float32"))
        
        if not vectors:
            logger.error("No embeddings generated")
            return False
        
        # Create index
        mat = np.vstack(vectors)
        mat = mat / (np.linalg.norm(mat, axis=1, keepdims=True) + 1e-12)
        
        if FAISS_ENABLED and HAS_FAISS:
            INDEX = faiss.IndexFlatIP(dims)
            INDEX.add(mat)
            try:
                faiss.write_index(INDEX, FAISS_INDEX_PATH)
                logger.info(f"âœ… Saved FAISS index to {FAISS_INDEX_PATH}")
            except Exception as e:
                logger.error(f"Failed to save FAISS index: {e}")
        else:
            INDEX = NumpyIndex(mat)
            try:
                INDEX.save(FALLBACK_VECTORS_PATH)
                logger.info(f"âœ… Saved numpy index to {FALLBACK_VECTORS_PATH}")
            except Exception as e:
                logger.error(f"Failed to save numpy index: {e}")
        
        logger.info(f"âœ… Index built: {len(vectors)} vectors, {dims} dimensions")
        return True

# =========== HELPER FUNCTIONS ===========
def normalize_text_simple(s: str) -> str:
    """Basic text normalization"""
    if not s:
        return ""
    s = s.lower()
    s = unicodedata.normalize("NFD", s)
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
    s = re.sub(r"[^\w\s]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def get_session_context(session_id: str) -> ConversationContext:
    """Get or create context for session using ConversationContext dataclass with auto-repair"""

    ctx = SESSION_CONTEXTS.get(session_id)

    if ctx is None:
        ctx = ConversationContext(session_id=session_id)
        SESSION_CONTEXTS[session_id] = ctx
        return ctx

    # ===== AUTO REPAIR FOR OLD CONTEXT OBJECTS =====
    if not hasattr(ctx, "last_tour_indices"):
        ctx.last_tour_indices = []

    if not hasattr(ctx, "current_tours"):
        ctx.current_tours = []

    if not hasattr(ctx, "mentioned_tours"):
        ctx.mentioned_tours = set()

    if not hasattr(ctx, "last_successful_tours"):
        ctx.last_successful_tours = []

    if not hasattr(ctx, "conversation_history"):
        ctx.conversation_history = []

    if not hasattr(ctx, "user_preferences"):
        ctx.user_preferences = {}

    return ctx


def extract_session_id(request_data: Dict, remote_addr: str) -> str:
    """Extract or create session ID"""
    session_id = request_data.get("session_id")
    if not session_id:
        ip = remote_addr or "0.0.0.0"
        current_hour = datetime.utcnow().strftime("%Y%m%d%H")
        unique_str = f"{ip}_{current_hour}"
        session_id = hashlib.md5(unique_str.encode()).hexdigest()[:12]
    return f"session_{session_id}"

def _prepare_llm_prompt(user_message: str, search_results: List, context: Dict) -> str:
    """Prepare prompt for LLM - THÃ”NG MINH vá»›i context & cÃ¢u há»i chung"""
    
    message_lower = user_message.lower()
    
    # PhÃ¢n loáº¡i cÃ¢u há»i
    is_general_question = any(keyword in message_lower for keyword in [
        'cÃ³ bao gá»“m', 'Ä‘Ã£ bao gá»“m', 'bao gá»“m gÃ¬', 'bao gá»“m nhá»¯ng gÃ¬',
        'cÃ³ gÃ¬', 'nhÆ° tháº¿ nÃ o', 'ra sao', 'tháº¿ nÃ o', 'giÃ¡ tour'
    ])
    
    has_specific_tour = context.get('current_tours') and len(context.get('current_tours', [])) > 0
    tour_count = len(context.get('current_tours', []))
    
    # PhÃ¡t hiá»‡n cÃ¢u há»i tiáº¿p theo (followup)
    is_followup = (
        context.get('last_action') == 'chat_response' and 
        (has_specific_tour or context.get('last_tour_name'))
    )
    
    # PhÃ¡t hiá»‡n rÃ ng buá»™c Ä‘á»‹a lÃ½
    has_location_constraint = False
    location_constraint = None
    filters = context.get('filters', {})
    if filters:
        if filters.get('location'):
            has_location_constraint = True
            location_constraint = filters.get('location')
        elif filters.get('near_location'):
            has_location_constraint = True
            location_constraint = filters.get('near_location')
    
    prompt_parts = [
        "Báº¡n lÃ  trá»£ lÃ½ tÆ° váº¥n du lá»‹ch Ruby Wings - CHUYÃŠN NGHIá»†P, THÃ”NG MINH, NHIá»†T TÃŒNH.",
        "",
        "âš ï¸ QUY Táº®C NGHIÃŠM NGáº¶T:",
    ]
    
    # RULE 1: CÃ¢u há»i CHUNG (khÃ´ng cÃ³ tour cá»¥ thá»ƒ)
    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "",
            "ðŸŽ¯ ÄÃ‚Y LÃ€ CÃ‚U Há»ŽI CHUNG - KHÃ”NG CÃ“ TOUR Cá»¤ THá»‚:",
            "â€¢ TRáº¢ Lá»œI NGáº®N Gá»ŒN (2-4 cÃ¢u) dá»±a trÃªn kiáº¿n thá»©c chung vá» tour du lá»‹ch",
            "â€¢ Sá»¬ Dá»¤NG OPENAI Ä‘á»ƒ tráº£ lá»i tá»± nhiÃªn, khÃ´ng nÃ³i 'khÃ´ng cÃ³ dá»¯ liá»‡u'",
            "â€¢ Káº¾T THÃšC báº±ng cÃ¢u há»i: 'Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t?'",
            "â€¢ KHÃ”NG liá»‡t kÃª tour, KHÃ”NG dump dá»¯ liá»‡u",
            "",
            "VÃ Dá»¤ ÄÃšNG:",
            "Q: 'GiÃ¡ tour bao gá»“m gÃ¬?'",
            "A: 'GiÃ¡ tour Ruby Wings thÆ°á»ng bao gá»“m: xe Ä‘Æ°a Ä‘Ã³n, Äƒn uá»‘ng theo chÆ°Æ¡ng trÃ¬nh, khÃ¡ch sáº¡n, hÆ°á»›ng dáº«n viÃªn vÃ  báº£o hiá»ƒm. TÃ¹y tour cá»¥ thá»ƒ cÃ³ thá»ƒ cÃ³ thÃªm vÃ© tham quan hoáº·c hoáº¡t Ä‘á»™ng Ä‘áº·c biá»‡t. Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t? ðŸ˜Š'",
            "",
            "Q: 'Tour cÃ³ phÃ¹ há»£p gia Ä‘Ã¬nh khÃ´ng?'",
            "A: 'Ruby Wings cÃ³ nhiá»u tour phÃ¹ há»£p gia Ä‘Ã¬nh vá»›i hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng, an toÃ n cho tráº» em vÃ  ngÆ°á»i lá»›n tuá»•i. Gia Ä‘Ã¬nh báº¡n cÃ³ bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch loáº¡i hÃ¬nh nÃ o (thiÃªn nhiÃªn, lá»‹ch sá»­, nghá»‰ dÆ°á»¡ng) Ä‘á»ƒ tÃ´i tÆ° váº¥n tour phÃ¹ há»£p nháº¥t?'",
        ])
    
    # RULE 2: CÃ¢u há»i TIáº¾P THEO (followup)
    elif is_followup:
        prompt_parts.extend([
            "",
            "ðŸ’­ ÄÃ‚Y LÃ€ CÃ‚U Há»ŽI TIáº¾P THEO - Sá»¬ Dá»¤NG CONTEXT:",
            f"â€¢ ÄÃ£ bÃ n vá» {tour_count} tour: {context.get('last_tour_name', '')}",
            "â€¢ PHáº¢I dá»±a vÃ o context cÅ© - KHÃ”NG reset",
            "â€¢ TRáº¢ Lá»œI TIáº¾P theo ngá»¯ cáº£nh Ä‘Ã£ cÃ³",
            "â€¢ KHÃ”NG liá»‡t kÃª láº¡i toÃ n bá»™ tour",
            "â€¢ Náº¿u há»i vá» giÃ¡/thá»i gian â†’ Chá»‰ nÃ³i vá» tour Ä‘ang bÃ n",
            "â€¢ Náº¿u há»i thÃªm Ä‘iá»u kiá»‡n â†’ Gá»£i Ã½ tour tá»« context hoáº·c há»i láº¡i",
            "",
            "VÃ Dá»¤ ÄÃšNG:",
            "Context: ÄÃ£ nÃ³i vá» 'Tour Báº¡ch MÃ£'",
            "Q: 'Tour nÃ y cÃ³ phÃ¹ há»£p nhÃ³m 10 ngÆ°á»i khÃ´ng?'",
            "A: 'Tour Báº¡ch MÃ£ ráº¥t phÃ¹ há»£p cho nhÃ³m 10 ngÆ°á»i! ChÃºng tÃ´i cÃ³ thá»ƒ tá»• chá»©c riÃªng vá»›i giÃ¡ Æ°u Ä‘Ã£i. NhÃ³m báº¡n thÃ­ch hoáº¡t Ä‘á»™ng nÃ o: trekking, thiá»n tÄ©nh tÃ¢m hay cáº£ hai? TÃ´i sáº½ tÆ° váº¥n lá»‹ch trÃ¬nh chi tiáº¿t.'",
        ])
    
    # RULE 3: Location constraint
    if has_location_constraint:
        prompt_parts.extend([
            "",
            "ðŸš¨ RÃ€NG BUá»˜C Äá»ŠA LÃ - NGHIÃŠM NGáº¶T:",
            f"â€¢ YÃªu cáº§u tour gáº§n/táº¡i: {location_constraint or 'khu vá»±c cá»¥ thá»ƒ'}",
            "â€¢ CHá»ˆ Ä‘á» xuáº¥t tour trong khu vá»±c nÃ y",
            "â€¢ Náº¾U khÃ´ng cÃ³ tour phÃ¹ há»£p:",
            "  â†’ 'Hiá»‡n Ruby Wings chÆ°a cÃ³ tour táº¡i [Ä‘á»‹a Ä‘iá»ƒm]. Tuy nhiÃªn, chÃºng tÃ´i cÃ³ tour gáº§n nháº¥t táº¡i [X].'",
            "  â†’ Há»i: 'Báº¡n cÃ³ muá»‘n xem tour á»Ÿ khu vá»±c lÃ¢n cáº­n khÃ´ng?'",
        ])
    
    # RULE 4: Giá»›i háº¡n tour
    prompt_parts.extend([
        "",
        "ðŸ“Š GIá»šI Háº N TOUR (Báº®T BUá»˜C):",
        "â€¢ Tá»‘i Ä‘a 2-3 tour/cÃ¢u tráº£ lá»i",
        "â€¢ Má»–I tour pháº£i cÃ³ LÃ DO rÃµ rÃ ng",
        "â€¢ KHÃ”NG liá»‡t kÃª >3 tour",
        "â€¢ Náº¿u cÃ³ nhiá»u tour phÃ¹ há»£p:",
        "  â†’ Chá»n 2-3 TIÃŠU BIá»‚U nháº¥t",
        "  â†’ TÃ³m táº¯t: 'CÃ²n X tour khÃ¡c...'",
        "  â†’ Há»i: 'Báº¡n muá»‘n xem thÃªm loáº¡i nÃ o?'",
    ])
    
    # CONTEXT INFO
    prompt_parts.extend([
        "",
        "ðŸ“š THÃ”NG TIN NGá»® Cáº¢NH:",
    ])
    
    if context.get('user_preferences'):
        prefs = []
        for k, v in context['user_preferences'].items():
            prefs.append(f"{k}: {v}")
        if prefs:
            prompt_parts.append(f"- Sá»Ÿ thÃ­ch: {'; '.join(prefs)}")
    
    if context.get('current_tours'):
        tours_info = [f"{t['name']}" for t in context['current_tours'][:3]]
        if tours_info:
            prompt_parts.append(f"- Tour Ä‘Ã£ bÃ n: {', '.join(tours_info)}")
    
    if filters:
        filter_strs = []
        if filters.get('price_max'):
            filter_strs.append(f"giÃ¡ <{filters['price_max']:,}Ä‘")
        if filters.get('location'):
            filter_strs.append(f"Vá»Š TRÃ: {filters['location']}")
        if filter_strs:
            prompt_parts.append(f"- RÃ ng buá»™c: {'; '.join(filter_strs)}")
    
    # SEARCH RESULTS
    prompt_parts.append("")
    prompt_parts.append("ðŸ“ Dá»® LIá»†U Tá»ª Há»† THá»NG:")
    
    if search_results:
        for i, (score, passage) in enumerate(search_results[:5], 1):
            text = passage.get('text', '')[:250]
            prompt_parts.append(f"[{i}] {text}")
    else:
        prompt_parts.append("(KhÃ´ng cÃ³ dá»¯ liá»‡u cá»¥ thá»ƒ - sá»­ dá»¥ng kiáº¿n thá»©c chung)")
    
    # YÃŠU Cáº¦U TRáº¢ Lá»œI
    prompt_parts.append("")
    prompt_parts.append("ðŸ’¬ YÃŠU Cáº¦U TRáº¢ Lá»œI:")
    
    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "1. Tráº£ lá»i NGáº®N Gá»ŒN (2-4 cÃ¢u) dá»±a OpenAI",
            "2. KHÃ”NG nÃ³i 'khÃ´ng cÃ³ dá»¯ liá»‡u'",
            "3. Káº¿t thÃºc: Há»i láº¡i Ä‘á»ƒ xÃ¡c Ä‘á»‹nh tour",
        ])
    elif is_followup:
        prompt_parts.extend([
            "1. Dá»±a vÃ o CONTEXT (tour Ä‘Ã£ bÃ n)",
            "2. Tráº£ lá»i TIáº¾P, KHÃ”NG reset",
            "3. Tá»‘i Ä‘a nháº¯c 1-2 tour tá»« context",
        ])
    else:
        prompt_parts.extend([
            "1. Chá»n 2-3 tour vá»›i LÃ DO rÃµ",
            "2. KHÃ”NG >3 tour",
            "3. Náº¿u nhiá»u: tÃ³m táº¯t + há»i tiáº¿p",
        ])
    
    prompt_parts.append("4. LuÃ´n káº¿t thÃºc: CÃ¢u há»i dáº«n dáº¯t hoáº·c 'ðŸ“ž Gá»i 0332510486'")
    
    return "\n".join(prompt_parts)

def _generate_fallback_response(user_message: str, search_results: List, tour_indices: List[int] = None) -> str:
    """Generate SMART fallback response - DÃ¹ng OpenAI khi cÃ³, context-aware"""
    message_lower = user_message.lower()
    
    # ===== Sá»¬ Dá»¤NG OPENAI Náº¾U CÃ“ =====
    if client and HAS_OPENAI:
        try:
            # Chuáº©n bá»‹ context
            context_parts = []
            
            # ThÃ´ng tin tour náº¿u cÃ³
            if tour_indices and TOURS_DB:
                for idx in tour_indices[:2]:
                    tour = TOURS_DB.get(idx)
                    if tour:
                        context_parts.append(f"Tour: {tour.name}")
                        if tour.duration:
                            context_parts.append(f"Thá»i gian: {tour.duration}")
                        if tour.price:
                            context_parts.append(f"GiÃ¡: {tour.price}")
                        if tour.summary:
                            context_parts.append(f"MÃ´ táº£: {tour.summary[:150]}")
            
            # Dá»¯ liá»‡u search
            if search_results:
                for i, (score, passage) in enumerate(search_results[:3], 1):
                    text = passage.get('text', '')[:200]
                    if text:
                        context_parts.append(f"ThÃ´ng tin {i}: {text}")
            
            # Táº¡o prompt thÃ´ng minh
            context_str = "\n".join(context_parts) if context_parts else "KhÃ´ng cÃ³ dá»¯ liá»‡u cá»¥ thá»ƒ"
            
            prompt = f"""Báº¡n lÃ  tÆ° váº¥n viÃªn Ruby Wings chuyÃªn nghiá»‡p.

THÃ”NG TIN CÃ“ Sáº´N:
{context_str}

YÃŠU Cáº¦U TRáº¢ Lá»œI:
1. Náº¿u cÃ³ thÃ´ng tin tour cá»¥ thá»ƒ â†’ TÆ° váº¥n dá»±a trÃªn Ä‘Ã³
2. Náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u â†’ Tráº£ lá»i dá»±a kiáº¿n thá»©c chung vá» tour du lá»‹ch
3. LUÃ”N káº¿t thÃºc báº±ng cÃ¢u há»i dáº«n dáº¯t hoáº·c "Gá»i 0332510486"
4. Ngáº¯n gá»n 2-4 cÃ¢u, nhiá»‡t tÃ¬nh, tá»± nhiÃªn
5. KHÃ”NG nÃ³i "khÃ´ng cÃ³ dá»¯ liá»‡u", "xin lá»—i khÃ´ng tÃ¬m tháº¥y"

CÃ¢u há»i cá»§a khÃ¡ch: {user_message}"""

            response = client.chat.completions.create(
                model=CHAT_MODEL,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.6,
                max_tokens=300
            )
            
            if response.choices:
                reply = response.choices[0].message.content or ""
                # Äáº£m báº£o cÃ³ hotline
                if "0332510486" not in reply:
                    reply += "\n\nðŸ“ž LiÃªn há»‡ 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t!"
                return reply
        
        except Exception as e:
            logger.error(f"OpenAI fallback error: {e}")
            # RÆ¡i xuá»‘ng logic template bÃªn dÆ°á»›i
    
    # ===== FALLBACK KHI KHÃ”NG CÃ“ OPENAI =====
    
    # CÃ³ tour cá»¥ thá»ƒ â†’ Tráº£ thÃ´ng tin tour
    if tour_indices and TOURS_DB:
        response_parts = []
        for idx in tour_indices[:2]:
            tour = TOURS_DB.get(idx)
            if tour:
                response_parts.append(f"**{tour.name}**")
                if tour.duration:
                    response_parts.append(f"â±ï¸ {tour.duration}")
                if tour.location:
                    response_parts.append(f"ðŸ“ {tour.location}")
                if tour.price:
                    response_parts.append(f"ðŸ’° {tour.price}")
                if tour.summary:
                    response_parts.append(f"ðŸ“ {tour.summary[:150]}...")
        
        if response_parts:
            return "\n".join(response_parts) + "\n\nðŸ“ž Gá»i 0332510486 Ä‘á»ƒ biáº¿t thÃªm!"
    
    # CÃ³ search results â†’ TÃ³m táº¯t
    if search_results:
        top_results = search_results[:2]
        response_parts = ["ThÃ´ng tin liÃªn quan:"]
        
        for i, (score, passage) in enumerate(top_results, 1):
            text = passage.get('text', '')[:150]
            if text:
                response_parts.append(f"\n{i}. {text}...")
        
        response_parts.append("\n\nðŸ“ž LiÃªn há»‡ 0332510486 Ä‘á»ƒ biáº¿t chi tiáº¿t!")
        return "".join(response_parts)
    
    # CÃ¢u há»i chung â†’ Template thÃ´ng minh theo keyword
    general_qa = {
        'bao gá»“m': "GiÃ¡ tour Ruby Wings thÆ°á»ng bao gá»“m: xe Ä‘Æ°a Ä‘Ã³n, Äƒn uá»‘ng theo chÆ°Æ¡ng trÃ¬nh, khÃ¡ch sáº¡n, hÆ°á»›ng dáº«n viÃªn vÃ  báº£o hiá»ƒm. TÃ¹y tour cá»¥ thá»ƒ cÃ³ thÃªm hoáº¡t Ä‘á»™ng Ä‘áº·c biá»‡t. Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t? ðŸ˜Š",
        
        'phÃ¹ há»£p gia Ä‘Ã¬nh': "Ruby Wings cÃ³ nhiá»u tour phÃ¹ há»£p gia Ä‘Ã¬nh vá»›i hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng, an toÃ n cho tráº» em vÃ  ngÆ°á»i lá»›n tuá»•i. Gia Ä‘Ã¬nh báº¡n bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch loáº¡i tour nÃ o (thiÃªn nhiÃªn, lá»‹ch sá»­, nghá»‰ dÆ°á»¡ng)?",
        
        'phÃ¹ há»£p': "Ruby Wings cÃ³ tour cho má»i Ä‘á»‘i tÆ°á»£ng! Báº¡n Ä‘i nhÃ³m bao nhiÃªu ngÆ°á»i vÃ  cÃ³ sá»Ÿ thÃ­ch gÃ¬ Ä‘áº·c biá»‡t khÃ´ng?",
        
        'giÃ¡': "GiÃ¡ tour Ruby Wings tá»« 800.000Ä‘ - 3.000.000Ä‘ tÃ¹y loáº¡i. Báº¡n cÃ³ ngÃ¢n sÃ¡ch khoáº£ng bao nhiÃªu vÃ  muá»‘n Ä‘i máº¥y ngÃ y Ä‘á»ƒ tÃ´i tÆ° váº¥n phÃ¹ há»£p?",
        
        'thá»i gian': "Ruby Wings cÃ³ tour 1 ngÃ y, 2 ngÃ y 1 Ä‘Ãªm, 3 ngÃ y 2 Ä‘Ãªm. Báº¡n cÃ³ khoáº£ng bao nhiÃªu thá»i gian ráº£nh?",
        
        'Ä‘á»‹a Ä‘iá»ƒm': "Ruby Wings tá»• chá»©c tour táº¡i Huáº¿, Quáº£ng Trá»‹, Báº¡ch MÃ£, TrÆ°á»ng SÆ¡n vÃ  nhiá»u nÆ¡i khÃ¡c. Báº¡n muá»‘n khÃ¡m phÃ¡ khu vá»±c nÃ o?",
        
        'nhÃ³m': "Tour nhÃ³m cá»§a Ruby Wings ráº¥t phÃ¹ há»£p! NhÃ³m báº¡n bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch hoáº¡t Ä‘á»™ng gÃ¬ (teambuilding, nghá»‰ dÆ°á»¡ng, khÃ¡m phÃ¡)?",
        
        'retreat': "Ruby Wings chuyÃªn tour retreat káº¿t há»£p thiá»n, khÃ­ cÃ´ng vÃ  thiÃªn nhiÃªn. Báº¡n muá»‘n tour bao nhiÃªu ngÃ y vÃ  má»©c Ä‘á»™ hoáº¡t Ä‘á»™ng nhÆ° nÃ o?",
    }
    
    # TÃ¬m keyword match
    for keyword, response in general_qa.items():
        if keyword in message_lower:
            return response
    
    # Default - Dáº«n dáº¯t há»i láº¡i
    return "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n tÃ¬m tour phÃ¹ há»£p! Báº¡n cÃ³ thá»ƒ cho tÃ´i biáº¿t:\n" \
           "â€¢ Muá»‘n Ä‘i Ä‘Ã¢u?\n" \
           "â€¢ Thá»i gian bao lÃ¢u?\n" \
           "â€¢ NgÃ¢n sÃ¡ch khoáº£ng bao nhiÃªu?\n" \
           "â€¢ Äi bao nhiÃªu ngÆ°á»i?\n\n" \
           "Hoáº·c gá»i ngay 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t! ðŸ˜Š"

# =========== ULTIMATE CHAT ENDPOINT - SIÃŠU THÃ”NG MINH ===========
@app.route("/chat", methods=["POST"])
def chat_endpoint_ultimate_v2():
    """
    Chat endpoint siÃªu thÃ´ng minh vá»›i context-aware máº¡nh máº½, xá»­ lÃ½ Ä‘a nhiá»‡m vÃ  trÃ­ nhá»› phiÃªn lÃ m viá»‡c
    """
    start_time = time.time()
    
    try:
        # ================== KHá»žI Táº O THÃ”NG MINH ==================
        data = request.get_json() or {}
        user_message = (data.get("message") or "").strip()
        session_id = extract_session_id(data, request.remote_addr)
        
        if not user_message:
            return jsonify({
                "reply": "ðŸŒŸ **XIN CHÃ€O! TÃ”I LÃ€ TRá»¢ LÃ AI RUBY WINGS** ðŸŒŸ\n\n"
                        "TÃ´i Ä‘Æ°á»£c trang bá»‹ trÃ­ thÃ´ng minh cao cáº¥p Ä‘á»ƒ:\n"
                        "â€¢ Hiá»ƒu context & ghi nhá»› tour Ä‘ang tháº£o luáº­n\n"
                        "â€¢ So sÃ¡nh chi tiáº¿t 2-3 tour cÃ¹ng lÃºc\n"
                        "â€¢ Äá» xuáº¥t tour chÃ­nh xÃ¡c theo nhu cáº§u\n"
                        "â€¢ Cáº£nh bÃ¡o tour khÃ´ng phÃ¹ há»£p vá»›i Ä‘á»‘i tÆ°á»£ng\n"
                        "â€¢ Xá»­ lÃ½ Ä‘a tÆ°Æ¡ng tÃ¡c trong 1 phiÃªn\n\n"
                        "ðŸ”® **HÃ£y há»i tÃ´i báº¥t ká»³ Ä‘iá»u gÃ¬ vá» 32 tour Ä‘áº·c sáº¯c!**\n"
                        "ðŸ“ž **Hotline 24/7:** 0332510486",
                "sources": [],
                "context": {},
                "processing_time": 0
            })
        
        # ================== Há»† THá»NG CONTEXT THÃ”NG MINH ==================
        context = get_session_context(session_id)
        
        # Khá»Ÿi táº¡o context nÃ¢ng cao
        if not hasattr(context, 'conversation_history'):
            context.conversation_history = []
        if not hasattr(context, 'current_tour'):
            context.current_tour = None
        if not hasattr(context, 'user_profile'):
            context.user_profile = {
                'group_size': None,
                'ages': [],
                'preferences': [],
                'budget_range': None,
                'duration_pref': None,
                'special_needs': []
            }
        if not hasattr(context, 'discussed_tours'):
            context.discussed_tours = []
        if not hasattr(context, 'comparison_mode'):
            context.comparison_mode = False
        
        # LÆ°u lá»‹ch sá»­ thÃ´ng minh
        context.conversation_history.append({
            'role': 'user',
            'message': user_message,
            'timestamp': datetime.utcnow().isoformat()
        })
        
        # Giá»›i háº¡n history (giá»¯ 15 tin nháº¯n gáº§n nháº¥t)
        if len(context.conversation_history) > 30:
            context.conversation_history = context.conversation_history[-15:]
        
        # ================== PHÃ‚N TÃCH NGá»® NGHÄ¨A NÃ‚NG CAO ==================
        message_lower = user_message.lower()
        
        # TrÃ­ch xuáº¥t thÃ´ng tin ngÆ°á»i dÃ¹ng thÃ´ng minh
        extracted_info = _extract_user_info(user_message, context.user_profile)
        context.user_profile.update(extracted_info)
        
        # PhÃ¡t hiá»‡n intent vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao
        intents = _detect_intents_with_llm(user_message, context.conversation_history[-3:])
        
        # ================== Há»† THá»NG TRÃ NHá»š TOUR ==================
        # XÃ¡c Ä‘á»‹nh tour Ä‘ang Ä‘Æ°á»£c tháº£o luáº­n
        current_tour_indices = _resolve_tour_reference(
            user_message, 
            context.current_tour, 
            context.discussed_tours,
            TOUR_NAME_TO_INDEX
        )
        
        # Náº¿u tÃ¬m tháº¥y tour cá»¥ thá»ƒ, cáº­p nháº­t context
        if current_tour_indices:
            context.current_tour = current_tour_indices[0]
            if context.current_tour not in context.discussed_tours:
                context.discussed_tours.append(context.current_tour)
        
        # ================== Xá»¬ LÃ ÄA TÃC Vá»¤ THÃ”NG MINH ==================
        reply = ""
        sources = []
        tour_indices = []
        
        # ðŸ”¹ TRÆ¯á»œNG Há»¢P 1: Há»ŽI Vá»€ TOUR Cá»¤ THá»‚ ÄANG THáº¢O LUáº¬N
        if ('price_inquiry' in intents or 'tour_detail' in intents) and context.current_tour:
            logger.info(f"ðŸ’Ž Processing specific tour inquiry: {context.current_tour}")
            
            tour = TOURS_DB.get(context.current_tour)
            if tour:
                if 'price_inquiry' in intents:
                    reply = f"ðŸ’° **GIÃ TOUR {tour.name.upper()}** ðŸ’°\n\n"
                    if tour.price:
                        # PhÃ¢n tÃ­ch cáº¥u trÃºc giÃ¡ thÃ´ng minh
                        price_analysis = _analyze_price_structure(tour.price)
                        reply += f"**Má»©c giÃ¡:** {price_analysis['range']}\n"
                        if price_analysis['per_person']:
                            reply += f"**GiÃ¡/ngÆ°á»i:** {price_analysis['per_person']}\n"
                        if price_analysis['group_discount']:
                            reply += f"**Chiáº¿t kháº¥u nhÃ³m:** {price_analysis['group_discount']}\n"
                        
                        # TÃ­nh toÃ¡n cho nhÃ³m cá»¥ thá»ƒ
                        if context.user_profile['group_size']:
                            group_price = _calculate_group_price(
                                tour.price, 
                                context.user_profile['group_size'],
                                context.user_profile.get('is_veteran', False)
                            )
                            if group_price:
                                reply += f"\n**Dá»± kiáº¿n cho nhÃ³m {context.user_profile['group_size']} ngÆ°á»i:** {group_price}\n"
                    else:
                        reply += "GiÃ¡ tour linh hoáº¡t theo sá»‘ lÆ°á»£ng vÃ  dá»‹ch vá»¥.\n"
                    
                    reply += "\nðŸ“Š **CHI TIáº¾T GIÃ TRá»Š:**\n"
                    if tour.includes:
                        for i, item in enumerate(tour.includes[:5], 1):
                            reply += f"{i}. {item[:80]}{'...' if len(item) > 80 else ''}\n"
                    
                    reply += "\nðŸŽ¯ **Æ¯U ÄÃƒI Äáº¶C BIá»†T:**\n"
                    reply += "â€¢ NhÃ³m 10+ ngÆ°á»i: Giáº£m 5-20%\n"
                    reply += "â€¢ Cá»±u chiáº¿n binh: ThÃªm 5%\n"
                    reply += "â€¢ Äáº·t sá»›m trÆ°á»›c 30 ngÃ y: Giáº£m 5-8%\n"
                    reply += "\nðŸ“ž **LiÃªn há»‡ 0332510486 Ä‘á»ƒ nháº­n bÃ¡o giÃ¡ chÃ­nh xÃ¡c!**"
                
                elif 'tour_detail' in intents:
                    reply = f"ðŸ“‹ **CHI TIáº¾T TOUR: {tour.name}** ðŸ“‹\n\n"
                    
                    # ThÃ´ng tin cÆ¡ báº£n
                    if tour.summary:
                        reply += f"**Tá»•ng quan:** {tour.summary}\n\n"
                    
                    if tour.duration:
                        reply += f"â±ï¸ **Thá»i gian:** {tour.duration}\n"
                    
                    if tour.location:
                        reply += f"ðŸ“ **Äá»‹a Ä‘iá»ƒm:** {tour.location}\n"
                    
                    # Äiá»ƒm ná»•i báº­t
                    if tour.includes:
                        reply += "\nâœ¨ **ÄIá»‚M Ná»”I Báº¬T:**\n"
                        for i, item in enumerate(tour.includes[:8], 1):
                            reply += f"â€¢ {item}\n"
                    
                    # Lá»‹ch trÃ¬nh chi tiáº¿t (náº¿u cÃ³ trong includes)
                    schedule_items = [item for item in (tour.includes or []) 
                                    if any(keyword in item.lower() for keyword in ['ngÃ y', 'buá»•i', 'sÃ¡ng', 'trÆ°a', 'chiá»u', 'tá»‘i'])]
                    if schedule_items:
                        reply += "\nðŸ—“ï¸ **Lá»ŠCH TRÃŒNH CHI TIáº¾T:**\n"
                        for item in schedule_items[:5]:
                            reply += f"â€¢ {item}\n"
                    
                    # PhÃ¹ há»£p vá»›i ai
                    suitability = _analyze_tour_suitability(tour, context.user_profile)
                    reply += f"\nðŸŽ¯ **Äá»I TÆ¯á»¢NG PHÃ™ Há»¢P:**\n{suitability}\n"
                    
                    # Cáº£nh bÃ¡o náº¿u khÃ´ng phÃ¹ há»£p
                    warnings = _check_tour_warnings(tour, context.user_profile)
                    if warnings:
                        reply += f"\nâš ï¸ **LÆ¯U Ã QUAN TRá»ŒNG:**\n{warnings}\n"
                    
                    reply += "\nðŸ“ž **TÆ° váº¥n chi tiáº¿t & Ä‘áº·t tour:** 0332510486"
                
                tour_indices = [context.current_tour]
        
        # ðŸ”¹ TRÆ¯á»œNG Há»¢P 2: SO SÃNH TOUR THÃ”NG MINH
        elif 'comparison' in intents:
            logger.info("âš–ï¸ Processing intelligent tour comparison")
            
            # TrÃ­ch xuáº¥t tour names tá»« cÃ¢u há»i vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao
            tour_names = _extract_tour_names_for_comparison(user_message, TOUR_NAME_TO_INDEX)
            
            if not tour_names and context.discussed_tours:
                # Náº¿u khÃ´ng tÃ¬m tháº¥y tÃªn tour, dÃ¹ng cÃ¡c tour Ä‘Ã£ tháº£o luáº­n
                tour_indices = context.discussed_tours[-2:]  # Láº¥y 2 tour gáº§n nháº¥t
            elif tour_names:
                # Map tÃªn tour sang indices
                for name in tour_names:
                    for norm_name, idx in TOUR_NAME_TO_INDEX.items():
                        if name.lower() in norm_name.lower():
                            tour_indices.append(idx)
                            break
            
            if len(tour_indices) >= 2:
                # KÃ­ch hoáº¡t cháº¿ Ä‘á»™ so sÃ¡nh
                context.comparison_mode = True
                
                # Táº¡o báº£ng so sÃ¡nh chi tiáº¿t
                comparison_data = []
                for idx in tour_indices[:3]:  # Tá»‘i Ä‘a 3 tour
                    tour = TOURS_DB.get(idx)
                    if tour:
                        comparison_data.append({
                            'name': tour.name,
                            'duration': tour.duration or 'N/A',
                            'location': tour.location or 'N/A',
                            'price': _extract_price_range(tour.price) if tour.price else 'LiÃªn há»‡',
                            'style': tour.style[:100] + '...' if tour.style and len(tour.style) > 100 else tour.style or 'N/A',
                            'suitability': _analyze_tour_suitability(tour, context.user_profile),
                            'highlights': tour.includes[:3] if tour.includes else [],
                            'tags': tour.tags or []
                        })
                
                if len(comparison_data) >= 2:
                    reply = "ðŸ“Š **SO SÃNH CHI TIáº¾T TOUR** ðŸ“Š\n\n"
                    
                    # Táº¡o báº£ng so sÃ¡nh
                    headers = ["TIÃŠU CHÃ"] + [tour['name'][:25] for tour in comparison_data]
                    
                    # CÃ¡c tiÃªu chÃ­ so sÃ¡nh
                    criteria = [
                        ('â±ï¸ Thá»i gian', lambda t: t['duration']),
                        ('ðŸ“ Äá»‹a Ä‘iá»ƒm', lambda t: t['location'][:30] if t['location'] else 'N/A'),
                        ('ðŸ’° GiÃ¡ cáº£', lambda t: t['price']),
                        ('ðŸŽ¯ Phong cÃ¡ch', lambda t: t['style'][:30] + '...' if t['style'] and len(t['style']) > 30 else t['style']),
                        ('ðŸ‘¥ PhÃ¹ há»£p', lambda t: t['suitability'][:40] + '...' if len(t['suitability']) > 40 else t['suitability'])
                    ]
                    
                    for criterion, get_value in criteria:
                        row = [criterion]
                        for tour in comparison_data:
                            value = get_value(tour)
                            row.append(value or 'N/A')
                        
                        # Format hÃ ng
                        row_str = " | ".join([str(cell).ljust(25) for cell in row])
                        reply += f"{row_str}\n"
                        reply += "-" * (len(row) * 27) + "\n"
                    
                    # PhÃ¢n tÃ­ch sÃ¢u
                    reply += "\nðŸ” **PHÃ‚N TÃCH CHUYÃŠN SÃ‚U:**\n"
                    
                    # So sÃ¡nh giÃ¡
                    prices = []
                    for tour in comparison_data:
                        if 'price' in tour and isinstance(tour['price'], str):
                            nums = re.findall(r'[\d,.]+', tour['price'])
                            if nums:
                                try:
                                    clean_num = int(nums[0].replace(',', '').replace('.', ''))
                                    prices.append((tour['name'], clean_num))
                                except:
                                    pass
                    
                    if prices:
                        min_tour = min(prices, key=lambda x: x[1])
                        max_tour = max(prices, key=lambda x: x[1])
                        if max_tour[1] > min_tour[1] * 1.3:
                            reply += f"â€¢ **Tiáº¿t kiá»‡m nháº¥t:** {min_tour[0]} ({min_tour[1]:,}Ä‘)\n"
                            reply += f"â€¢ **Äáº§y Ä‘á»§ tráº£i nghiá»‡m:** {max_tour[0]}\n"
                    
                    # So sÃ¡nh Ä‘á»™ phÃ¹ há»£p
                    for tour in comparison_data:
                        if 'gia Ä‘Ã¬nh' in tour['suitability'].lower() and 'tráº» em' in tour['suitability'].lower():
                            reply += f"â€¢ **Cho gia Ä‘Ã¬nh:** {tour['name']}\n"
                        if 'lá»‹ch sá»­' in tour['style'].lower() or any('history' in tag for tag in tour.get('tags', [])):
                            reply += f"â€¢ **Yáº¿u tá»‘ lá»‹ch sá»­:** {tour['name']}\n"
                        if 'thiá»n' in tour['style'].lower() or any('meditation' in tag for tag in tour.get('tags', [])):
                            reply += f"â€¢ **Thiá»n & chá»¯a lÃ nh:** {tour['name']}\n"
                    
                    # Khuyáº¿n nghá»‹ dá»±a trÃªn profile
                    if context.user_profile['ages']:
                        age_warnings = []
                        for tour in comparison_data:
                            if any('trekking' in str(tour['highlights']).lower() or 'Ä‘i bá»™' in str(tour['highlights']).lower()):
                                if any(age > 60 for age in context.user_profile['ages']):
                                    age_warnings.append(f"â€¢ {tour['name']} cÃ³ trekking, cÃ¢n nháº¯c vá»›i ngÆ°á»i lá»›n tuá»•i\n")
                        
                        if age_warnings:
                            reply += "\nâš ï¸ **Cáº¢NH BÃO PHÃ™ Há»¢P:**\n" + "".join(age_warnings)
                    
                    reply += "\nðŸ’¡ **Lá»œI KHUYÃŠN:**\n"
                    reply += "1. Xem xÃ©t yáº¿u tá»‘ Æ°u tiÃªn (giÃ¡, thá»i gian, tráº£i nghiá»‡m)\n"
                    reply += "2. Kiá»ƒm tra ká»¹ Ä‘á»™ phÃ¹ há»£p vá»›i thÃ nh viÃªn\n"
                    reply += "3. LiÃªn há»‡ tÆ° váº¥n Ä‘á»ƒ hiá»ƒu rÃµ hÆ¡n vá» tá»«ng tour\n\n"
                    reply += "ðŸ“ž **TÆ° váº¥n chá»n tour phÃ¹ há»£p:** 0332510486"
            
            else:
                reply = "Äá»ƒ so sÃ¡nh tour, vui lÃ²ng cung cáº¥p tÃªn 2-3 tour cá»¥ thá»ƒ. VÃ­ dá»¥:\n"
                reply += "â€¢ 'So sÃ¡nh tour Báº¡ch MÃ£ vÃ  tour TrÆ°á»ng SÆ¡n'\n"
                reply += "â€¢ 'Tour nÃ o tá»‘t hÆ¡n giá»¯a MÆ°a Äá» vÃ  KÃ½ á»©c?'\n"
                reply += "â€¢ 'PhÃ¢n biá»‡t tour 1 ngÃ y vÃ  2 ngÃ y cá»§a Ruby Wings'"
        
        # ðŸ”¹ TRÆ¯á»œNG Há»¢P 3: Äá»€ XUáº¤T TOUR THÃ”NG MINH
        elif 'recommendation' in intents or any(word in message_lower for word in ['phÃ¹ há»£p', 'gá»£i Ã½', 'tÆ° váº¥n']):
            logger.info("ðŸŽ¯ Processing intelligent recommendation")
            
            # PhÃ¢n tÃ­ch nhu cáº§u chi tiáº¿t
            requirements = _analyze_user_requirements(user_message, context.user_profile)
            
            # TÃ¬m tour phÃ¹ há»£p vá»›i Ä‘iá»ƒm sá»‘ chi tiáº¿t
            scored_tours = []
            for idx, tour in TOURS_DB.items():
                score, reasons, warnings = _calculate_tour_match_score(
                    tour, 
                    requirements, 
                    context.user_profile
                )
                
                if score > 0:
                    scored_tours.append({
                        'index': idx,
                        'score': score,
                        'tour': tour,
                        'reasons': reasons,
                        'warnings': warnings,
                        'match_percentage': min(100, int(score * 10))
                    })
            
            # Sáº¯p xáº¿p theo Ä‘iá»ƒm
            scored_tours.sort(key=lambda x: x['score'], reverse=True)
            
            if scored_tours:
                reply = "ðŸŽ¯ **Äá»€ XUáº¤T TOUR THÃ”NG MINH** ðŸŽ¯\n\n"
                
                # Tour phÃ¹ há»£p nháº¥t
                top_tour = scored_tours[0]
                reply += f"ðŸ† **PHÃ™ Há»¢P NHáº¤T ({top_tour['match_percentage']}%)**\n"
                reply += f"**{top_tour['tour'].name}**\n"
                
                if top_tour['reasons']:
                    reply += f"âœ… **LÃ½ do:** {', '.join(top_tour['reasons'][:3])}\n"
                
                if top_tour['tour'].duration:
                    reply += f"â±ï¸ {top_tour['tour'].duration} | "
                if top_tour['tour'].location:
                    reply += f"ðŸ“ {top_tour['tour'].location[:40]}\n"
                
                # ThÃ´ng tin quan trá»ng
                if top_tour['tour'].price:
                    price_summary = _summarize_price(top_tour['tour'].price)
                    reply += f"ðŸ’° {price_summary}\n"
                
                if top_tour['warnings']:
                    reply += f"âš ï¸ **LÆ°u Ã½:** {top_tour['warnings'][0]}\n"
                
                reply += "\n"
                
                # CÃ¡c lá»±a chá»n khÃ¡c (2-3 tour)
                other_tours = scored_tours[1:4]
                if other_tours:
                    reply += "ðŸ“‹ **Lá»°A CHá»ŒN KHÃC:**\n"
                    for t in other_tours:
                        reply += f"â€¢ **{t['tour'].name}** ({t['match_percentage']}%)\n"
                        if t['tour'].duration:
                            reply += f"  â±ï¸ {t['tour'].duration}"
                        if t['tour'].location:
                            reply += f" | ðŸ“ {t['tour'].location[:25]}"
                        reply += "\n"
                
                # Khuyáº¿n nghá»‹ dá»±a trÃªn phÃ¢n tÃ­ch sÃ¢u
                reply += "\nðŸ” **PHÃ‚N TÃCH CHUYÃŠN SÃ‚U:**\n"
                
                # Kiá»ƒm tra tÃ­nh phÃ¹ há»£p vá»›i tá»«ng thÃ nh viÃªn
                if requirements.get('has_elderly') and requirements.get('has_children'):
                    family_tours = [t for t in scored_tours[:3] 
                                  if 'gia Ä‘Ã¬nh' in str(t['reasons']).lower()]
                    if family_tours:
                        reply += "â€¢ âœ… **Ráº¥t phÃ¹ há»£p cho gia Ä‘Ã¬nh Ä‘a tháº¿ há»‡**\n"
                
                if requirements.get('needs_gentle'):
                    gentle_tours = [t for t in scored_tours[:3] 
                                  if any('nháº¹ nhÃ ng' in reason.lower() for reason in t['reasons'])]
                    if gentle_tours:
                        reply += "â€¢ âœ… **Nhá»‹p Ä‘á»™ nháº¹ nhÃ ng, khÃ´ng vá»™i vÃ£**\n"
                
                if requirements.get('budget_conscious'):
                    budget_tours = [t for t in scored_tours[:3] 
                                  if _is_budget_friendly(t['tour'].price)]
                    if budget_tours:
                        reply += "â€¢ âœ… **GiÃ¡ cáº£ há»£p lÃ½, tiáº¿t kiá»‡m**\n"
                
                # Cáº£nh bÃ¡o náº¿u cÃ³
                if requirements.get('has_children') and requirements.get('children_ages'):
                    for t in scored_tours[:2]:
                        if 'trekking' in str(t['tour'].includes).lower():
                            reply += f"â€¢ âš ï¸ **{t['tour'].name} cÃ³ trekking, cÃ¢n nháº¯c vá»›i tráº» nhá»**\n"
                
                reply += "\nðŸ’¡ **Báº N Cáº¦N BIáº¾T:**\n"
                reply += "â€¢ Má»—i tour cÃ³ Ä‘iá»ƒm máº¡nh riÃªng, phÃ¹ há»£p vá»›i nhu cáº§u khÃ¡c nhau\n"
                reply += "â€¢ CÃ³ thá»ƒ káº¿t há»£p hoáº·c tÃ¹y chá»‰nh tour theo yÃªu cáº§u\n"
                reply += "â€¢ LiÃªn há»‡ tÆ° váº¥n Ä‘á»ƒ Ä‘Æ°á»£c phÃ¢n tÃ­ch chi tiáº¿t hÆ¡n\n\n"
                reply += "ðŸ“ž **TÆ° váº¥n chá»n tour hoÃ n háº£o:** 0332510486"
                
                tour_indices = [t['index'] for t in scored_tours[:3]]
            
            else:
                # Sá»­ dá»¥ng AI Ä‘á»ƒ Ä‘á» xuáº¥t thÃ´ng minh khi khÃ´ng tÃ¬m tháº¥y
                if client and HAS_OPENAI:
                    try:
                        profile_summary = _summarize_user_profile(context.user_profile)
                        
                        prompt = f"""Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n tour Ruby Wings. KhÃ¡ch hÃ ng cÃ³ nhu cáº§u nhÆ°ng chÆ°a tÃ¬m tháº¥y tour phÃ¹ há»£p ngay.

THÃ”NG TIN KHÃCH:
{profile_summary}

YÃŠU Cáº¦U Cá»¤ THá»‚:
{user_message}

THÃ”NG TIN RUBY WINGS:
- 32 tour Ä‘a dáº¡ng: lá»‹ch sá»­, thiá»n, thiÃªn nhiÃªn, biá»ƒn Ä‘áº£o
- Tour 1 ngÃ y Ä‘áº¿n 6 ngÃ y
- PhÃ¹ há»£p má»i Ä‘á»‘i tÆ°á»£ng

YÃŠU Cáº¦U TRáº¢ Lá»œI:
1. Thá»«a nháº­n nhu cáº§u phá»©c táº¡p
2. Äá» nghá»‹ chia nhá» nhu cáº§u Ä‘á»ƒ tÆ° váº¥n tá»‘t hÆ¡n
3. Gá»£i Ã½ cÃ¡c loáº¡i tour cÃ³ thá»ƒ káº¿t há»£p
4. Má»i liÃªn há»‡ chuyÃªn gia

Giá»ng vÄƒn: ChuyÃªn nghiá»‡p, tháº¥u hiá»ƒu, nhiá»‡t tÃ¬nh"""

                        response = client.chat.completions.create(
                            model=CHAT_MODEL,
                            messages=[
                                {"role": "system", "content": prompt},
                                {"role": "user", "content": user_message}
                            ],
                            temperature=0.7,
                            max_tokens=400
                        )
                        
                        reply = response.choices[0].message.content if response.choices else ""
                        
                    except Exception as e:
                        logger.error(f"OpenAI recommendation error: {e}")
                        reply = "Nhu cáº§u cá»§a báº¡n khÃ¡ Ä‘áº·c biá»‡t. Äá»ƒ tÃ´i tÆ° váº¥n chÃ­nh xÃ¡c hÆ¡n:\n\n"
                        reply += "1. **Æ¯u tiÃªn hÃ ng Ä‘áº§u** cá»§a nhÃ³m báº¡n lÃ  gÃ¬? (giÃ¡ cáº£, tráº£i nghiá»‡m, an toÃ n)\n"
                        reply += "2. **Hoáº¡t Ä‘á»™ng yÃªu thÃ­ch** nháº¥t? (thiá»n, trekking, vÄƒn hÃ³a, áº©m thá»±c)\n"
                        reply += "3. **Háº¡n cháº¿** nÃ o cáº§n lÆ°u Ã½? (sá»©c khá»e, dá»‹ á»©ng, sá»Ÿ thÃ­ch)\n\n"
                        reply += "Hoáº·c liÃªn há»‡ trá»±c tiáº¿p chuyÃªn gia: ðŸ“ž 0332510486"
                else:
                    reply = "Äá»ƒ tÆ° váº¥n tour phÃ¹ há»£p nháº¥t, vui lÃ²ng cung cáº¥p thÃªm thÃ´ng tin:\n"
                    reply += "â€¢ Sá»‘ lÆ°á»£ng vÃ  Ä‘á»™ tuá»•i thÃ nh viÃªn\n"
                    reply += "â€¢ Sá»Ÿ thÃ­ch chÃ­nh cá»§a nhÃ³m\n"
                    reply += "â€¢ NgÃ¢n sÃ¡ch dá»± kiáº¿n\n"
                    reply += "â€¢ Thá»i gian cÃ³ thá»ƒ Ä‘i\n\n"
                    reply += "ðŸ“ž **Hoáº·c gá»i ngay:** 0332510486"
        
        # ðŸ”¹ TRÆ¯á»œNG Há»¢P 4: TÃŒM TOUR THEO TIÃŠU CHÃ PHá»¨C Táº P
        elif any(keyword in intents for keyword in ['family', 'senior', 'children', 'veteran', 'retreat']):
            logger.info("ðŸŽ¯ Processing complex criteria search")
            
            # Ãp dá»¥ng bá»™ lá»c thÃ´ng minh
            filtered_tours = _apply_intelligent_filters(TOURS_DB, context.user_profile, user_message)
            
            if filtered_tours:
                reply = f"ðŸ” **TÃŒM THáº¤Y {len(filtered_tours)} TOUR PHÃ™ Há»¢P** ðŸ”\n\n"
                
                # NhÃ³m tour theo loáº¡i
                tour_categories = {
                    'Gia Ä‘Ã¬nh & Nháº¹ nhÃ ng': [],
                    'Lá»‹ch sá»­ & Tri Ã¢n': [],
                    'Thiá»n & Retreat': [],
                    'ThiÃªn nhiÃªn & KhÃ¡m phÃ¡': []
                }
                
                for idx, tour in filtered_tours[:10]:  # Giá»›i háº¡n 10 tour
                    category = _categorize_tour(tour)
                    tour_categories[category].append((idx, tour))
                
                # Hiá»ƒn thá»‹ theo nhÃ³m
                displayed_count = 0
                for category, tours in tour_categories.items():
                    if tours:
                        reply += f"**{category}:**\n"
                        for idx, tour in tours[:3]:  # 3 tour má»—i nhÃ³m
                            displayed_count += 1
                            emoji = "ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦" if 'gia Ä‘Ã¬nh' in category.lower() else \
                                   "ðŸ›ï¸" if 'lá»‹ch sá»­' in category.lower() else \
                                   "ðŸ•‰ï¸" if 'thiá»n' in category.lower() else "ðŸŒ¿"
                            
                            reply += f"{emoji} **{tour.name}**\n"
                            if tour.duration:
                                reply += f"   â±ï¸ {tour.duration}"
                            if tour.location:
                                reply += f" | ðŸ“ {tour.location[:25]}\n"
                            
                            # Äiá»ƒm phÃ¹ há»£p
                            score, reasons, _ = _calculate_tour_match_score(
                                tour, 
                                _analyze_user_requirements(user_message, context.user_profile),
                                context.user_profile
                            )
                            if reasons:
                                reply += f"   âœ… {reasons[0][:50]}...\n"
                            reply += "\n"
                
                if displayed_count < len(filtered_tours):
                    reply += f"ðŸ“Š **VÃ  {len(filtered_tours) - displayed_count} tour khÃ¡c phÃ¹ há»£p...**\n\n"
                
                reply += "ðŸ’¡ **Máº¸O CHá»ŒN TOUR:**\n"
                reply += "1. Tour gia Ä‘Ã¬nh: Æ¯u tiÃªn nhá»‹p Ä‘á»™ cháº­m, Ã­t trekking\n"
                reply += "2. Tour lá»‹ch sá»­: PhÃ¹ há»£p giÃ¡o dá»¥c vÃ  tri Ã¢n\n"
                reply += "3. Tour retreat: Táº­p trung thiá»n vÃ  chá»¯a lÃ nh\n"
                reply += "4. Tour thiÃªn nhiÃªn: KhÃ¡m phÃ¡ vÃ  tráº£i nghiá»‡m máº¡nh\n\n"
                reply += "ðŸ“ž **TÆ° váº¥n chá»n tour theo tiÃªu chÃ­:** 0332510486"
                
                tour_indices = [idx for idx, _ in filtered_tours[:5]]
            
            else:
                reply = "Hiá»‡n chÆ°a cÃ³ tour nÃ o Ä‘Ã¡p á»©ng Ä‘áº§y Ä‘á»§ cÃ¡c tiÃªu chÃ­ cá»§a báº¡n. Tuy nhiÃªn:\n\n"
                reply += "âœ… **GIáº¢I PHÃP THAY THáº¾:**\n"
                reply += "1. **Tour tÃ¹y chá»‰nh:** Ruby Wings cÃ³ thá»ƒ thiáº¿t káº¿ tour riÃªng\n"
                reply += "2. **Äiá»u chá»‰nh tiÃªu chÃ­:** Má»Ÿ rá»™ng má»™t sá»‘ yÃªu cáº§u\n"
                reply += "3. **Káº¿t há»£p nhiá»u tour:** Chá»n 2 tour ngáº¯n thay vÃ¬ 1 tour dÃ i\n\n"
                reply += "ðŸ“ž **LiÃªn há»‡ thiáº¿t káº¿ tour riÃªng:** 0332510486"
        
        # ðŸ”¹ TRÆ¯á»œNG Há»¢P 5: THÃ”NG TIN CHUNG & TRIáº¾T LÃ
        elif 'general_info' in intents:
            logger.info("ðŸ›ï¸ Processing enhanced general info")
            
            if 'triáº¿t lÃ½' in message_lower or 'chuáº©n má»±c' in message_lower:
                reply = "âœ¨ **TRIáº¾T LÃ RUBY WINGS: CHUáº¨N Má»°C - CHÃ‚N THÃ€NH - CÃ“ CHIá»€U SÃ‚U** âœ¨\n\n"
                reply += "**1. CHUáº¨N Má»°C TRONG Tá»ªNG TOUR:**\n"
                reply += "â€¢ **An toÃ n tuyá»‡t Ä‘á»‘i:** TiÃªu chuáº©n cao nháº¥t vá» an toÃ n\n"
                reply += "â€¢ **Dá»‹ch vá»¥ chuáº©n:** Tá»« xe Ä‘á»i má»›i Ä‘áº¿n hÆ°á»›ng dáº«n viÃªn chuyÃªn nghiá»‡p\n"
                reply += "â€¢ **Minh báº¡ch:** GiÃ¡ cáº£ rÃµ rÃ ng, khÃ´ng phÃ¡t sinh\n\n"
                
                reply += "**2. CHÃ‚N THÃ€NH TRONG Tá»ªNG Káº¾T Ná»I:**\n"
                reply += "â€¢ **Giao tiáº¿p tháº­t:** TÆ° váº¥n trung thá»±c, khÃ´ng Ã©p mua\n"
                reply += "â€¢ **Äá»“ng hÃ nh tháº­t:** HDV táº­n tÃ¢m, hiá»ƒu khÃ¡ch hÃ ng\n"
                reply += "â€¢ **Tráº£i nghiá»‡m tháº­t:** KhÃ¡m phÃ¡ báº£n cháº¥t, khÃ´ng chá»‰ bá» ná»•i\n\n"
                
                reply += "**3. CÃ“ CHIá»€U SÃ‚U TRONG Tá»ªNG TRáº¢I NGHIá»†M:**\n"
                reply += "â€¢ **Ã nghÄ©a:** Má»—i tour mang thÃ´ng Ä‘iá»‡p riÃªng (tri Ã¢n, chá»¯a lÃ nh, khÃ¡m phÃ¡)\n"
                reply += "â€¢ **GiÃ¡ trá»‹:** Äá»ng láº¡i bÃ i há»c, cáº£m xÃºc, ká»· niá»‡m\n"
                reply += "â€¢ **Chuyá»ƒn hÃ³a:** GiÃºp khÃ¡ch hÃ ng thay Ä‘á»•i tÃ­ch cá»±c sau tour\n\n"
                
                reply += "ðŸ† **THá»‚ HIá»†N TRONG TOUR:**\n"
                reply += "â€¢ Tour lá»‹ch sá»­: Tri Ã¢n sÃ¢u sáº¯c, khÃ´ng chá»‰ tham quan\n"
                reply += "â€¢ Tour thiá»n: Chá»¯a lÃ nh thá»±c sá»±, khÃ´ng chá»‰ nghá»‰ dÆ°á»¡ng\n"
                reply += "â€¢ Tour gia Ä‘Ã¬nh: Káº¿t ná»‘i thá»±c cháº¥t, khÃ´ng chá»‰ vui chÆ¡i\n\n"
                reply += "ðŸ“ž **Tráº£i nghiá»‡m triáº¿t lÃ½ nÃ y:** 0332510486"
            
            elif 'khÃ¡c biá»‡t' in message_lower or 'Ä‘iá»ƒm máº¡nh' in message_lower:
                reply = "ðŸš€ **ÄIá»‚M KHÃC BIá»†T Cá»¦A RUBY WINGS** ðŸš€\n\n"
                reply += "**1. TOUR CÃ“ CHIá»€U SÃ‚U:**\n"
                reply += "â€¢ KhÃ´ng chá»‰ tham quan, mÃ  cÃ²n tráº£i nghiá»‡m Ã½ nghÄ©a\n"
                reply += "â€¢ Má»—i tour cÃ³ thÃ´ng Ä‘iá»‡p riÃªng (tri Ã¢n, chá»¯a lÃ nh, khÃ¡m phÃ¡)\n"
                reply += "â€¢ Káº¿t há»£p thiá»n, khÃ­ cÃ´ng, trá»‹ liá»‡u thiÃªn nhiÃªn\n\n"
                
                reply += "**2. CHUYÃŠN GIA THá»°C Sá»°:**\n"
                reply += "â€¢ HDV am hiá»ƒu sÃ¢u vá» lá»‹ch sá»­, vÄƒn hÃ³a, thiá»n\n"
                reply += "â€¢ CÃ³ chuyÃªn gia sá»©c khá»e Ä‘á»“ng hÃ nh trong tour retreat\n"
                reply += "â€¢ Káº¿t ná»‘i vá»›i nhÃ¢n chá»©ng lá»‹ch sá»­, nghá»‡ nhÃ¢n Ä‘á»‹a phÆ°Æ¡ng\n\n"
                
                reply += "**3. LINH HOáº T CAO:**\n"
                reply += "â€¢ Thiáº¿t káº¿ tour theo yÃªu cáº§u\n"
                reply += "â€¢ Äiá»u chá»‰nh lá»‹ch trÃ¬nh phÃ¹ há»£p vá»›i nhÃ³m\n"
                reply += "â€¢ Há»— trá»£ 24/7 trong suá»‘t hÃ nh trÃ¬nh\n\n"
                
                reply += "**4. GIÃ TRá»Š Bá»€N Vá»®NG:**\n"
                reply += "â€¢ TÃ´n trá»ng vÄƒn hÃ³a báº£n Ä‘á»‹a\n"
                reply += "â€¢ Báº£o vá»‡ mÃ´i trÆ°á»ng Ä‘iá»ƒm Ä‘áº¿n\n"
                reply += "â€¢ Há»— trá»£ cá»™ng Ä‘á»“ng Ä‘á»‹a phÆ°Æ¡ng\n\n"
                
                reply += "ðŸŽ¯ **SO SÃNH Vá»šI CÃ”NG TY KHÃC:**\n"
                reply += "| TiÃªu chÃ­ | Ruby Wings | CÃ´ng ty thÆ°á»ng |\n"
                reply += "|----------|------------|----------------|\n"
                reply += "| Äá»™ sÃ¢u | â­â­â­â­â­ | â­â­ |\n"
                reply += "| CÃ¡ nhÃ¢n hÃ³a | â­â­â­â­â­ | â­â­ |\n"
                reply += "| ChuyÃªn mÃ´n | â­â­â­â­â­ | â­â­â­ |\n"
                reply += "| Linh hoáº¡t | â­â­â­â­â­ | â­â­ |\n"
                reply += "| GiÃ¡ trá»‹ | â­â­â­â­â­ | â­â­â­ |\n\n"
                reply += "ðŸ“ž **Tráº£i nghiá»‡m sá»± khÃ¡c biá»‡t:** 0332510486"
            
            else:
                reply = "ðŸ›ï¸ **RUBY WINGS TRAVEL - HÃ€NH TRÃŒNH Ã NGHÄ¨A** ðŸ›ï¸\n\n"
                reply += "**Sá»¨ Má»†NH:** Lan tá»a giÃ¡ trá»‹ sá»‘ng Chuáº©n má»±c - ChÃ¢n thÃ nh - CÃ³ chiá»u sÃ¢u\n\n"
                reply += "**3 TRá»¤ Cá»˜T CHÃNH:**\n"
                reply += "1. **TOUR Lá»ŠCH Sá»¬ - TRI Ã‚N**\n"
                reply += "   â€¢ Káº¿t ná»‘i quÃ¡ khá»© - hiá»‡n táº¡i\n"
                reply += "   â€¢ Gáº·p gá»¡ nhÃ¢n chá»©ng, cá»±u chiáº¿n binh\n"
                reply += "   â€¢ Tham quan di tÃ­ch vá»›i gÃ³c nhÃ¬n sÃ¢u\n\n"
                
                reply += "2. **TOUR RETREAT - CHá»®A LÃ€NH**\n"
                reply += "   â€¢ Thiá»n, khÃ­ cÃ´ng, yoga giá»¯a thiÃªn nhiÃªn\n"
                reply += "   â€¢ TÄ©nh tÃ¢m, giáº£m stress, cÃ¢n báº±ng nÄƒng lÆ°á»£ng\n"
                reply += "   â€¢ Káº¿t há»£p trá»‹ liá»‡u thiÃªn nhiÃªn\n\n"
                
                reply += "3. **TOUR TRáº¢I NGHIá»†M - KHÃM PHÃ**\n"
                reply += "   â€¢ VÄƒn hÃ³a báº£n Ä‘á»‹a, áº©m thá»±c Ä‘áº·c sáº¯c\n"
                reply += "   â€¢ ThiÃªn nhiÃªn nguyÃªn sÆ¡, biá»ƒn Ä‘áº£o hoang sÆ¡\n"
                reply += "   â€¢ Hoáº¡t Ä‘á»™ng Ä‘á»™i nhÃ³m, teambuilding\n\n"
                
                reply += "**32 TOUR ÄA Dáº NG:**\n"
                reply += "â€¢ Thá»i gian: 1 ngÃ y Ä‘áº¿n 6 ngÃ y\n"
                reply += "â€¢ Äá»‹a Ä‘iá»ƒm: Huáº¿, Quáº£ng Trá»‹, Báº¡ch MÃ£, TrÆ°á»ng SÆ¡n, PhÃº Quá»‘c, ÄÃ  Láº¡t...\n"
                reply += "â€¢ Äá»‘i tÆ°á»£ng: Gia Ä‘Ã¬nh, nhÃ³m, cÃ¡ nhÃ¢n, cá»±u chiáº¿n binh, há»c sinh\n\n"
                reply += "ðŸ“ž **Káº¿t ná»‘i vá»›i chÃºng tÃ´i:** 0332510486"
        
        # ðŸ”¹ TRÆ¯á»œNG Há»¢P 6: Xá»¬ LÃ CÃ‚U Há»ŽI NGOÃ€I PHáº M VI THÃ”NG MINH
        elif _is_out_of_scope(user_message):
            logger.info("ðŸŒ Processing out-of-scope intelligently")
            
            if 'chuyá»‡n cÆ°á»i' in message_lower:
                reply = "ðŸ˜Š **VUI Váºº CÃ™NG RUBY WINGS!** ðŸ˜Š\n\n"
                reply += "TÃ´i chuyÃªn vá» tÆ° váº¥n tour, nhÆ°ng cÃ³ thá»ƒ chia sáº» Ä‘iá»u thÃº vá»‹:\n\n"
                reply += "ðŸŽ­ **CÃ‚U CHUYá»†N VUI Vá»€ DU Lá»ŠCH:**\n"
                reply += "Má»™t khÃ¡ch há»i: 'Tour nÃ y cÃ³ nhiá»u muá»—i khÃ´ng?'\n"
                reply += "HDV Ä‘Ã¡p: 'KhÃ´ng áº¡, chÃºng tÃ´i Ä‘Ã£ dáº¡y chÃºng cÃ¡ch lá»‹ch sá»± rá»“i!' ðŸ¦ŸðŸ˜„\n\n"
                reply += "ðŸŽ¯ **THAY VÃ€O ÄÃ“, Báº N CÃ“ THá»‚:**\n"
                reply += "â€¢ Nghe nhá»¯ng cÃ¢u chuyá»‡n thÃº vá»‹ tá»« HDV trong tour\n"
                reply += "â€¢ Tráº£i nghiá»‡m khÃ´ng khÃ­ vui váº» táº¡i cÃ¡c Ä‘Ãªm lá»­a tráº¡i\n"
                reply += "â€¢ ThÆ°á»Ÿng thá»©c cÃ¡c tiáº¿t má»¥c vÄƒn nghá»‡ Ä‘áº·c sáº¯c\n\n"
                reply += "ðŸ“ž **Äáº·t tour Ä‘á»ƒ cÃ³ tráº£i nghiá»‡m vui váº» thá»±c sá»±:** 0332510486"
            
            else:
                reply = "ðŸŒ¿ **TÃ”I CHUYÃŠN Vá»€ DU Lá»ŠCH TRáº¢I NGHIá»†M** ðŸŒ¿\n\n"
                reply += "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n vá»›i:\n\n"
                reply += "ðŸŽ¯ **32 TOUR Äáº¶C Sáº®C:**\n"
                reply += "â€¢ Lá»‹ch sá»­, vÄƒn hÃ³a, thiÃªn nhiÃªn, biá»ƒn Ä‘áº£o\n"
                reply += "â€¢ Thiá»n, retreat, chá»¯a lÃ nh\n"
                reply += "â€¢ Gia Ä‘Ã¬nh, nhÃ³m, cÃ¡ nhÃ¢n hÃ³a\n\n"
                reply += "ðŸ” **THÃ”NG TIN CHI TIáº¾T:**\n"
                reply += "â€¢ GiÃ¡ cáº£, lá»‹ch trÃ¬nh, Ä‘á»‹a Ä‘iá»ƒm\n"
                reply += "â€¢ So sÃ¡nh cÃ¡c tour\n"
                reply += "â€¢ TÆ° váº¥n theo nhu cáº§u riÃªng\n\n"
                reply += "ðŸ’¡ **HÃƒY Há»ŽI TÃ”I Vá»€:**\n"
                reply += "â€¢ 'Tour nÃ o phÃ¹ há»£p cho gia Ä‘Ã¬nh cÃ³ tráº» nhá»?'\n"
                reply += "â€¢ 'So sÃ¡nh tour Báº¡ch MÃ£ vÃ  TrÆ°á»ng SÆ¡n'\n"
                reply += "â€¢ 'Tour retreat 1 ngÃ y giÃ¡ bao nhiÃªu?'\n\n"
                reply += "ðŸ“ž **Hotline tÆ° váº¥n má»i tháº¯c máº¯c:** 0332510486"
        
        # ðŸ”¹ TRÆ¯á»œNG Há»¢P 7: Máº¶C Äá»ŠNH - Xá»¬ LÃ THÃ”NG MINH Tá»”NG Há»¢P
        else:
            logger.info("ðŸ¤– Processing with intelligent synthesis")
            
            # TÃ¬m kiáº¿m semantic nÃ¢ng cao
            search_results = query_index(user_message, TOP_K * 2)  # TÃ¬m nhiá»u hÆ¡n
            
            if UpgradeFlags.is_enabled("2_DEDUPLICATION") and search_results:
                search_results = DeduplicationEngine.deduplicate_passages(search_results)
            
            # Ãp dá»¥ng bá»™ lá»c thÃ´ng minh
            filtered_indices = _apply_smart_filters_to_search(search_results, context.user_profile)
            
            if filtered_indices:
                tour_indices = filtered_indices[:5]
            elif search_results:
                # Láº¥y tour tá»« káº¿t quáº£ tÃ¬m kiáº¿m
                tour_indices = []
                for score, content in search_results:
                    # TÃ¬m tour index tá»« content
                    for idx, tour in TOURS_DB.items():
                        if tour.name in content and idx not in tour_indices:
                            tour_indices.append(idx)
                            if len(tour_indices) >= 3:
                                break
                    if len(tour_indices) >= 3:
                        break
            
            # Táº¡o prompt thÃ´ng minh vá»›i context Ä‘áº§y Ä‘á»§
            context_info = {
                'user_message': user_message,
                'user_profile': context.user_profile,
                'current_tour': context.current_tour,
                'discussed_tours': context.discussed_tours[-3:],  # 3 tour gáº§n nháº¥t
                'comparison_mode': context.comparison_mode,
                'tour_indices': tour_indices,
                'intents': intents
            }
            
            prompt = _prepare_llm_prompt_v2(user_message, search_results, context_info)
            
            # Gá»i AI vá»›i context phong phÃº
            if client and HAS_OPENAI:
                try:
                    messages = [
                        {"role": "system", "content": prompt},
                        {"role": "user", "content": user_message}
                    ]
                    
                    # ThÃªm lá»‹ch sá»­ há»™i thoáº¡i gáº§n nháº¥t
                    for msg in context.conversation_history[-4:-1]:  # 3 tin nháº¯n gáº§n nháº¥t (trá»« cÃ¡i cuá»‘i)
                        if msg['role'] in ['user', 'assistant']:
                            messages.insert(-1, {"role": msg['role'], "content": msg['message'][:200]})
                    
                    response = client.chat.completions.create(
                        model=CHAT_MODEL,
                        messages=messages,
                        temperature=0.7,
                        max_tokens=600,
                        top_p=0.9,
                        frequency_penalty=0.1,
                        presence_penalty=0.1
                    )
                    
                    if response.choices:
                        reply = response.choices[0].message.content or ""
                    else:
                        reply = _generate_intelligent_fallback(user_message, search_results, tour_indices, context_info)
                
                except Exception as e:
                    logger.error(f"OpenAI synthesis error: {e}")
                    reply = _generate_intelligent_fallback(user_message, search_results, tour_indices, context_info)
            else:
                reply = _generate_intelligent_fallback(user_message, search_results, tour_indices, context_info)
            
            sources = [m for _, m in search_results[:3]]
        
        # ================== NÃ‚NG CAO CHáº¤T LÆ¯á»¢NG PHáº¢N Há»’I ==================
        # Äáº£m báº£o tÃ­nh nháº¥t quÃ¡n vÃ  há»¯u Ã­ch
        reply = _enhance_response_quality(reply, context)
        
        # ThÃªm hotline náº¿u chÆ°a cÃ³
        if "0332510486" not in reply and "hotline" not in reply.lower():
            reply += "\n\nðŸ“ž **Hotline tÆ° váº¥n chuyÃªn sÃ¢u:** 0332510486"
        
        # Giá»›i háº¡n Ä‘á»™ dÃ i thÃ´ng minh
        if len(reply) > 2500:
            # Cáº¯t nhÆ°ng giá»¯ pháº§n quan trá»ng
            important_parts = reply.split('\n\n')
            if len(important_parts) > 3:
                reply = '\n\n'.join(important_parts[:4]) + "...\n\nðŸ’¡ **Äá»ƒ biáº¿t thÃªm chi tiáº¿t, vui lÃ²ng liÃªn há»‡ hotline 0332510486**"
            else:
                reply = reply[:2500] + "...\n\nðŸ’¡ **Äá»ƒ biáº¿t thÃªm chi tiáº¿t, vui lÃ²ng liÃªn há»‡ hotline 0332510486**"
        
        # ================== Cáº¬P NHáº¬T CONTEXT THÃ”NG MINH ==================
        # Cáº­p nháº­t tour Ä‘ang tháº£o luáº­n
        if tour_indices and not context.current_tour:
            context.current_tour = tour_indices[0]
        
        # LÆ°u cÃ¡c tour Ä‘Ã£ Ä‘á» cáº­p
        for idx in tour_indices:
            if idx not in context.discussed_tours:
                context.discussed_tours.append(idx)
        
        # Giá»›i háº¡n sá»‘ lÆ°á»£ng tour Ä‘Ã£ tháº£o luáº­n
        if len(context.discussed_tours) > 10:
            context.discussed_tours = context.discussed_tours[-5:]
        
        # LÆ°u pháº£n há»“i vÃ o lá»‹ch sá»­
        context.conversation_history.append({
            'role': 'assistant',
            'message': reply[:500],  # LÆ°u má»™t pháº§n Ä‘á»ƒ tiáº¿t kiá»‡m
            'timestamp': datetime.utcnow().isoformat(),
            'tour_indices': tour_indices,
            'intents': intents
        })
        
        # ================== PHáº¢N Há»’I CUá»I CÃ™NG ==================
        processing_time = time.time() - start_time
        
        chat_response = ChatResponse(
            reply=reply,
            sources=sources,
            context={
                "session_id": session_id,
                "current_tour": context.current_tour,
                "discussed_tours": context.discussed_tours[-3:],
                "user_profile": context.user_profile,
                "detected_intents": intents,
                "processing_time_ms": int(processing_time * 1000),
                "tours_found": len(tour_indices),
                "comparison_mode": context.comparison_mode
            },
            tour_indices=tour_indices,
            processing_time_ms=int(processing_time * 1000),
            from_memory=False
        )
        
        # Cache thÃ´ng minh vá»›i key phá»©c táº¡p
        if UpgradeFlags.get_all_flags().get("ENABLE_CACHING", True):
            context_hash = hashlib.md5(json.dumps({
                'tour_indices': tour_indices,
                'user_profile': context.user_profile,
                'current_tour': context.current_tour,
                'intents': intents
            }, sort_keys=True).encode()).hexdigest()
            
            cache_key = CacheSystem.get_cache_key(user_message, context_hash)
            CacheSystem.set(cache_key, chat_response.to_dict(), ttl=3600)  # 1 giá»
        
        logger.info(f"âœ… Processed in {processing_time:.2f}s | "
                   f"Intents: {intents} | "
                   f"Tours: {len(tour_indices)} | "
                   f"Profile: {context.user_profile}")
        
        return jsonify(chat_response.to_dict())
    
    except Exception as e:
        logger.error(f"âŒ Ultimate chat error: {e}\n{traceback.format_exc()}")
        
        processing_time = time.time() - start_time
        
        # Error response thÃ´ng minh
        error_response = ChatResponse(
            reply="âš¡ **XIN Lá»–I, CÃ“ CHÃšT TRá»¤C TRáº¶C!** âš¡\n\n"
                  "NhÆ°ng Ä‘á»«ng lo, Ruby Wings váº«n sáºµn sÃ ng há»— trá»£ báº¡n:\n\n"
                  "ðŸ”§ **GIáº¢I PHÃP NGAY:**\n"
                  "1. **Gá»i trá»±c tiáº¿p:** ðŸ“ž 0332510486 (Æ°u tiÃªn kháº©n cáº¥p)\n"
                  "2. **Thá»­ cÃ¡ch khÃ¡c:**\n"
                  "   â€¢ Há»i ngáº¯n gá»n hÆ¡n\n"
                  "   â€¢ Chá»‰ Ä‘á»‹nh tÃªn tour cá»¥ thá»ƒ\n"
                  "   â€¢ MÃ´ táº£ 1-2 nhu cáº§u chÃ­nh\n\n"
                  "ðŸŽ¯ **HOáº¶C Há»ŽI TÃ”I NGAY:**\n"
                  "â€¢ 'Tour 1 ngÃ y cho gia Ä‘Ã¬nh'\n"
                  "â€¢ 'So sÃ¡nh 2 tour phá»• biáº¿n nháº¥t'\n"
                  "â€¢ 'Tour giÃ¡ dÆ°á»›i 1 triá»‡u'\n\n"
                  "â° **ChÃºng tÃ´i luÃ´n sáºµn sÃ ng 24/7!** ðŸŒŸ",
            sources=[],
            context={
                "error": str(e),
                "processing_time_ms": int(processing_time * 1000)
            },
            tour_indices=[],
            processing_time_ms=int(processing_time * 1000),
            from_memory=False
        )
        
        return jsonify(error_response.to_dict()), 500


# =========== CÃC HÃ€M Há»– TRá»¢ THÃ”NG MINH ===========

def _extract_user_info(message: str, existing_profile: dict) -> dict:
    """TrÃ­ch xuáº¥t thÃ´ng tin ngÆ°á»i dÃ¹ng thÃ´ng minh tá»« message"""
    info = {}
    message_lower = message.lower()
    
    # Sá»‘ ngÆ°á»i
    people_patterns = [
        r'(\d+)\s*ngÆ°á»i',
        r'nhÃ³m\s*(\d+)',
        r'(\d+)\s*thÃ nh viÃªn',
        r'(\d+)\s*ngÆ°á»i tham gia'
    ]
    for pattern in people_patterns:
        match = re.search(pattern, message_lower)
        if match:
            info['group_size'] = int(match.group(1))
            break
    
    # Äá»™ tuá»•i
    if any(word in message_lower for word in ['tráº» em', 'con nhá»', 'tráº»', 'bÃ©']):
        info['has_children'] = True
        # Æ¯á»›c tÃ­nh tuá»•i tá»« context
        if 'tuá»•i' in message_lower:
            age_match = re.search(r'(\d+)\s*tuá»•i', message_lower)
            if age_match:
                info['children_ages'] = [int(age_match.group(1))]
        else:
            info['children_ages'] = [5, 15]  # Máº·c Ä‘á»‹nh
    
    if any(word in message_lower for word in ['ngÆ°á»i lá»›n tuá»•i', 'cao tuá»•i', 'Ã´ng bÃ ', 'cá»¥']):
        info['has_elderly'] = True
        info['needs_gentle'] = True
    
    # Sá»Ÿ thÃ­ch
    interests = []
    if any(word in message_lower for word in ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi', 'cÃ¢y']):
        interests.append('nature')
    if any(word in message_lower for word in ['lá»‹ch sá»­', 'di tÃ­ch', 'chiáº¿n tranh', 'tri Ã¢n']):
        interests.append('history')
    if any(word in message_lower for word in ['thiá»n', 'tÄ©nh tÃ¢m', 'yoga', 'chá»¯a lÃ nh']):
        interests.append('meditation')
    if any(word in message_lower for word in ['biá»ƒn', 'Ä‘áº£o', 'bÃ£i biá»ƒn']):
        interests.append('beach')
    if any(word in message_lower for word in ['áº©m thá»±c', 'Ä‘á»“ Äƒn', 'mÃ³n ngon']):
        interests.append('food')
    
    if interests:
        info['preferences'] = interests
    
    # NgÃ¢n sÃ¡ch
    budget_patterns = [
        r'(\d[\d,\.]+)\s*Ä‘á»“ng',
        r'(\d[\d,\.]+)\s*vnÄ‘',
        r'giÃ¡\s*(\d[\d,\.]+)',
        r'táº§m\s*(\d[\d,\.]+)'
    ]
    for pattern in budget_patterns:
        match = re.search(pattern, message_lower)
        if match:
            try:
                budget_str = match.group(1).replace(',', '').replace('.', '')
                budget = int(budget_str)
                if budget < 2000000:
                    info['budget_range'] = 'low'
                elif budget < 5000000:
                    info['budget_range'] = 'medium'
                else:
                    info['budget_range'] = 'high'
                break
            except:
                pass
    
    # Thá»i gian
    if '1 ngÃ y' in message_lower or 'ngÃ y' in message_lower:
        info['duration_pref'] = '1_day'
    elif '2 ngÃ y' in message_lower:
        info['duration_pref'] = '2_days'
    elif '3 ngÃ y' in message_lower:
        info['duration_pref'] = '3_days'
    
    # Nhu cáº§u Ä‘áº·c biá»‡t
    special_needs = []
    if any(word in message_lower for word in ['cá»±u chiáº¿n binh', 'ccb', 'veteran']):
        special_needs.append('veteran')
        info['is_veteran'] = True
    if any(word in message_lower for word in ['nháº¹ nhÃ ng', 'khÃ´ng vá»™i', 'cháº­m rÃ£i']):
        special_needs.append('gentle_pace')
        info['needs_gentle'] = True
    if any(word in message_lower for word in ['retreat', 'tÄ©nh dÆ°á»¡ng', 'nghá»‰ ngÆ¡i']):
        special_needs.append('retreat')
    
    if special_needs:
        info['special_needs'] = special_needs
    
    return info


def _detect_intents_with_llm(message: str, conversation_history: list) -> list:
    """PhÃ¡t hiá»‡n intent vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao sá»­ dá»¥ng LLM"""
    intents = []
    message_lower = message.lower()
    
    # Intent detection cÆ¡ báº£n
    intent_patterns = {
        'price_inquiry': ['giÃ¡', 'bao nhiÃªu tiá»n', 'chi phÃ­', 'cÃ³ Ä‘áº¯t khÃ´ng'],
        'tour_detail': ['chi tiáº¿t', 'lá»‹ch trÃ¬nh', 'cÃ³ gÃ¬', 'bao gá»“m'],
        'comparison': ['so sÃ¡nh', 'khÃ¡c nhau', 'nÃªn chá»n', 'tá»‘t hÆ¡n'],
        'recommendation': ['phÃ¹ há»£p', 'gá»£i Ã½', 'Ä‘á» xuáº¥t', 'tÆ° váº¥n'],
        'booking_info': ['Ä‘áº·t tour', 'Ä‘Äƒng kÃ½', 'booking', 'giá»¯ chá»—'],
        'general_info': ['giá»›i thiá»‡u', 'lÃ  gÃ¬', 'tháº¿ nÃ o', 'triáº¿t lÃ½'],
        'family': ['gia Ä‘Ã¬nh', 'tráº» em', 'con nhá»', 'bá»‘ máº¹'],
        'senior': ['ngÆ°á»i lá»›n tuá»•i', 'cao tuá»•i', 'Ã´ng bÃ '],
        'veteran': ['cá»±u chiáº¿n binh', 'ccb', 'chiáº¿n sÄ©'],
        'retreat': ['thiá»n', 'tÄ©nh tÃ¢m', 'retreat', 'chá»¯a lÃ nh'],
        'history': ['lá»‹ch sá»­', 'di tÃ­ch', 'tri Ã¢n', 'chiáº¿n tranh'],
        'nature': ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi', 'trekking'],
        'beach': ['biá»ƒn', 'Ä‘áº£o', 'bÃ£i biá»ƒn', 'cÃ¡t']
    }
    
    for intent, patterns in intent_patterns.items():
        for pattern in patterns:
            if pattern in message_lower:
                intents.append(intent)
                break
    
    # ThÃªm intent dá»±a trÃªn context
    if conversation_history:
        last_messages = [msg['message'].lower() for msg in conversation_history[-2:]]
        last_text = ' '.join(last_messages)
        
        # Náº¿u Ä‘ang nÃ³i vá» giÃ¡
        if any(word in last_text for word in ['giÃ¡', 'tiá»n', 'chi phÃ­']):
            intents.append('price_followup')
        
        # Náº¿u Ä‘ang so sÃ¡nh
        if any(word in last_text for word in ['so sÃ¡nh', 'khÃ¡c', 'giá»¯a']):
            intents.append('comparison_context')
    
    return list(set(intents))  # Remove duplicates


def _resolve_tour_reference(message: str, current_tour: int, discussed_tours: list, tour_name_map: dict) -> list:
    """XÃ¡c Ä‘á»‹nh tour Ä‘ang Ä‘Æ°á»£c tháº£o luáº­n thÃ´ng minh"""
    indices = []
    message_lower = message.lower()
    
    # Strategy 1: Tá»« khÃ³a chá»‰ Ä‘á»‹nh tour hiá»‡n táº¡i
    current_keywords = ['tour Ä‘Ã³', 'cÃ¡i Ä‘Ã³', 'nÃ³', 'cÃ¡i kia', 'tour nÃ y']
    if any(keyword in message_lower for keyword in current_keywords) and current_tour:
        return [current_tour]
    
    # Strategy 2: TÃªn tour cá»¥ thá»ƒ
    for norm_name, idx in tour_name_map.items():
        # Kiá»ƒm tra tÃªn tour cÃ³ trong message khÃ´ng
        name_words = set(norm_name.lower().split())
        msg_words = set(message_lower.split())
        common_words = name_words.intersection(msg_words)
        
        if len(common_words) >= 2:  # Ãt nháº¥t 2 tá»« trÃ¹ng
            indices.append(idx)
    
    # Strategy 3: Tour Ä‘Ã£ tháº£o luáº­n gáº§n Ä‘Ã¢y
    if not indices and discussed_tours:
        # Kiá»ƒm tra cÃ¡c tá»« khÃ³a liÃªn quan Ä‘áº¿n tour Ä‘Ã£ tháº£o luáº­n
        for idx in discussed_tours[-3:]:  # 3 tour gáº§n nháº¥t
            tour = TOURS_DB.get(idx)
            if tour:
                # Kiá»ƒm tra cÃ¡c tá»« khÃ³a liÃªn quan
                relevant_keywords = []
                if tour.location:
                    relevant_keywords.extend(tour.location.lower().split())
                if tour.tags:
                    for tag in tour.tags:
                        relevant_keywords.extend(tag.split(':'))
                
                if any(keyword in message_lower for keyword in relevant_keywords):
                    indices.append(idx)
    
    return indices[:3]  # Giá»›i háº¡n 3 tour


def _analyze_price_structure(price_text: str) -> dict:
    """PhÃ¢n tÃ­ch cáº¥u trÃºc giÃ¡ thÃ´ng minh"""
    analysis = {
        'range': price_text,
        'per_person': None,
        'group_discount': None,
        'notes': []
    }
    
    price_lower = price_text.lower()
    
    # TrÃ­ch xuáº¥t khoáº£ng giÃ¡
    ranges = re.findall(r'(\d[\d,\.]+)\s*â€“\s*(\d[\d,\.]+)', price_text)
    if ranges:
        analysis['range'] = f"{ranges[0][0]} â€“ {ranges[0][1]} VNÄ/ngÆ°á»i"
    
    # GiÃ¡ theo ngÆ°á»i
    if '/ngÆ°á»i' in price_lower or 'khÃ¡ch' in price_lower:
        analysis['per_person'] = 'GiÃ¡ tÃ­nh theo tá»«ng khÃ¡ch'
    
    # Chiáº¿t kháº¥u nhÃ³m
    if 'nhÃ³m' in price_lower:
        group_matches = re.findall(r'(\d+)%\s*nhÃ³m', price_lower)
        if group_matches:
            analysis['group_discount'] = f"Chiáº¿t kháº¥u {group_matches[0]}% cho nhÃ³m"
    
    # Ghi chÃº Ä‘áº·c biá»‡t
    special_keywords = ['cá»±u chiáº¿n binh', 'há»c sinh', 'sinh viÃªn', 'Ä‘áº·t sá»›m']
    for keyword in special_keywords:
        if keyword in price_lower:
            analysis['notes'].append(f"CÃ³ Æ°u Ä‘Ã£i cho {keyword}")
    
    return analysis


def _calculate_group_price(price_text: str, group_size: int, is_veteran: bool = False) -> str:
    """TÃ­nh toÃ¡n giÃ¡ cho nhÃ³m cá»¥ thá»ƒ"""
    try:
        # TrÃ­ch xuáº¥t giÃ¡ cÆ¡ báº£n
        numbers = re.findall(r'(\d[\d,\.]+)', price_text)
        if numbers:
            base_price = int(numbers[0].replace(',', '').replace('.', ''))
            
            # Ãp dá»¥ng chiáº¿t kháº¥u nhÃ³m
            discount = 0
            if group_size >= 10 and group_size < 15:
                discount = 0.05
            elif group_size >= 15 and group_size < 20:
                discount = 0.08
            elif group_size >= 20:
                discount = 0.11
            
            # ThÃªm chiáº¿t kháº¥u cá»±u chiáº¿n binh
            if is_veteran:
                discount += 0.05
            
            total = base_price * group_size * (1 - discount)
            
            # Format káº¿t quáº£
            if total > 1000000:
                return f"Khoáº£ng {total/1000000:.1f} triá»‡u VNÄ cho cáº£ nhÃ³m"
            else:
                return f"Khoáº£ng {total:,.0f} VNÄ cho cáº£ nhÃ³m"
    except:
        pass
    
    return None


def _analyze_tour_suitability(tour, user_profile: dict) -> str:
    """PhÃ¢n tÃ­ch Ä‘á»™ phÃ¹ há»£p cá»§a tour vá»›i ngÆ°á»i dÃ¹ng"""
    suitability = []
    tour_text = str(tour.includes or '') + ' ' + str(tour.style or '')
    tour_text_lower = tour_text.lower()
    
    # Kiá»ƒm tra cho gia Ä‘Ã¬nh
    if user_profile.get('has_children'):
        if any(word in tour_text_lower for word in ['gia Ä‘Ã¬nh', 'tráº» em', 'nháº¹ nhÃ ng']):
            suitability.append('PhÃ¹ há»£p gia Ä‘Ã¬nh')
        elif any(word in tour_text_lower for word in ['trekking', 'Ä‘i bá»™', 'Ä‘Æ°á»ng khÃ³']):
            suitability.append('Háº¡n cháº¿ vá»›i tráº» nhá»')
    
    # Kiá»ƒm tra cho ngÆ°á»i lá»›n tuá»•i
    if user_profile.get('has_elderly'):
        if any(word in tour_text_lower for word in ['nhá»‹p cháº­m', 'nháº¹ nhÃ ng', 'khÃ´ng trekking']):
            suitability.append('PhÃ¹ há»£p ngÆ°á»i lá»›n tuá»•i')
        elif any(word in tour_text_lower for word in ['Ä‘Æ°á»ng dá»‘c', 'leo nÃºi', 'váº¥t váº£']):
            suitability.append('KhÃ³ khÄƒn vá»›i ngÆ°á»i lá»›n tuá»•i')
    
    # Kiá»ƒm tra cho cá»±u chiáº¿n binh
    if user_profile.get('is_veteran'):
        if any(word in tour_text_lower for word in ['lá»‹ch sá»­', 'tri Ã¢n', 'cá»±u chiáº¿n binh']):
            suitability.append('Ráº¥t phÃ¹ há»£p cá»±u chiáº¿n binh')
    
    # Kiá»ƒm tra cho retreat
    if 'retreat' in user_profile.get('special_needs', []):
        if any(word in tour_text_lower for word in ['thiá»n', 'tÄ©nh tÃ¢m', 'retreat']):
            suitability.append('LÃ½ tÆ°á»Ÿng cho retreat')
    
    if not suitability:
        # PhÃ¢n tÃ­ch chung
        if any(word in tour_text_lower for word in ['lá»‹ch sá»­', 'di tÃ­ch']):
            suitability.append('PhÃ¹ há»£p yÃªu thÃ­ch lá»‹ch sá»­')
        elif any(word in tour_text_lower for word in ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi']):
            suitability.append('PhÃ¹ há»£p yÃªu thiÃªn nhiÃªn')
        elif any(word in tour_text_lower for word in ['biá»ƒn', 'Ä‘áº£o']):
            suitability.append('PhÃ¹ há»£p yÃªu biá»ƒn')
        else:
            suitability.append('Äa dáº¡ng Ä‘á»‘i tÆ°á»£ng')
    
    return ', '.join(suitability[:3])


def _check_tour_warnings(tour, user_profile: dict) -> str:
    """Kiá»ƒm tra vÃ  Ä‘Æ°a ra cáº£nh bÃ¡o vá» tour"""
    warnings = []
    tour_text = str(tour.includes or '') + ' ' + str(tour.notes or '')
    tour_text_lower = tour_text.lower()
    
    # Cáº£nh bÃ¡o cho tráº» em
    if user_profile.get('has_children'):
        if any(word in tour_text_lower for word in ['khÃ´ng phÃ¹ há»£p tráº»', 'tráº» dÆ°á»›i', 'háº¡n cháº¿ tráº»']):
            warnings.append('Tour khÃ´ng khuyáº¿n khÃ­ch cho tráº» em')
        elif any(word in tour_text_lower for word in ['trekking', 'Ä‘i bá»™ nhiá»u', 'Ä‘Æ°á»ng khÃ³']):
            warnings.append('CÃ³ hoáº¡t Ä‘á»™ng trekking, cÃ¢n nháº¯c vá»›i tráº» nhá»')
    
    # Cáº£nh bÃ¡o cho ngÆ°á»i lá»›n tuá»•i
    if user_profile.get('has_elderly'):
        if any(word in tour_text_lower for word in ['Ä‘Æ°á»ng dá»‘c', 'leo nÃºi', 'váº¥t váº£']):
            warnings.append('CÃ³ hoáº¡t Ä‘á»™ng thá»ƒ cháº¥t máº¡nh')
        elif 'sá»©c khá»e' in tour_text_lower:
            warnings.append('YÃªu cáº§u sá»©c khá»e tá»‘t')
    
    # Cáº£nh bÃ¡o chung
    if 'lÆ°u Ã½' in tour_text_lower or 'chÃº Ã½' in tour_text_lower:
        # TrÃ­ch xuáº¥t pháº§n lÆ°u Ã½
        notes_start = tour_text_lower.find('lÆ°u Ã½')
        if notes_start != -1:
            note_text = tour_text[notes_start:notes_start+200]
            warnings.append(f"LÆ°u Ã½ quan trá»ng: {note_text[:100]}...")
    
    return ', '.join(warnings[:2]) if warnings else "KhÃ´ng cÃ³ cáº£nh bÃ¡o Ä‘áº·c biá»‡t"


def _extract_tour_names_for_comparison(message: str, tour_name_map: dict) -> list:
    """TrÃ­ch xuáº¥t tÃªn tour cho má»¥c Ä‘Ã­ch so sÃ¡nh vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao"""
    tour_names = []
    message_lower = message.lower()
    
    # Pattern cho so sÃ¡nh
    patterns = [
        r'tour\s+["\']?([^"\']+?)["\']?\s+vÃ \s+tour\s+["\']?([^"\']+?)["\']?',
        r'tour\s+["\']?([^"\']+?)["\']?\s+so\s+sÃ¡nh\s+vá»›i\s+tour\s+["\']?([^"\']+?)["\']?',
        r'giá»¯a\s+tour\s+["\']?([^"\']+?)["\']?\s+vÃ \s+tour\s+["\']?([^"\']+?)["\']?',
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, message_lower, re.IGNORECASE)
        for match in matches:
            for name in match:
                if name.strip() and len(name.strip()) > 3:
                    tour_names.append(name.strip())
    
    # Náº¿u khÃ´ng tÃ¬m tháº¥y báº±ng pattern, tÃ¬m cÃ¡c tá»« khÃ³a tour
    if not tour_names:
        for norm_name in tour_name_map.keys():
            name_lower = norm_name.lower()
            # Kiá»ƒm tra náº¿u tÃªn tour xuáº¥t hiá»‡n trong message
            if any(word in message_lower for word in name_lower.split()[:3]):
                tour_names.append(norm_name)
    
    return list(set(tour_names))[:3]  # Tá»‘i Ä‘a 3 tour


def _analyze_user_requirements(message: str, user_profile: dict) -> dict:
    """PhÃ¢n tÃ­ch nhu cáº§u ngÆ°á»i dÃ¹ng chi tiáº¿t"""
    requirements = user_profile.copy()
    message_lower = message.lower()
    
    # PhÃ¢n tÃ­ch cÆ°á»ng Ä‘á»™
    if any(word in message_lower for word in ['nháº¹ nhÃ ng', 'thÆ° giÃ£n', 'khÃ´ng vá»™i']):
        requirements['intensity'] = 'low'
    elif any(word in message_lower for word in ['trung bÃ¬nh', 'vá»«a pháº£i']):
        requirements['intensity'] = 'medium'
    elif any(word in message_lower for word in ['máº¡nh máº½', 'khÃ¡m phÃ¡', 'trekking']):
        requirements['intensity'] = 'high'
    
    # PhÃ¢n tÃ­ch má»¥c tiÃªu
    goals = []
    if any(word in message_lower for word in ['há»c há»i', 'giÃ¡o dá»¥c', 'kiáº¿n thá»©c']):
        goals.append('education')
    if any(word in message_lower for word in ['nghá»‰ ngÆ¡i', 'thÆ° giÃ£n', 'xáº£ stress']):
        goals.append('relaxation')
    if any(word in message_lower for word in ['tráº£i nghiá»‡m', 'khÃ¡m phÃ¡', 'má»›i láº¡']):
        goals.append('adventure')
    if any(word in message_lower for word in ['káº¿t ná»‘i', 'gáº¯n káº¿t', 'Ä‘oÃ n viÃªn']):
        goals.append('bonding')
    
    if goals:
        requirements['goals'] = goals
    
    # PhÃ¢n tÃ­ch rÃ ng buá»™c
    constraints = []
    if any(word in message_lower for word in ['háº¡n cháº¿ Ä‘i láº¡i', 'khÃ³ di chuyá»ƒn', 'sá»©c khá»e']):
        constraints.append('mobility_issues')
    if any(word in message_lower for word in ['dá»‹ á»©ng', 'kiÃªng ká»µ', 'khÃ´ng Äƒn Ä‘Æ°á»£c']):
        constraints.append('dietary_restrictions')
    if any(word in message_lower for word in ['sá»£ Ä‘á»™ cao', 'say sÃ³ng', 'say xe']):
        constraints.append('phobias')
    
    if constraints:
        requirements['constraints'] = constraints
    
    return requirements


def _calculate_tour_match_score(tour, requirements: dict, user_profile: dict) -> tuple:
    """TÃ­nh Ä‘iá»ƒm phÃ¹ há»£p cá»§a tour vá»›i nhu cáº§u ngÆ°á»i dÃ¹ng"""
    score = 0
    reasons = []
    warnings = []
    
    tour_text = (str(tour.includes or '') + ' ' + 
                 str(tour.style or '') + ' ' + 
                 str(tour.summary or '')).lower()
    
    # Äiá»ƒm cÆ¡ báº£n
    base_score = 10
    
    # Kiá»ƒm tra Ä‘á»™ phÃ¹ há»£p vá»›i gia Ä‘Ã¬nh
    if requirements.get('has_children'):
        if 'gia Ä‘Ã¬nh' in tour_text or 'tráº» em' in tour_text:
            score += 20
            reasons.append('phÃ¹ há»£p gia Ä‘Ã¬nh cÃ³ tráº» em')
        elif 'khÃ´ng phÃ¹ há»£p tráº»' in tour_text:
            score -= 15
            warnings.append('khÃ´ng khuyáº¿n khÃ­ch cho tráº» em')
    
    # Kiá»ƒm tra cho ngÆ°á»i lá»›n tuá»•i
    if requirements.get('has_elderly'):
        if any(word in tour_text for word in ['nhá»‹p cháº­m', 'nháº¹ nhÃ ng', 'khÃ´ng vá»™i']):
            score += 15
            reasons.append('nhá»‹p Ä‘á»™ phÃ¹ há»£p ngÆ°á»i lá»›n tuá»•i')
        elif any(word in tour_text for word in ['trekking', 'leo nÃºi', 'Ä‘Æ°á»ng khÃ³']):
            score -= 10
            warnings.append('cÃ³ hoáº¡t Ä‘á»™ng thá»ƒ cháº¥t máº¡nh')
    
    # Kiá»ƒm tra cho cá»±u chiáº¿n binh
    if requirements.get('is_veteran'):
        if any(word in tour_text for word in ['lá»‹ch sá»­', 'tri Ã¢n', 'cá»±u chiáº¿n binh']):
            score += 25
            reasons.append('thiáº¿t káº¿ riÃªng cho cá»±u chiáº¿n binh')
    
    # Kiá»ƒm tra sá»Ÿ thÃ­ch
    if requirements.get('preferences'):
        for preference in requirements['preferences']:
            if preference == 'nature' and any(word in tour_text for word in ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi']):
                score += 10
                reasons.append('tráº£i nghiá»‡m thiÃªn nhiÃªn')
            elif preference == 'history' and any(word in tour_text for word in ['lá»‹ch sá»­', 'di tÃ­ch', 'tri Ã¢n']):
                score += 10
                reasons.append('yáº¿u tá»‘ lá»‹ch sá»­')
            elif preference == 'meditation' and any(word in tour_text for word in ['thiá»n', 'tÄ©nh tÃ¢m', 'retreat']):
                score += 15
                reasons.append('cÃ³ hoáº¡t Ä‘á»™ng thiá»n')
            elif preference == 'beach' and any(word in tour_text for word in ['biá»ƒn', 'Ä‘áº£o', 'bÃ£i biá»ƒn']):
                score += 10
                reasons.append('tráº£i nghiá»‡m biá»ƒn Ä‘áº£o')
    
    # Kiá»ƒm tra ngÃ¢n sÃ¡ch
    if requirements.get('budget_range') and tour.price:
        price_lower = tour.price.lower()
        if requirements['budget_range'] == 'low':
            if '500' in price_lower or '600' in price_lower or '700' in price_lower:
                score += 10
                reasons.append('giÃ¡ cáº£ pháº£i chÄƒng')
        elif requirements['budget_range'] == 'medium':
            if '1.5' in price_lower or '2.0' in price_lower or '2.5' in price_lower:
                score += 10
                reasons.append('giÃ¡ trá»‹ tÆ°Æ¡ng xá»©ng')
    
    # Kiá»ƒm tra thá»i gian
    if requirements.get('duration_pref') and tour.duration:
        if requirements['duration_pref'] == '1_day' and '1 ngÃ y' in tour.duration.lower():
            score += 10
            reasons.append('Ä‘Ãºng thá»i lÆ°á»£ng yÃªu cáº§u')
        elif requirements['duration_pref'] == '2_days' and '2 ngÃ y' in tour.duration.lower():
            score += 10
            reasons.append('Ä‘Ãºng thá»i lÆ°á»£ng yÃªu cáº§u')
    
    # Äiá»ƒm tá»•ng
    total_score = base_score + score
    
    return total_score, reasons[:3], warnings[:2]


def _summarize_price(price_text: str) -> str:
    """TÃ³m táº¯t giÃ¡ tour"""
    if not price_text:
        return "GiÃ¡ linh hoáº¡t theo yÃªu cáº§u"
    
    # TrÃ­ch xuáº¥t sá»‘
    numbers = re.findall(r'(\d[\d,\.]+)', price_text)
    if numbers:
        try:
            first_num = int(numbers[0].replace(',', '').replace('.', ''))
            if first_num < 1000000:
                return f"Khoáº£ng {first_num:,.0f} VNÄ/ngÆ°á»i"
            elif first_num < 3000000:
                return f"Khoáº£ng {first_num/1000000:.1f} triá»‡u VNÄ/ngÆ°á»i"
            else:
                return f"Tá»« {first_num/1000000:.1f} triá»‡u VNÄ/ngÆ°á»i"
        except:
            pass
    
    return price_text[:80] + ('...' if len(price_text) > 80 else '')


def _apply_intelligent_filters(tours_db: dict, user_profile: dict, message: str) -> list:
    """Ãp dá»¥ng bá»™ lá»c thÃ´ng minh cho tours"""
    filtered_tours = []
    message_lower = message.lower()
    
    for idx, tour in tours_db.items():
        include = True
        tour_text = (str(tour.includes or '') + ' ' + 
                     str(tour.style or '') + ' ' + 
                     str(tour.notes or '')).lower()
        
        # Lá»c theo Ä‘á»‘i tÆ°á»£ng
        if user_profile.get('has_children'):
            if 'khÃ´ng phÃ¹ há»£p tráº»' in tour_text:
                include = False
            elif 'trekking' in tour_text and 'Ä‘i bá»™' in tour_text:
                include = False  # Háº¡n cháº¿ vá»›i tráº» nhá»
        
        if user_profile.get('has_elderly'):
            if any(word in tour_text for word in ['leo nÃºi', 'Ä‘Æ°á»ng dá»‘c', 'váº¥t váº£']):
                include = False
        
        # Lá»c theo sá»Ÿ thÃ­ch tá»« message
        if 'thiá»n' in message_lower and 'thiá»n' not in tour_text:
            include = False
        if 'lá»‹ch sá»­' in message_lower and not any(word in tour_text for word in ['lá»‹ch sá»­', 'tri Ã¢n', 'di tÃ­ch']):
            include = False
        if 'biá»ƒn' in message_lower and not any(word in tour_text for word in ['biá»ƒn', 'Ä‘áº£o']):
            include = False
        
        # Lá»c theo yÃªu cáº§u Ä‘áº·c biá»‡t
        if 'nháº¹ nhÃ ng' in message_lower and any(word in tour_text for word in ['trekking', 'leo nÃºi', 'váº¥t váº£']):
            include = False
        
        if include:
            # TÃ­nh Ä‘iá»ƒm phÃ¹ há»£p
            score, _, _ = _calculate_tour_match_score(
                tour, 
                _analyze_user_requirements(message, user_profile),
                user_profile
            )
            filtered_tours.append((idx, tour, score))
    
    # Sáº¯p xáº¿p theo Ä‘iá»ƒm
    filtered_tours.sort(key=lambda x: x[2], reverse=True)
    
    return [(idx, tour) for idx, tour, score in filtered_tours]


def _categorize_tour(tour) -> str:
    """PhÃ¢n loáº¡i tour"""
    tour_text = (str(tour.style or '') + ' ' + str(tour.includes or '')).lower()
    
    if any(word in tour_text for word in ['gia Ä‘Ã¬nh', 'tráº» em', 'nháº¹ nhÃ ng']):
        return 'Gia Ä‘Ã¬nh & Nháº¹ nhÃ ng'
    elif any(word in tour_text for word in ['lá»‹ch sá»­', 'tri Ã¢n', 'cá»±u chiáº¿n binh']):
        return 'Lá»‹ch sá»­ & Tri Ã¢n'
    elif any(word in tour_text for word in ['thiá»n', 'retreat', 'tÄ©nh tÃ¢m']):
        return 'Thiá»n & Retreat'
    elif any(word in tour_text for word in ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi', 'khÃ¡m phÃ¡']):
        return 'ThiÃªn nhiÃªn & KhÃ¡m phÃ¡'
    elif any(word in tour_text for word in ['biá»ƒn', 'Ä‘áº£o']):
        return 'Biá»ƒn & Äáº£o'
    else:
        return 'Äa dáº¡ng tráº£i nghiá»‡m'


def _summarize_user_profile(user_profile: dict) -> str:
    """TÃ³m táº¯t thÃ´ng tin ngÆ°á»i dÃ¹ng"""
    summary = "**THÃ”NG TIN KHÃCH HÃ€NG:**\n"
    
    if user_profile.get('group_size'):
        summary += f"â€¢ Sá»‘ ngÆ°á»i: {user_profile['group_size']}\n"
    
    if user_profile.get('has_children'):
        summary += "â€¢ CÃ³ tráº» em\n"
        if user_profile.get('children_ages'):
            ages = user_profile['children_ages']
            summary += f"â€¢ Äá»™ tuá»•i tráº»: {min(ages)}-{max(ages)} tuá»•i\n"
    
    if user_profile.get('has_elderly'):
        summary += "â€¢ CÃ³ ngÆ°á»i lá»›n tuá»•i\n"
    
    if user_profile.get('is_veteran'):
        summary += "â€¢ CÃ³ cá»±u chiáº¿n binh\n"
    
    if user_profile.get('preferences'):
        pref_map = {
            'nature': 'ThiÃªn nhiÃªn',
            'history': 'Lá»‹ch sá»­',
            'meditation': 'Thiá»n',
            'beach': 'Biá»ƒn',
            'food': 'áº¨m thá»±c'
        }
        preferences = [pref_map.get(p, p) for p in user_profile['preferences']]
        summary += f"â€¢ Sá»Ÿ thÃ­ch: {', '.join(preferences)}\n"
    
    if user_profile.get('budget_range'):
        budget_map = {
            'low': 'Tiáº¿t kiá»‡m (< 2 triá»‡u)',
            'medium': 'Trung bÃ¬nh (2-5 triá»‡u)',
            'high': 'Cao cáº¥p (> 5 triá»‡u)'
        }
        summary += f"â€¢ NgÃ¢n sÃ¡ch: {budget_map.get(user_profile['budget_range'], user_profile['budget_range'])}\n"
    
    if user_profile.get('duration_pref'):
        duration_map = {
            '1_day': '1 ngÃ y',
            '2_days': '2 ngÃ y',
            '3_days': '3 ngÃ y'
        }
        summary += f"â€¢ Thá»i gian: {duration_map.get(user_profile['duration_pref'], user_profile['duration_pref'])}\n"
    
    if user_profile.get('special_needs'):
        summary += f"â€¢ Nhu cáº§u Ä‘áº·c biá»‡t: {', '.join(user_profile['special_needs'])}\n"
    
    return summary


def _is_out_of_scope(message: str) -> bool:
    """Kiá»ƒm tra cÃ¢u há»i ngoÃ i pháº¡m vi"""
    message_lower = message.lower()
    
    out_of_scope_keywords = [
        'chá»©ng khoÃ¡n', 'tá»‰ giÃ¡', 'thá»i sá»±', 'tin tá»©c',
        'chuyá»‡n cÆ°á»i', 'Ä‘á»‘ vui', 'game', 'giáº£i trÃ­',
        'thá»ƒ thao', 'bÃ³ng Ä‘Ã¡', 'ca nháº¡c', 'phim áº£nh',
        'chÃ­nh trá»‹', 'tÃ´n giÃ¡o', 'nháº¡y cáº£m',
        'thá»i trang', 'mua sáº¯m', 'lÃ m Ä‘áº¹p'
    ]
    
    return any(keyword in message_lower for keyword in out_of_scope_keywords)


def _is_budget_friendly(price_text: str) -> bool:
    """Kiá»ƒm tra giÃ¡ cÃ³ pháº£i chÄƒng khÃ´ng"""
    if not price_text:
        return False
    
    # TrÃ­ch xuáº¥t sá»‘ Ä‘áº§u tiÃªn
    numbers = re.findall(r'(\d[\d,\.]+)', price_text)
    if numbers:
        try:
            price = int(numbers[0].replace(',', '').replace('.', ''))
            return price < 2000000
        except:
            pass
    
    return False


def _extract_price_range(price_text: str) -> str:
    """TrÃ­ch xuáº¥t khoáº£ng giÃ¡ tá»« text"""
    if not price_text:
        return "LiÃªn há»‡"
    
    # TÃ¬m khoáº£ng giÃ¡
    range_match = re.search(r'(\d[\d,\.]+)\s*[â€“\-]\s*(\d[\d,\.]+)', price_text)
    if range_match:
        return f"{range_match.group(1)} â€“ {range_match.group(2)} VNÄ"
    
    # TÃ¬m giÃ¡ Ä‘Æ¡n
    single_match = re.search(r'(\d[\d,\.]+)\s*VNÄ', price_text)
    if single_match:
        return f"{single_match.group(1)} VNÄ"
    
    return price_text[:50] + ('...' if len(price_text) > 50 else '')


def _apply_smart_filters_to_search(search_results: list, user_profile: dict) -> list:
    """Ãp dá»¥ng bá»™ lá»c thÃ´ng minh cho káº¿t quáº£ tÃ¬m kiáº¿m"""
    filtered_indices = []
    
    for score, content in search_results:
        # TÃ¬m tour index tá»« content
        for idx, tour in TOURS_DB.items():
            if tour.name in content and idx not in filtered_indices:
                # Kiá»ƒm tra phÃ¹ há»£p cÆ¡ báº£n
                tour_text = (str(tour.includes or '') + ' ' + str(tour.style or '')).lower()
                
                # Lá»c cho tráº» em
                if user_profile.get('has_children'):
                    if 'khÃ´ng phÃ¹ há»£p tráº»' in tour_text:
                        continue
                
                # Lá»c cho ngÆ°á»i lá»›n tuá»•i
                if user_profile.get('has_elderly'):
                    if any(word in tour_text for word in ['leo nÃºi', 'váº¥t váº£', 'Ä‘Æ°á»ng dá»‘c']):
                        continue
                
                filtered_indices.append(idx)
                break
    
    return filtered_indices[:5]


def _prepare_llm_prompt_v2(user_message: str, search_results: list, context_info: dict) -> str:
    """Chuáº©n bá»‹ prompt thÃ´ng minh cho LLM"""
    # Táº­p há»£p thÃ´ng tin context
    tours_info = []
    for idx in context_info.get('tour_indices', [])[:3]:
        tour = TOURS_DB.get(idx)
        if tour:
            tours_info.append(f"â€¢ {tour.name}: {tour.summary or 'No summary'}")
    
    user_profile = context_info.get('user_profile', {})
    profile_summary = _summarize_user_profile(user_profile)
    
    # Táº­p há»£p search results
    search_context = "\n".join([content[:200] for _, content in search_results[:3]])
    
    prompt = f"""Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n tour Ruby Wings - thÃ´ng minh, am hiá»ƒu vÃ  nhiá»‡t tÃ¬nh.

THÃ”NG TIN KHÃCH HÃ€NG:
{profile_summary}

CONTEXT HIá»†N Táº I:
â€¢ Tour Ä‘ang tháº£o luáº­n: {context_info.get('current_tour', 'None')}
â€¢ Tour Ä‘Ã£ Ä‘á» cáº­p: {len(context_info.get('discussed_tours', []))} tour
â€¢ Äang so sÃ¡nh: {'CÃ³' if context_info.get('comparison_mode') else 'KhÃ´ng'}

TOUR CÃ“ LIÃŠN QUAN:
{chr(10).join(tours_info) if tours_info else 'KhÃ´ng cÃ³ tour cá»¥ thá»ƒ'}

THÃ”NG TIN TÃŒM KIáº¾M:
{search_context}

CÃ‚U Há»ŽI: {user_message}

YÃŠU Cáº¦U TRáº¢ Lá»œI:
1. HIá»‚U CONTEXT: Nháº­n biáº¿t tour Ä‘ang tháº£o luáº­n vÃ  nhu cáº§u ngÆ°á»i dÃ¹ng
2. CHÃNH XÃC: Chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« Ruby Wings, khÃ´ng bá»‹a
3. Há»®U ÃCH: Cung cáº¥p thÃ´ng tin giÃ¡ trá»‹, cÃ³ thá»ƒ hÃ nh Ä‘á»™ng Ä‘Æ°á»£c
4. CÃ NHÃ‚N HÃ“A: Gá»£i Ã½ dá»±a trÃªn thÃ´ng tin ngÆ°á»i dÃ¹ng
5. Káº¾T Ná»I: Äá» cáº­p Ä‘áº¿n hotline khi cáº§n tÆ° váº¥n sÃ¢u

QUAN TRá»ŒNG:
- Náº¿u há»i vá» giÃ¡/lá»‹ch trÃ¬nh tour cá»¥ thá»ƒ: cung cáº¥p chi tiáº¿t tá»« thÃ´ng tin tour
- Náº¿u so sÃ¡nh: Ä‘Æ°a ra phÃ¢n tÃ­ch khÃ¡ch quan
- Náº¿u Ä‘á» xuáº¥t: giáº£i thÃ­ch lÃ½ do phÃ¹ há»£p
- Náº¿u khÃ´ng biáº¿t: thÃ nh tháº­t vÃ  hÆ°á»›ng dáº«n liÃªn há»‡ hotline

TRáº¢ Lá»œI Báº°NG TIáº¾NG VIá»†T, CHUYÃŠN NGHIá»†P, THÃ‚N THIá»†N."""

    return prompt


def _generate_intelligent_fallback(user_message: str, search_results: list, tour_indices: list, context_info: dict) -> str:
    """Táº¡o pháº£n há»“i fallback thÃ´ng minh"""
    if tour_indices:
        # CÃ³ tour liÃªn quan
        reply = "ðŸ” **TÃ”I TÃŒM THáº¤Y Má»˜T Sá» TOUR LIÃŠN QUAN** ðŸ”\n\n"
        
        for idx in tour_indices[:3]:
            tour = TOURS_DB.get(idx)
            if tour:
                reply += f"**{tour.name}**\n"
                if tour.summary:
                    reply += f"{tour.summary[:100]}...\n"
                if tour.duration:
                    reply += f"â±ï¸ {tour.duration} | "
                if tour.location:
                    reply += f"ðŸ“ {tour.location[:30]}\n"
                reply += "\n"
        
        reply += "ðŸ’¡ **Báº N MUá»N BIáº¾T GÃŒ Vá»€ CÃC TOUR NÃ€Y?**\n"
        reply += "â€¢ 'GiÃ¡ tour nÃ y bao nhiÃªu?'\n"
        reply += "â€¢ 'Tour nÃ y cÃ³ gÃ¬ Ä‘áº·c biá»‡t?'\n"
        reply += "â€¢ 'CÃ³ phÃ¹ há»£p cho gia Ä‘Ã¬nh khÃ´ng?'\n\n"
        reply += "ðŸ“ž **Hoáº·c gá»i tÆ° váº¥n trá»±c tiáº¿p:** 0332510486"
    
    elif search_results:
        # CÃ³ káº¿t quáº£ tÃ¬m kiáº¿m
        reply = "ðŸ“š **THÃ”NG TIN LIÃŠN QUAN Tá»ª RUBY WINGS** ðŸ“š\n\n"
        
        for i, (score, content) in enumerate(search_results[:3], 1):
            # TrÃ­ch xuáº¥t thÃ´ng tin quan trá»ng
            lines = content.split('\n')
            for line in lines:
                if len(line) > 30 and any(keyword in line.lower() for keyword in ['tour', 'giÃ¡', 'bao gá»“m', 'thá»i gian']):
                    reply += f"{i}. {line[:150]}...\n"
                    break
        
        reply += "\nðŸŽ¯ **Äá»‚ ÄÆ¯á»¢C TÆ¯ Váº¤N CHÃNH XÃC:**\n"
        reply += "1. Cung cáº¥p thÃªm thÃ´ng tin vá» nhu cáº§u\n"
        reply += "2. Chá»‰ Ä‘á»‹nh tÃªn tour cá»¥ thá»ƒ\n"
        reply += "3. LiÃªn há»‡ chuyÃªn gia Ruby Wings\n\n"
        reply += "ðŸ“ž **Hotline 24/7:** 0332510486"
    
    else:
        # KhÃ´ng cÃ³ thÃ´ng tin
        reply = "ðŸ¤” **TÃ”I CHÆ¯A HIá»‚U RÃ• NHU Cáº¦U Cá»¦A Báº N** ðŸ¤”\n\n"
        reply += "Äá»ƒ tÃ´i há»— trá»£ tá»‘t hÆ¡n, báº¡n cÃ³ thá»ƒ:\n\n"
        reply += "ðŸŽ¯ **Há»ŽI Cá»¤ THá»‚ HÆ N:**\n"
        reply += "â€¢ 'Tour 1 ngÃ y á»Ÿ Huáº¿ giÃ¡ bao nhiÃªu?'\n"
        reply += "â€¢ 'Tour nÃ o cÃ³ thiá»n vÃ  giÃ¡ dÆ°á»›i 1 triá»‡u?'\n"
        reply += "â€¢ 'So sÃ¡nh tour Báº¡ch MÃ£ vÃ  TrÆ°á»ng SÆ¡n'\n\n"
        reply += "ðŸ“‹ **HOáº¶C CUNG Cáº¤P THÃ”NG TIN:**\n"
        reply += "â€¢ Sá»‘ ngÆ°á»i vÃ  Ä‘á»™ tuá»•i\n"
        reply += "â€¢ Sá»Ÿ thÃ­ch chÃ­nh cá»§a nhÃ³m\n"
        reply += "â€¢ Thá»i gian vÃ  ngÃ¢n sÃ¡ch\n\n"
        reply += "ðŸ“ž **Gá»i ngay Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n nhanh:** 0332510486"
    
    return reply


def _enhance_response_quality(reply: str, context) -> str:
    """NÃ¢ng cao cháº¥t lÆ°á»£ng pháº£n há»“i"""
    # ThÃªm thÃ´ng tin context náº¿u cÃ³
    if context.current_tour and "tour" not in reply.lower()[:100]:
        tour = TOURS_DB.get(context.current_tour)
        if tour and tour.name not in reply:
            # ChÃ¨n thÃ´ng tin tour á»Ÿ Ä‘áº§u náº¿u phÃ¹ há»£p
            lines = reply.split('\n')
            if len(lines) > 2:
                lines.insert(1, f"\nðŸ“Œ **Äang nÃ³i vá»:** {tour.name}")
                reply = '\n'.join(lines)
    
    # Äáº£m báº£o cÃ³ call-to-action
    if not any(word in reply.lower() for word in ['gá»i', 'liÃªn há»‡', 'hotline', '0332510486']):
        if len(reply.split('\n')) > 5:
            reply += "\n\nðŸ“ž **Cáº§n há»— trá»£ thÃªm? Gá»i ngay:** 0332510486"
    
    # Format láº¡i cho Ä‘áº¹p
    lines = reply.split('\n')
    formatted_lines = []
    for line in lines:
        if line.strip() and not line.startswith(('â€¢', 'ðŸ“Œ', 'ðŸŽ¯', 'ðŸ’°', 'ðŸ“', 'â±ï¸', 'âœ…', 'âš ï¸', 'ðŸ”')):
            if len(line) > 80 and ' ' in line[60:]:
                # Tá»± Ä‘á»™ng xuá»‘ng dÃ²ng cho dÃ²ng dÃ i
                words = line.split()
                new_line = ""
                current_length = 0
                for word in words:
                    if current_length + len(word) + 1 > 80:
                        formatted_lines.append(new_line)
                        new_line = word + " "
                        current_length = len(word) + 1
                    else:
                        new_line += word + " "
                        current_length += len(word) + 1
                if new_line:
                    formatted_lines.append(new_line.strip())
                continue
        formatted_lines.append(line)
    
    return '\n'.join(formatted_lines)

# =========== OTHER ENDPOINTS ===========
@app.route("/")
def home():
    """Home endpoint"""
    return jsonify({
        "status": "ok",
        "version": "4.0",
        "upgrades": UpgradeFlags.get_all_flags(),
        "services": {
            "openai": "available" if client else "unavailable",
            "faiss": "available" if HAS_FAISS else "unavailable",
            "google_sheets": "available" if HAS_GOOGLE_SHEETS else "unavailable",
            "meta_capi": "available" if HAS_META_CAPI else "unavailable",
        },
        "counts": {
            "tours": len(TOURS_DB),
            "passages": len(FLAT_TEXTS),
            "tour_names": len(TOUR_NAME_TO_INDEX),
        }
    })

@app.route("/reindex", methods=["POST"])
def reindex():
    """Rebuild index endpoint"""
    secret = request.headers.get("X-RBW-ADMIN", "")
    if not secret and os.environ.get("RBW_ALLOW_REINDEX", "") != "1":
        return jsonify({"error": "reindex not allowed"}), 403
    
    load_knowledge()
    build_index(force_rebuild=True)
    
    return jsonify({
        "ok": True,
        "count": len(FLAT_TEXTS),
        "tours": len(TOURS_DB)
    })

# =========== GOOGLE SHEETS INTEGRATION ===========
_gsheet_client = None
_gsheet_client_lock = threading.Lock()

def get_gspread_client(force_refresh: bool = False):
    """Get Google Sheets client"""
    global _gsheet_client
    
    if not GOOGLE_SERVICE_ACCOUNT_JSON:
        logger.error("GOOGLE_SERVICE_ACCOUNT_JSON not set")
        return None
    
    with _gsheet_client_lock:
        if _gsheet_client is not None and not force_refresh:
            return _gsheet_client
        
        try:
            info = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
            scopes = [
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/drive",
            ]
            creds = Credentials.from_service_account_info(info, scopes=scopes)
            _gsheet_client = gspread.authorize(creds)
            logger.info("âœ… Google Sheets client initialized")
            return _gsheet_client
        except Exception as e:
            logger.error(f"âŒ Google Sheets client failed: {e}")
            return None

@app.route('/api/save-lead', methods=['POST', 'OPTIONS'])
def save_lead():
    """Save lead from form submission - Äáº¦Y Äá»¦ 9 TRÆ¯á»œNG (A-I)"""
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200
    
    try:
        data = request.get_json() or {}
        
        # Extract data
        phone = data.get('phone', '').strip()
        name = data.get('name', '').strip()
        email = data.get('email', '').strip()
        tour_interest = data.get('tour_interest', '').strip()
        page_url = data.get('page_url', '').strip()
        note = data.get('note', '').strip()
        
        if not phone:
            return jsonify({'error': 'Phone number is required'}), 400
        
        # Clean phone
        phone_clean = re.sub(r'[^\d+]', '', phone)
        
        # Validate phone
        if not re.match(r'^(0|\+?84)\d{9,10}$', phone_clean):
            return jsonify({'error': 'Invalid phone number format'}), 400
        
        # Timestamp
        timestamp = datetime.now().isoformat()
        
        # Create lead data
        lead_data = {
            'timestamp': timestamp,
            'phone': phone_clean,
            'name': name,
            'email': email,
            'tour_interest': tour_interest,
            'page_url': page_url,
            'note': note,
            'source': 'Lead Form'
        }
        
        # Send to Meta CAPI
        if ENABLE_META_CAPI_CALL and HAS_META_CAPI:
            try:
                result = send_meta_lead(
                    request,
                    phone=phone_clean,
                    contact_name=name,
                    email=email,
                    content_name=f"Tour: {tour_interest}" if tour_interest else "General Inquiry",
                    value=200000,
                    currency="VND"
                )
                increment_stat('meta_capi_calls')
                logger.info(f"âœ… Form lead sent to Meta CAPI: {phone_clean[:4]}***")
                if DEBUG and HAS_META_CAPI:
                    logger.debug(f"Meta CAPI result: {result}")
            except Exception as e:
                increment_stat('meta_capi_errors')
                logger.error(f"Meta CAPI error: {e}")
        
        # Save to Google Sheets - Äáº¦Y Äá»¦ 9 TRÆ¯á»œNG (A-I)
        if ENABLE_GOOGLE_SHEETS:
            try:
                import gspread
                from google.oauth2.service_account import Credentials
                
                if GOOGLE_SERVICE_ACCOUNT_JSON and GOOGLE_SHEET_ID:
                    creds_json = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
                    creds = Credentials.from_service_account_info(
                        creds_json,
                        scopes=['https://www.googleapis.com/auth/spreadsheets']
                    )
                    
                    gc = gspread.authorize(creds)
                    sh = gc.open_by_key(GOOGLE_SHEET_ID)
                    ws = sh.worksheet(GOOGLE_SHEET_NAME)
                    
                    # ÄÃšng 9 TRÆ¯á»œNG THEO THá»¨ Tá»° A-I:
                    # A: created_at (timestamp)
                    # B: source_channel
                    # C: action_type
                    # D: page_url
                    # E: contact_name
                    # F: phone
                    # G: service_interest
                    # H: note
                    # I: raw_status
                    row = [
                        timestamp,                          # A: created_at
                        'Website - Lead Form',              # B: source_channel
                        'Form Submission',                  # C: action_type
                        page_url or '',                     # D: page_url
                        name or '',                         # E: contact_name
                        phone_clean,                        # F: phone
                        tour_interest or '',                # G: service_interest
                        note or email or '',                # H: note (dÃ¹ng email náº¿u khÃ´ng cÃ³ note)
                        'New'                               # I: raw_status
                    ]
                    
                    ws.append_row(row)
                    logger.info("âœ… Form lead saved to Google Sheets (9 fields)")
            except Exception as e:
                logger.error(f"Google Sheets error: {e}")
        
        # Fallback storage
        if ENABLE_FALLBACK_STORAGE:
            try:
                if os.path.exists(FALLBACK_STORAGE_PATH):
                    with open(FALLBACK_STORAGE_PATH, 'r', encoding='utf-8') as f:
                        leads = json.load(f)
                else:
                    leads = []
                
                leads.append(lead_data)
                leads = leads[-1000:]
                
                with open(FALLBACK_STORAGE_PATH, 'w', encoding='utf-8') as f:
                    json.dump(leads, f, ensure_ascii=False, indent=2)
                
                logger.info("âœ… Form lead saved to fallback storage")
            except Exception as e:
                logger.error(f"Fallback storage error: {e}")
        
        # Update stats
        increment_stat('leads')
        
        return jsonify({
            'success': True,
            'message': 'Lead Ä‘Ã£ Ä‘Æ°á»£c lÆ°u! Äá»™i ngÅ© Ruby Wings sáº½ liÃªn há»‡ sá»›m nháº¥t. ðŸ“ž',
            'data': {
                'phone': phone_clean[:3] + '***' + phone_clean[-2:],
                'timestamp': timestamp
            }
        })
        
    except Exception as e:
        logger.error(f"âŒ Save lead error: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/call-button', methods=['POST', 'OPTIONS'])
def call_button():
    """Track call button click"""
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200
    
    try:
        data = request.get_json() or {}
        
        page_url = data.get('page_url', '')
        call_type = data.get('call_type', 'regular')
        
        # Send to Meta CAPI
        if ENABLE_META_CAPI_CALL and HAS_META_CAPI:
            try:
                result = send_meta_call_button(
                    request,
                    page_url=page_url,
                    call_type=call_type,
                    button_location='fixed_bottom_left',
                    button_text='Gá»i ngay'
                )
                increment_stat('meta_capi_calls')
                logger.info(f"ðŸ“ž Call button tracked: {call_type}")
                if DEBUG and HAS_META_CAPI:
                    logger.debug(f"Meta CAPI result: {result}")
            except Exception as e:
                increment_stat('meta_capi_errors')
                logger.error(f"Meta CAPI call error: {e}")
        
        return jsonify({
            'success': True,
            'message': 'Call tracked',
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Call button error: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    try:
        return jsonify({
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "services": {
                "chatbot": "running",
                "openai": "available" if client else "unavailable",
                "faiss": "available" if INDEX else "unavailable",
                "tours_db": len(TOURS_DB),
                "upgrades": {k: v for k, v in UpgradeFlags.get_all_flags().items() 
                           if k.startswith("UPGRADE_")}
            },
            "memory_profile": {
                "ram_profile": RAM_PROFILE,
                "is_low_ram": IS_LOW_RAM,
                "is_high_ram": IS_HIGH_RAM,
                "tour_count": len(TOURS_DB),
                "context_count": len(SESSION_CONTEXTS)
            }
        })
    except Exception as e:
        return jsonify({
            "status": "unhealthy",
            "error": str(e)
        }), 500

# =========== INITIALIZATION ===========
def initialize_app():
    """Initialize the application"""
    logger.info("ðŸš€ Starting Ruby Wings Chatbot v4.0 (Dataclass Rewrite)...")
    
    # Apply memory optimizations
    optimize_for_memory_profile()
    
    # Load knowledge base
    load_knowledge()
    
    # Load or build tours database
    if os.path.exists(FAISS_MAPPING_PATH):
        try:
            with open(FAISS_MAPPING_PATH, 'r', encoding='utf-8') as f:
                MAPPING[:] = json.load(f)
            FLAT_TEXTS[:] = [m.get('text', '') for m in MAPPING]
            logger.info(f"ðŸ“ Loaded {len(MAPPING)} mappings from disk")
        except Exception as e:
            logger.error(f"Failed to load mappings: {e}")
    
    # Build tour databases
    index_tour_names()
    build_tours_db()
    
    # Build index in background
    def build_index_background():
        time.sleep(2)
        success = build_index(force_rebuild=False)
        if success:
            logger.info("âœ… Index ready")
        else:
            logger.warning("âš ï¸ Index building failed")
    
    threading.Thread(target=build_index_background, daemon=True).start()
    
    # Initialize Google Sheets client
    if ENABLE_GOOGLE_SHEETS:
        threading.Thread(target=get_gspread_client, daemon=True).start()
    
    # Log active upgrades
    active_upgrades = [name for name, enabled in UpgradeFlags.get_all_flags().items() 
                      if enabled and name.startswith("UPGRADE_")]
    logger.info(f"ðŸ”§ Active upgrades: {len(active_upgrades)}")
    for upgrade in active_upgrades:
        logger.info(f"   â€¢ {upgrade}")
    
    # Log memory profile
    logger.info(f"ðŸ§  Memory Profile: {RAM_PROFILE}MB | Low RAM: {IS_LOW_RAM} | High RAM: {IS_HIGH_RAM}")
    logger.info(f"ðŸ“Š Tours Database: {len(TOURS_DB)} tours loaded")
    
    logger.info("âœ… Application initialized successfully with dataclasses")

# =========== APPLICATION START ===========
if __name__ == "__main__":
    initialize_app()
    
    # Save mappings if not exists
    if MAPPING and not os.path.exists(FAISS_MAPPING_PATH):
        try:
            with open(FAISS_MAPPING_PATH, 'w', encoding='utf-8') as f:
                json.dump(MAPPING, f, ensure_ascii=False, indent=2)
            logger.info(f"ðŸ’¾ Saved mappings to {FAISS_MAPPING_PATH}")
        except Exception as e:
            logger.error(f"Failed to save mappings: {e}")
    
    # Start server
    logger.info(f"ðŸŒ Starting server on {HOST}:{PORT}")
    app.run(host=HOST, port=PORT, debug=DEBUG, threaded=True)

else:
    # For WSGI
    initialize_app()