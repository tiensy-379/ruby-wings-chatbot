def safe_validate(reply):
    try:
        if not isinstance(reply, dict):
            return reply
        # Only validate when tour is selected
        if not reply.get("tour_name"):
            return reply
        return AutoValidator.validate_response(reply)
    except Exception as e:
        try:
            reply.setdefault("warnings", []).append(str(e))
        except:
            pass
        return reply


# app.py - Ruby Wings Chatbot v4.0 (Complete Rewrite with Dataclasses)
# =========== IMPORTS ===========
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("ruby-wings")
import os
import sys
import json
import threading
import logging
import re
import unicodedata
import traceback
import hashlib
import time
import random
from functools import lru_cache, wraps
from typing import List, Tuple, Dict, Optional, Any, Set, Union, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import defaultdict, deque
from difflib import SequenceMatcher
from enum import Enum
import difflib
# Try to import numpy with detailed error handling
try:
    
    import numpy as np
    NUMPY_AVAILABLE = True
    logger.info("âœ… NumPy available")
except ImportError as e:
    logger.error(f"âŒ NumPy import failed: {e}")
    # Create a minimal numpy-like fallback for basic operations
    class NumpyFallback:
        def __init__(self):
            self.float32 = float
            self.int64 = int
            
        def array(self, data, dtype=None):
            # Simple list wrapper
            class SimpleArray:
                def __init__(self, data):
                    self.data = list(data)
                    self.shape = (len(data),) if isinstance(data[0], (int, float)) else (len(data), len(data[0]))
                
                def astype(self, dtype):
                    return self
                
                def reshape(self, shape):
                    return self
                
                def __getitem__(self, idx):
                    return self.data[idx]
                
                def __len__(self):
                    return len(self.data)
            
            return SimpleArray(data)
        
        def empty(self, shape, dtype):
            if len(shape) == 1:
                return [0.0] * shape[0]
            else:
                return [[0.0] * shape[1] for _ in range(shape[0])]
        
        def vstack(self, arrays):
            result = []
            for arr in arrays:
                if hasattr(arr, 'data'):
                    result.extend(arr.data)
                else:
                    result.extend(arr)
            return result
        
        def load(self, path):
            # Mock load function
            class MockNpz:
                def __init__(self):
                    self.files = ['mat']
                
                def __getitem__(self, key):
                    if key == 'mat':
                        # Return empty array
                        return self.array([[0.0]])
                    return None
            
            return MockNpz()
        
        def savez_compressed(self, path, **kwargs):
            # Mock save function
            logger.warning(f"âš ï¸ NumPy fallback: Mock saving to {path}")
            return None
    
    np = NumpyFallback()
    NUMPY_AVAILABLE = False
    logger.warning("âš ï¸ Using NumPy fallback - limited functionality")
from flask import Flask, request, jsonify, g
from flask_cors import CORS

# =========== ENTITY IMPORTS ===========
from entities import (
    QuestionType,
    ConversationState,
    PriceLevel,
    DurationType,
    Tour,
    UserProfile,
    SearchResult,
    ConversationContext,
    FilterSet,
    LLMRequest,
    ChatResponse,
    LeadData,
    CacheEntry,
    EnhancedJSONEncoder
)

# =========== CONFIGURATION ===========
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ruby_wings.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("rbw_v4")

# =========== IMPORTS WITH FALLBACKS ===========
HAS_FAISS = False
faiss_index = None
faiss_mapping = {}


try:
    import faiss
    HAS_FAISS = True
    logger.info("âœ… FAISS available")
except ImportError:
    logger.warning("âš ï¸ FAISS not available, using numpy fallback")

HAS_OPENAI = False
client = None
embedding_client = client

try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    logger.warning("âš ï¸ OpenAI not available, using fallback responses")

# Google Sheets
try:
    import gspread
    from google.oauth2.service_account import Credentials
    from google.auth.exceptions import GoogleAuthError
    from gspread.exceptions import APIError, SpreadsheetNotFound, WorksheetNotFound
    HAS_GOOGLE_SHEETS = True
except ImportError:
    HAS_GOOGLE_SHEETS = False
    logger.warning("âš ï¸ Google Sheets not available")

# Meta CAPI
try:
    from meta_capi import send_meta_pageview, send_meta_lead, send_meta_call_button
    HAS_META_CAPI = True
    logger.info("âœ… Meta CAPI available")
except ImportError:
    HAS_META_CAPI = False
    logger.warning("âš ï¸ Meta CAPI not available")

# =========== ENVIRONMENT VARIABLES ===========
# Memory Profile
RAM_PROFILE = os.environ.get("RAM_PROFILE", "512").strip()
IS_LOW_RAM = RAM_PROFILE == "512"
IS_HIGH_RAM = RAM_PROFILE == "2048"

# Core API Keys
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "").strip()
OPENAI_BASE_URL = os.environ.get("OPENAI_BASE_URL", "").strip()
GOOGLE_SERVICE_ACCOUNT_JSON = os.environ.get("GOOGLE_SERVICE_ACCOUNT_JSON", "").strip()

# Knowledge & Index
KNOWLEDGE_PATH = os.environ.get("KNOWLEDGE_PATH", "knowledge.json")
FAISS_INDEX_PATH = os.environ.get("FAISS_INDEX_PATH", "faiss_index.bin")
FAISS_MAPPING_PATH = os.environ.get("FAISS_MAPPING_PATH", "faiss_mapping.json")
FALLBACK_VECTORS_PATH = os.environ.get("FALLBACK_VECTORS_PATH", "vectors.npz")

# Models
EMBEDDING_MODEL = os.environ.get("EMBEDDING_MODEL", "text-embedding-3-small")
CHAT_MODEL = os.environ.get("CHAT_MODEL", "gpt-4o-mini")
TOP_K = int(os.environ.get("TOP_K", "10"))

# FAISS
FAISS_ENABLED = os.environ.get("FAISS_ENABLED", "true").lower() in ("1", "true", "yes") and not IS_LOW_RAM

# Google Sheets
GOOGLE_SHEET_ID = os.environ.get("GOOGLE_SHEET_ID", "1SdVbwkuxb8l1meEW--ddyfh4WmUvSXXMOPQ5bCyPkdk")
GOOGLE_SHEET_NAME = os.environ.get("GOOGLE_SHEET_NAME", "RBW_Lead_Raw_Inbox")
ENABLE_GOOGLE_SHEETS = os.environ.get("ENABLE_GOOGLE_SHEETS", "true").lower() in ("1", "true", "yes")

# Storage
ENABLE_FALLBACK_STORAGE = os.environ.get("ENABLE_FALLBACK_STORAGE", "true").lower() in ("1", "true", "yes")
FALLBACK_STORAGE_PATH = os.environ.get("FALLBACK_STORAGE_PATH", "leads_fallback.json")

# Meta CAPI
META_CAPI_TOKEN = os.environ.get("META_CAPI_TOKEN", "").strip()
META_PIXEL_ID = os.environ.get("META_PIXEL_ID", "").strip()
META_CAPI_ENDPOINT = os.environ.get("META_CAPI_ENDPOINT", "https://graph.facebook.com/v17.0/")
ENABLE_META_CAPI_CALL = os.environ.get("ENABLE_META_CAPI_CALL", "true").lower() in ("1", "true", "yes")

# Server
FLASK_ENV = os.environ.get("FLASK_ENV", "production")
DEBUG = os.environ.get("DEBUG", "false").lower() in ("1", "true", "yes")
SECRET_KEY = os.environ.get("SECRET_KEY", "ruby-wings-secret-key-2024")
CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "https://www.rubywings.vn,http://localhost:3000").split(",")
HOST = os.environ.get("HOST", "0.0.0.0")
PORT = int(os.environ.get("PORT", "10000"))

# =========== STATS TRACKING (FIX Lá»–I STATE) ===========
# ThÃªm global stats tracking system
STATS_LOCK = threading.Lock()
GLOBAL_STATS = {
    'meta_capi_calls': 0,
    'meta_capi_errors': 0,
    'leads': 0,
    'errors': 0,
    'total_requests': 0
}

def increment_stat(stat_name: str, amount: int = 1):
    """Thread-safe stat increment"""
    with STATS_LOCK:
        if stat_name in GLOBAL_STATS:
            GLOBAL_STATS[stat_name] += amount
        else:
            GLOBAL_STATS[stat_name] = amount

def get_stats() -> dict:
    """Get current stats"""
    with STATS_LOCK:
        return GLOBAL_STATS.copy()

# =========== UPGRADE FEATURE FLAGS ===========
class UpgradeFlags:
    """Control all 10 upgrades with environment variables"""
    
    @staticmethod
    def get_all_flags():
        return {
            # CORE UPGRADES (Essential fixes)
            "UPGRADE_1_MANDATORY_FILTER": os.environ.get("UPGRADE_1_MANDATORY_FILTER", "true").lower() == "true",
            "UPGRADE_2_DEDUPLICATION": os.environ.get("UPGRADE_2_DEDUPLICATION", "true").lower() == "true",
            "UPGRADE_3_ENHANCED_FIELDS": os.environ.get("UPGRADE_3_ENHANCED_FIELDS", "true").lower() == "true",
            "UPGRADE_4_QUESTION_PIPELINE": os.environ.get("UPGRADE_4_QUESTION_PIPELINE", "true").lower() == "true",
            
            # ADVANCED UPGRADES
            "UPGRADE_5_QUERY_SPLITTER": os.environ.get("UPGRADE_5_QUERY_SPLITTER", "true").lower() == "true",
            "UPGRADE_6_FUZZY_MATCHING": os.environ.get("UPGRADE_6_FUZZY_MATCHING", "true").lower() == "true",
            "UPGRADE_7_STATE_MACHINE": os.environ.get("UPGRADE_7_STATE_MACHINE", "true").lower() == "true",
            "UPGRADE_8_SEMANTIC_ANALYSIS": os.environ.get("UPGRADE_8_SEMANTIC_ANALYSIS", "true").lower() == "true",
            "UPGRADE_9_AUTO_VALIDATION": os.environ.get("UPGRADE_9_AUTO_VALIDATION", "true").lower() == "true",
            "UPGRADE_10_TEMPLATE_SYSTEM": os.environ.get("UPGRADE_10_TEMPLATE_SYSTEM", "true").lower() == "true",
            
            # PERFORMANCE OPTIONS
            "ENABLE_CACHING": os.environ.get("ENABLE_CACHING", "true").lower() == "true",
            "CACHE_TTL_SECONDS": int(os.environ.get("CACHE_TTL_SECONDS", "300")),
            "ENABLE_QUERY_LOGGING": os.environ.get("ENABLE_QUERY_LOGGING", "true").lower() == "true",
            
            # MEMORY OPTIMIZATION
            "EMBEDDING_CACHE_SIZE": 100 if IS_LOW_RAM else 1000,
            "TOUR_CACHE_ENABLED": not IS_LOW_RAM,
            "PRELOAD_EMBEDDINGS": not IS_LOW_RAM,
        }
    
    @staticmethod
    def is_enabled(upgrade_name: str) -> bool:
        flags = UpgradeFlags.get_all_flags()
        return flags.get(f"UPGRADE_{upgrade_name}", False)

# =========== FLASK APP CONFIG ===========
app = Flask(__name__)
app.json_encoder = EnhancedJSONEncoder  # Use custom JSON encoder
CORS(app, origins=CORS_ORIGINS, supports_credentials=True)

# =========== GLOBAL STATE (USING DATACLASSES) ===========
# Initialize OpenAI client
# ==== OpenAI client (SDK 1.x safe, Render compatible) ====
from openai import OpenAI
import httpx
import os

def create_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY is not set")

    # Render-safe HTTP client (no proxies param in OpenAI 1.x)
    http_client = httpx.Client(
        timeout=60.0,
        follow_redirects=True
    )

    return OpenAI(
        api_key=api_key,
        http_client=http_client
    )

# Create global OpenAI client
client = create_openai_client()


# Knowledge base state
KNOW: Dict = {}                      # Raw knowledge.json data
FLAT_TEXTS: List[str] = []           # All text passages for indexing
MAPPING: List[Dict] = []             # Mapping from text to original path
INDEX = None                         # FAISS or numpy index
INDEX_LOCK = threading.Lock()        # Thread safety for index operations

# Tour databases (USING Tour DATACLASS)
TOUR_NAME_TO_INDEX: Dict[str, int] = {}      # Normalized tour name â†’ index
TOURS_DB: Dict[int, Tour] = {}               # Structured tour database using Tour objects
TOUR_TAGS: Dict[int, List[str]] = {}         # Auto-generated tags for filtering

# Session management (USING ConversationContext DATACLASS)
SESSION_CONTEXTS: Dict[str, ConversationContext] = {}
SESSION_LOCK = threading.Lock()
SESSION_TIMEOUT = 1800  # 30 minutes

# Cache system
_response_cache: Dict[str, CacheEntry] = {}
_cache_lock = threading.Lock()

# Embedding cache (memory optimized)
_embedding_cache: Dict[str, Tuple[List[float], int]] = {}
_embedding_cache_lock = threading.Lock()
MAX_EMBEDDING_CACHE_SIZE = UpgradeFlags.get_all_flags()["EMBEDDING_CACHE_SIZE"]

# =========== MEMORY OPTIMIZATION FUNCTIONS ===========
def optimize_for_memory_profile():
    """Apply memory optimizations based on RAM profile"""
    flags = UpgradeFlags.get_all_flags()
    
    if IS_LOW_RAM:
        logger.info("ðŸ§  Low RAM mode (512MB) - optimizing memory usage")
        # Disable heavy preloading
        global FAISS_ENABLED
        FAISS_ENABLED = False
        
        # Reduce cache sizes
        import functools
        functools.lru_cache(maxsize=128)(embed_text)
        
        # Limit tour loading
        global MAX_TOURS_TO_LOAD
        MAX_TOURS_TO_LOAD = 50
        
    elif IS_HIGH_RAM:
        logger.info("ðŸš€ High RAM mode (2GB) - enabling all features")
        # Enable all features
        FAISS_ENABLED = HAS_FAISS
        MAX_TOURS_TO_LOAD = 1000
        
        # Increase cache sizes
        import functools
        functools.lru_cache(maxsize=flags["EMBEDDING_CACHE_SIZE"])(embed_text)

# =========== UPGRADE 1: MANDATORY FILTER SYSTEM (DATACLASS COMPATIBLE) ===========
class MandatoryFilterSystem:
    """
    UPGRADE 1: Extract and apply mandatory filters BEFORE semantic search
    """
    
    FILTER_PATTERNS = {
        'duration': [
            (r'(?:thá»i gian|máº¥y ngÃ y|bao lÃ¢u|kÃ©o dÃ i)\s*(?:lÃ \s*)?(\d+)\s*(?:ngÃ y|Ä‘Ãªm)', 'exact_duration'),
            (r'(\d+)\s*ngÃ y\s*(?:vÃ \s*)?(\d+)?\s*Ä‘Ãªm', 'days_nights'),
            (r'(\d+)\s*ngÃ y\s*(?:trá»Ÿ lÃªn|trá»Ÿ xuá»‘ng)', 'duration_range'),
            (r'(?:tour|tour)\s*(?:khoáº£ng|táº§m|khoáº£ng)?\s*(\d+)\s*ngÃ y', 'approx_duration'),
            (r'(\d+)\s*ngÃ y', 'exact_duration'),  # THÃŠM DÃ’NG NÃ€Y
        ],
        
        'price': [
            (r'dÆ°á»›i\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'max_price'),
            (r'trÃªn\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'min_price'),
            (r'khoáº£ng\s*(\d[\d,\.]*)\s*(?:Ä‘áº¿n|-)\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'price_range'),
            (r'giÃ¡\s*(?:tá»«\s*)?(\d[\d,\.]*)\s*(?:Ä‘áº¿n|-|tá»›i)\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'price_range'),
            (r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)\s*trá»Ÿ xuá»‘ng', 'max_price'),
            (r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)\s*trá»Ÿ lÃªn', 'min_price'),
        ],
        
        'location': [
            (r'(?:á»Ÿ|táº¡i|vá»|Ä‘áº¿n|thÄƒm)\s+([^.,!?\n]+?)(?:\s|$|\.|,|!|\?)', 'location'),
            (r'(?:Ä‘iá»ƒm Ä‘áº¿n|Ä‘á»‹a Ä‘iá»ƒm|nÆ¡i|vÃ¹ng)\s+(?:lÃ \s*)?([^.,!?\n]+)', 'location'),
            (r'(?:quanh|gáº§n|khu vá»±c)\s+([^.,!?\n]+)', 'near_location'),
        ],
        
        'date_time': [
            (r'(?:thÃ¡ng|vÃ o)\s*(\d{1,2})', 'month'),
            (r'(?:cuá»‘i tuáº§n|weekend)', 'weekend'),
            (r'(?:dá»‹p|lá»…|táº¿t)\s+([^.,!?\n]+)', 'holiday'),
        ],
        
        'group_type': [
            (r'(?:gia Ä‘Ã¬nh|family)', 'family'),
            (r'(?:cáº·p Ä‘Ã´i|couple|Ä‘Ã´i lá»©a)', 'couple'),
            (r'(?:nhÃ³m báº¡n|báº¡n bÃ¨|friends)', 'friends'),
            (r'(?:cÃ´ng ty|doanh nghiá»‡p|team building)', 'corporate'),
            (r'(?:má»™t mÃ¬nh|Ä‘i láº»|solo)', 'solo'),
        ],
    }
    
    @staticmethod
    def extract_filters(message: str) -> FilterSet:
        """
        Extract ALL mandatory filters from user message
        """
        filters = FilterSet()
        
        if not message:
            return filters
        
        message_lower = message.lower()
        
        # 1. DURATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['duration']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'exact_duration':
                    try:
                        days = int(match.group(1))
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'days_nights':
                    try:
                        days = int(match.group(1))
                        nights = int(match.group(2)) if match.group(2) else days
                        # Store in appropriate fields
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass
        
        # 2. PRICE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['price']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                try:
                    if filter_type == 'max_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_max = amount
                            logger.info(f"ðŸ’° Extracted MAX price filter: {amount} VND")
                    
                    elif filter_type == 'min_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_min = amount
                            logger.info(f"ðŸ’° Extracted MIN price filter: {amount} VND")
                    
                    elif filter_type == 'price_range':
                        min_amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(3))
                        max_amount = MandatoryFilterSystem._parse_price(match.group(2), match.group(3))
                        if min_amount and max_amount:
                            filters.price_min = min_amount
                            filters.price_max = max_amount
                            logger.info(f"ðŸ’° Extracted PRICE RANGE: {min_amount} - {max_amount} VND")
                
                except (ValueError, IndexError, AttributeError):
                    continue
        
        # 3. LOCATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['location']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                location = match.group(1).strip()
                if location and len(location) > 1:
                    if filter_type == 'location':
                        filters.location = location
                    elif filter_type == 'near_location':
                        filters.near_location = location
        
        # 4. DATE/TIME FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['date_time']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'month':
                    try:
                        filters.month = int(match.group(1))
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'weekend':
                    filters.weekend = True
                elif filter_type == 'holiday':
                    filters.holiday = match.group(1).strip()
        
        # 5. GROUP TYPE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['group_type']:
            if re.search(pattern, message_lower):
                filters.group_type = filter_type
        
        # 6. SPECIAL KEYWORDS
        special_keywords = {
            'ráº»': ('price_max', 1500000),
            'giÃ¡ ráº»': ('price_max', 1500000),
            'tiáº¿t kiá»‡m': ('price_max', 1500000),
            'cao cáº¥p': ('price_min', 3000000),
            'sang trá»ng': ('price_min', 3000000),
            'premium': ('price_min', 3000000),
            'ngáº¯n ngÃ y': ('duration_max', 2),
            'dÃ i ngÃ y': ('duration_min', 3),
        }
        
        for keyword, (filter_key, value) in special_keywords.items():
            if keyword in message_lower:
                if filter_key == 'price_max':
                    filters.price_max = value
                elif filter_key == 'price_min':
                    filters.price_min = value
                elif filter_key == 'duration_max':
                    filters.duration_max = value
                elif filter_key == 'duration_min':
                    filters.duration_min = value
        
        logger.info(f"ðŸŽ¯ Extracted filters: {filters}")
        return filters
    
    @staticmethod
    def _parse_price(amount_str: str, unit: str) -> Optional[int]:
        """Parse price string like '1.5 triá»‡u' to integer VND"""
        if not amount_str:
            return None
        
        try:
            amount_str = amount_str.replace(',', '').replace('.', '')
            if not amount_str.isdigit():
                return None
            
            amount = int(amount_str)
            
            if unit in ['triá»‡u', 'tr']:
                return amount * 1000000
            elif unit == 'k':
                return amount * 1000
            elif unit == 'nghÃ¬n':
                return amount * 1000
            else:
                return amount if amount > 1000 else amount * 1000
        
        except (ValueError, AttributeError):
            return None
    
    @staticmethod
    def apply_filters(tours_db: Dict[int, Tour], filters: FilterSet) -> List[int]:
        """
        Apply mandatory filters to tour database
        Returns list of tour indices that pass ALL filters
        Enhanced version with better error handling and group_type support
        """
        if filters.is_empty() or not tours_db:
            logger.info(f"ðŸ” No filters or empty DB, returning all {len(tours_db)} tours")
            return list(tours_db.keys())
        
        passing_tours = []
        total_tours = len(tours_db)
        
        try:
            logger.info(f"ðŸŽ¯ Applying filters: {filters}")
            
            # Validate group_type if present
            if hasattr(filters, 'group_type') and filters.group_type:
                valid_group_types = ['family', 'friends', 'corporate', 'solo', 'couple', 'senior', 'group']
                if filters.group_type not in valid_group_types:
                    logger.warning(f"âš ï¸ Invalid group_type: {filters.group_type}, using default filtering")
                    # Continue without group_type filter but log warning
            
            for tour_idx, tour in tours_db.items():
                passes_all = True
                
                # PRICE FILTERING - ENHANCED
                if passes_all and (filters.price_max is not None or filters.price_min is not None):
                    tour_price_text = tour.price or ""
                    if not tour_price_text or tour_price_text.lower() == 'liÃªn há»‡':
                        # If tour doesn't have price, check if we require price filter
                        if filters.price_max is not None or filters.price_min is not None:
                            # If price is required but not available, fail this tour
                            passes_all = False
                    else:
                        tour_prices = MandatoryFilterSystem._extract_tour_prices(tour_price_text)
                        if not tour_prices:
                            # Can't extract price, be conservative - pass if no strict requirement
                            if filters.price_max is not None and filters.price_min is not None:
                                passes_all = False
                        else:
                            min_tour_price = min(tour_prices)
                            max_tour_price = max(tour_prices)
                            
                            # Apply price range filter
                            if filters.price_max is not None and min_tour_price > filters.price_max:
                                passes_all = False
                            if filters.price_min is not None and max_tour_price < filters.price_min:
                                passes_all = False
                
                # DURATION FILTERING - ENHANCED
                if passes_all and (filters.duration_min is not None or filters.duration_max is not None):
                    duration_text = (tour.duration or "").lower()
                    tour_duration = MandatoryFilterSystem._extract_duration_days(duration_text)
                    
                    if tour_duration is not None:
                        if filters.duration_min is not None and tour_duration < filters.duration_min:
                            passes_all = False
                        if filters.duration_max is not None and tour_duration > filters.duration_max:
                            passes_all = False
                    else:
                        # If duration cannot be extracted, be conservative
                        if filters.duration_min is not None and filters.duration_max is not None:
                            passes_all = False
                
                # LOCATION FILTERING - ENHANCED
                if passes_all and (filters.location is not None or filters.near_location is not None):
                    tour_location = (tour.location or "").lower()
                    if filters.location is not None:
                        filter_location = filters.location.lower()
                        # Enhanced location matching
                        if filter_location and filter_location not in tour_location:
                            # Try partial matching for common location names
                            location_keywords = {
                                'huáº¿': ['huáº¿', 'hue'],
                                'quáº£ng trá»‹': ['quáº£ng trá»‹', 'quang tri'],
                                'báº¡ch mÃ£': ['báº¡ch mÃ£', 'bach ma'],
                                'trÆ°á»ng sÆ¡n': ['trÆ°á»ng sÆ¡n', 'truong son'],
                                'Ä‘Ã´ng hÃ ': ['Ä‘Ã´ng hÃ ', 'dong ha']
                            }
                            
                            # Check if filter_location matches any keyword
                            matches = False
                            for keyword, variants in location_keywords.items():
                                if filter_location in variants:
                                    # Check if any variant is in tour_location
                                    for variant in variants:
                                        if variant in tour_location:
                                            matches = True
                                            break
                                if matches:
                                    break
                            
                            if not matches:
                                passes_all = False
                    
                    if filters.near_location is not None and passes_all:
                        near_location = filters.near_location.lower()
                        if near_location and near_location not in tour_location:
                            passes_all = False
                
                # GROUP TYPE FILTERING - ADDED SUPPORT
                if passes_all and hasattr(filters, 'group_type') and filters.group_type:
                    group_type = filters.group_type.lower()
                    tour_summary = (tour.summary or "").lower()
                    tour_tags = [tag.lower() for tag in (tour.tags or [])]
                    
                    # Enhanced group type matching
                    group_type_matched = False
                    
                    # Define keywords for each group type
                    group_keywords = {
                        'family': ['gia Ä‘Ã¬nh', 'tráº» em', 'con nhá»', 'bá»‘ máº¹', 'Ä‘a tháº¿ há»‡'],
                        'friends': ['nhÃ³m báº¡n', 'báº¡n bÃ¨', 'báº¡n tráº»', 'thanh niÃªn', 'sinh viÃªn'],
                        'corporate': ['cÃ´ng ty', 'team building', 'doanh nghiá»‡p', 'nhÃ¢n viÃªn', 'Ä‘á»“ng nghiá»‡p'],
                        'solo': ['má»™t mÃ¬nh', 'Ä‘i láº»', 'solo', 'cÃ¡ nhÃ¢n'],
                        'couple': ['cáº·p Ä‘Ã´i', 'Ä‘Ã´i lá»©a', 'ngÆ°á»i yÃªu', 'tÃ¬nh nhÃ¢n'],
                        'senior': ['ngÆ°á»i lá»›n tuá»•i', 'cao tuá»•i', 'cá»±u chiáº¿n binh', 'veteran'],
                        'group': ['nhÃ³m', 'Ä‘oÃ n', 'táº­p thá»ƒ']
                    }
                    
                    if group_type in group_keywords:
                        keywords = group_keywords[group_type]
                        
                        # Check in tour tags
                        for tag in tour_tags:
                            if any(keyword in tag for keyword in keywords):
                                group_type_matched = True
                                break
                        
                        # Check in tour summary
                        if not group_type_matched:
                            if any(keyword in tour_summary for keyword in keywords):
                                group_type_matched = True
                        
                        # Special handling for senior/veteran
                        if group_type == 'senior':
                            # Also check for historical/meaningful tours
                            if any(word in tour_summary for word in ['lá»‹ch sá»­', 'tri Ã¢n', 'kÃ½ á»©c', 'chiáº¿n tranh']):
                                group_type_matched = True
                        
                        if not group_type_matched:
                            passes_all = False
                    else:
                        logger.warning(f"âš ï¸ Unknown group_type: {group_type}, skipping group filter")
                
                # MONTH FILTERING - ADDED SUPPORT
                if passes_all and hasattr(filters, 'month') and filters.month:
                    try:
                        month = int(filters.month)
                        # Simple season-based filtering
                        tour_summary = (tour.summary or "").lower()
                        
                        # Tours suitable for specific months
                        # This is simplified - in reality would need more complex logic
                        if month in [1, 2, 3]:  # Dry season, good for most tours
                            # No filtering, most tours are suitable
                            pass
                        elif month in [9, 10, 11, 12]:  # Rainy season
                            # Avoid tours with lots of outdoor activities
                            if any(word in tour_summary for word in ['trekking', 'leo nÃºi', 'Ä‘i bá»™ Ä‘Æ°á»ng dÃ i']):
                                passes_all = False
                    except (ValueError, TypeError):
                        # Invalid month format, ignore filter
                        pass
                
                # WEEKEND/HOLIDAY FILTERING - ADDED SUPPORT
                if passes_all:
                    tour_duration = MandatoryFilterSystem._extract_duration_days((tour.duration or "").lower())
                    
                    if hasattr(filters, 'weekend') and filters.weekend and tour_duration:
                        # Weekend tours should be 1-2 days
                        if tour_duration > 2:
                            passes_all = False
                    
                    if hasattr(filters, 'holiday') and filters.holiday and tour_duration:
                        # Holiday tours might be longer
                        # No specific filtering for now
                        pass
                
                if passes_all:
                    passing_tours.append(tour_idx)
            
            logger.info(f"âœ… Filtering complete: {len(passing_tours)}/{total_tours} tours pass")
            
            # If filtering results in too few tours, provide fallback
            if len(passing_tours) < 3 and total_tours > 10:
                logger.info(f"âš ï¸ Only {len(passing_tours)} tours passed filters, applying lenient filtering")
                
                # Apply lenient filtering: tours must pass at least 50% of non-empty filters
                if not filters.is_empty():
                    lenient_passing_tours = []
                    
                    # Count non-empty filters
                    non_empty_filters = 0
                    if filters.price_max is not None or filters.price_min is not None:
                        non_empty_filters += 1
                    if filters.duration_min is not None or filters.duration_max is not None:
                        non_empty_filters += 1
                    if filters.location is not None or filters.near_location is not None:
                        non_empty_filters += 1
                    if hasattr(filters, 'group_type') and filters.group_type:
                        non_empty_filters += 1
                    
                    if non_empty_filters > 0:
                        for tour_idx, tour in tours_db.items():
                            passed_filters = 0
                            
                            # Check price
                            if not (filters.price_max is not None or filters.price_min is not None):
                                passed_filters += 1
                            else:
                                tour_price_text = tour.price or ""
                                if tour_price_text and tour_price_text.lower() != 'liÃªn há»‡':
                                    tour_prices = MandatoryFilterSystem._extract_tour_prices(tour_price_text)
                                    if tour_prices:
                                        min_tour_price = min(tour_prices)
                                        max_tour_price = max(tour_prices)
                                        
                                        price_passed = True
                                        if filters.price_max is not None and min_tour_price > filters.price_max:
                                            price_passed = False
                                        if filters.price_min is not None and max_tour_price < filters.price_min:
                                            price_passed = False
                                        
                                        if price_passed:
                                            passed_filters += 1
                            
                            # Check duration
                            if not (filters.duration_min is not None or filters.duration_max is not None):
                                passed_filters += 1
                            else:
                                duration_text = (tour.duration or "").lower()
                                tour_duration = MandatoryFilterSystem._extract_duration_days(duration_text)
                                
                                if tour_duration is not None:
                                    duration_passed = True
                                    if filters.duration_min is not None and tour_duration < filters.duration_min:
                                        duration_passed = False
                                    if filters.duration_max is not None and tour_duration > filters.duration_max:
                                        duration_passed = False
                                    
                                    if duration_passed:
                                        passed_filters += 1
                            
                            # Check location
                            if not (filters.location is not None or filters.near_location is not None):
                                passed_filters += 1
                            else:
                                tour_location = (tour.location or "").lower()
                                location_passed = True
                                
                                if filters.location is not None:
                                    filter_location = filters.location.lower()
                                    if filter_location not in tour_location:
                                        location_passed = False
                                
                                if filters.near_location is not None and location_passed:
                                    near_location = filters.near_location.lower()
                                    if near_location not in tour_location:
                                        location_passed = False
                                
                                if location_passed:
                                    passed_filters += 1
                            
                            # Check group type
                            if not (hasattr(filters, 'group_type') and filters.group_type):
                                passed_filters += 1
                            else:
                                # Simplified group type check for lenient filtering
                                group_type = filters.group_type.lower()
                                tour_summary = (tour.summary or "").lower()
                                tour_tags = [tag.lower() for tag in (tour.tags or [])]
                                
                                group_passed = False
                                if group_type == 'family':
                                    if any(word in tour_summary for word in ['gia Ä‘Ã¬nh', 'tráº» em', 'con nhá»']):
                                        group_passed = True
                                elif group_type == 'friends':
                                    if any(word in tour_summary for word in ['nhÃ³m báº¡n', 'báº¡n bÃ¨']):
                                        group_passed = True
                                elif group_type == 'senior':
                                    if any(word in tour_summary for word in ['lá»‹ch sá»­', 'tri Ã¢n', 'nháº¹ nhÃ ng']):
                                        group_passed = True
                                else:
                                    # For other group types, be lenient
                                    group_passed = True
                                
                                if group_passed:
                                    passed_filters += 1
                            
                            # Pass if at least 50% of filters passed
                            if passed_filters >= non_empty_filters * 0.5:
                                lenient_passing_tours.append(tour_idx)
                        
                        # Use lenient results if better
                        if len(lenient_passing_tours) > len(passing_tours):
                            logger.info(f"ðŸ”„ Using lenient filtering: {len(lenient_passing_tours)} tours")
                            passing_tours = lenient_passing_tours
            
        except Exception as e:
            logger.error(f"âŒ Error in apply_filters: {e}\n{traceback.format_exc()}")
            # Fallback: return all tours
            passing_tours = list(tours_db.keys())
        
        return passing_tours
        
    @staticmethod
    def _extract_tour_prices(price_text: str) -> List[int]:
        """Extract price numbers from tour price text"""
        prices = []
        
        number_patterns = [
            r'(\d[\d,\.]+)\s*(?:triá»‡u|tr)',
            r'(\d[\d,\.]+)\s*(?:k|nghÃ¬n)',
            r'(\d[\d,\.]+)\s*(?:Ä‘á»“ng|vnÄ‘|vnd)',
            r'(\d[\d,\.]+)\s*-\s*(\d[\d,\.]+)',
        ]
        
        for pattern in number_patterns:
            matches = re.finditer(pattern, price_text, re.IGNORECASE)
            for match in matches:
                try:
                    for i in range(1, 3):
                        if match.group(i):
                            num_str = match.group(i).replace(',', '').replace('.', '')
                            if num_str.isdigit():
                                num = int(num_str)
                                
                                if 'triá»‡u' in match.group(0).lower() or 'tr' in match.group(0).lower():
                                    num = num * 1000000
                                elif 'k' in match.group(0).lower() or 'nghÃ¬n' in match.group(0).lower():
                                    num = num * 1000
                                
                                prices.append(num)
                except (ValueError, AttributeError):
                    continue
        
        if not prices:
            raw_numbers = re.findall(r'\d[\d,\.]+', price_text)
            for num_str in raw_numbers[:2]:
                try:
                    num_str = num_str.replace(',', '').replace('.', '')
                    if num_str.isdigit():
                        num = int(num_str)
                        if 100 <= num <= 10000:
                            num = num * 1000
                        prices.append(num)
                except ValueError:
                    continue
        
        return prices
    
    @staticmethod
    def _extract_duration_days(duration_text: str) -> Optional[int]:
        """Extract duration in days from text"""
        if not duration_text:
            return None
        
        patterns = [
            r'(\d+)\s*ngÃ y',
            r'(\d+)\s*ngÃ y\s*\d*\s*Ä‘Ãªm',
            r'(\d+)\s*Ä‘Ãªm',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, duration_text)
            if match:
                try:
                    return int(match.group(1))
                except (ValueError, IndexError):
                    continue
        
        return None

# =========== UPGRADE 2: DEDUPLICATION ENGINE (DATACLASS COMPATIBLE) ===========
class DeduplicationEngine:
    """
    UPGRADE 2: Remove duplicate and highly similar results
    """
    
    SIMILARITY_THRESHOLD = 0.85
    MIN_TEXT_LENGTH = 20
    
    @staticmethod
    def calculate_similarity(text1: str, text2: str) -> float:
        """Calculate text similarity using multiple methods"""
        if not text1 or not text2:
            return 0.0
        
        text1_norm = DeduplicationEngine._normalize_text(text1)
        text2_norm = DeduplicationEngine._normalize_text(text2)
        
        if len(text1_norm) < DeduplicationEngine.MIN_TEXT_LENGTH or len(text2_norm) < DeduplicationEngine.MIN_TEXT_LENGTH:
            return 0.0
        
        seq_ratio = SequenceMatcher(None, text1_norm, text2_norm).ratio()
        
        words1 = set(text1_norm.split())
        words2 = set(text2_norm.split())
        
        if not words1 or not words2:
            jaccard = 0.0
        else:
            intersection = words1.intersection(words2)
            union = words1.union(words2)
            jaccard = len(intersection) / len(union)
        
        prefix_len = min(50, min(len(text1_norm), len(text2_norm)))
        prefix1 = text1_norm[:prefix_len]
        prefix2 = text2_norm[:prefix_len]
        prefix_sim = SequenceMatcher(None, prefix1, prefix2).ratio()
        
        similarity = (seq_ratio * 0.5) + (jaccard * 0.3) + (prefix_sim * 0.2)
        
        return similarity
    
    @staticmethod
    def _normalize_text(text: str) -> str:
        """Normalize text for comparison"""
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        stopwords = {'vÃ ', 'cá»§a', 'cho', 'vá»›i', 'táº¡i', 'á»Ÿ', 'nÃ y', 'Ä‘Ã³', 'kia', 'vá»', 'trong'}
        words = [word for word in text.split() if word not in stopwords]
        
        return ' '.join(words)
    
    @staticmethod
    def deduplicate_passages(passages: List[Tuple[float, Dict]], 
                            similarity_threshold: float = None) -> List[Tuple[float, Dict]]:
        """
        Remove duplicate passages from results
        """
        if len(passages) <= 1:
            return passages
        
        threshold = similarity_threshold or DeduplicationEngine.SIMILARITY_THRESHOLD
        unique_passages = []
        seen_passages = []
        
        sorted_passages = sorted(passages, key=lambda x: x[0], reverse=True)
        
        for score, passage in sorted_passages:
            text = passage.get('text', '').strip()
            path = passage.get('path', '')
            
            if not text or len(text) < DeduplicationEngine.MIN_TEXT_LENGTH:
                unique_passages.append((score, passage))
                continue
            
            is_duplicate = False
            for seen_text, seen_path in seen_passages:
                tour_match1 = re.search(r'tours\[(\d+)\]', path)
                tour_match2 = re.search(r'tours\[(\d+)\]', seen_path)
                
                if tour_match1 and tour_match2:
                    if tour_match1.group(1) == tour_match2.group(1):
                        field1 = path.split('.')[-1] if '.' in path else ''
                        field2 = seen_path.split('.')[-1] if '.' in seen_path else ''
                        if field1 == field2:
                            is_duplicate = True
                            break
                
                similarity = DeduplicationEngine.calculate_similarity(text, seen_text)
                if similarity > threshold:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_passages.append((score, passage))
                seen_passages.append((text, path))
        
        logger.info(f"ðŸ”„ Deduplication: {len(passages)} â†’ {len(unique_passages)} passages")
        return unique_passages
    
    @staticmethod
    def merge_similar_tours(tour_indices: List[int], tours_db: Dict[int, Tour]) -> List[int]:
        """Merge tours that are essentially the same"""
        if len(tour_indices) <= 1:
            return tour_indices
        
        tour_groups = []
        processed = set()
        
        for i, idx1 in enumerate(tour_indices):
            if idx1 in processed:
                continue
            
            group = [idx1]
            tour1 = tours_db.get(idx1)
            name1 = (tour1.name if tour1 else "").strip()
            
            if not name1:
                processed.add(idx1)
                tour_groups.append(group)
                continue
            
            for j, idx2 in enumerate(tour_indices[i+1:], i+1):
                if idx2 in processed:
                    continue
                
                tour2 = tours_db.get(idx2)
                name2 = (tour2.name if tour2 else "").strip()
                
                if not name2:
                    continue
                
                similarity = DeduplicationEngine.calculate_similarity(name1, name2)
                if similarity > 0.9:
                    group.append(idx2)
                    processed.add(idx2)
            
            processed.add(idx1)
            tour_groups.append(group)
        
        best_tours = []
        for group in tour_groups:
            if not group:
                continue
            
            if len(group) == 1:
                best_tours.append(group[0])
                continue
            
            best_score = -1
            best_idx = group[0]
            
            for idx in group:
                tour = tours_db.get(idx)
                if not tour:
                    continue
                
                score = 0
                
                if tour.name:
                    score += 2
                if tour.duration:
                    score += 2
                if tour.location:
                    score += 2
                if tour.price:
                    score += 3
                if tour.includes:
                    score += 2
                if tour.summary:
                    score += 1
                
                for field in [tour.includes, tour.summary, tour.notes]:
                    if isinstance(field, str) and len(field) > 50:
                        score += 1
                    elif isinstance(field, list) and field:
                        score += len(field)
                
                if score > best_score:
                    best_score = score
                    best_idx = idx
            
            best_tours.append(best_idx)
        
        logger.info(f"ðŸ”„ Tour merging: {len(tour_indices)} â†’ {len(best_tours)} unique tours")
        return best_tours

# =========== UPGRADE 3: ENHANCED FIELD DETECTION (DATACLASS COMPATIBLE) ===========
class EnhancedFieldDetector:
    """
    UPGRADE 3: Better detection of what user is asking for
    """
    
    FIELD_DETECTION_RULES = [
        # TOUR LIST
        {
            "field": "tour_name",
            "patterns": [
                (r'liá»‡t kÃª.*tour|danh sÃ¡ch.*tour|cÃ¡c tour|cÃ³ nhá»¯ng tour nÃ o', 1.0),
                (r'tour nÃ o.*cÃ³|tour nÃ o.*hiá»‡n|tour nÃ o.*Ä‘ang', 0.9),
                (r'ká»ƒ tÃªn.*tour|nÃªu tÃªn.*tour|tÃªn cÃ¡c tour', 0.9),
                (r'cÃ³ máº¥y.*tour|bao nhiÃªu.*tour|sá»‘ lÆ°á»£ng.*tour', 0.8),
                (r'list tour|show tour|all tour|every tour', 0.8),
            ],
            "keywords": [
                ("liá»‡t kÃª", 0.9), ("danh sÃ¡ch", 0.9), ("cÃ¡c", 0.7),
                ("táº¥t cáº£", 0.8), ("má»i", 0.7), ("máº¥y", 0.6),
                ("bao nhiÃªu", 0.7), ("sá»‘ lÆ°á»£ng", 0.7),
            ]
        },
        
        # PRICE
        {
            "field": "price",
            "patterns": [
                (r'giÃ¡.*bao nhiÃªu|bao nhiÃªu tiá»n|chi phÃ­.*bao nhiÃªu', 1.0),
                (r'giÃ¡ tour|giÃ¡ cáº£|giÃ¡ thÃ nh|chi phÃ­ tour', 0.9),
                (r'tour.*giÃ¡.*bao nhiÃªu|tour.*bao nhiÃªu tiá»n', 0.95),
                (r'pháº£i tráº£.*bao nhiÃªu|tá»‘n.*bao nhiÃªu|máº¥t.*bao nhiÃªu', 0.8),
                (r'Ä‘Ã³ng.*bao nhiÃªu|thanh toÃ¡n.*bao nhiÃªu', 0.8),
            ],
            "keywords": [
                ("giÃ¡", 0.8), ("tiá»n", 0.7), ("chi phÃ­", 0.8),
                ("Ä‘Ã³ng", 0.6), ("tráº£", 0.6), ("tá»‘n", 0.6),
                ("phÃ­", 0.7), ("kinh phÃ­", 0.7), ("tá»•ng chi", 0.7),
            ]
        },
        
        # DURATION
        {
            "field": "duration",
            "patterns": [
                (r'thá»i gian.*bao lÃ¢u|máº¥y ngÃ y.*Ä‘i|bao lÃ¢u.*tour', 1.0),
                (r'tour.*bao nhiÃªu ngÃ y|máº¥y ngÃ y.*tour', 0.9),
                (r'Ä‘i trong.*bao lÃ¢u|kÃ©o dÃ i.*bao lÃ¢u', 0.9),
                (r'thá»i lÆ°á»£ng.*bao nhiÃªu|thá»i gian.*dÃ i bao lÃ¢u', 0.8),
            ],
            "keywords": [
                ("bao lÃ¢u", 0.9), ("máº¥y ngÃ y", 0.9), ("thá»i gian", 0.8),
                ("kÃ©o dÃ i", 0.7), ("thá»i lÆ°á»£ng", 0.8), ("ngÃ y", 0.6),
                ("Ä‘Ãªm", 0.6), ("thá»i háº¡n", 0.7),
            ]
        },
        
        # LOCATION
        {
            "field": "location",
            "patterns": [
                (r'á»Ÿ Ä‘Ã¢u|Ä‘i Ä‘Ã¢u|Ä‘áº¿n Ä‘Ã¢u|tá»›i Ä‘Ã¢u|thÄƒm quan Ä‘Ã¢u', 1.0),
                (r'Ä‘á»‹a Ä‘iá»ƒm.*nÃ o|nÆ¡i nÃ o|vÃ¹ng nÃ o|khu vá»±c nÃ o', 0.9),
                (r'tour.*á»Ÿ.*Ä‘Ã¢u|tour.*Ä‘i.*Ä‘Ã¢u', 0.9),
                (r'khÃ¡m phÃ¡.*Ä‘Ã¢u|thÄƒm.*Ä‘Ã¢u|ghÃ©.*Ä‘Ã¢u', 0.8),
            ],
            "keywords": [
                ("á»Ÿ Ä‘Ã¢u", 1.0), ("Ä‘i Ä‘Ã¢u", 1.0), ("Ä‘áº¿n Ä‘Ã¢u", 0.9),
                ("tá»›i Ä‘Ã¢u", 0.9), ("Ä‘á»‹a Ä‘iá»ƒm", 0.8), ("nÆ¡i", 0.7),
                ("vÃ¹ng", 0.7), ("khu vá»±c", 0.7),
            ]
        },
        
        # SUMMARY
        {
            "field": "summary",
            "patterns": [
                (r'cÃ³ gÃ¬ hay|cÃ³ gÃ¬ Ä‘áº·c biá»‡t|cÃ³ gÃ¬ thÃº vá»‹', 0.9),
                (r'tour nÃ y tháº¿ nÃ o|tour ra sao|chuyáº¿n Ä‘i nhÆ° nÃ o', 0.8),
                (r'giá»›i thiá»‡u.*tour|mÃ´ táº£.*tour|nÃ³i vá».*tour', 0.8),
                (r'tour.*cÃ³ gÃ¬|Ä‘i.*Ä‘Æ°á»£c gÃ¬|tráº£i nghiá»‡m.*gÃ¬', 0.7),
                (r'Ä‘iá»ƒm nháº¥n.*tour|ná»•i báº­t.*gÃ¬|Ä‘áº·c sáº¯c.*gÃ¬', 0.7),
            ],
            "keywords": [
                ("cÃ³ gÃ¬", 0.7), ("tháº¿ nÃ o", 0.6), ("ra sao", 0.6),
                ("giá»›i thiá»‡u", 0.7), ("mÃ´ táº£", 0.7), ("nÃ³i vá»", 0.6),
                ("Ä‘iá»ƒm nháº¥n", 0.7), ("ná»•i báº­t", 0.7), ("Ä‘áº·c sáº¯c", 0.7),
            ]
        },
        
        # INCLUDES
        {
            "field": "includes",
            "patterns": [
                (r'lá»‹ch trÃ¬nh.*chi tiáº¿t|chÆ°Æ¡ng trÃ¬nh.*chi tiáº¿t', 0.9),
                (r'lÃ m gÃ¬.*tour|hoáº¡t Ä‘á»™ng.*gÃ¬|sinh hoáº¡t.*gÃ¬', 0.8),
                (r'tour.*gá»“m.*gÃ¬|bao gá»“m.*gÃ¬|gá»“m nhá»¯ng gÃ¬', 0.8),
                (r'Ä‘i Ä‘Ã¢u.*lÃ m gÃ¬|thÄƒm quan.*gÃ¬|khÃ¡m phÃ¡.*gÃ¬', 0.7),
            ],
            "keywords": [
                ("lá»‹ch trÃ¬nh", 0.8), ("chÆ°Æ¡ng trÃ¬nh", 0.8), ("lÃ m gÃ¬", 0.7),
                ("hoáº¡t Ä‘á»™ng", 0.7), ("sinh hoáº¡t", 0.6), ("gá»“m", 0.6),
                ("bao gá»“m", 0.7), ("gá»“m nhá»¯ng", 0.7),
            ]
        },
    ]
    
    @staticmethod
    def detect_field_with_confidence(message: str) -> Tuple[Optional[str], float, Dict[str, float]]:
        """
        Detect which field user is asking about with confidence scores
        """
        if not message:
            return None, 0.0, {}
        
        message_lower = message.lower()
        scores = {}
        
        for rule in EnhancedFieldDetector.FIELD_DETECTION_RULES:
            field = rule["field"]
            field_score = 0.0
            
            for pattern, weight in rule["patterns"]:
                if re.search(pattern, message_lower):
                    field_score = max(field_score, weight)
            
            for keyword, weight in rule["keywords"]:
                if keyword in message_lower:
                    position = message_lower.find(keyword)
                    position_factor = 1.0 - (position / max(len(message_lower), 1))
                    adjusted_weight = weight * (0.7 + 0.3 * position_factor)
                    field_score = max(field_score, adjusted_weight)
            
            if field_score > 0:
                field_score = min(field_score * 1.1, 1.0)
            
            scores[field] = field_score
        
        best_field = None
        best_score = 0.0
        
        for field, score in scores.items():
            if score > best_score:
                best_score = score
                best_field = field
        
        if (best_score < 0.3 and 
            ("cÃ³ gÃ¬" in message_lower or "tháº¿ nÃ o" in message_lower) and
            "tour" in message_lower):
            best_field = "summary"
            best_score = 0.6
        
        logger.info(f"ðŸ” Field detection: '{message}' â†’ {best_field} (confidence: {best_score:.2f})")
        return best_field, best_score, scores

# =========== UPGRADE 4: QUESTION PIPELINE (DATACLASS COMPATIBLE) ===========
class QuestionPipeline:
    """
    UPGRADE 4: Process different types of questions differently
    """
    
    @staticmethod
    def classify_question(message: str) -> Tuple[QuestionType, float, Dict]:
        """
        Classify question type with confidence and metadata
        """
        message_lower = message.lower()
        type_scores = defaultdict(float)
        metadata = {}
        
        # LISTING detection - CHá»ˆ khi yÃªu cáº§u rÃµ rÃ ng liá»‡t kÃª DANH SÃCH
        listing_patterns = [
            (r'liá»‡t kÃª.*táº¥t cáº£.*tour|danh sÃ¡ch.*táº¥t cáº£.*tour|táº¥t cáº£.*tour', 0.95),
            (r'liá»‡t kÃª.*tour|danh sÃ¡ch.*tour|list.*tour', 0.9),
            (r'ká»ƒ tÃªn.*tour|nÃªu tÃªn.*tour', 0.9),
            (r'cÃ³ nhá»¯ng.*tour nÃ o|cÃ³ máº¥y.*tour|máº¥y.*tour', 0.7),
            (r'bÃªn báº¡n.*cÃ³.*tour|hiá»‡n cÃ³.*tour', 0.75),
        ]
        
        for pattern, weight in listing_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.LISTING] = max(
                    type_scores[QuestionType.LISTING], weight
                )
        
        # COMPARISON detection
        comparison_patterns = [
            (r'so sÃ¡nh.*vÃ |Ä‘á»‘i chiáº¿u.*vÃ ', 0.95),
            (r'khÃ¡c nhau.*nÃ o|giá»‘ng nhau.*nÃ o', 0.9),
            (r'nÃªn chá»n.*nÃ o|tá»‘t hÆ¡n.*nÃ o|hÆ¡n kÃ©m.*nÃ o', 0.85),
            (r'tour.*vÃ .*tour', 0.8),
            (r'sÃ¡nh.*vá»›i|Ä‘á»‘i chiáº¿u.*vá»›i', 0.8),
        ]
        
        for pattern, weight in comparison_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.COMPARISON] = max(
                    type_scores[QuestionType.COMPARISON], weight
                )
                metadata['comparison_type'] = 'direct'
        
        # RECOMMENDATION detection
        recommendation_patterns = [
            (r'phÃ¹ há»£p.*vá»›i|nÃªn Ä‘i.*nÃ o|gá»£i Ã½.*tour', 0.95),
            (r'tour nÃ o.*phÃ¹ há»£p|phÃ¹ há»£p.*tour nÃ o', 0.95),
            (r'tour.*tá»‘t.*nháº¥t|tour.*hay nháº¥t|tour.*lÃ½ tÆ°á»Ÿng', 0.9),
            (r'Ä‘á» xuáº¥t.*tour|tÆ° váº¥n.*tour|chá»n.*tour nÃ o', 0.9),
            (r'tour nÃ o.*cho.*gia Ä‘Ã¬nh|tour.*gia Ä‘Ã¬nh|gia Ä‘Ã¬nh.*tour', 0.9),
            (r'tour nÃ o.*cho|dÃ nh cho.*tour|tour.*dÃ nh cho', 0.85),
            (r'nÃªn.*tour nÃ o|nÃªn chá»n.*tour|tour.*nÃªn', 0.85),
            (r'tour.*nháº¹ nhÃ ng|tour.*dá»…|tour.*phÃ¹ há»£p.*ngÆ°á»i', 0.85),
            (r'tour.*tráº» em|tour.*con nÃ­t|tour.*bÃ©', 0.85),
            (r'tour.*ngÆ°á»i lá»›n tuá»•i|tour.*cao tuá»•i|tour.*nghá»‰ dÆ°á»¡ng', 0.85),
            (r'chi phÃ­.*vá»«a pháº£i|giÃ¡.*phÃ¹ há»£p|giÃ¡.*há»£p lÃ½', 0.8),
            (r'cho.*tÃ´i|dÃ nh cho.*tÃ´i|há»£p vá»›i.*tÃ´i', 0.75),
            (r'náº¿u.*thÃ¬.*nÃªn.*tour|nÃªn chá»n.*tour', 0.8),
        ]
        
        for pattern, weight in recommendation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.RECOMMENDATION] = max(
                    type_scores[QuestionType.RECOMMENDATION], weight
                )
        
        # GREETING detection
        greeting_words = ['xin chÃ o', 'chÃ o', 'hello', 'hi', 'helo', 'chao']
        greeting_score = 0.0
        for word in greeting_words:
            if word in message_lower:
                if message_lower.startswith(word) or f" {word} " in message_lower or message_lower.endswith(f" {word}"):
                    greeting_score += 0.3
        
        other_intent_score = max([score for qtype, score in type_scores.items() 
                                 if qtype != QuestionType.GREETING], default=0.0)
        
        if greeting_score > 0.8 and other_intent_score < 0.3:
            type_scores[QuestionType.GREETING] = min(greeting_score, 1.0)
        
        # FAREWELL detection
        farewell_words = ['táº¡m biá»‡t', 'cáº£m Æ¡n', 'thanks', 'thank you', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            type_scores[QuestionType.FAREWELL] = 0.95
        
        # CALCULATION detection
        calculation_patterns = [
            (r'tÃ­nh toÃ¡n|tÃ­nh.*bao nhiÃªu|tá»•ng.*bao nhiÃªu', 0.9),
            (r'cá»™ng.*láº¡i|nhÃ¢n.*lÃªn|chia.*ra', 0.8),
            (r'bao nhiÃªu.*ngÆ°á»i|máº¥y.*ngÆ°á»i|sá»‘ lÆ°á»£ng.*ngÆ°á»i', 0.7),
        ]
        
        for pattern, weight in calculation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.CALCULATION] = max(
                    type_scores[QuestionType.CALCULATION], weight
                )
        
        # COMPLEX question detection
        complex_indicators = [
            ('vÃ ', 0.3), ('rá»“i', 0.4), ('sau Ä‘Ã³', 0.5),
            ('tiáº¿p theo', 0.5), ('ngoÃ i ra', 0.4), ('thÃªm ná»¯a', 0.4),
        ]
        
        complex_score = 0.0
        for indicator, weight in complex_indicators:
            if indicator in message_lower:
                complex_score += weight
        
        if complex_score > 0.8:
            type_scores[QuestionType.COMPLEX] = min(complex_score / 2, 1.0)
            metadata['complex_parts'] = QuestionPipeline._split_complex_question(message)
        
        # DEFAULT: INFORMATION request
        if not type_scores:
            type_scores[QuestionType.INFORMATION] = 0.6
        else:
            info_keywords = ['lÃ  gÃ¬', 'bao nhiÃªu', 'á»Ÿ Ä‘Ã¢u', 'khi nÃ o', 'tháº¿ nÃ o', 'ai', 'táº¡i sao']
            if any(keyword in message_lower for keyword in info_keywords):
                type_scores[QuestionType.INFORMATION] = max(
                    type_scores.get(QuestionType.INFORMATION, 0),
                    0.5
                )
        
        # Determine best type
        best_type = QuestionType.INFORMATION
        best_score = 0.0
        
        for qtype, score in type_scores.items():
            if score > best_score:
                best_score = score
                best_type = qtype
        
        if best_score < 0.5:
            best_type = QuestionType.INFORMATION
            best_score = 0.5
        
        logger.info(f"ðŸŽ¯ Question classification: '{message}' â†’ {best_type.value} (score: {best_score:.2f})")
        return best_type, best_score, metadata
    
    @staticmethod
    def _split_complex_question(message: str) -> List[str]:
        """Split complex multi-part question into simpler parts"""
        split_patterns = [
            r'\s+vÃ \s+',
            r'\s+rá»“i\s+',
            r'\s+sau Ä‘Ã³\s+',
            r'\s+tiáº¿p theo\s+',
            r'\s+ngoÃ i ra\s+',
            r'\s+thÃªm ná»¯a\s+',
            r'\s+Ä‘á»“ng thá»i\s+',
            r'\s+cuá»‘i cÃ¹ng\s+',
        ]
        
        parts = [message]
        
        for pattern in split_patterns:
            new_parts = []
            for part in parts:
                split_result = re.split(pattern, part, flags=re.IGNORECASE)
                new_parts.extend([p.strip() for p in split_result if p.strip()])
            parts = new_parts
        
        return parts
    
    @staticmethod
    def process_comparison_question(tour_indices: List[int], tours_db: Dict[int, Tour], 
                                  aspect: str = "", context: Dict = None) -> str:
        """
        Process comparison question between tours
        """
        if len(tour_indices) < 2:
            return "Cáº§n Ã­t nháº¥t 2 tour Ä‘á»ƒ so sÃ¡nh."
        
        tours_to_compare = []
        for idx in tour_indices[:3]:
            tour = tours_db.get(idx)
            if tour:
                tours_to_compare.append((idx, tour))
        
        if len(tours_to_compare) < 2:
            return "KhÃ´ng tÃ¬m tháº¥y Ä‘á»§ thÃ´ng tin tour Ä‘á»ƒ so sÃ¡nh."
        
        if not aspect:
            aspect = 'price'
        
        result_lines = []
        
        headers = ["TIÃŠU CHÃ"]
        for idx, tour in tours_to_compare:
            tour_name = tour.name or f'Tour #{idx}'
            headers.append(tour_name[:25])
        
        result_lines.append(" | ".join(headers))
        result_lines.append("-" * (len(headers) * 30))
        
        comparison_fields = [
            ('duration', 'â±ï¸ Thá»i gian'),
            ('location', 'ðŸ“ Äá»‹a Ä‘iá»ƒm'),
            ('price', 'ðŸ’° GiÃ¡ tour'),
            ('accommodation', 'ðŸ¨ Chá»— á»Ÿ'),
            ('meals', 'ðŸ½ï¸ Ä‚n uá»‘ng'),
            ('transport', 'ðŸš— Di chuyá»ƒn'),
            ('summary', 'ðŸ“ MÃ´ táº£'),
        ]
        
        for field, display_name in comparison_fields:
            if aspect and field != aspect and aspect not in ['all', 'táº¥t cáº£']:
                continue
            
            row = [display_name]
            all_values = []
            
            for idx, tour in tours_to_compare:
                value = getattr(tour, field, 'N/A')
                if isinstance(value, list):
                    value = ', '.join(value[:2])
                row.append(str(value)[:30])
                all_values.append(str(value).lower())
            
            if len(set(all_values)) > 1 or aspect == field:
                result_lines.append(" | ".join(row))
        
        result_lines.append("\n" + "="*50)
        result_lines.append("**ÄÃNH GIÃ & Gá»¢I Ã:**")
        
        durations = [tour.duration for _, tour in tours_to_compare]
        if any('1 ngÃ y' in d for d in durations) and any('2 ngÃ y' in d for d in durations):
            result_lines.append("â€¢ Náº¿u báº¡n cÃ³ Ã­t thá»i gian: Chá»n tour 1 ngÃ y")
            result_lines.append("â€¢ Náº¿u muá»‘n tráº£i nghiá»‡m sÃ¢u: Chá»n tour 2 ngÃ y")
        
        prices = []
        for _, tour in tours_to_compare:
            price_text = tour.price or ''
            price_nums = re.findall(r'\d[\d,\.]+', price_text)
            if price_nums:
                try:
                    price = int(price_nums[0].replace(',', '').replace('.', ''))
                    prices.append(price)
                except:
                    pass
        
        if len(prices) >= 2:
            min_price_idx = prices.index(min(prices))
            max_price_idx = prices.index(max(prices))
            
            if prices[max_price_idx] > prices[min_price_idx] * 1.5:
                result_lines.append(f"â€¢ Tiáº¿t kiá»‡m chi phÃ­: {headers[min_price_idx + 1]}")
                result_lines.append(f"â€¢ Tráº£i nghiá»‡m cao cáº¥p: {headers[max_price_idx + 1]}")
        
        result_lines.append("\nðŸ’¡ *LiÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t*")
        
        return "\n".join(result_lines)

# =========== UPGRADE 5: COMPLEX QUERY SPLITTER (DATACLASS COMPATIBLE) ===========
class ComplexQueryProcessor:
    """
    UPGRADE 5: Handle complex multi-condition queries
    """
    
    @staticmethod
    def split_query(query: str) -> List[Dict[str, Any]]:
        """
        Split complex query into sub-queries with priorities
        """
        sub_queries = []
        
        complexity_score = ComplexQueryProcessor._calculate_complexity(query)
        if complexity_score < 1.5:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': {},
                'focus': 'general'
            }]
        
        conditions = ComplexQueryProcessor._extract_conditions(query)
        
        if len(conditions) <= 1:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': conditions[0] if conditions else {},
                'focus': 'general'
            }]
        
        sub_queries.append({
            'query': query,
            'priority': 1.0,
            'filters': ComplexQueryProcessor._merge_conditions(conditions),
            'focus': 'specific'
        })
        
        location_conds = [c for c in conditions if 'location' in c]
        other_conds = [c for c in conditions if 'location' not in c]
        
        if location_conds and other_conds:
            for other_cond in other_conds[:2]:
                merged = ComplexQueryProcessor._merge_conditions(location_conds + [other_cond])
                sub_queries.append({
                    'query': f"{query} (focus on location + {list(other_cond.keys())[0]})",
                    'priority': 0.8,
                    'filters': merged,
                    'focus': list(other_cond.keys())[0]
                })
        
        important_conds = ['price', 'duration', 'location']
        for cond_type in important_conds:
            conds_of_type = [c for c in conditions if cond_type in c]
            if conds_of_type:
                sub_queries.append({
                    'query': f"{query} (focus on {cond_type})",
                    'priority': 0.6,
                    'filters': conds_of_type[0],
                    'focus': cond_type
                })
        
        sub_queries.sort(key=lambda x: x['priority'], reverse=True)
        
        logger.info(f"ðŸ”€ Split query into {len(sub_queries)} sub-queries")
        return sub_queries[:3]
    
    @staticmethod
    def _calculate_complexity(query: str) -> float:
        """Calculate how complex a query is"""
        complexity = 0.0
        
        aspects = {
            'price': ['giÃ¡', 'tiá»n', 'chi phÃ­', 'Ä‘áº¯t', 'ráº»'],
            'duration': ['ngÃ y', 'Ä‘Ãªm', 'bao lÃ¢u', 'thá»i gian'],
            'location': ['á»Ÿ', 'táº¡i', 'Ä‘áº¿n', 'vá»', 'Ä‘á»‹a Ä‘iá»ƒm'],
            'quality': ['tá»‘t', 'hay', 'Ä‘áº¹p', 'háº¥p dáº«n', 'thÃº vá»‹'],
            'type': ['thiá»n', 'khÃ­ cÃ´ng', 'retreat', 'chá»¯a lÃ nh'],
        }
        
        query_lower = query.lower()
        
        distinct_aspects = 0
        for aspect, keywords in aspects.items():
            if any(keyword in query_lower for keyword in keywords):
                distinct_aspects += 1
        
        complexity += distinct_aspects * 0.5
        complexity += min(len(query.split()) / 10, 1.0)
        
        conjunctions = ['vÃ ', 'vá»›i', 'cÃ³', 'cho', 'mÃ ', 'nhÆ°ng']
        for conj in conjunctions:
            if conj in query_lower:
                complexity += 0.3
        
        return complexity
    
    @staticmethod
    def _extract_conditions(query: str) -> List[Dict[str, Any]]:
        """Extract individual conditions from query"""
        conditions = []
        
        filters = MandatoryFilterSystem.extract_filters(query)
        
        if filters.price_min is not None or filters.price_max is not None:
            price_cond = {'price': {}}
            if filters.price_min is not None:
                price_cond['price']['min'] = filters.price_min
            if filters.price_max is not None:
                price_cond['price']['max'] = filters.price_max
            conditions.append(price_cond)
        
        if filters.duration_min is not None or filters.duration_max is not None:
            duration_cond = {'duration': {}}
            if filters.duration_min is not None:
                duration_cond['duration']['min'] = filters.duration_min
            if filters.duration_max is not None:
                duration_cond['duration']['max'] = filters.duration_max
            conditions.append(duration_cond)
        
        if filters.location:
            conditions.append({'location': filters.location})
        if filters.near_location:
            conditions.append({'near_location': filters.near_location})
        
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['ráº»', 'giÃ¡ ráº»', 'tiáº¿t kiá»‡m']):
            conditions.append({'price_quality': 'budget'})
        if any(word in query_lower for word in ['cao cáº¥p', 'sang', 'premium']):
            conditions.append({'price_quality': 'premium'})
        
        if 'thiá»n' in query_lower:
            conditions.append({'activity_type': 'meditation'})
        if 'khÃ­ cÃ´ng' in query_lower:
            conditions.append({'activity_type': 'qigong'})
        if 'retreat' in query_lower:
            conditions.append({'activity_type': 'retreat'})
        if 'chá»¯a lÃ nh' in query_lower:
            conditions.append({'activity_type': 'healing'})
        
        tour_name_patterns = [
            r'tour\s+([^vÃ \s,]+)\s+vÃ \s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+vá»›i\s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+.*tour\s+([^\s,]+)',
        ]
        
        for pattern in tour_name_patterns:
            matches = re.finditer(pattern, query_lower)
            for match in matches:
                for i in range(1, 3):
                    if match.group(i):
                        tour_name = match.group(i).strip()
                        normalized_name = FuzzyMatcher.normalize_vietnamese(tour_name)
                        for name, idx in TOUR_NAME_TO_INDEX.items():
                            if normalized_name in name or name in normalized_name:
                                conditions.append({'specific_tour': idx})
                                logger.info(f"ðŸ” Extracted tour name from complex query: {tour_name} â†’ index {idx}")
        
        return conditions
    
    @staticmethod
    def _merge_conditions(conditions: List[Dict]) -> Dict[str, Any]:
        """Merge multiple conditions into one filter dict"""
        merged = {}
        
        for condition in conditions:
            for key, value in condition.items():
                if key in merged:
                    if isinstance(merged[key], dict) and isinstance(value, dict):
                        merged[key].update(value)
                    elif isinstance(merged[key], list) and isinstance(value, list):
                        merged[key].extend(value)
                    else:
                        if isinstance(value, dict) or (isinstance(value, str) and len(value) > len(str(merged[key]))):
                            merged[key] = value
                else:
                    merged[key] = value
        
        return merged

# =========== UPGRADE 6: FUZZY MATCHING (DATACLASS COMPATIBLE) ===========
class FuzzyMatcher:
    """
    UPGRADE 6: Handle misspellings and variations in tour names
    """
    
    SIMILARITY_THRESHOLD = 0.75
    
    @staticmethod
    def normalize_vietnamese(text: str) -> str:
        """
        Normalize Vietnamese text for fuzzy matching
        """
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        
        replacements = {
            'Ä‘': 'd',
            'khÃ´ng': 'ko',
            'khong': 'ko',
            'rá»“i': 'roi',
            'vá»›i': 'voi',
            'Ä‘Æ°á»£c': 'duoc',
            'má»™t': 'mot',
            'hai': '2',
            'ba': '3',
            'bá»‘n': '4',
            'nÄƒm': '5',
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    @staticmethod
    def find_similar_tours(query: str, tour_names: Dict[str, int]) -> List[Tuple[int, float]]:
        """
        Find tours with names similar to query - Enhanced version
        Returns list of (tour_idx, similarity_score) sorted by similarity
        """
        if not query or not tour_names:
            logger.info(f"ðŸ” Fuzzy matching: Empty query or tour_names, returning empty list")
            return []
        
        query_lower = query.lower().strip()
        query_norm = FuzzyMatcher.normalize_vietnamese(query_lower)
        
        if not query_norm:
            logger.info(f"ðŸ” Fuzzy matching: Cannot normalize query '{query}'")
            return []
        
        logger.info(f"ðŸ” Fuzzy matching: Query '{query}' -> Normalized: '{query_norm}'")
        
        matches = []
        query_words = set(query_norm.split())
        
        # Define common stop words to ignore
        stop_words = {'tour', 'chÆ°Æ¡ng', 'trÃ¬nh', 'cá»§a', 'cho', 'vá»›i', 'vÃ ', 'táº¡i', 'á»Ÿ', 'tá»«'}
        query_filtered_words = [word for word in query_norm.split() if word not in stop_words]
        
        # Enhanced keyword extraction
        query_keywords = set(query_filtered_words)
        
        # Check for specific tour patterns
        known_tour_patterns = {
            'báº¡ch mÃ£': ['báº¡ch mÃ£', 'bach ma'],
            'trÆ°á»ng sÆ¡n': ['trÆ°á»ng sÆ¡n', 'truong son', 'tÃ¢y trÆ°á»ng sÆ¡n'],
            'mÆ°a Ä‘á»': ['mÆ°a Ä‘á»', 'mua do'],
            'ngá»n lá»­a': ['ngá»n lá»­a', 'ngon lua'],
            'kÃ½ á»©c': ['kÃ½ á»©c', 'ky uc'],
            'lá»‹ch sá»­': ['lá»‹ch sá»­', 'lich su'],
            'Ä‘áº¡i ngÃ n': ['Ä‘áº¡i ngÃ n', 'dai ngan'],
            'non nÆ°á»›c': ['non nÆ°á»›c', 'non nuoc'],
            'tour': ['tour', 'hanh trinh'],
            'khÃ¡t vá»ng': ['khÃ¡t vá»ng', 'khat vong'],
            'tÄ©nh láº·ng': ['tÄ©nh láº·ng', 'tinh lang'],
            'retreat': ['retreat', 'tÄ©nh tÃ¢m', 'tinh tam'],
            'thiá»n': ['thiá»n', 'thien'],
            'huáº¿': ['huáº¿', 'hue'],
            'quáº£ng trá»‹': ['quáº£ng trá»‹', 'quang tri']
        }
        
        # Extract potential tour name from query
        extracted_tour_names = []
        for pattern, variants in known_tour_patterns.items():
            for variant in variants:
                if variant in query_lower:
                    extracted_tour_names.append(pattern)
                    break
        
        logger.info(f"ðŸ” Extracted tour patterns: {extracted_tour_names}")
        
        for tour_name, tour_idx in tour_names.items():
            tour_name_lower = tour_name.lower().strip()
            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name_lower)
            
            if not tour_norm:
                continue
            
            # Calculate multiple similarity scores
            scores = []
            
            # 1. Direct string similarity
            direct_similarity = SequenceMatcher(None, query_norm, tour_norm).ratio()
            scores.append(('direct', direct_similarity))
            
            # 2. Check if query contains tour name or vice versa (partial match)
            if query_norm in tour_norm:
                scores.append(('query_in_tour', min(direct_similarity + 0.3, 1.0)))
            if tour_norm in query_norm:
                scores.append(('tour_in_query', min(direct_similarity + 0.3, 1.0)))
            
            # 3. Word overlap similarity
            tour_words = set(tour_norm.split())
            tour_filtered_words = [word for word in tour_norm.split() if word not in stop_words]
            
            common_words = query_words.intersection(tour_words)
            if common_words:
                word_overlap = len(common_words) / max(len(query_words), len(tour_words))
                scores.append(('word_overlap', word_overlap))
            
            # 4. Enhanced keyword matching
            if query_keywords:
                keyword_matches = sum(1 for keyword in query_keywords if any(keyword in word for word in tour_filtered_words))
                if keyword_matches > 0:
                    keyword_score = keyword_matches / len(query_keywords)
                    scores.append(('keyword', keyword_score))
            
            # 5. Pattern matching for known tour names
            pattern_score = 0
            for pattern in extracted_tour_names:
                if pattern in tour_norm:
                    pattern_score += 0.5
            if pattern_score > 0:
                scores.append(('pattern', min(pattern_score, 1.0)))
            
            # 6. Abbreviation/alias matching
            # Check if tour has common abbreviations
            tour_abbreviations = {
                'báº¡ch mÃ£': 'bm',
                'trÆ°á»ng sÆ¡n': 'ts',
                'mÆ°a Ä‘á»': 'md',
                'huáº¿': 'h',
                'quáº£ng trá»‹': 'qt'
            }
            
            for full, abbrev in tour_abbreviations.items():
                if full in tour_norm and abbrev in query_norm:
                    scores.append(('abbreviation', 0.7))
                    break
            
            # 7. Number matching (for tour durations like 1 ngÃ y, 2 ngÃ y)
            import re
            query_numbers = set(re.findall(r'\d+', query_norm))
            tour_numbers = set(re.findall(r'\d+', tour_norm))
            if query_numbers and tour_numbers:
                number_match = len(query_numbers.intersection(tour_numbers)) / len(query_numbers)
                if number_match > 0:
                    scores.append(('number', number_match))
            
            # Calculate final similarity (weighted average)
            weights = {
                'direct': 0.3,
                'query_in_tour': 0.25,
                'tour_in_query': 0.25,
                'word_overlap': 0.15,
                'keyword': 0.15,
                'pattern': 0.1,
                'abbreviation': 0.05,
                'number': 0.05
            }
            
            weighted_scores = []
            for score_type, score_value in scores:
                if score_type in weights:
                    weighted_scores.append(score_value * weights[score_type])
            
            final_similarity = sum(weighted_scores) if weighted_scores else direct_similarity
            
            # Apply bonuses for specific cases
            bonuses = 0
            
            # Bonus for exact word match
            exact_word_match = any(word == tour_word for word in query_filtered_words for tour_word in tour_filtered_words)
            if exact_word_match:
                bonuses += 0.1
            
            # Bonus for matching at beginning of tour name
            if query_filtered_words and any(tour_norm.startswith(word) for word in query_filtered_words):
                bonuses += 0.15
            
            # Bonus for historical/relevant keywords
            historical_keywords = ['lá»‹ch sá»­', 'chiáº¿n tranh', 'di tÃ­ch', 'tri Ã¢n', 'cá»±u chiáº¿n binh']
            if any(keyword in query_norm for keyword in historical_keywords) and \
            any(keyword in tour_norm for keyword in historical_keywords):
                bonuses += 0.2
            
            # Bonus for wellness/retreat keywords
            wellness_keywords = ['thiá»n', 'yoga', 'retreat', 'tÄ©nh tÃ¢m', 'khÃ­ cÃ´ng', 'chá»¯a lÃ nh']
            if any(keyword in query_norm for keyword in wellness_keywords) and \
            any(keyword in tour_norm for keyword in wellness_keywords):
                bonuses += 0.2
            
            final_similarity = min(final_similarity + bonuses, 1.0)
            
            # Adjust threshold based on query complexity
            dynamic_threshold = 0.5  # Base threshold
            
            # Lower threshold for complex queries (more words)
            if len(query_filtered_words) >= 3:
                dynamic_threshold = 0.4
            
            # Higher threshold for very short queries
            if len(query_filtered_words) == 1:
                dynamic_threshold = 0.6
            
            # Special case for known tour patterns
            if extracted_tour_names and any(pattern in tour_norm for pattern in extracted_tour_names):
                dynamic_threshold = 0.3
            
            if final_similarity >= dynamic_threshold:
                matches.append((tour_idx, final_similarity))
                logger.debug(f"  âœ“ Match: '{tour_name}' (idx: {tour_idx}) - Score: {final_similarity:.2f}")
        
        # Sort by similarity score (descending)
        matches.sort(key=lambda x: x[1], reverse=True)
        
        # Limit results but ensure we get relevant matches
        max_results = 10
        if matches:
            # Ensure we include all high-confidence matches (>0.7)
            high_confidence = [m for m in matches if m[1] > 0.7]
            if high_confidence:
                matches = high_confidence + [m for m in matches if m[1] <= 0.7][:max_results - len(high_confidence)]
            else:
                matches = matches[:max_results]
        
        logger.info(f"âœ… Fuzzy matching: '{query}' â†’ {len(matches)} matches (threshold: dynamic)")
        
        # Log top matches for debugging
        if matches:
            for i, (idx, score) in enumerate(matches[:5]):
                tour_name = next((name for name, tid in tour_names.items() if tid == idx), "Unknown")
                logger.debug(f"  Top {i+1}: {tour_name} (idx: {idx}) - Score: {score:.2f}")
        
        return matches


    # ThÃªm phÆ°Æ¡ng thá»©c helper cho normalization nÃ¢ng cao náº¿u cáº§n
    @staticmethod
    def enhanced_normalize_vietnamese(text: str) -> str:
        """
        Enhanced Vietnamese text normalization
        """
        if not text:
            return ""
        
        # Basic normalization (giá»¯ nguyÃªn tá»« hÃ m gá»‘c)
        normalized = text.lower().strip()
        
        # Remove extra spaces
        normalized = ' '.join(normalized.split())
        
        # Common replacements for tour names
        replacements = {
            'â€“': ' ',
            '-': ' ',
            'â€“': ' ',
            '(': ' ',
            ')': ' ',
            ',': ' ',
            '.': ' ',
            '!': ' ',
            '?': ' ',
            '"': ' ',
            "'": ' ',
            ';': ' ',
            ':': ' ',
        }
        
        for old, new in replacements.items():
            normalized = normalized.replace(old, new)
        
        # Remove multiple spaces again
        normalized = ' '.join(normalized.split())
        
        return normalized
        
    @staticmethod
    def find_tour_by_partial_name(partial_name: str, tours_db: Dict[int, Tour]) -> List[int]:
        """
        Find tours by partial name match
        """
        if not partial_name or not tours_db:
            return []
        
        partial_norm = FuzzyMatcher.normalize_vietnamese(partial_name)
        matches = []
        
        for tour_idx, tour in tours_db.items():
            tour_name = tour.name or ""
            if not tour_name:
                continue
            
            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name)
            
            if partial_norm in tour_norm:
                match_ratio = len(partial_norm) / len(tour_norm) if tour_norm else 0
                matches.append((tour_idx, match_ratio))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        return [idx for idx, _ in matches[:3]]

# =========== UPGRADE 7: STATE MACHINE (DATACLASS COMPATIBLE) ===========
class ConversationStateMachine:
    """
    UPGRADE 7: Track conversation state for better context
    """
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.state = ConversationState.INITIAL
        self.context = ConversationContext(session_id=session_id)
        self.transitions = []
        self.created_at = datetime.utcnow()
        self.last_updated = datetime.utcnow()
    
    def update(self, user_message: str, bot_response: str, tour_indices: List[int] = None):
        """Update state based on new interaction"""
        self.last_updated = datetime.utcnow()
        self.context.update(user_message, bot_response, tour_indices)
        
        new_state = self._determine_state(user_message, bot_response)
        
        self.transitions.append({
            'timestamp': datetime.utcnow().isoformat(),
            'from': self.state.value,
            'to': new_state.value,
            'message': user_message[:100]
        })
        
        self.state = new_state
        
        logger.info(f"ðŸ”„ State update: {self.state.value} for session {self.session_id}")
    
    def _determine_state(self, user_message: str, bot_response: str) -> ConversationState:
        """Determine new state based on current interaction"""
        message_lower = user_message.lower()
        
        farewell_words = ['táº¡m biá»‡t', 'cáº£m Æ¡n', 'thanks', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            return ConversationState.FAREWELL
        
        tour_ref_patterns = [
            r'tour nÃ y', r'tour Ä‘Ã³', r'tour Ä‘ang nÃ³i', r'cÃ¡i tour',
            r'nÃ³', r'cÃ¡i Ä‘Ã³', r'cÃ¡i nÃ y', r'Ä‘áº¥y'
        ]
        
        if any(re.search(pattern, message_lower) for pattern in tour_ref_patterns):
            if self.context.current_tours:
                return ConversationState.TOUR_SELECTED
            elif self.context.last_successful_tours:
                self.context.current_tours = self.context.last_successful_tours
                return ConversationState.TOUR_SELECTED
        
        if 'so sÃ¡nh' in message_lower or 'sÃ¡nh' in message_lower:
            return ConversationState.COMPARING
        
        if any(word in message_lower for word in ['phÃ¹ há»£p', 'gá»£i Ã½', 'Ä‘á» xuáº¥t', 'tÆ° váº¥n', 'nÃªn chá»n']):
            return ConversationState.RECOMMENDATION
        
        if any(word in message_lower for word in ['Ä‘áº·t', 'booking', 'Ä‘Äƒng kÃ½', 'giá»¯ chá»—']):
            return ConversationState.BOOKING
        
        if self.context.current_tours:
            return ConversationState.ASKING_DETAILS
        
        return ConversationState.INITIAL
    
    def get_context_hint(self) -> str:
        """Get hint about current context for LLM prompt"""
        hints = []
        
        if self.state == ConversationState.TOUR_SELECTED and self.context.current_tours:
            tour_indices = self.context.current_tours
            if len(tour_indices) == 1:
                hints.append(f"User is asking about tour index {tour_indices[0]}")
            else:
                hints.append(f"User is asking about tours {tour_indices}")
        
        if self.context.user_preferences:
            prefs = []
            for key, value in self.context.user_preferences.items():
                prefs.append(f"{key}: {value}")
            if prefs:
                hints.append(f"User preferences: {', '.join(prefs)}")
        
        return "; ".join(hints) if hints else "No specific context"
    
    def extract_reference(self, message: str) -> List[int]:
        """Extract tour reference from message using conversation context"""
        message_lower = message.lower()
        
        if self.context.current_tours:
            for tour_idx in self.context.current_tours:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"ðŸ”„ State machine: Using current tour {tour_idx}")
                        return self.context.current_tours
        
        ref_patterns = [
            (r'tour nÃ y', 1.0),
            (r'tour Ä‘Ã³', 0.9),
            (r'tour Ä‘ang nÃ³i', 0.9),
            (r'cÃ¡i tour', 0.8),
            (r'nÃ³', 0.7),
            (r'Ä‘áº¥y', 0.7),
            (r'cÃ¡i Ä‘Ã³', 0.7),
        ]
        
        for pattern, confidence in ref_patterns:
            if re.search(pattern, message_lower):
                if self.context.current_tours:
                    logger.info(f"ðŸ”„ State machine: Resolved reference to {self.context.current_tours}")
                    return self.context.current_tours
                elif self.context.last_successful_tours:
                    logger.info(f"ðŸ”„ State machine: Using last successful tours {self.context.last_successful_tours}")
                    return self.context.last_successful_tours
        
        if self.context.mentioned_tours:
            recent_tours = list(self.context.mentioned_tours)
            for tour_idx in recent_tours[-3:]:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"ðŸ”„ State machine: Matched to recently mentioned tour {tour_idx}")
                        return [tour_idx]
        
        return []

# =========== UPGRADE 8: DEEP SEMANTIC ANALYSIS (DATACLASS COMPATIBLE) ===========
class SemanticAnalyzer:
    """
    UPGRADE 8: Deep understanding of user intent beyond keywords
    """
    
    USER_PROFILE_PATTERNS = {
        'age_group': [
            (r'ngÆ°á»i giÃ |ngÆ°á»i lá»›n tuá»•i|cao tuá»•i', 'senior'),
            (r'thanh niÃªn|tráº»|sinh viÃªn|há»c sinh', 'young'),
            (r'trung niÃªn|trung tuá»•i', 'middle_aged'),
            (r'gia Ä‘Ã¬nh.*tráº» em|tráº» nhá»|con nÃ­t', 'family_with_kids'),
        ],
        
        'group_type': [
            (r'má»™t mÃ¬nh|Ä‘i láº»|solo', 'solo'),
            (r'cáº·p Ä‘Ã´i|Ä‘Ã´i lá»©a|ngÆ°á»i yÃªu', 'couple'),
            (r'gia Ä‘Ã¬nh|bá»‘ máº¹ con', 'family'),
            (r'báº¡n bÃ¨|nhÃ³m báº¡n|há»™i báº¡n', 'friends'),
            (r'cÃ´ng ty|doanh nghiá»‡p|Ä‘á»“ng nghiá»‡p', 'corporate'),
        ],
        
        'interest_type': [
            (r'thiÃªn nhiÃªn|rá»«ng|cÃ¢y|cáº£nh quan', 'nature'),
            (r'lá»‹ch sá»­|di tÃ­ch|chiáº¿n tranh|tri Ã¢n', 'history'),
            (r'vÄƒn hÃ³a|cá»™ng Ä‘á»“ng|dÃ¢n tá»™c|truyá»n thá»‘ng', 'culture'),
            (r'thiá»n|tÃ¢m linh|tÄ©nh tÃ¢m|yoga', 'spiritual'),
            (r'khÃ­ cÃ´ng|sá»©c khá»e|chá»¯a lÃ nh|wellness', 'wellness'),
            (r'áº©m thá»±c|Ä‘á»“ Äƒn|mÃ³n ngon|Ä‘áº·c sáº£n', 'food'),
            (r'phiÃªu lÆ°u|máº¡o hiá»ƒm|khÃ¡m phÃ¡|tráº£i nghiá»‡m', 'adventure'),
        ],
        
        'budget_level': [
            (r'kinh táº¿|tiáº¿t kiá»‡m|ráº»|giÃ¡ tháº¥p', 'budget'),
            (r'trung bÃ¬nh|vá»«a pháº£i|pháº£i chÄƒng', 'midrange'),
            (r'cao cáº¥p|sang trá»ng|premium|Ä‘áº¯t', 'premium'),
        ],
        
        'physical_level': [
            (r'nháº¹ nhÃ ng|dá»… dÃ ng|khÃ´ng má»‡t', 'easy'),
            (r'vá»«a pháº£i|trung bÃ¬nh|bÃ¬nh thÆ°á»ng', 'moderate'),
            (r'thá»­ thÃ¡ch|khÃ³|má»‡t|leo nÃºi', 'challenging'),
        ],
    }
    
    @staticmethod
    def analyze_user_profile(message: str, current_context: ConversationContext = None) -> UserProfile:
        """
        Analyze message to build user profile
        """
        if current_context and hasattr(current_context, 'user_profile') and current_context.user_profile:
            profile = current_context.user_profile
        else:
            profile = UserProfile()
        
        message_lower = message.lower()
        
        for category, patterns in SemanticAnalyzer.USER_PROFILE_PATTERNS.items():
            for pattern, value in patterns:
                if re.search(pattern, message_lower):
                    if category == 'interests':
                        if value not in profile.interests:
                            profile.interests.append(value)
                            profile.confidence_scores[f'interest_{value}'] = 0.8
                    else:
                        setattr(profile, category, value)
                        profile.confidence_scores[category] = 0.8
        
        SemanticAnalyzer._infer_attributes(profile, message_lower)
        profile.overall_confidence = SemanticAnalyzer._calculate_confidence(profile)
        
        logger.info(f"ðŸ‘¤ User profile analysis: {profile}")
        return profile
    
    @staticmethod
    def _infer_attributes(profile: UserProfile, message_lower: str):
        """Infer additional attributes from context"""
        if not profile.age_group:
            if profile.group_type and 'family_with_kids' in profile.group_type:
                profile.age_group = 'middle_aged'
                profile.confidence_scores['age_group'] = 0.6
            elif 'senior' in message_lower or 'giÃ ' in message_lower:
                profile.age_group = 'senior'
                profile.confidence_scores['age_group'] = 0.7
        
        if not profile.physical_level:
            if 'adventure' in profile.interests:
                profile.physical_level = 'challenging'
                profile.confidence_scores['physical_level'] = 0.6
            elif 'spiritual' in profile.interests or 'wellness' in profile.interests:
                profile.physical_level = 'easy'
                profile.confidence_scores['physical_level'] = 0.6
        
        if not profile.budget_level:
            budget_keywords = {
                'budget': ['ráº»', 'tiáº¿t kiá»‡m', 'Ã­t tiá»n', 'kinh táº¿'],
                'premium': ['cao cáº¥p', 'sang', 'Ä‘áº¯t', 'premium']
            }
            
            for level, keywords in budget_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    profile.budget_level = level
                    profile.confidence_scores['budget_level'] = 0.7
                    break
    
    @staticmethod
    def _calculate_confidence(profile: UserProfile) -> float:
        """Calculate overall confidence in user profile"""
        if not profile.confidence_scores:
            return 0.0
        
        total = 0.0
        count = 0
        
        for key, score in profile.confidence_scores.items():
            total += score
            count += 1
        
        return total / max(count, 1)
    
    @staticmethod
    def match_tours_to_profile(profile: UserProfile, tours_db: Dict[int, Tour], 
                              max_results: int = 5) -> List[Tuple[int, float, List[str]]]:
        """
        Match tours to user profile with explanation
        """
        matches = []
        
        for tour_idx, tour in tours_db.items():
            score = 0.0
            reasons = []
            
            tour_tags = tour.tags or []
            
            if profile.age_group:
                if profile.age_group == 'senior':
                    if any('easy' in tag for tag in tour_tags):
                        score += 0.3
                        reasons.append("phÃ¹ há»£p ngÆ°á»i lá»›n tuá»•i")
                    if any('nature' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("thiÃªn nhiÃªn nháº¹ nhÃ ng")
            
            if profile.interests:
                for interest in profile.interests:
                    tour_summary = (tour.summary or "").lower()
                    if (interest in tour_summary or 
                        any(interest in tag for tag in tour_tags)):
                        score += 0.4
                        reasons.append(f"cÃ³ yáº¿u tá»‘ {interest}")
            
            if profile.budget_level:
                tour_price = tour.price or ""
                price_nums = re.findall(r'\d[\d,\.]+', tour_price)
                
                if price_nums:
                    try:
                        first_price = int(price_nums[0].replace(',', '').replace('.', ''))
                        
                        if profile.budget_level == 'budget' and first_price < 2000000:
                            score += 0.3
                            reasons.append("giÃ¡ há»£p lÃ½")
                        elif profile.budget_level == 'premium' and first_price > 2500000:
                            score += 0.3
                            reasons.append("cao cáº¥p")
                        elif profile.budget_level == 'midrange' and 1500000 <= first_price <= 3000000:
                            score += 0.3
                            reasons.append("giÃ¡ vá»«a pháº£i")
                    except:
                        pass
            
            if profile.physical_level:
                if profile.physical_level == 'easy':
                    if any('easy' in tag or 'meditation' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng")
            
            if score > 0:
                matches.append((tour_idx, score, reasons))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        return matches[:max_results]

# =========== UPGRADE 9: AUTO-VALIDATION SYSTEM (DATACLASS COMPATIBLE) ===========
class AutoValidator:
    """
    UPGRADE 9: Validate and correct information before returning
    """
    
    VALIDATION_RULES = {
        'duration': {
            'patterns': [
                r'(\d+)\s*ngÃ y\s*(\d+)\s*Ä‘Ãªm',
                r'(\d+)\s*ngÃ y',
                r'(\d+)\s*Ä‘Ãªm',
            ],
            'constraints': {
                'max_days': 7,
                'max_nights': 7,
                'valid_day_night_combos': [(1,0), (1,1), (2,1), (2,2), (3,2), (3,3)],
                'common_durations': ['1 ngÃ y', '2 ngÃ y 1 Ä‘Ãªm', '3 ngÃ y 2 Ä‘Ãªm']
            }
        },
        
        'price': {
            'patterns': [
                r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)',
                r'(\d[\d,\.]*)\s*-\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)?',
                r'(\d[\d,\.]*)\s*(Ä‘á»“ng|vnÄ‘|vnd)',
            ],
            'constraints': {
                'min_tour_price': 500000,
                'max_tour_price': 10000000,
                'common_ranges': [
                    (800000, 1500000),
                    (1500000, 2500000),
                    (2500000, 4000000),
                ]
            }
        },
        
        'location': {
            'patterns': [
                r'á»Ÿ\s+([^.,!?]+)',
                r'táº¡i\s+([^.,!?]+)',
                r'Ä‘áº¿n\s+([^.,!?]+)',
            ],
            'constraints': {
                'valid_locations': ['Huáº¿', 'Quáº£ng Trá»‹', 'Báº¡ch MÃ£', 'TrÆ°á»ng SÆ¡n', 'ÄÃ´ng HÃ ', 'Khe Sanh'],
                'max_length': 100
            }
        },
    }
    
    @staticmethod
    def validate_response(response: str) -> str:
        """
        Validate and correct response content
        """
        if not response:
            return response
        
        validated = response
        
        validated = AutoValidator._validate_duration(validated)
        validated = AutoValidator._validate_price(validated)
        validated = AutoValidator._validate_locations(validated)
        validated = AutoValidator._check_unrealistic_info(validated)
        
        if validated != response:
            validated = AutoValidator._add_validation_note(validated)
        
        return validated
    
    @staticmethod
    def _validate_duration(text: str) -> str:
        """Validate and correct duration information"""
        for pattern in AutoValidator.VALIDATION_RULES['duration']['patterns']:
            matches = list(re.finditer(pattern, text))
            for match in matches:
                try:
                    if match.lastindex == 2:
                        days = int(match.group(1))
                        nights = int(match.group(2))
                        
                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']
                        
                        valid_combos = constraints['valid_day_night_combos']
                        is_valid_combo = bool(valid_combos)
                        
                        if days > constraints['max_days'] or nights > constraints['max_nights']:
                            replacement = random.choice(constraints['common_durations'])
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"âš ï¸ Corrected unrealistic duration: {days} ngÃ y {nights} Ä‘Ãªm â†’ {replacement}")
                        
                        elif not is_valid_combo:
                            valid_days = min(days, constraints['max_days'])
                            valid_nights = min(nights, constraints['max_nights'])
                            if abs(valid_days - valid_nights) > 1:
                                valid_nights = valid_days
                            
                            replacement = f"{valid_days} ngÃ y {valid_nights} Ä‘Ãªm"
                            text = text.replace(match.group(0), replacement)
                            logger.info(f"ðŸ”„ Fixed duration combo: {replacement}")
                    
                    elif match.lastindex == 1:
                        num = int(match.group(1))
                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']
                        
                        if num > constraints['max_days']:
                            replacement = f"{constraints['max_days']} ngÃ y"
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"âš ï¸ Capped long duration: {num} â†’ {constraints['max_days']}")
                
                except (ValueError, IndexError):
                    continue
        
        return text
    
    @staticmethod
    def _validate_price(text: str) -> str:
        """Validate and correct price information"""
        for pattern in AutoValidator.VALIDATION_RULES['price']['patterns']:
            matches = list(re.finditer(pattern, text, re.IGNORECASE))
            for match in matches:
                try:
                    amount_str = match.group(1).replace(',', '').replace('.', '')
                    if not amount_str.isdigit():
                        continue
                    
                    amount = int(amount_str)
                    
                    unit = match.group(2).lower() if match.lastindex >= 2 else ''
                    
                    if unit in ['triá»‡u', 'tr']:
                        amount = amount * 1000000
                    elif unit in ['k', 'nghÃ¬n']:
                        amount = amount * 1000
                    
                    constraints = AutoValidator.VALIDATION_RULES['price']['constraints']
                    
                    if amount < constraints['min_tour_price']:
                        replacement = "giÃ¡ há»£p lÃ½"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"âš ï¸ Corrected too-low price: {amount} â†’ {replacement}")
                    
                    elif amount > constraints['max_tour_price']:
                        replacement = "giÃ¡ cao cáº¥p"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"âš ï¸ Corrected too-high price: {amount} â†’ {replacement}")
                
                except (ValueError, IndexError, AttributeError):
                    continue
        
        return text
    
    @staticmethod
    def _validate_locations(text: str) -> str:
        """Validate location names"""
        wrong_locations = {
            'hÃ  ná»™i': 'Huáº¿',
            'há»“ chÃ­ minh': 'Quáº£ng Trá»‹',
            'Ä‘Ã  náºµng': 'Báº¡ch MÃ£',
            'nha trang': 'TrÆ°á»ng SÆ¡n',
        }
        
        for wrong, correct in wrong_locations.items():
            if wrong in text.lower():
                text = text.replace(wrong, correct)
                text = text.replace(wrong.capitalize(), correct)
                logger.info(f"ðŸ”„ Corrected location: {wrong} â†’ {correct}")
        
        return text
    
    @staticmethod
    def _check_unrealistic_info(text: str) -> str:
        """Check for other unrealistic information"""
        unrealistic_patterns = [
            (r'\d+\s*giá»\s*bay', "thá»i gian di chuyá»ƒn"),
            (r'\d+\s*sao', "cháº¥t lÆ°á»£ng dá»‹ch vá»¥"),
            (r'\d+\s*táº§ng', "chá»— á»Ÿ"),
            (r'\d+\s*m\s*cao', "Ä‘á»‹a hÃ¬nh"),
        ]
        
        for pattern, replacement in unrealistic_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
                logger.info(f"ðŸ”„ Replaced unrealistic info with: {replacement}")
        
        return text
    
    @staticmethod
    def _add_validation_note(text: str) -> str:
        """Add note about information validation"""
        note = "\n\n*ThÃ´ng tin Ä‘Æ°á»£c cung cáº¥p dá»±a trÃªn dá»¯ liá»‡u hiá»‡n cÃ³. " \
               "Vui lÃ²ng liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ xÃ¡c nháº­n chi tiáº¿t chÃ­nh xÃ¡c nháº¥t.*"
        
        if note not in text:
            text += note
        
        return text

# =========== UPGRADE 10: TEMPLATE SYSTEM (DATACLASS COMPATIBLE) ===========
class TemplateSystem:
    """
    UPGRADE 10: Beautiful, structured responses for different question types
    """
    
    TEMPLATES = {
        'tour_list': {
            'header': "âœ¨ **DANH SÃCH TOUR RUBY WINGS** âœ¨\n\n",
            'item': "**{index}. {tour_name}** {emoji}\n"
                   "   ðŸ“… {duration}\n"
                   "   ðŸ“ {location}\n"
                   "   ðŸ’° {price}\n"
                   "   {summary}\n",
            'footer': "\nðŸ“ž **LiÃªn há»‡ Ä‘áº·t tour:** 0332510486\n"
                     "ðŸ“ **Ruby Wings Travel** - HÃ nh trÃ¬nh tráº£i nghiá»‡m Ä‘áº·c sáº¯c\n"
                     "ðŸ’¡ *Há»i chi tiáº¿t vá» báº¥t ká»³ tour nÃ o báº±ng cÃ¡ch nháº­p tÃªn tour*",
            'emoji_map': {
                '1 ngÃ y': 'ðŸŒ…',
                '2 ngÃ y': 'ðŸŒ„',
                '3 ngÃ y': 'ðŸ”ï¸',
                'default': 'âœ¨'
            }
        },
        
        'tour_detail': {
            'header': "ðŸŽ¯ **{tour_name}**\n\n",
            'sections': {
                'overview': "ðŸ“‹ **THÃ”NG TIN CHÃNH:**\n"
                          "   â±ï¸ Thá»i gian: {duration}\n"
                          "   ðŸ“ Äá»‹a Ä‘iá»ƒm: {location}\n"
                          "   ðŸ’° GiÃ¡ tour: {price}\n\n",
                'description': "ðŸ“– **MÃ” Táº¢ TOUR:**\n{summary}\n\n",
                'includes': "ðŸŽª **Lá»ŠCH TRÃŒNH & Dá»ŠCH Vá»¤:**\n{includes}\n\n",
                'accommodation': "ðŸ¨ **CHá»– á»ž:**\n{accommodation}\n\n",
                'meals': "ðŸ½ï¸ **Ä‚N Uá»NG:**\n{meals}\n\n",
                'transport': "ðŸš— **DI CHUYá»‚N:**\n{transport}\n\n",
                'notes': "ðŸ“ **GHI CHÃš:**\n{notes}\n\n",
            },
            'footer': "ðŸ“ž **Äáº¶T TOUR & TÆ¯ Váº¾N:** 0332510486\n"
                     "â­ *Tour phÃ¹ há»£p cho: {suitable_for}*",
            'default_values': {
                'duration': 'Äang cáº­p nháº­t',
                'location': 'Äang cáº­p nháº­t',
                'price': 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡',
                'summary': 'HÃ nh trÃ¬nh tráº£i nghiá»‡m Ä‘áº·c sáº¯c cá»§a Ruby Wings',
                'includes': 'Chi tiáº¿t lá»‹ch trÃ¬nh liÃªn há»‡ tÆ° váº¥n',
                'accommodation': 'Äang cáº­p nháº­t',
                'meals': 'Äang cáº­p nháº­t',
                'transport': 'Äang cáº­p nháº­t',
                'notes': 'Vui lÃ²ng liÃªn há»‡ Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t',
                'suitable_for': 'má»i Ä‘á»‘i tÆ°á»£ng',
            }
        },
        
        'comparison': {
            'header': "ðŸ“Š **SO SÃNH TOUR**\n\n",
            'table_header': "| TiÃªu chÃ­ | {tour1} | {tour2} |\n|----------|----------|----------|\n",
            'table_row': "| {criterion} | {value1} | {value2} |\n",
            'recommendation': "\nðŸ’¡ **Gá»¢I Ã Lá»°A CHá»ŒN:**\n{recommendations}\n",
            'footer': "\nðŸ“ž **TÆ° váº¥n chi tiáº¿t:** 0332510486\n"
                     "ðŸ¤” *Cáº§n so sÃ¡nh thÃªm tiÃªu chÃ­ nÃ o?*",
        },
        
        'recommendation': {
            'header': "ðŸŽ¯ **Äá»€ XUáº¤T TOUR PHÃ™ Há»¢P**\n\n",
            'top_recommendation': "ðŸ† **PHÃ™ Há»¢P NHáº¤T ({score}%)**\n"
                                "**{tour_name}**\n"
                                "   âœ… {reasons}\n"
                                "   ðŸ“… {duration} | ðŸ“ {location} | ðŸ’° {price}\n\n",
            'other_recommendations': "ðŸ“‹ **Lá»°A CHá»ŒN KHÃC:**\n",
            'other_item': "   â€¢ **{tour_name}** ({score}%)\n"
                         "     ðŸ“… {duration} | ðŸ“ {location}\n",
            'criteria': "\nðŸ” **TIÃŠU CHÃ Äá»€ XUáº¤T:**\n{criteria}\n",
            'footer': "\nðŸ“ž **LiÃªn há»‡ tÆ° váº¥n cÃ¡ nhÃ¢n hÃ³a:** 0332510486\n"
                     "ðŸ’¬ *Cho tÃ´i biáº¿t thÃªm sá»Ÿ thÃ­ch cá»§a báº¡n Ä‘á»ƒ Ä‘á» xuáº¥t chÃ­nh xÃ¡c hÆ¡n*",
        },
        
        'information': {
            'header': "â„¹ï¸ **THÃ”NG TIN:**\n\n",
            'content': "{content}\n",
            'sources': "\nðŸ“š *Nguá»“n thÃ´ng tin tá»« dá»¯ liá»‡u Ruby Wings*",
            'footer': "\nðŸ“ž **Hotline há»— trá»£:** 0332510486",
        },
        
        'greeting': {
            'template': "ðŸ‘‹ **Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI cá»§a Ruby Wings**\n\n"
                       "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:\n"
                       "â€¢ TÃ¬m hiá»ƒu vá» cÃ¡c tour tráº£i nghiá»‡m\n"
                       "â€¢ So sÃ¡nh cÃ¡c tour\n"
                       "â€¢ Äá» xuáº¥t tour phÃ¹ há»£p vá»›i báº¡n\n"
                       "â€¢ Cung cáº¥p thÃ´ng tin chi tiáº¿t vá» tour\n\n"
                       "ðŸ’¡ **VÃ­ dá»¥ báº¡n cÃ³ thá»ƒ há»i:**\n"
                       "- 'CÃ³ nhá»¯ng tour nÃ o?'\n"
                       "- 'Tour Báº¡ch MÃ£ giÃ¡ bao nhiÃªu?'\n"
                       "- 'Tour nÃ o phÃ¹ há»£p cho gia Ä‘Ã¬nh?'\n\n"
                       "HÃ£y cho tÃ´i biáº¿t báº¡n cáº§n gÃ¬ nhÃ©! ðŸ˜Š",
        },
        
        'farewell': {
            'template': "ðŸ™ **Cáº£m Æ¡n báº¡n Ä‘Ã£ trÃ² chuyá»‡n cÃ¹ng Ruby Wings!**\n\n"
                       "ChÃºc báº¡n má»™t ngÃ y trÃ n Ä‘áº§y nÄƒng lÆ°á»£ng vÃ  bÃ¬nh an.\n"
                       "Hy vá»ng sá»›m Ä‘Æ°á»£c Ä‘á»“ng hÃ nh cÃ¹ng báº¡n trong tour tráº£i nghiá»‡m sáº¯p tá»›i!\n\n"
                       "ðŸ“ž **LiÃªn há»‡ Ä‘áº·t tour:** 0332510486\n"
                       "ðŸŒ **Website:** rubywings.vn\n\n"
                       "Háº¹n gáº·p láº¡i! âœ¨",
        },
    }
    
    @staticmethod
    def render(template_name: str, **kwargs) -> str:
        """Render template with provided variables"""
        template_data = TemplateSystem.TEMPLATES.get(template_name)
        if not template_data:
            return kwargs.get('content', '')
        
        if template_name in ['greeting', 'farewell']:
            return template_data['template']
        
        response_parts = []
        
        if 'header' in template_data:
            header = template_data['header']
            for key, value in kwargs.items():
                header = header.replace(f'{{{key}}}', str(value))
            response_parts.append(header)
        
        if template_name == 'tour_list':
            response_parts.append(TemplateSystem._render_tour_list(template_data, kwargs))
        
        elif template_name == 'tour_detail':
            response_parts.append(TemplateSystem._render_tour_detail(template_data, kwargs))
        
        elif template_name == 'comparison':
            response_parts.append(TemplateSystem._render_comparison(template_data, kwargs))
        
        elif template_name == 'recommendation':
            response_parts.append(TemplateSystem._render_recommendation(template_data, kwargs))
        
        elif template_name == 'information':
            response_parts.append(TemplateSystem._render_information(template_data, kwargs))
        
        if 'footer' in template_data:
            footer = template_data['footer']
            for key, value in kwargs.items():
                footer = footer.replace(f'{{{key}}}', str(value))
            response_parts.append(footer)
        
        return '\n'.join(response_parts)
    
    @staticmethod
    def _render_tour_list(template_data: Dict, kwargs: Dict) -> str:
        """Render tour list template"""
        tours = kwargs.get('tours', [])
        if not tours:
            return "Hiá»‡n chÆ°a cÃ³ thÃ´ng tin tour."
        
        items = []
        for i, tour in enumerate(tours[:10], 1):
            duration = tour.duration or ''
            emoji = template_data['emoji_map'].get('default')
            for dur_pattern, dur_emoji in template_data['emoji_map'].items():
                if dur_pattern in duration.lower():
                    emoji = dur_emoji
                    break
            
            item_template = template_data['item']
            item = item_template.format(
                index=i,
                tour_name=tour.name or f'Tour #{i}',
                emoji=emoji or 'âœ¨',
                duration=duration or 'Äang cáº­p nháº­t',
                location=tour.location or 'Äang cáº­p nháº­t',
                price=tour.price or 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡',
                summary=(tour.summary or 'Tour tráº£i nghiá»‡m Ä‘áº·c sáº¯c')[:100] + '...'
            )
            items.append(item)
        
        return '\n'.join(items)
    
    @staticmethod
    def _render_tour_detail(template_data: Dict, kwargs: Dict) -> str:
        """Render tour detail template"""
        sections = []
        
        for section_name, section_template in template_data['sections'].items():
            value = kwargs.get(section_name, template_data['default_values'].get(section_name, ''))
            
            if value and value != template_data['default_values'].get(section_name):
                if isinstance(value, list):
                    if section_name == 'includes':
                        value = '\n'.join([f'   â€¢ {item}' for item in value[:5]])
                    else:
                        value = ', '.join(value[:3])
                
                section = section_template.format(**{section_name: value})
                sections.append(section)
        
        return '\n'.join(sections)
    
    @staticmethod
    def _render_comparison(template_data: Dict, kwargs: Dict) -> str:
        """Render comparison template"""
        comparison_table = []
        
        tour1_name = kwargs.get('tour1_name', 'Tour 1')[:20]
        tour2_name = kwargs.get('tour2_name', 'Tour 2')[:20]
        table_header = template_data['table_header'].format(tour1=tour1_name, tour2=tour2_name)
        comparison_table.append(table_header)
        
        criteria = kwargs.get('criteria', [])
        for criterion in criteria[:8]:
            row = template_data['table_row'].format(
                criterion=criterion.get('name', ''),
                value1=criterion.get('value1', 'N/A')[:20],
                value2=criterion.get('value2', 'N/A')[:20]
            )
            comparison_table.append(row)
        
        return '\n'.join(comparison_table)
    
    @staticmethod
    def _render_recommendation(template_data: Dict, kwargs: Dict) -> str:
        """Render recommendation template"""
        recommendation_text = []
        
        top_tour = kwargs.get('top_tour')
        if top_tour:
            top_text = template_data['top_recommendation'].format(
                score=int(top_tour.get('score', 0) * 100),
                tour_name=top_tour.get('name', ''),
                reasons=', '.join(top_tour.get('reasons', ['phÃ¹ há»£p'])[:3]),
                duration=top_tour.get('duration', ''),
                location=top_tour.get('location', ''),
                price=top_tour.get('price', 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡')
            )
            recommendation_text.append(top_text)
        
        other_tours = kwargs.get('other_tours', [])
        if other_tours:
            recommendation_text.append(template_data['other_recommendations'])
            
            for tour in other_tours[:2]:
                other_item = template_data['other_item'].format(
                    tour_name=tour.get('name', ''),
                    score=int(tour.get('score', 0) * 100),
                    duration=tour.get('duration', ''),
                    location=tour.get('location', '')
                )
                recommendation_text.append(other_item)
        
        return '\n'.join(recommendation_text)
    
    @staticmethod
    def _render_information(template_data: Dict, kwargs: Dict) -> str:
        """Render information template"""
        content = kwargs.get('content', '')
        if not content:
            return ""
        
        info_text = template_data['content'].format(content=content)
        
        if kwargs.get('has_sources'):
            info_text += template_data['sources']
        
        return info_text

# =========== TOUR DATABASE BUILDER (USING Tour DATACLASS) ===========
def load_knowledge(path: str = KNOWLEDGE_PATH):
    """Load knowledge base from JSON file"""
    global KNOW, FLAT_TEXTS, MAPPING
    
    try:
        with open(path, "r", encoding="utf-8") as f:
            KNOW = json.load(f)
        logger.info(f"âœ… Loaded knowledge from {path}")
    except Exception as e:
        logger.error(f"âŒ Could not open {path}: {e}")
        KNOW = {}
    
    FLAT_TEXTS = []
    MAPPING = []
    
    def scan(obj, prefix="root"):
        if isinstance(obj, dict):
            for k, v in obj.items():
                scan(v, f"{prefix}.{k}")
        elif isinstance(obj, list):
            for i, v in enumerate(obj):
                scan(v, f"{prefix}[{i}]")
        elif isinstance(obj, str):
            t = obj.strip()
            if t:
                FLAT_TEXTS.append(t)
                MAPPING.append({"path": prefix, "text": t})
        else:
            try:
                s = str(obj).strip()
                if s:
                    FLAT_TEXTS.append(s)
                    MAPPING.append({"path": prefix, "text": s})
            except Exception:
                pass
    
    scan(KNOW)
    logger.info(f"ðŸ“Š Knowledge scanned: {len(FLAT_TEXTS)} passages")

def index_tour_names():
    """Build tour name to index mapping"""
    global TOUR_NAME_TO_INDEX
    TOUR_NAME_TO_INDEX = {}
    
    for m in MAPPING:
        path = m.get("path", "")
        if path.endswith(".tour_name"):
            txt = m.get("text", "") or ""
            norm = normalize_text_simple(txt)
            if not norm:
                continue
            
            match = re.search(r"\[(\d+)\]", path)
            if match:
                idx = int(match.group(1))
                prev = TOUR_NAME_TO_INDEX.get(norm)
                if prev is None:
                    TOUR_NAME_TO_INDEX[norm] = idx
                else:
                    existing_txt = MAPPING[next(
                        i for i, m2 in enumerate(MAPPING) 
                        if re.search(rf"\[{prev}\]", m2.get('path','')) and ".tour_name" in m2.get('path','')
                    )].get("text","")
                    if len(txt) > len(existing_txt):
                        TOUR_NAME_TO_INDEX[norm] = idx
    
    logger.info(f"ðŸ“ Indexed {len(TOUR_NAME_TO_INDEX)} tour names")

def build_tours_db():
    """Build structured tour database from MAPPING using Tour dataclass"""
    global TOURS_DB, TOUR_TAGS
    
    TOURS_DB.clear()
    TOUR_TAGS.clear()
    
    # First pass: collect all fields for each tour
    for m in MAPPING:
        path = m.get("path", "")
        text = m.get("text", "")
        
        if not path or not text:
            continue
        
        tour_match = re.search(r'tours\[(\d+)\]', path)
        if not tour_match:
            continue
        
        tour_idx = int(tour_match.group(1))
        
        field_match = re.search(r'tours\[\d+\]\.(\w+)(?:\[\d+\])?', path)
        if not field_match:
            continue
        
        field_name = field_match.group(1)
        
        # Initialize tour entry
        if tour_idx not in TOURS_DB:
            TOURS_DB[tour_idx] = Tour(index=tour_idx)
        
        # Update field in Tour object
        tour_obj = TOURS_DB[tour_idx]
        if field_name == 'tour_name':
            tour_obj.name = text
        elif field_name == 'duration':
            tour_obj.duration = text
        elif field_name == 'location':
            tour_obj.location = text
        elif field_name == 'price':
            tour_obj.price = text
        elif field_name == 'summary':
            tour_obj.summary = text
        elif field_name == 'includes':
            if isinstance(tour_obj.includes, list):
                tour_obj.includes.append(text)
            else:
                tour_obj.includes = [text]
        elif field_name == 'accommodation':
            tour_obj.accommodation = text
        elif field_name == 'meals':
            tour_obj.meals = text
        elif field_name == 'transport':
            tour_obj.transport = text
        elif field_name == 'notes':
            tour_obj.notes = text
        elif field_name == 'style':
            tour_obj.style = text
    
    # Second pass: generate tags and metadata
    for tour_idx, tour_obj in TOURS_DB.items():
        tags = []
        
        # Location tags
        if tour_obj.location:
            locations = [loc.strip() for loc in tour_obj.location.split(",") if loc.strip()]
            tags.extend([f"location:{loc}" for loc in locations[:2]])
        
        # Duration tags
        if tour_obj.duration:
            duration_lower = tour_obj.duration.lower()
            if "1 ngÃ y" in duration_lower:
                tags.append("duration:1day")
            elif "2 ngÃ y" in duration_lower:
                tags.append("duration:2day")
            elif "3 ngÃ y" in duration_lower:
                tags.append("duration:3day")
            else:
                day_match = re.search(r'(\d+)\s*ngÃ y', duration_lower)
                if day_match:
                    days = int(day_match.group(1))
                    tags.append(f"duration:{days}day")
        
        # Price tags
        if tour_obj.price:
            price_nums = re.findall(r'[\d,\.]+', tour_obj.price)
            if price_nums:
                try:
                    clean_nums = []
                    for p in price_nums[:2]:
                        p_clean = p.replace(',', '').replace('.', '')
                        if p_clean.isdigit():
                            clean_nums.append(int(p_clean))
                    
                    if clean_nums:
                        avg_price = sum(clean_nums) / len(clean_nums)
                        if avg_price < 1000000:
                            tags.append("price:budget")
                        elif avg_price < 2000000:
                            tags.append("price:midrange")
                        else:
                            tags.append("price:premium")
                except:
                    pass
        
        # Style/theme tags
        text_to_check = (tour_obj.style + " " + (tour_obj.summary or '')).lower()
        
        theme_keywords = {
            'meditation': ['thiá»n', 'chÃ¡nh niá»‡m', 'tÃ¢m linh'],
            'history': ['lá»‹ch sá»­', 'di tÃ­ch', 'chiáº¿n tranh', 'tri Ã¢n'],
            'nature': ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi', 'cÃ¢y'],
            'culture': ['vÄƒn hÃ³a', 'cá»™ng Ä‘á»“ng', 'dÃ¢n tá»™c'],
            'wellness': ['khÃ­ cÃ´ng', 'sá»©c khá»e', 'chá»¯a lÃ nh'],
            'adventure': ['phiÃªu lÆ°u', 'máº¡o hiá»ƒm', 'khÃ¡m phÃ¡'],
        }
        
        for theme, keywords in theme_keywords.items():
            if any(keyword in text_to_check for keyword in keywords):
                tags.append(f"theme:{theme}")
        
        # Destination tags from tour name
        if tour_obj.name:
            name_lower = tour_obj.name.lower()
            if "báº¡ch mÃ£" in name_lower:
                tags.append("destination:bachma")
            if "trÆ°á»ng sÆ¡n" in name_lower:
                tags.append("destination:truongson")
            if "quáº£ng trá»‹" in name_lower:
                tags.append("destination:quangtri")
            if "huáº¿" in name_lower:
                tags.append("destination:hue")
        
        # Update Tour object tags
        tour_obj.tags = list(set(tags))
        TOUR_TAGS[tour_idx] = tour_obj.tags
        
        # Calculate completeness score
        completeness = 0
        important_fields = ['name', 'duration', 'location', 'price', 'summary']
        for field in important_fields:
            if getattr(tour_obj, field, None):
                completeness += 1
        
        tour_obj.completeness_score = completeness / len(important_fields)
    
    logger.info(f"âœ… Built tours database: {len(TOURS_DB)} tours with tags")

def get_passages_by_field(field_name: str, limit: int = 50, 
                         tour_indices: Optional[List[int]] = None) -> List[Tuple[float, Dict]]:
    """
    Get passages for a specific field
    """
    exact_matches = []
    global_matches = []
    
    for m in MAPPING:
        path = m.get("path", "")
        if path.endswith(f".{field_name}") or f".{field_name}" in path:
            is_exact_match = False
            if tour_indices:
                for ti in tour_indices:
                    if f"[{ti}]" in path:
                        is_exact_match = True
                        break
            
            if is_exact_match:
                exact_matches.append((2.0, m))
            elif not tour_indices:
                global_matches.append((1.0, m))
    
    all_results = exact_matches + global_matches
    all_results.sort(key=lambda x: x[0], reverse=True)
    return all_results[:limit]

# =========== CACHE SYSTEM (DATACLASS COMPATIBLE) ===========
class CacheSystem:
    """Simple caching system for responses"""
    
    @staticmethod
    def get_cache_key(query: str, context_hash: str = "") -> str:
        """Generate cache key"""
        key_parts = [query]
        if context_hash:
            key_parts.append(context_hash)
        return hashlib.md5("|".join(key_parts).encode()).hexdigest()
    
    @staticmethod
    def get(key: str, ttl_seconds: int = 300):
        """Get item from cache"""
        with _cache_lock:
            if key in _response_cache:
                cache_entry = _response_cache[key]
                if not cache_entry.is_expired():
                    logger.info(f"ðŸ’¾ Cache hit for key: {key[:20]}...")
                    return cache_entry.value
                else:
                    del _response_cache[key]
            return None
    
    @staticmethod
    def set(key: str, value: Any, expiry: int = None):
        """
        Set item in cache with enhanced features
        - Supports custom expiry (TTL in seconds)
        - Intelligent cache eviction
        - Thread-safe with lock
        """
        with _cache_lock:
            try:
                # Get TTL from parameter or config
                ttl_seconds = expiry or UpgradeFlags.get_all_flags().get("CACHE_TTL_SECONDS", 300)
                
                # Create cache entry
                cache_entry = CacheEntry(
                    key=key,
                    value=value,
                    created_at=datetime.utcnow(),
                    ttl_seconds=ttl_seconds,
                    access_count=0,  # Track how many times accessed
                    last_accessed=datetime.utcnow()
                )
                
                # Store in cache
                _response_cache[key] = cache_entry
                
                # Intelligent cache cleaning
                CacheSystem._clean_cache()
                
                logger.debug(f"ðŸ’¾ Cached response for key: {key[:50]}... (TTL: {ttl_seconds}s)")
                
            except Exception as e:
                logger.error(f"âŒ Cache set error: {e}")
                # Don't crash if cache fails


    @staticmethod
    def _clean_cache():
        """
        Intelligent cache cleaning with multiple strategies
        """
        try:
            now = datetime.utcnow()
            cache_size = len(_response_cache)
            
            # Strategy 1: Remove expired entries
            expired_keys = []
            for key, entry in _response_cache.items():
                # Check if entry has expired
                if hasattr(entry, 'is_expired'):
                    if entry.is_expired(now):
                        expired_keys.append(key)
                else:
                    # Fallback: manual expiration check
                    age = (now - entry.created_at).total_seconds()
                    if age > (entry.ttl_seconds if hasattr(entry, 'ttl_seconds') else 300):
                        expired_keys.append(key)
            
            # Remove expired entries
            for key in expired_keys:
                del _response_cache[key]
            
            if expired_keys:
                logger.debug(f"ðŸ§¹ Removed {len(expired_keys)} expired cache entries")
            
            # Strategy 2: If still over limit, remove least recently used
            current_size = len(_response_cache)
            if current_size > 1000:
                logger.warning(f"âš ï¸ Cache size ({current_size}) exceeds limit, performing LRU cleanup")
                
                # Sort by last accessed time (oldest first)
                lru_items = sorted(_response_cache.items(), 
                                key=lambda x: x[1].last_accessed if hasattr(x[1], 'last_accessed') 
                                else x[1].created_at)
                
                # Remove oldest 20% or at least 200 items
                remove_count = max(200, int(current_size * 0.2))
                remove_keys = [k for k, _ in lru_items[:remove_count]]
                
                for key in remove_keys:
                    if key in _response_cache:
                        del _response_cache[key]
                
                logger.info(f"ðŸ§¹ LRU cleanup removed {len(remove_keys)} items")
            
            # Strategy 3: Clean up very old entries regardless of size
            if _response_cache:
                very_old_threshold = 86400  # 24 hours in seconds
                very_old_keys = []
                
                for key, entry in _response_cache.items():
                    age = (now - entry.created_at).total_seconds()
                    if age > very_old_threshold:
                        very_old_keys.append(key)
                
                if very_old_keys:
                    for key in very_old_keys:
                        del _response_cache[key]
                    logger.debug(f"ðŸ§¹ Removed {len(very_old_keys)} very old cache entries")
            
            # Final size check
            final_size = len(_response_cache)
            if final_size > 0:
                logger.debug(f"ðŸ“Š Cache stats: {final_size} items, " 
                            f"approx. {final_size * 0.5:.1f}KB memory")
                
        except Exception as e:
            logger.error(f"âŒ Cache cleanup error: {e}")


    @staticmethod
    def get(key: str, update_access: bool = True) -> Optional[Any]:
        """
        Get item from cache with enhanced features
        - Updates access count and timestamp
        - Auto-removes expired items
        """
        with _cache_lock:
            try:
                if key not in _response_cache:
                    return None
                
                entry = _response_cache[key]
                now = datetime.utcnow()
                
                # Check expiration
                if hasattr(entry, 'is_expired'):
                    if entry.is_expired(now):
                        del _response_cache[key]
                        logger.debug(f"ðŸ—‘ï¸  Auto-removed expired cache: {key[:50]}...")
                        return None
                else:
                    # Manual expiration check
                    age = (now - entry.created_at).total_seconds()
                    ttl = entry.ttl_seconds if hasattr(entry, 'ttl_seconds') else 300
                    if age > ttl:
                        del _response_cache[key]
                        return None
                
                # Update access metadata if requested
                if update_access:
                    if hasattr(entry, 'access_count'):
                        entry.access_count += 1
                    if hasattr(entry, 'last_accessed'):
                        entry.last_accessed = now
                
                logger.debug(f"ðŸ’¾ Cache hit for key: {key[:50]}...")
                return entry.value
                
            except Exception as e:
                logger.error(f"âŒ Cache get error: {e}")
                return None


    @staticmethod
    def delete(key: str) -> bool:
        """Delete specific cache entry"""
        with _cache_lock:
            try:
                if key in _response_cache:
                    del _response_cache[key]
                    logger.debug(f"ðŸ—‘ï¸  Deleted cache: {key[:50]}...")
                    return True
                return False
            except Exception as e:
                logger.error(f"âŒ Cache delete error: {e}")
                return False


    @staticmethod
    def clear() -> int:
        """Clear all cache, return number of items cleared"""
        with _cache_lock:
            try:
                count = len(_response_cache)
                _response_cache.clear()
                logger.info(f"ðŸ§¹ Cleared all cache ({count} items)")
                return count
            except Exception as e:
                logger.error(f"âŒ Cache clear error: {e}")
                return 0


    @staticmethod
    def stats() -> Dict[str, Any]:
        """Get cache statistics"""
        with _cache_lock:
            try:
                now = datetime.utcnow()
                total_size = len(_response_cache)
                
                # Calculate age distribution
                age_distribution = {
                    "under_1min": 0,
                    "1min_10min": 0,
                    "10min_1hour": 0,
                    "1hour_24hour": 0,
                    "over_24hour": 0
                }
                
                # Calculate expiration status
                expired_count = 0
                will_expire_soon = 0  # Within 60 seconds
                
                for entry in _response_cache.values():
                    # Age distribution
                    age = (now - entry.created_at).total_seconds()
                    if age < 60:
                        age_distribution["under_1min"] += 1
                    elif age < 600:
                        age_distribution["1min_10min"] += 1
                    elif age < 3600:
                        age_distribution["10min_1hour"] += 1
                    elif age < 86400:
                        age_distribution["1hour_24hour"] += 1
                    else:
                        age_distribution["over_24hour"] += 1
                    
                    # Expiration check
                    ttl = entry.ttl_seconds if hasattr(entry, 'ttl_seconds') else 300
                    remaining = ttl - age
                    if remaining <= 0:
                        expired_count += 1
                    elif remaining < 60:
                        will_expire_soon += 1
                
                return {
                    "total_items": total_size,
                    "age_distribution": age_distribution,
                    "expired_items": expired_count,
                    "expiring_soon": will_expire_soon,
                    "memory_estimate_kb": total_size * 0.5  # Rough estimate
                }
                
            except Exception as e:
                logger.error(f"âŒ Cache stats error: {e}")
                return {"error": str(e)}


    @staticmethod
    def get_cache_key(user_message: str, context_hash: str = None) -> str:
        """
        Generate cache key with enhanced hashing
        """
        try:
            # Normalize the user message
            normalized = user_message.lower().strip()
            
            # Remove extra whitespace
            normalized = ' '.join(normalized.split())
            
            # Create base key
            base_content = normalized
            
            # Add context hash if provided
            if context_hash:
                base_content += f"|{context_hash}"
            
            # Create hash (shorter for efficiency)
            import hashlib
            cache_key = hashlib.md5(base_content.encode('utf-8')).hexdigest()[:16]
            
            # Add prefix for identification
            cache_key = f"chat_{cache_key}"
            
            return cache_key
            
        except Exception as e:
            logger.error(f"âŒ Cache key generation error: {e}")
            # Fallback: use simple hash
            import hashlib
            return f"chat_fallback_{hashlib.md5(user_message.encode()).hexdigest()[:8]}"


    # Cáº­p nháº­t class CacheEntry Ä‘á»ƒ há»— trá»£ cÃ¡c tÃ­nh nÄƒng má»›i
    @dataclass
    class CacheEntry:
        """
        Enhanced cache entry with metadata for intelligent cache management
        """
        key: str
        value: Any
        created_at: datetime
        ttl_seconds: int = 300
        access_count: int = 0
        last_accessed: datetime = None
        
        def __post_init__(self):
            """Initialize last_accessed if not provided"""
            if self.last_accessed is None:
                self.last_accessed = self.created_at
        
        def is_expired(self, current_time: datetime = None) -> bool:
            """Check if cache entry has expired"""
            if current_time is None:
                current_time = datetime.utcnow()
            
            age = (current_time - self.created_at).total_seconds()
            return age > self.ttl_seconds
        
        def age_seconds(self) -> float:
            """Get age of cache entry in seconds"""
            return (datetime.utcnow() - self.created_at).total_seconds()
        
        def ttl_remaining(self) -> float:
            """Get remaining TTL in seconds"""
            age = self.age_seconds()
            remaining = self.ttl_seconds - age
            return max(0, remaining)

# =========== EMBEDDING FUNCTIONS (MEMORY OPTIMIZED) ===========
@lru_cache(maxsize=128 if IS_LOW_RAM else 1000)
def embed_text(text: str) -> Tuple[List[float], int]:
    """Embed text using OpenAI or fallback (with memory optimization)"""
    if not text:
        return [], 0
    
    text = text[:2000]
    
    if client:
        try:
            response = client.embeddings.create(
                model=EMBEDDING_MODEL,
                input=text
            )
            if response.data:
                embedding = response.data[0].embedding
                return embedding, len(embedding)
        except Exception as e:
            logger.error(f"OpenAI embedding error: {e}")
    
    # Fallback: deterministic hash-based embedding
    h = hash(text) % (10 ** 12)
    dim = 1536
    embedding = [(float((h >> (i % 32)) & 0xFF) + (i % 7)) / 255.0 
                 for i in range(dim)]
    
    return embedding, dim

def query_index(
    query: str,
    top_k: int = 5,
    min_score: float = 0.78
):
    """
    Semantic search dÃ¹ng FAISS â€“ CHáº¶N Bá»ŠA TUYá»†T Äá»I
    Tráº£ vá» [] náº¿u KHÃ”NG cÃ³ dá»¯ liá»‡u Ä‘á»§ tin cáº­y
    """

    # ========== SAFETY CHECK ==========
    if not query or not query.strip():
        return []

    if not INDEX or not MAPPING: 
        logger.error("âŒ FAISS index hoáº·c mapping chÆ°a Ä‘Æ°á»£c load")
        return []

    # ========== EMBEDDING QUERY ==========
    try:
        embedding = embedding_client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=query
        ).data[0].embedding
    except Exception as e:
        logger.error(f"âŒ Embedding error: {e}")
        return []

    import numpy as np

    query_vector = np.array([embedding], dtype="float32")

    # ========== FAISS SEARCH ==========
    try:
        distances, indices = faiss_index.search(
query_vector, top_k)
    except Exception as e:
        logger.error(f"âŒ FAISS search error: {e}")
        return []

    results = []

    for score, idx in zip(distances[0], indices[0]):
        if idx == -1:
            continue

        # FAISS cosine similarity (index Ä‘Ã£ normalize)
        similarity = float(score)

        # ðŸš¨ NGÆ¯á» NG CHáº¶N Bá»ŠA
        if similarity < min_score:
            continue

        mapping = faiss_mapping.get(
str(idx))
        if not mapping:
            continue

        text = mapping.get("text", "").strip()
        if not text:
            continue

        results.append((similarity, text))

    # ========== SORT & RETURN ==========
    results.sort(key=lambda x: x[0], reverse=True)

    if not results:
        logger.info(
            f"âš ï¸ No semantic match above threshold "
            f"(min_score={min_score}) for query: {query}"
        )

    return results


class NumpyIndex:
    """Simple numpy-based index with safe numpy handling"""

    def __init__(self, mat=None):
        if NUMPY_AVAILABLE:
            if mat is None:
                self.mat = np.empty((0, 0), dtype="float32")
            else:
                # Force numpy float32 2D
                self.mat = np.asarray(mat, dtype="float32")
                if self.mat.ndim == 1:
                    self.mat = self.mat.reshape(1, -1)
        else:
            self.mat = mat if mat is not None else []

        # SAFE dimension detection (no numpy truth check)
        if NUMPY_AVAILABLE:
            if self.mat.shape[0] > 0 and self.mat.ndim == 2:
                self.dim = int(self.mat.shape[1])
            else:
                self.dim = 0
            self.size = int(self.mat.shape[0])
        else:
            self.size = len(self.mat)
            self.dim = len(self.mat[0]) if self.size > 0 else 0

    def is_empty(self):
        if NUMPY_AVAILABLE:
            return self.mat.shape[0] == 0
        return len(self.mat) == 0

    def search(self, query_vec, k=5):
        if self.is_empty():
            return [], []

        if NUMPY_AVAILABLE:
            q = np.asarray(query_vec, dtype="float32").reshape(1, -1)
            sims = np.dot(self.mat, q.T).reshape(-1)
            topk = np.argsort(-sims)[:k]
            return sims[topk].tolist(), topk.tolist()
        else:
            return [], []

    
    def search(self, qvec, k):
        if not self.mat or (NUMPY_AVAILABLE and self.mat.shape[0] == 0) or (not NUMPY_AVAILABLE and len(self.mat) == 0):
            # Return empty results
            return np.array([[]]), np.array([[]], dtype=np.int64)
        
        q = np.array(qvec).flatten()
        
        if NUMPY_AVAILABLE:
            # Use numpy if available
            q = q / (np.linalg.norm(q) + 1e-12)
            m = self.mat / (np.linalg.norm(self.mat, axis=1, keepdims=True) + 1e-12)
            sims = np.dot(q, m.T)
            idx = np.argsort(-sims)[:k]
            scores = sims[idx]
        else:
            # Fallback calculation
            q_norm = q / (sum(x*x for x in q)**0.5 + 1e-12)
            scores = []
            for i, row in enumerate(self.mat):
                row_norm = row / (sum(x*x for x in row)**0.5 + 1e-12)
                sim = sum(q_norm[j] * row_norm[j] for j in range(min(len(q_norm), len(row_norm))))
                scores.append((sim, i))
            
            scores.sort(key=lambda x: x[0], reverse=True)
            top_k = scores[:k]
            if top_k:
                scores_arr = np.array([s[0] for s in top_k])
                idx_arr = np.array([s[1] for s in top_k])
            else:
                scores_arr = np.array([])
                idx_arr = np.array([], dtype=np.int64)
            
            return scores_arr.reshape(1, -1), idx_arr.reshape(1, -1)
        
        return scores.reshape(1, -1), idx.reshape(1, -1)
    
    def save(self, path):
        if NUMPY_AVAILABLE:
            np.savez_compressed(path, mat=self.mat)
        else:
            logger.warning(f"âš ï¸ Cannot save index without NumPy: {path}")
    
    @classmethod
    def load(cls, path):
        if NUMPY_AVAILABLE:
            try:
                arr = np.load(path)
                return cls(arr['mat'])
            except Exception as e:
                logger.error(f"Failed to load numpy index: {e}")
                return cls()
        else:
            logger.warning(f"âš ï¸ Cannot load index without NumPy: {path}")
            return cls()

def build_index(force_rebuild: bool = False) -> bool:
    """Build or load FAISS/numpy index"""
    global INDEX, EMBEDDING_MODEL
    
    with INDEX_LOCK:
        # Try to load existing index
        if not force_rebuild:
            if FAISS_ENABLED and HAS_FAISS and os.path.exists(FAISS_INDEX_PATH):
                try:
                    INDEX = faiss.read_index(FAISS_INDEX_PATH)
                    logger.info(f"âœ… Loaded FAISS index from {FAISS_INDEX_PATH}")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load FAISS index: {e}")
            
            # Try numpy fallback
            if os.path.exists(FALLBACK_VECTORS_PATH):
                try:
                    arr = np.load(FALLBACK_VECTORS_PATH)
                    INDEX = NumpyIndex(arr['mat'])
                    logger.info("âœ… Loaded numpy index")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load numpy index: {e}")
        
        # Build new index
        if not FLAT_TEXTS:
            logger.warning("No texts to index")
            return False
        
        logger.info(f"ðŸ”¨ Building index for {len(FLAT_TEXTS)} passages...")
        
        # Generate embeddings
        vectors = []
        dims = None
        
        for text in FLAT_TEXTS:
            emb, d = embed_text(text)
            if emb:
                if dims is None:
                    dims = len(emb)
                vectors.append(np.array(emb, dtype="float32"))
        
        if not vectors:
            logger.error("No embeddings generated")
            return False
        
        # Create index
        mat = np.vstack(vectors)
        mat = mat / (np.linalg.norm(mat, axis=1, keepdims=True) + 1e-12)
        
        if FAISS_ENABLED and HAS_FAISS:
            INDEX = faiss.IndexFlatIP(dims)
            INDEX.add(mat)
            try:
                faiss.write_index(INDEX, FAISS_INDEX_PATH)
                logger.info(f"âœ… Saved FAISS index to {FAISS_INDEX_PATH}")
            except Exception as e:
                logger.error(f"Failed to save FAISS index: {e}")
        else:
            INDEX = NumpyIndex(mat)
            try:
                INDEX.save(FALLBACK_VECTORS_PATH)
                logger.info(f"âœ… Saved numpy index to {FALLBACK_VECTORS_PATH}")
            except Exception as e:
                logger.error(f"Failed to save numpy index: {e}")
        
        logger.info(f"âœ… Index built: {len(vectors)} vectors, {dims} dimensions")
        return True

# =========== HELPER FUNCTIONS ===========
def _format_price(price):
    return price
def normalize_text_simple(s: str) -> str:
    """Basic text normalization"""
    if not s:
        return ""
    s = s.lower()
    s = unicodedata.normalize("NFD", s)
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
    s = re.sub(r"[^\w\s]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def get_session_context(session_id: str) -> ConversationContext:
    """Get or create context for session using ConversationContext dataclass with auto-repair"""

    ctx = SESSION_CONTEXTS.get(session_id)

    if ctx is None:
        ctx = ConversationContext(session_id=session_id)
        SESSION_CONTEXTS[session_id] = ctx
        return ctx

    # ===== AUTO REPAIR FOR OLD CONTEXT OBJECTS =====
    if not hasattr(ctx, "last_tour_indices"):
        ctx.last_tour_indices = []

    if not hasattr(ctx, "current_tours"):
        ctx.current_tours = []

    if not hasattr(ctx, "mentioned_tours"):
        ctx.mentioned_tours = set()

    if not hasattr(ctx, "last_successful_tours"):
        ctx.last_successful_tours = []

    if not hasattr(ctx, "conversation_history"):
        ctx.conversation_history = []

    if not hasattr(ctx, "user_preferences"):
        ctx.user_preferences = {}

    return ctx

def save_session_context(session_id: str, context: ConversationContext):
    """LÆ°u context cho session"""
    with SESSION_LOCK:
        SESSION_CONTEXTS[session_id] = context
        # Dá»n dáº¹p session cÅ© (giá»¯ tá»‘i Ä‘a 100 session)
        if len(SESSION_CONTEXTS) > 100:
            # XÃ³a cÃ¡c session cÅ© nháº¥t
            sorted_sessions = sorted(
                SESSION_CONTEXTS.items(),
                key=lambda x: getattr(x[1], 'last_updated', datetime.utcnow())
            )
            for key, _ in sorted_sessions[:20]:
                if key in SESSION_CONTEXTS:
                    del SESSION_CONTEXTS[key]
def extract_session_id(request_data: Dict, remote_addr: str) -> str:
    """Extract or create session ID"""
    session_id = request_data.get("session_id")
    if not session_id:
        ip = remote_addr or "0.0.0.0"
        current_hour = datetime.utcnow().strftime("%Y%m%d%H")
        unique_str = f"{ip}_{current_hour}"
        session_id = hashlib.md5(unique_str.encode()).hexdigest()[:12]
    return f"session_{session_id}"

def _prepare_llm_prompt(user_message: str, search_results: List, context: Dict) -> str:
    """Prepare prompt for LLM - THÃ”NG MINH vá»›i context & cÃ¢u há»i chung"""
    
    message_lower = user_message.lower()
    
    # PhÃ¢n loáº¡i cÃ¢u há»i
    is_general_question = any(keyword in message_lower for keyword in [
        'cÃ³ bao gá»“m', 'Ä‘Ã£ bao gá»“m', 'bao gá»“m gÃ¬', 'bao gá»“m nhá»¯ng gÃ¬',
        'cÃ³ gÃ¬', 'nhÆ° tháº¿ nÃ o', 'ra sao', 'tháº¿ nÃ o', 'giÃ¡ tour'
    ])
    
    has_specific_tour = context.get('current_tours') and len(context.get('current_tours', [])) > 0
    tour_count = len(context.get('current_tours', []))
    
    # PhÃ¡t hiá»‡n cÃ¢u há»i tiáº¿p theo (followup)
    is_followup = (
        context.get('last_action') == 'chat_response' and 
        (has_specific_tour or context.get('last_tour_name'))
    )
    
    # PhÃ¡t hiá»‡n rÃ ng buá»™c Ä‘á»‹a lÃ½
    has_location_constraint = False
    location_constraint = None
    filters = context.get('filters', {})
    if filters:
        if filters.get('location'):
            has_location_constraint = True
            location_constraint = filters.get('location')
        elif filters.get('near_location'):
            has_location_constraint = True
            location_constraint = filters.get('near_location')
    
    prompt_parts = [
        "Báº¡n lÃ  trá»£ lÃ½ tÆ° váº¥n du lá»‹ch Ruby Wings - CHUYÃŠN NGHIá»†P, THÃ”NG MINH, NHIá»†T TÃŒNH.",
        "",
        "âš ï¸ QUY Táº®C NGHIÃŠM NGáº¶T:",
    ]
    
    # RULE 1: CÃ¢u há»i CHUNG (khÃ´ng cÃ³ tour cá»¥ thá»ƒ)
    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "",
            "ðŸŽ¯ ÄÃ‚Y LÃ€ CÃ‚U Há»ŽI CHUNG - KHÃ”NG CÃ“ TOUR Cá»¤ THá»‚:",
            "â€¢ TRáº¢ Lá»œI NGáº®N Gá»ŒN (2-4 cÃ¢u) dá»±a trÃªn kiáº¿n thá»©c chung vá» tour du lá»‹ch",
            "â€¢ Sá»¬ Dá»¤NG OPENAI Ä‘á»ƒ tráº£ lá»i tá»± nhiÃªn, khÃ´ng nÃ³i 'khÃ´ng cÃ³ dá»¯ liá»‡u'",
            "â€¢ Káº¾T THÃšC báº±ng cÃ¢u há»i: 'Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t?'",
            "â€¢ KHÃ”NG liá»‡t kÃª tour, KHÃ”NG dump dá»¯ liá»‡u",
            "",
            "VÃ Dá»¤ ÄÃšNG:",
            "Q: 'GiÃ¡ tour bao gá»“m gÃ¬?'",
            "A: 'GiÃ¡ tour Ruby Wings thÆ°á»ng bao gá»“m: xe Ä‘Æ°a Ä‘Ã³n, Äƒn uá»‘ng theo chÆ°Æ¡ng trÃ¬nh, khÃ¡ch sáº¡n, hÆ°á»›ng dáº«n viÃªn vÃ  báº£o hiá»ƒm. TÃ¹y tour cá»¥ thá»ƒ cÃ³ thá»ƒ cÃ³ thÃªm vÃ© tham quan hoáº·c hoáº¡t Ä‘á»™ng Ä‘áº·c biá»‡t. Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t? ðŸ˜Š'",
            "",
            "Q: 'Tour cÃ³ phÃ¹ há»£p gia Ä‘Ã¬nh khÃ´ng?'",
            "A: 'Ruby Wings cÃ³ nhiá»u tour phÃ¹ há»£p gia Ä‘Ã¬nh vá»›i hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng, an toÃ n cho tráº» em vÃ  ngÆ°á»i lá»›n tuá»•i. Gia Ä‘Ã¬nh báº¡n cÃ³ bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch loáº¡i hÃ¬nh nÃ o (thiÃªn nhiÃªn, lá»‹ch sá»­, nghá»‰ dÆ°á»¡ng) Ä‘á»ƒ tÃ´i tÆ° váº¥n tour phÃ¹ há»£p nháº¥t?'",
        ])
    
    # RULE 2: CÃ¢u há»i TIáº¾P THEO (followup)
    elif is_followup:
        prompt_parts.extend([
            "",
            "ðŸ’­ ÄÃ‚Y LÃ€ CÃ‚U Há»ŽI TIáº¾P THEO - Sá»¬ Dá»¤NG CONTEXT:",
            f"â€¢ ÄÃ£ bÃ n vá» {tour_count} tour: {context.get('last_tour_name', '')}",
            "â€¢ PHáº¢I dá»±a vÃ o context cÅ© - KHÃ”NG reset",
            "â€¢ TRáº¢ Lá»œI TIáº¾P theo ngá»¯ cáº£nh Ä‘Ã£ cÃ³",
            "â€¢ KHÃ”NG liá»‡t kÃª láº¡i toÃ n bá»™ tour",
            "â€¢ Náº¿u há»i vá» giÃ¡/thá»i gian â†’ Chá»‰ nÃ³i vá» tour Ä‘ang bÃ n",
            "â€¢ Náº¿u há»i thÃªm Ä‘iá»u kiá»‡n â†’ Gá»£i Ã½ tour tá»« context hoáº·c há»i láº¡i",
            "",
            "VÃ Dá»¤ ÄÃšNG:",
            "Context: ÄÃ£ nÃ³i vá» 'Tour Báº¡ch MÃ£'",
            "Q: 'Tour nÃ y cÃ³ phÃ¹ há»£p nhÃ³m 10 ngÆ°á»i khÃ´ng?'",
            "A: 'Tour Báº¡ch MÃ£ ráº¥t phÃ¹ há»£p cho nhÃ³m 10 ngÆ°á»i! ChÃºng tÃ´i cÃ³ thá»ƒ tá»• chá»©c riÃªng vá»›i giÃ¡ Æ°u Ä‘Ã£i. NhÃ³m báº¡n thÃ­ch hoáº¡t Ä‘á»™ng nÃ o: trekking, thiá»n tÄ©nh tÃ¢m hay cáº£ hai? TÃ´i sáº½ tÆ° váº¥n lá»‹ch trÃ¬nh chi tiáº¿t.'",
        ])
    
    # RULE 3: Location constraint
    if has_location_constraint:
        prompt_parts.extend([
            "",
            "ðŸš¨ RÃ€NG BUá»˜C Äá»ŠA LÃ - NGHIÃŠM NGáº¶T:",
            f"â€¢ YÃªu cáº§u tour gáº§n/táº¡i: {location_constraint or 'khu vá»±c cá»¥ thá»ƒ'}",
            "â€¢ CHá»ˆ Ä‘á» xuáº¥t tour trong khu vá»±c nÃ y",
            "â€¢ Náº¾U khÃ´ng cÃ³ tour phÃ¹ há»£p:",
            "  â†’ 'Hiá»‡n Ruby Wings chÆ°a cÃ³ tour táº¡i [Ä‘á»‹a Ä‘iá»ƒm]. Tuy nhiÃªn, chÃºng tÃ´i cÃ³ tour gáº§n nháº¥t táº¡i [X].'",
            "  â†’ Há»i: 'Báº¡n cÃ³ muá»‘n xem tour á»Ÿ khu vá»±c lÃ¢n cáº­n khÃ´ng?'",
        ])
    
    # RULE 4: Giá»›i háº¡n tour
    prompt_parts.extend([
        "",
        "ðŸ“Š GIá»šI Háº N TOUR (Báº®T BUá»˜C):",
        "â€¢ Tá»‘i Ä‘a 2-3 tour/cÃ¢u tráº£ lá»i",
        "â€¢ Má»–I tour pháº£i cÃ³ LÃ DO rÃµ rÃ ng",
        "â€¢ KHÃ”NG liá»‡t kÃª >3 tour",
        "â€¢ Náº¿u cÃ³ nhiá»u tour phÃ¹ há»£p:",
        "  â†’ Chá»n 2-3 TIÃŠU BIá»‚U nháº¥t",
        "  â†’ TÃ³m táº¯t: 'CÃ²n X tour khÃ¡c...'",
        "  â†’ Há»i: 'Báº¡n muá»‘n xem thÃªm loáº¡i nÃ o?'",
    ])
    
    # CONTEXT INFO
    prompt_parts.extend([
        "",
        "ðŸ“š THÃ”NG TIN NGá»® Cáº¢NH:",
    ])
    
    if context.get('user_preferences'):
        prefs = []
        for k, v in context['user_preferences'].items():
            prefs.append(f"{k}: {v}")
        if prefs:
            prompt_parts.append(f"- Sá»Ÿ thÃ­ch: {'; '.join(prefs)}")
    
    if context.get('current_tours'):
        tours_info = [f"{t['name']}" for t in context['current_tours'][:3]]
        if tours_info:
            prompt_parts.append(f"- Tour Ä‘Ã£ bÃ n: {', '.join(tours_info)}")
    
    if filters:
        filter_strs = []
        if filters.get('price_max'):
            filter_strs.append(f"giÃ¡ <{filters['price_max']:,}Ä‘")
        if filters.get('location'):
            filter_strs.append(f"Vá»Š TRÃ: {filters['location']}")
        if filter_strs:
            prompt_parts.append(f"- RÃ ng buá»™c: {'; '.join(filter_strs)}")
    
    # SEARCH RESULTS
    prompt_parts.append("")
    prompt_parts.append("ðŸ“ Dá»® LIá»†U Tá»ª Há»† THá»NG:")
    
    if search_results:
        for i, (score, passage) in enumerate(search_results[:5], 1):
            text = passage.get('text', '')[:250]
            prompt_parts.append(f"[{i}] {text}")
    else:
        prompt_parts.append("(KhÃ´ng cÃ³ dá»¯ liá»‡u cá»¥ thá»ƒ - sá»­ dá»¥ng kiáº¿n thá»©c chung)")
    
    # YÃŠU Cáº¦U TRáº¢ Lá»œI
    prompt_parts.append("")
    prompt_parts.append("ðŸ’¬ YÃŠU Cáº¦U TRáº¢ Lá»œI:")
    
    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "1. Tráº£ lá»i NGáº®N Gá»ŒN (2-4 cÃ¢u) dá»±a OpenAI",
            "2. KHÃ”NG nÃ³i 'khÃ´ng cÃ³ dá»¯ liá»‡u'",
            "3. Káº¿t thÃºc: Há»i láº¡i Ä‘á»ƒ xÃ¡c Ä‘á»‹nh tour",
        ])
    elif is_followup:
        prompt_parts.extend([
            "1. Dá»±a vÃ o CONTEXT (tour Ä‘Ã£ bÃ n)",
            "2. Tráº£ lá»i TIáº¾P, KHÃ”NG reset",
            "3. Tá»‘i Ä‘a nháº¯c 1-2 tour tá»« context",
        ])
    else:
        prompt_parts.extend([
            "1. Chá»n 2-3 tour vá»›i LÃ DO rÃµ",
            "2. KHÃ”NG >3 tour",
            "3. Náº¿u nhiá»u: tÃ³m táº¯t + há»i tiáº¿p",
        ])
    
    prompt_parts.append("4. LuÃ´n káº¿t thÃºc: CÃ¢u há»i dáº«n dáº¯t hoáº·c 'ðŸ“ž Gá»i 0332510486'")
    
    return "\n".join(prompt_parts)

def _generate_fallback_response(user_message: str, search_results: List, tour_indices: List[int] = None) -> str:
    """Generate SMART fallback response - DÃ¹ng OpenAI khi cÃ³, context-aware"""
    message_lower = user_message.lower()
    
    # ===== Sá»¬ Dá»¤NG OPENAI Náº¾U CÃ“ =====
    if client and HAS_OPENAI:
        try:
            # Chuáº©n bá»‹ context
            context_parts = []
            
            # ThÃ´ng tin tour náº¿u cÃ³
            if tour_indices and TOURS_DB:
                for idx in tour_indices[:2]:
                    tour = TOURS_DB.get(idx)
                    if tour:
                        context_parts.append(f"Tour: {tour.name}")
                        if tour.duration:
                            context_parts.append(f"Thá»i gian: {tour.duration}")
                        if tour.price:
                            context_parts.append(f"GiÃ¡: {tour.price}")
                        if tour.summary:
                            context_parts.append(f"MÃ´ táº£: {tour.summary[:150]}")
            
            # Dá»¯ liá»‡u search
            if search_results:
                for i, (score, passage) in enumerate(search_results[:3], 1):
                    text = passage.get('text', '')[:200]
                    if text:
                        context_parts.append(f"ThÃ´ng tin {i}: {text}")
            
            # Táº¡o prompt thÃ´ng minh
            context_str = "\n".join(context_parts) if context_parts else "KhÃ´ng cÃ³ dá»¯ liá»‡u cá»¥ thá»ƒ"
            
            prompt = f"""Báº¡n lÃ  tÆ° váº¥n viÃªn Ruby Wings chuyÃªn nghiá»‡p.

THÃ”NG TIN CÃ“ Sáº´N:
{context_str}

YÃŠU Cáº¦U TRáº¢ Lá»œI:
1. Náº¿u cÃ³ thÃ´ng tin tour cá»¥ thá»ƒ â†’ TÆ° váº¥n dá»±a trÃªn Ä‘Ã³
2. Náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u â†’ Tráº£ lá»i dá»±a kiáº¿n thá»©c chung vá» tour du lá»‹ch
3. LUÃ”N káº¿t thÃºc báº±ng cÃ¢u há»i dáº«n dáº¯t hoáº·c "Gá»i 0332510486"
4. Ngáº¯n gá»n 2-4 cÃ¢u, nhiá»‡t tÃ¬nh, tá»± nhiÃªn
5. KHÃ”NG nÃ³i "khÃ´ng cÃ³ dá»¯ liá»‡u", "xin lá»—i khÃ´ng tÃ¬m tháº¥y"

CÃ¢u há»i cá»§a khÃ¡ch: {user_message}"""

            response = client.chat.completions.create(
                model=CHAT_MODEL,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.6,
                max_tokens=300
            )
            
            if response.choices:
                reply = response.choices[0].message.content or ""
                # Äáº£m báº£o cÃ³ hotline
                if "0332510486" not in reply:
                    reply += "\n\nðŸ“ž LiÃªn há»‡ 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t!"
                return reply
        
        except Exception as e:
            logger.error(f"OpenAI fallback error: {e}")
            # RÆ¡i xuá»‘ng logic template bÃªn dÆ°á»›i
    
    # ===== FALLBACK KHI KHÃ”NG CÃ“ OPENAI =====
    
    # CÃ³ tour cá»¥ thá»ƒ â†’ Tráº£ thÃ´ng tin tour
    if tour_indices and TOURS_DB:
        response_parts = []
        for idx in tour_indices[:2]:
            tour = TOURS_DB.get(idx)
            if tour:
                response_parts.append(f"**{tour.name}**")
                if tour.duration:
                    response_parts.append(f"â±ï¸ {tour.duration}")
                if tour.location:
                    response_parts.append(f"ðŸ“ {tour.location}")
                if tour.price:
                    response_parts.append(f"ðŸ’° {tour.price}")
                if tour.summary:
                    response_parts.append(f"ðŸ“ {tour.summary[:150]}...")
        
        if response_parts:
            return "\n".join(response_parts) + "\n\nðŸ“ž Gá»i 0332510486 Ä‘á»ƒ biáº¿t thÃªm!"
    
    # CÃ³ search results â†’ TÃ³m táº¯t
    if search_results:
        top_results = search_results[:2]
        response_parts = ["ThÃ´ng tin liÃªn quan:"]
        
        for i, (score, passage) in enumerate(top_results, 1):
            text = passage.get('text', '')[:150]
            if text:
                response_parts.append(f"\n{i}. {text}...")
        
        response_parts.append("\n\nðŸ“ž LiÃªn há»‡ 0332510486 Ä‘á»ƒ biáº¿t chi tiáº¿t!")
        return "".join(response_parts)
    
    # CÃ¢u há»i chung â†’ Template thÃ´ng minh theo keyword
    general_qa = {
        'bao gá»“m': "GiÃ¡ tour Ruby Wings thÆ°á»ng bao gá»“m: xe Ä‘Æ°a Ä‘Ã³n, Äƒn uá»‘ng theo chÆ°Æ¡ng trÃ¬nh, khÃ¡ch sáº¡n, hÆ°á»›ng dáº«n viÃªn vÃ  báº£o hiá»ƒm. TÃ¹y tour cá»¥ thá»ƒ cÃ³ thÃªm hoáº¡t Ä‘á»™ng Ä‘áº·c biá»‡t. Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t? ðŸ˜Š",
        
        'phÃ¹ há»£p gia Ä‘Ã¬nh': "Ruby Wings cÃ³ nhiá»u tour phÃ¹ há»£p gia Ä‘Ã¬nh vá»›i hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng, an toÃ n cho tráº» em vÃ  ngÆ°á»i lá»›n tuá»•i. Gia Ä‘Ã¬nh báº¡n bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch loáº¡i tour nÃ o (thiÃªn nhiÃªn, lá»‹ch sá»­, nghá»‰ dÆ°á»¡ng)?",
        
        'phÃ¹ há»£p': "Ruby Wings cÃ³ tour cho má»i Ä‘á»‘i tÆ°á»£ng! Báº¡n Ä‘i nhÃ³m bao nhiÃªu ngÆ°á»i vÃ  cÃ³ sá»Ÿ thÃ­ch gÃ¬ Ä‘áº·c biá»‡t khÃ´ng?",
        
        'giÃ¡': "GiÃ¡ tour Ruby Wings tá»« 800.000Ä‘ - 3.000.000Ä‘ tÃ¹y loáº¡i. Báº¡n cÃ³ ngÃ¢n sÃ¡ch khoáº£ng bao nhiÃªu vÃ  muá»‘n Ä‘i máº¥y ngÃ y Ä‘á»ƒ tÃ´i tÆ° váº¥n phÃ¹ há»£p?",
        
        'thá»i gian': "Ruby Wings cÃ³ tour 1 ngÃ y, 2 ngÃ y 1 Ä‘Ãªm, 3 ngÃ y 2 Ä‘Ãªm. Báº¡n cÃ³ khoáº£ng bao nhiÃªu thá»i gian ráº£nh?",
        
        'Ä‘á»‹a Ä‘iá»ƒm': "Ruby Wings tá»• chá»©c tour táº¡i Huáº¿, Quáº£ng Trá»‹, Báº¡ch MÃ£, TrÆ°á»ng SÆ¡n vÃ  nhiá»u nÆ¡i khÃ¡c. Báº¡n muá»‘n khÃ¡m phÃ¡ khu vá»±c nÃ o?",
        
        'nhÃ³m': "Tour nhÃ³m cá»§a Ruby Wings ráº¥t phÃ¹ há»£p! NhÃ³m báº¡n bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch hoáº¡t Ä‘á»™ng gÃ¬ (teambuilding, nghá»‰ dÆ°á»¡ng, khÃ¡m phÃ¡)?",
        
        'retreat': "Ruby Wings chuyÃªn tour retreat káº¿t há»£p thiá»n, khÃ­ cÃ´ng vÃ  thiÃªn nhiÃªn. Báº¡n muá»‘n tour bao nhiÃªu ngÃ y vÃ  má»©c Ä‘á»™ hoáº¡t Ä‘á»™ng nhÆ° nÃ o?",
    }
    
    # TÃ¬m keyword match
    for keyword, response in general_qa.items():
        if keyword in message_lower:
            return response
    
    # Default - Dáº«n dáº¯t há»i láº¡i
    return "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n tÃ¬m tour phÃ¹ há»£p! Báº¡n cÃ³ thá»ƒ cho tÃ´i biáº¿t:\n" \
           "â€¢ Muá»‘n Ä‘i Ä‘Ã¢u?\n" \
           "â€¢ Thá»i gian bao lÃ¢u?\n" \
           "â€¢ NgÃ¢n sÃ¡ch khoáº£ng bao nhiÃªu?\n" \
           "â€¢ Äi bao nhiÃªu ngÆ°á»i?\n\n" \
           "Hoáº·c gá»i ngay 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t! ðŸ˜Š"




# =========== MAIN CHAT ENDPOINT - Äá»ˆNH CAO THÃ”NG MINH V4.1 ===========
@app.route("/chat", methods=["POST"])
def chat_endpoint_ultimate():
    """
    Main chat endpoint vá»›i xá»­ lÃ½ AI thÃ´ng minh, context-aware máº¡nh máº½
    Version 4.2 (Enhanced with service_inquiry and location_query)
    """
    start_time = time.time()
    
    try:
        # ================== INITIALIZATION ==================
        data = request.get_json() or {}
        user_message = (data.get("message") or "").strip()
        session_id = extract_session_id(data, request.remote_addr)
        
        if not user_message:
            return jsonify({
                "reply": "ðŸ‘‹ **Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI cá»§a Ruby Wings Travel**\n\n"
                        "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:\n"
                        "â€¢ TÃ¬m hiá»ƒu vá» 32 tour tráº£i nghiá»‡m Ä‘áº·c sáº¯c\n"
                        "â€¢ So sÃ¡nh cÃ¡c tour Ä‘á»ƒ chá»n phÃ¹ há»£p nháº¥t\n"
                        "â€¢ TÆ° váº¥n tour theo nhu cáº§u gia Ä‘Ã¬nh, nhÃ³m, cÃ¡ nhÃ¢n\n"
                        "â€¢ Cung cáº¥p thÃ´ng tin chi tiáº¿t vá» giÃ¡, lá»‹ch trÃ¬nh, Ä‘á»‹a Ä‘iá»ƒm\n\n"
                        "ðŸ“ž **Hotline tÆ° váº¥n 24/7:** 0332510486\n"
                        "ðŸ’¡ **Há»i ngay:** 'Tour nÃ o phÃ¹ há»£p cho gia Ä‘Ã¬nh?', 'Tour Báº¡ch MÃ£ giÃ¡ bao nhiÃªu?'",
                "sources": [],
                "context": {},
                "processing_time": 0
            })
        
        # ================== CONTEXT MANAGEMENT SYSTEM ==================
        context = get_session_context(session_id)
        
        # Khá»Ÿi táº¡o context náº¿u chÆ°a cÃ³
        if not hasattr(context, 'conversation_history'):
            context.conversation_history = []
        if not hasattr(context, 'current_tour'):
            context.current_tour = None
        if not hasattr(context, 'user_profile'):
            context.user_profile = {}
        
        # LÆ°u user message vÃ o history
        context.conversation_history.append({
            'role': 'user',
            'message': user_message,
            'timestamp': datetime.utcnow().isoformat()
        })
        
        # Giá»›i háº¡n history (giá»¯ 20 tin nháº¯n gáº§n nháº¥t)
        if len(context.conversation_history) > 40:
            context.conversation_history = context.conversation_history[-20:]
        
        # ================== ADVANCED CONTEXT ANALYSIS V2 ==================
        message_lower = user_message.lower()
        
        # 1. PHÃ‚N TÃCH Cáº¤P Äá»˜ PHá»¨C Táº P NÃ‚NG CAO
        complexity_score = 0
        complexity_indicators = {
            'vÃ ': 1, 'cho': 1, 'vá»›i': 1, 'nhÆ°ng': 2, 'tuy nhiÃªn': 2,
            'náº¿u': 2, 'khi': 1, 'Ä‘á»ƒ': 1, 'mÃ ': 1, 'hoáº·c': 1, 'so sÃ¡nh': 3,
            'phÃ¢n biá»‡t': 3, 'khÃ¡c nhau': 3, 'tÆ°Æ¡ng tá»±': 2, 'giá»¯a': 2,
            'táº¡i sao': 2, 'lÃ m tháº¿ nÃ o': 3, 'cÃ³ thá»ƒ khÃ´ng': 2,
            'trÆ°á»›c khi': 1, 'sau khi': 1, 'trong khi': 1, 'máº·c dÃ¹': 2,
            'do Ä‘Ã³': 2, 'vÃ¬ váº­y': 2, 'nÃªn': 2, 'nháº±m': 1
        }
        
        for indicator, weight in complexity_indicators.items():
            if indicator in message_lower:
                complexity_score += weight
        
        # 2. PHÃ‚N TÃCH Äá»˜ DÃ€I CÃ‚U Há»ŽI NÃ‚NG CAO
        word_count = len(user_message.split())
        char_count = len(user_message)
        sentence_count = user_message.count('.') + user_message.count('?') + user_message.count('!')
        
        if word_count > 25:
            complexity_score += 3
        elif word_count > 15:
            complexity_score += 2
        elif word_count > 8:
            complexity_score += 1
            
        if char_count > 150:
            complexity_score += 1
            
        if sentence_count > 1:
            complexity_score += 1
        
        # 3. PHÃ‚N TÃCH NGÃ”N NGá»® Há»ŒC & CÃš PHÃP
        question_words = ['ai', 'cÃ¡i gÃ¬', 'gÃ¬', 'á»Ÿ Ä‘Ã¢u', 'khi nÃ o', 'táº¡i sao', 'tháº¿ nÃ o', 'bao nhiÃªu', 'máº¥y']
        question_word_count = sum(1 for word in question_words if word in message_lower)
        complexity_score += min(question_word_count, 2)  # Tá»‘i Ä‘a +2
        
        # PhÃ¢n tÃ­ch má»©c Ä‘á»™ chi tiáº¿t
        detail_indicators = ['cá»¥ thá»ƒ', 'chi tiáº¿t', 'rÃµ rÃ ng', 'tá»«ng', 'má»—i', 'cÃ¡c loáº¡i']
        if any(indicator in message_lower for indicator in detail_indicators):
            complexity_score += 2
        
        # 4. PHÃ‚N TÃCH Cáº¢M XÃšC (SENTIMENT ANALYSIS CÆ  Báº¢N)
        positive_words = ['tuyá»‡t vá»i', 'xuáº¥t sáº¯c', 'hoÃ n háº£o', 'tá»‘t', 'hay', 'thÃ­ch', 'Æ°a', 'mong muá»‘n', 'hÃ i lÃ²ng']
        negative_words = ['tá»‡', 'dá»Ÿ', 'kÃ©m', 'khÃ´ng thÃ­ch', 'ghÃ©t', 'phÃ n nÃ n', 'tháº¥t vá»ng', 'buá»“n', 'chÃ¡n']
        urgent_words = ['gáº¥p', 'ngay', 'láº­p tá»©c', 'nhanh', 'kháº©n cáº¥p', 'cÃ ng sá»›m cÃ ng tá»‘t']
        
        sentiment_score = 0
        sentiment_type = 'neutral'
        
        positive_count = sum(1 for word in positive_words if word in message_lower)
        negative_count = sum(1 for word in negative_words if word in message_lower)
        urgent_count = sum(1 for word in urgent_words if word in message_lower)
        
        if positive_count > negative_count:
            sentiment_score = positive_count
            sentiment_type = 'positive'
        elif negative_count > positive_count:
            sentiment_score = -negative_count
            sentiment_type = 'negative'
            
        if urgent_count > 0:
            complexity_score += 2  # CÃ¢u há»i kháº©n cáº¥p cáº§n xá»­ lÃ½ Æ°u tiÃªn
        
        # 5. PHÃ‚N TÃCH Äá»I TÆ¯á»¢NG & Má»¤C ÄÃCH
        audience_keywords = {
            'business': ['cÃ´ng ty', 'doanh nghiá»‡p', 'team building', 'Ä‘á»“ng nghiá»‡p', 'nhÃ¢n viÃªn'],
            'family': ['gia Ä‘Ã¬nh', 'con nhá»', 'tráº» em', 'Ã´ng bÃ ', 'bá»‘ máº¹', 'Ä‘a tháº¿ há»‡'],
            'youth': ['báº¡n tráº»', 'thanh niÃªn', 'sinh viÃªn', 'há»c sinh', 'tuá»•i teen'],
            'senior': ['ngÆ°á»i lá»›n tuá»•i', 'cao tuá»•i', 'vá» hÆ°u', 'cá»±u chiáº¿n binh', 'trung niÃªn'],
            'solo': ['má»™t mÃ¬nh', 'Ä‘i láº»', 'solo', 'cÃ¡ nhÃ¢n', 'tá»± Ä‘i']
        }
        
        audience_type = None
        for audience, keywords in audience_keywords.items():
            if any(keyword in message_lower for keyword in keywords):
                audience_type = audience
                complexity_score += 1  # CÃ¢u há»i cÃ³ Ä‘á»‘i tÆ°á»£ng cá»¥ thá»ƒ
                break
        
        # 6. PHÃ‚N TÃCH Má»¨C Äá»˜ KHáº¨N Cáº¤P & Æ¯U TIÃŠN
        priority_level = 'normal'
        if urgent_count > 0 or 'gáº¥p' in message_lower:
            priority_level = 'high'
            complexity_score += 2
        elif 'khi nÃ o' in message_lower or 'thá»i gian' in message_lower:
            priority_level = 'medium'
            complexity_score += 1
        
        # 7. PHÃ‚N TÃCH Má»¨C Äá»˜ TRANG TRá»ŒNG
        formal_words = ['kÃ­nh chÃ o', 'thÆ°a', 'xin há»i', 'vui lÃ²ng', 'lÃ m Æ¡n', 'cáº£m Æ¡n']
        informal_words = ['hey', 'hello', 'hi', 'Ãª', 'nÃ¨', 'Æ¡i']
        
        formality_score = 0
        if any(word in message_lower for word in formal_words):
            formality_score = 1  # Trang trá»ng
        elif any(word in message_lower for word in informal_words):
            formality_score = -1  # ThÃ¢n máº­t
        
        # 8. Tá»”NG Há»¢P CHá»ˆ Sá» PHÃ‚N TÃCH
        context_analysis = {
            'complexity_score': min(complexity_score, 10),  # Giá»›i háº¡n 10
            'word_count': word_count,
            'char_count': char_count,
            'sentence_count': sentence_count,
            'question_word_count': question_word_count,
            'sentiment': {
                'type': sentiment_type,
                'score': sentiment_score,
                'positive_count': positive_count,
                'negative_count': negative_count
            },
            'urgency': {
                'level': priority_level,
                'urgent_count': urgent_count
            },
            'audience_type': audience_type,
            'formality': formality_score,
            'has_specific_request': any(word in message_lower for word in detail_indicators),
            'is_comparison': 'so sÃ¡nh' in message_lower or 'khÃ¡c nhau' in message_lower
        }
        
        logger.info(f"ðŸ§  Context Analysis: {context_analysis}")
        

        
        # ================== ENHANCED INTENT DETECTION V3 ==================
        intent_categories = {
            'service_inquiry': [
                'bao gá»“m', 'cÃ³ nhá»¯ng gÃ¬', 'dá»‹ch vá»¥', 'cung cáº¥p', 'cÃ³ cho',
                'cÃ³ Ä‘Æ°a Ä‘Ã³n', 'cÃ³ Äƒn', 'cÃ³ á»Ÿ', 'cÃ³ hÆ°á»›ng dáº«n viÃªn',
                'cÃ³ báº£o hiá»ƒm', 'cÃ³ vÃ© tham quan', 'cÃ³ nÆ°á»›c uá»‘ng',
                'Ä‘iá»u kiá»‡n', 'Ä‘iá»u khoáº£n', 'chÃ­nh sÃ¡ch', 'há»— trá»£',
                'phÆ°Æ¡ng tiá»‡n', 'Äƒn uá»‘ng', 'nÆ¡i á»Ÿ', 'khÃ¡ch sáº¡n', 'homestay',
                'gá»“m nhá»¯ng gÃ¬', 'Ä‘Æ°á»£c cung cáº¥p gÃ¬', 'cÃ³ sáºµn gÃ¬',
                'Ä‘iá»u gÃ¬ Ä‘Æ°á»£c bao gá»“m', 'cÃ³ cho mÆ°á»£n', 'cÃ³ trang thiáº¿t bá»‹',
                'cÃ³ wifi', 'cÃ³ Ä‘iá»u hÃ²a', 'cÃ³ bá»¯a sÃ¡ng', 'all inclusive',
                'full package', 'dá»‹ch vá»¥ Ä‘i kÃ¨m', 'tiá»‡n Ã­ch', 'tiá»‡n nghi'
            ],
            
            'location_query': [
                'Ä‘i Ä‘Ã  náºµng', 'Ä‘i huáº¿', 'Ä‘i quáº£ng trá»‹', 'Ä‘i báº¡ch mÃ£',
                'Ä‘i trÆ°á»ng sÆ¡n', 'á»Ÿ Ä‘Ã¢u', 'táº¡i sao', 'táº¡i Ä‘Ã¢u',
                'Ä‘áº¿n Ä‘Ã¢u', 'thÄƒm quan Ä‘Ã¢u', 'khu vá»±c', 'Ä‘á»‹a bÃ n',
                'miá»n trung', 'huáº¿ quáº£ng trá»‹', 'Ä‘Ã´ng hÃ ', 'Ä‘á»‹a Ä‘iá»ƒm',
                'Ä‘iá»ƒm Ä‘áº¿n', 'nÆ¡i Ä‘áº¿n', 'vá»‹ trÃ­', 'tá»a Ä‘á»™', 'báº£n Ä‘á»“',
                'khu vá»±c nÃ o', 'vÃ¹ng nÃ o', 'tá»‰nh nÃ o', 'thÃ nh phá»‘ nÃ o',
                'huyá»‡n nÃ o', 'xÃ£ nÃ o', 'lÃ ng nÃ o', 'báº£n nÃ o', 'khu du lá»‹ch',
                'Ä‘iá»ƒm tham quan', 'danh lam tháº¯ng cáº£nh', 'Ä‘á»‹a danh'
            ],
            
            'tour_listing': [
                'cÃ³ nhá»¯ng tour nÃ o', 'danh sÃ¡ch tour', 'liá»‡t kÃª tour', 
                'tour nÃ o cÃ³', 'tour gÃ¬', 'cÃ³ tour', 'cÃ³ tour nÃ o',
                'cÃ³ chÆ°Æ¡ng trÃ¬nh', 'cÃ³ dá»‹ch vá»¥', 'cÃ³ tour',
                'xem tour', 'xem cÃ¡c tour', 'tour Ä‘ang cÃ³', 'tour hiá»‡n táº¡i',
                'tour nÃ o Ä‘ang cháº¡y', 'tour kháº£ dá»¥ng', 'tour sáºµn cÃ³',
                'cÃ¡c tour hiá»‡n cÃ³', 'táº¥t cáº£ tour', 'full list',
                'danh má»¥c tour', 'catalogue tour', 'bá»™ sÆ°u táº­p tour',
                'tour má»›i nháº¥t', 'tour hot', 'tour ná»•i báº­t', 'tour Ä‘áº·c biá»‡t',
                'tour limited', 'tour theo mÃ¹a', 'tour theo thÃ¡ng'
            ],

            'price_inquiry': [
                'giÃ¡ bao nhiÃªu', 'bao nhiÃªu tiá»n', 'chi phÃ­', 'giÃ¡ tour',
                'báº£ng giÃ¡', 'bao nhiÃªu', 'giÃ¡ tháº¿ nÃ o', 'giÃ¡ sao',
                'giÃ¡ khÃ´ng', 'háº¿t bao nhiÃªu tiá»n', 'chi phÃ­ háº¿t bao nhiÃªu',
                'giÃ¡ cáº£', 'má»©c giÃ¡', 'Ä‘Æ¡n giÃ¡', 'chi phÃ­ tour',
                'tour giÃ¡ ráº»', 'tour giÃ¡ tá»‘t', 'tour tiáº¿t kiá»‡m',
                'tour cao cáº¥p giÃ¡', 'tour vip giÃ¡', 'giÃ¡ khuyáº¿n mÃ£i',
                'giÃ¡ Æ°u Ä‘Ã£i', 'giÃ¡ Ä‘áº·c biá»‡t', 'giÃ¡ cuá»‘i', 'giÃ¡ gá»‘c',
                'giÃ¡ niÃªm yáº¿t', 'giÃ¡ sau giáº£m', 'giÃ¡ cuá»‘i cÃ¹ng',
                'tá»•ng chi phÃ­', 'tá»•ng sá»‘ tiá»n', 'cáº§n bao nhiÃªu tiá»n',
                'kinh phÃ­', 'ngÃ¢n sÃ¡ch', 'táº§m giÃ¡', 'khoáº£ng giÃ¡'
            ],

            'tour_detail': [
                'chi tiáº¿t tour', 'lá»‹ch trÃ¬nh', 'cÃ³ gÃ¬', 'bao gá»“m gÃ¬',
                'thÃ´ng tin', 'mÃ´ táº£', 'Ä‘i nhá»¯ng Ä‘Ã¢u', 'tham quan gÃ¬',
                'chÆ°Æ¡ng trÃ¬nh tháº¿ nÃ o', 'ná»™i dung tour', 'hÃ nh trÃ¬nh',
                'lá»™ trÃ¬nh', 'káº¿ hoáº¡ch', 'chÆ°Æ¡ng trÃ¬nh chi tiáº¿t',
                'thÃ´ng tin Ä‘áº§y Ä‘á»§', 'full detail', 'mÃ´ táº£ Ä‘áº§y Ä‘á»§',
                'giá»›i thiá»‡u chi tiáº¿t', 'trÃ¬nh bÃ y chi tiáº¿t', 'nÃ³i rÃµ hÆ¡n',
                'cá»¥ thá»ƒ hÆ¡n', 'thÃ´ng tin tour', 'tour info', 'tour facts',
                'Ä‘áº·c Ä‘iá»ƒm tour', 'Ä‘iá»ƒm ná»•i báº­t', 'highlight', 'Ä‘iá»ƒm Ä‘áº·c sáº¯c'
            ],

            'comparison': [
                'so sÃ¡nh', 'khÃ¡c nhau', 'nÃªn chá»n', 'tá»‘t hÆ¡n',
                'hÆ¡n kÃ©m', 'phÃ¢n biá»‡t', 'so vá»›i', 'cÃ¡i nÃ o hÆ¡n',
                'tour nÃ o tá»‘t hÆ¡n', 'tour nÃ o hay hÆ¡n', 'tour nÃ o Ä‘Ã¡ng giÃ¡ hÆ¡n',
                'Ä‘Ã¡nh giÃ¡ giá»¯a', 'so sÃ¡nh giá»¯a', 'Ä‘á»‘i chiáº¿u',
                'cÃ¹ng loáº¡i', 'tÆ°Æ¡ng Ä‘á»“ng', 'giá»‘ng nhau', 'khÃ¡c biá»‡t',
                'Æ°u Ä‘iá»ƒm nhÆ°á»£c Ä‘iá»ƒm', 'pros and cons', 'Ä‘iá»ƒm máº¡nh Ä‘iá»ƒm yáº¿u',
                'tour a vs tour b', 'tour nÃ y vá»›i tour kia'
            ],

            'recommendation': [
                'phÃ¹ há»£p', 'gá»£i Ã½', 'Ä‘á» xuáº¥t', 'tÆ° váº¥n', 'nÃªn Ä‘i',
                'chá»n nÃ o', 'tÃ¬m tour', 'nÃªn chá»n tour nÃ o',
                'tÆ° váº¥n giÃºp', 'gá»£i Ã½ giÃºp mÃ¬nh', 'tÆ° váº¥n cho tÃ´i',
                'Ä‘á» xuáº¥t tour', 'giá»›i thiá»‡u tour', 'tour Ä‘á» cá»­',
                'tour recommend', 'tour suggested', 'tour Ä‘Æ°á»£c Ä‘á» xuáº¥t',
                'nÃªn Ä‘i tour nÃ o', 'tour phÃ¹ há»£p nháº¥t', 'tour tá»‘t nháº¥t cho',
                'tour hay nháº¥t', 'tour Ä‘Ã¡ng tráº£i nghiá»‡m', 'tour nÃªn thá»­',
                'tour há»£p vá»›i', 'tour dÃ nh cho', 'tour theo sá»Ÿ thÃ­ch'
            ],

            'booking_info': [
                'Ä‘áº·t tour', 'Ä‘Äƒng kÃ½', 'booking', 'giá»¯ chá»—',
                'thanh toÃ¡n', 'Ä‘áº·t chá»—', 'cÃ¡ch Ä‘áº·t',
                'Ä‘áº·t nhÆ° tháº¿ nÃ o', 'Ä‘áº·t ra sao', 'quy trÃ¬nh Ä‘áº·t',
                'lÃ m sao Ä‘á»ƒ Ä‘áº·t', 'hÆ°á»›ng dáº«n Ä‘áº·t tour', 'Ä‘áº·t tour online',
                'Ä‘áº·t tour trá»±c tuyáº¿n', 'form Ä‘áº·t tour', 'Ä‘iá»n form Ä‘áº·t tour',
                'thá»§ tá»¥c Ä‘áº·t tour', 'Ä‘iá»u kiá»‡n Ä‘áº·t tour', 'chÃ­nh sÃ¡ch Ä‘áº·t tour',
                'cÃ¡ch thá»©c thanh toÃ¡n', 'phÆ°Æ¡ng thá»©c thanh toÃ¡n',
                'cÃ¡ch book tour', 'book nhÆ° tháº¿ nÃ o', 'reservation',
                'Ä‘áº·t trÆ°á»›c', 'pre-order', 'pre-book', 'giá»¯ chá»— trÆ°á»›c'
            ],

            'policy': [
                'chÃ­nh sÃ¡ch', 'giáº£m giÃ¡', 'Æ°u Ä‘Ã£i', 'khuyáº¿n mÃ£i',
                'giáº£m', 'promotion', 'hoÃ n tiá»n', 'há»§y tour',
                'Ä‘á»•i lá»‹ch', 'Ä‘iá»u kiá»‡n', 'Ä‘iá»u khoáº£n', 'terms',
                'Ä‘iá»u lá»‡', 'quy Ä‘á»‹nh', 'chÃ­nh sÃ¡ch há»§y',
                'chÃ­nh sÃ¡ch hoÃ n tiá»n', 'chÃ­nh sÃ¡ch Ä‘á»•i tour',
                'chÃ­nh sÃ¡ch báº£o hiá»ƒm', 'chÃ­nh sÃ¡ch tráº» em',
                'chÃ­nh sÃ¡ch ngÆ°á»i cao tuá»•i', 'chÃ­nh sÃ¡ch nhÃ³m',
                'discount', 'voucher', 'coupon', 'mÃ£ giáº£m giÃ¡',
                'khuyáº¿n máº¡i', 'Æ°u Ä‘Ã£i Ä‘áº·c biá»‡t', 'giÃ¡ sá»‘c',
                'flash sale', 'sale off', 'giáº£m giÃ¡ sá»‘c'
            ],

            'general_info': [
                'giá»›i thiá»‡u', 'lÃ  gÃ¬', 'tháº¿ nÃ o', 'ra sao',
                'sá»© má»‡nh', 'giÃ¡ trá»‹', 'triáº¿t lÃ½', 'bÃªn báº¡n lÃ  ai',
                'cÃ´ng ty lÃ  gÃ¬', 'ruby wings lÃ  gÃ¬', 'vá» ruby wings',
                'thÃ´ng tin cÃ´ng ty', 'about us', 'about company',
                'táº§m nhÃ¬n', 'vision', 'mission', 'má»¥c tiÃªu',
                'lá»‹ch sá»­ cÃ´ng ty', 'Ä‘á»™i ngÅ©', 'nhÃ¢n sá»±',
                'vÄƒn hÃ³a cÃ´ng ty', 'core value', 'giÃ¡ trá»‹ cá»‘t lÃµi',
                'Ä‘á»‘i tÃ¡c', 'partner', 'collaboration', 'há»£p tÃ¡c'
            ],

            'weather_info': [
                'thá»i tiáº¿t', 'khÃ­ háº­u', 'náº¯ng mÆ°a', 'mÃ¹a nÃ o',
                'nhiá»‡t Ä‘á»™', 'thá»i tiáº¿t cÃ³ Ä‘áº¹p khÃ´ng', 'mÆ°a khÃ´ng',
                'náº¯ng khÃ´ng', 'khÃ­ háº­u tháº¿ nÃ o', 'thá»i tiáº¿t táº¡i',
                'mÆ°a nhiá»u khÃ´ng', 'náº¯ng nhiá»u khÃ´ng', 'Ä‘á»™ áº©m',
                'giÃ³', 'bÃ£o', 'lá»¥t', 'thiÃªn tai', 'thá»i tiáº¿t cÃ³ thuáº­n lá»£i',
                'mÃ¹a du lá»‹ch', 'thá»i Ä‘iá»ƒm tá»‘t nháº¥t', 'best time to visit',
                'mÃ¹a cao Ä‘iá»ƒm', 'mÃ¹a tháº¥p Ä‘iá»ƒm', 'thá»i tiáº¿t theo mÃ¹a',
                'dá»± bÃ¡o thá»i tiáº¿t', 'weather forecast', 'weather condition'
            ],

            'food_info': [
                'áº©m thá»±c', 'mÃ³n Äƒn', 'Ä‘áº·c sáº£n', 'Ä‘á»“ Äƒn',
                'bÃ¡nh bÃ¨o', 'máº¯m nÃªm', 'Äƒn gÃ¬', 'Äƒn uá»‘ng tháº¿ nÃ o',
                'cÃ³ Äƒn Ä‘áº·c sáº£n khÃ´ng', 'Ä‘á»“ Äƒn Ä‘á»‹a phÆ°Æ¡ng', 'local food',
                'street food', 'áº©m thá»±c Ä‘Æ°á»ng phá»‘', 'nhÃ  hÃ ng',
                'quÃ¡n Äƒn', 'Ä‘áº·c sáº£n vÃ¹ng miá»n', 'mÃ³n ngon',
                'Ä‘á»“ uá»‘ng', 'thá»©c uá»‘ng', 'Ä‘á»“ Äƒn kÃ¨m', 'set menu',
                'thá»±c Ä‘Æ¡n', 'menu', 'dining', 'áº©m thá»±c huáº¿',
                'Ä‘áº·c sáº£n huáº¿', 'Ä‘áº·c sáº£n quáº£ng trá»‹', 'Ä‘áº·c sáº£n miá»n trung'
            ],

            'culture_info': [
                'vÄƒn hÃ³a', 'lá»‹ch sá»­', 'truyá»n thá»‘ng', 'di tÃ­ch',
                'di sáº£n', 'vÄƒn minh', 'báº£n sáº¯c', 'vÄƒn hÃ³a Ä‘á»‹a phÆ°Æ¡ng',
                'phong tá»¥c', 'táº­p quÃ¡n', 'lá»… há»™i', 'festival',
                'tÃ­n ngÆ°á»¡ng', 'tÃ´n giÃ¡o', 'kiáº¿n trÃºc', 'nghá»‡ thuáº­t',
                'Ã¢m nháº¡c', 'mÃºa', 'di sáº£n vÄƒn hÃ³a', 'di sáº£n unesco',
                'vÄƒn hÃ³a dÃ¢n tá»™c', 'vÄƒn hÃ³a báº£n Ä‘á»‹a', 'lá»‹ch sá»­ Ä‘á»‹a phÆ°Æ¡ng',
                'truyá»n thuyáº¿t', 'cá»• tÃ­ch', 'historical site',
                'cultural heritage', 'cultural experience'
            ],

            'wellness_info': [
                'thiá»n', 'yoga', 'chá»¯a lÃ nh', 'sá»©c khá»e', 'retreat',
                'tÄ©nh tÃ¢m', 'khÃ­ cÃ´ng', 'nghá»‰ dÆ°á»¡ng', 'há»“i phá»¥c',
                'thÆ° giÃ£n', 'wellness', 'spa', 'massage',
                'thiá»n Ä‘á»‹nh', 'mindfulness', 'meditation',
                'yoga therapy', 'health retreat', 'detox',
                'wellness retreat', 'sá»©c khá»e tinh tháº§n',
                'mental health', 'balance', 'cÃ¢n báº±ng',
                'giáº£m stress', 'giáº£m cÄƒng tháº³ng', 'tháº£ lá»ng'
            ],

            'group_info': [
                'nhÃ³m', 'Ä‘oÃ n', 'cÃ´ng ty', 'gia Ä‘Ã¬nh', 'báº¡n bÃ¨',
                'táº­p thá»ƒ', 'cá»±u chiáº¿n binh', 'Ä‘i theo Ä‘oÃ n',
                'Ä‘i Ä‘Ã´ng ngÆ°á»i', 'Ä‘oÃ n riÃªng', 'nhÃ³m lá»›n',
                'nhÃ³m nhá»', 'team', 'Ä‘á»™i', 'group tour',
                'private tour', 'tour riÃªng', 'tour Ä‘oÃ n',
                'tour cÃ´ng ty', 'tour team building',
                'tour gia Ä‘Ã¬nh', 'tour báº¡n bÃ¨', 'tour sinh viÃªn',
                'tour há»c sinh', 'tour Ä‘á»“ng nghiá»‡p', 'tour táº­p thá»ƒ'
            ],

            'custom_request': [
                'tÃ¹y chá»‰nh', 'riÃªng', 'cÃ¡ nhÃ¢n hÃ³a', 'theo yÃªu cáº§u',
                'riÃªng biá»‡t', 'thiáº¿t káº¿ tour', 'lÃ m tour riÃªng',
                'tour theo yÃªu cáº§u', 'custom tour', 'private tour',
                'tailor made', 'bespoke tour', 'Ä‘oÃ n riÃªng',
                'lá»‹ch trÃ¬nh riÃªng', 'chÆ°Æ¡ng trÃ¬nh riÃªng',
                'tour thiáº¿t káº¿ riÃªng', 'personalized tour',
                'tour cÃ¡ nhÃ¢n', 'Ä‘áº·t theo Ã½ muá»‘n', 'theo Ã½ tÃ´i',
                'theo sá»Ÿ thÃ­ch', 'theo ngÃ¢n sÃ¡ch', 'theo thá»i gian'
            ],

            'sustainability': [
                'bá»n vá»¯ng', 'mÃ´i trÆ°á»ng', 'xanh', 'cá»™ng Ä‘á»“ng',
                'phÃ¡t triá»ƒn bá»n vá»¯ng', 'du lá»‹ch xanh',
                'du lá»‹ch bá»n vá»¯ng', 'eco tour', 'eco friendly',
                'thÃ¢n thiá»‡n mÃ´i trÆ°á»ng', 'báº£o vá»‡ mÃ´i trÆ°á»ng',
                'tÃ¡i cháº¿', 'reduce reuse recycle', 'carbon footprint',
                'du lá»‹ch cÃ³ trÃ¡ch nhiá»‡m', 'responsible tourism',
                'du lá»‹ch cá»™ng Ä‘á»“ng', 'community tourism',
                'du lá»‹ch sinh thÃ¡i', 'ecotourism', 'green tourism',
                'sustainable travel', 'ethical tourism'
            ],

            'experience': [
                'tráº£i nghiá»‡m', 'cáº£m giÃ¡c', 'cáº£m nháº­n', 'thá»±c táº¿',
                'trá»±c tiáº¿p', 'tráº£i nghiá»‡m nhÆ° tháº¿ nÃ o', 'cÃ³ gÃ¬ hay',
                'cáº£m nháº­n tháº¿ nÃ o', 'experience', 'cáº£m xÃºc',
                'ká»· niá»‡m', 'khoáº£nh kháº¯c', 'moment', 'memory',
                'cÃ¢u chuyá»‡n', 'story', 'chuyáº¿n Ä‘i Ä‘Ã¡ng nhá»›',
                'Ä‘iá»u Ä‘áº·c biá»‡t', 'Ä‘iá»ƒm nháº¥n', 'highlight experience',
                'hoáº¡t Ä‘á»™ng Ä‘áº·c biá»‡t', 'special activity', 'unique experience',
                'tráº£i nghiá»‡m Ä‘á»™c Ä‘Ã¡o', 'tráº£i nghiá»‡m khÃ¡c biá»‡t'
            ],
            
            # THÃŠM INTENT Má»šI - AN TOÃ€N VÃŒ CÃ“ FALLBACK HANDLING
            'accessibility_info': [
                'ngÆ°á»i khuyáº¿t táº­t', 'xe lÄƒn', 'wheelchair', 'accessible',
                'thang mÃ¡y', 'elevator', 'ramp', 'Ä‘Æ°á»ng dá»‘c',
                'cho ngÆ°á»i giÃ ', 'cho tráº» em', 'dá»… di chuyá»ƒn',
                'tiá»‡n nghi cho ngÆ°á»i giÃ ', 'tiá»‡n nghi cho tráº» em',
                'an toÃ n cho', 'phÃ¹ há»£p cho ngÆ°á»i khuyáº¿t táº­t'
            ],
            
            'transportation_info': [
                'phÆ°Æ¡ng tiá»‡n', 'xe cá»™', 'transport', 'vehicle',
                'loáº¡i xe', 'xe gÃ¬', 'bus', 'xe khÃ¡ch', 'xe du lá»‹ch',
                'xe Ä‘Æ°a Ä‘Ã³n', 'pick up', 'drop off', 'Ä‘iá»ƒm Ä‘Ã³n',
                'thá»i gian Ä‘Ã³n', 'xe bao nhiÃªu chá»—', 'xe mÃ¡y láº¡nh',
                'air conditioner', 'xe Ä‘á»i má»›i', 'xe thoáº£i mÃ¡i'
            ],
            
            'safety_info': [
                'an toÃ n', 'báº£o Ä‘áº£m', 'secure', 'safety',
                'an ninh', 'security', 'báº£o hiá»ƒm', 'insurance',
                'cá»©u há»™', 'rescue', 'y táº¿', 'medical',
                'phÃ²ng chÃ¡y', 'fire safety', 'sÆ¡ cá»©u', 'first aid',
                'hÆ°á»›ng dáº«n an toÃ n', 'safety briefing', 'emergency'
            ]
        }
        
        # NÃ‚NG Cáº¤P LOGIC PHÃT HIá»†N INTENT THÃ”NG MINH HÆ N
        detected_intents = []
        intent_scores = {}
        
        for intent, keywords in intent_categories.items():
            score = 0
            matched_keywords = []
            
            for keyword in keywords:
                if keyword in message_lower:
                    score += 1
                    matched_keywords.append(keyword)
                    
                    # Bonus cho keyword dÃ i (cá»¥ thá»ƒ hÆ¡n)
                    if len(keyword.split()) >= 2:
                        score += 0.5
                    
                    # Bonus cho keyword chÃ­nh xÃ¡c
                    if f' {keyword} ' in f' {message_lower} ':
                        score += 0.3
            
            if score > 0:
                intent_scores[intent] = {
                    'score': score,
                    'keywords': matched_keywords[:3]  # Giá»¯ 3 keyword Ä‘áº§u
                }
                
                # Äá»§ Ä‘iá»ƒm threshold thÃ¬ thÃªm vÃ o detected_intents
                if score >= 1.0:  # Threshold cÃ³ thá»ƒ Ä‘iá»u chá»‰nh
                    if intent not in detected_intents:
                        detected_intents.append(intent)
        
        # Sáº¯p xáº¿p intents theo score Ä‘á»ƒ debug
        sorted_intents = sorted(intent_scores.items(), key=lambda x: x[1]['score'], reverse=True)
        if sorted_intents:
            logger.info(f"ðŸŽ¯ Intent Scores (Top 3): {sorted_intents[:3]}")
        
        # Æ¯U TIÃŠN INTENT CHÃNH NÃ‚NG CAO
        primary_intent = None
        
        if detected_intents:
            # Strategy 1: Æ¯u tiÃªn theo priority order
            priority_order = [
                'comparison', 'recommendation', 'service_inquiry',
                'location_query', 'price_inquiry', 'tour_detail',
                'tour_listing', 'custom_request', 'booking_info',
                'group_info', 'wellness_info', 'policy',
                'culture_info', 'weather_info', 'food_info',
                'general_info', 'sustainability', 'experience',
                'accessibility_info', 'transportation_info', 'safety_info'
            ]
            
            # TÃ¬m intent cÃ³ Ä‘iá»ƒm cao nháº¥t trong priority order
            best_score = -1
            for intent in priority_order:
                if intent in detected_intents:
                    score_data = intent_scores.get(intent, {'score': 0})
                    current_score = score_data['score']
                    
                    # Æ¯u tiÃªn intent cÃ³ score cao hÆ¡n
                    if current_score > best_score:
                        best_score = current_score
                        primary_intent = intent
            
            # Strategy 2: Náº¿u khÃ´ng tÃ¬m tháº¥y theo priority, láº¥y intent cÃ³ score cao nháº¥t
            if not primary_intent:
                highest_intent = max(intent_scores.items(), key=lambda x: x[1]['score'])[0]
                primary_intent = highest_intent
            
            # Strategy 3: Xá»­ lÃ½ trÆ°á»ng há»£p multiple high scores
            top_intents = [intent for intent, data in sorted_intents[:2] if data['score'] > 2]
            if len(top_intents) > 1 and primary_intent:
                # Ghi nháº­n multiple intents cho response generation xá»­ lÃ½
                context.multiple_intents = top_intents
                logger.info(f"ðŸŽ¯ Multiple High-Score Intents: {top_intents}")
        
        # Ghi log chi tiáº¿t
        logger.info(f"ðŸŽ¯ Detected Intents: {detected_intents}")
        logger.info(f"ðŸŽ¯ Primary Intent: {primary_intent}")



        
        # ================== ENHANCED TOUR RESOLUTION ENGINE V2 ==================
        tour_indices = []
        tour_names_mentioned = []
        
        # IMPORT: Cáº§n thÃªm á»Ÿ Ä‘áº§u file náº¿u chÆ°a cÃ³
        # from difflib import SequenceMatcher
        import re
        import difflib
        
        # Strategy 0: Pre-process user message for better matching
        cleaned_message = user_message.lower()
        
        # Chuáº©n hÃ³a tá»« Ä‘á»“ng nghÄ©a Ä‘á»ƒ tÄƒng kháº£ nÄƒng matching
        synonym_mapping = {
            'tour': ['tour', 'tour', 'chÆ°Æ¡ng trÃ¬nh', 'lá»‹ch trÃ¬nh', 'trip', 'chuyáº¿n Ä‘i'],
            'báº¡ch mÃ£': ['báº¡ch mÃ£', 'bach ma', 'vÆ°á»n quá»‘c gia báº¡ch mÃ£'],
            'trÆ°á»ng sÆ¡n': ['trÆ°á»ng sÆ¡n', 'truong son', 'Ä‘Æ°á»ng há»“ chÃ­ minh', 'Ä‘Æ°á»ng hcm'],
            'huáº¿': ['huáº¿', 'hue', 'thÃ nh phá»‘ huáº¿', 'cá»‘ Ä‘Ã´ huáº¿'],
            'quáº£ng trá»‹': ['quáº£ng trá»‹', 'quang tri', 'Ä‘Ã´ng hÃ ', 'Ä‘á»‹a Ä‘áº¡o vá»‹nh má»‘c'],
            'thiá»n': ['thiá»n', 'meditation', 'thiá»n Ä‘á»‹nh', 'tÄ©nh tÃ¢m'],
            'retreat': ['retreat', 'tÄ©nh dÆ°á»¡ng', 'nghá»‰ dÆ°á»¡ng', 'chá»¯a lÃ nh'],
            'lá»‹ch sá»­': ['lá»‹ch sá»­', 'history', 'di tÃ­ch', 'chiáº¿n tranh', 'tri Ã¢n'],
            'thiÃªn nhiÃªn': ['thiÃªn nhiÃªn', 'nature', 'rá»«ng nÃºi', 'cÃ¢y cá»‘i', 'trekking'],
            'áº©m thá»±c': ['áº©m thá»±c', 'food', 'Ä‘á»“ Äƒn', 'mÃ³n Äƒn', 'Ä‘áº·c sáº£n']
        }
        
        # Ãp dá»¥ng chuáº©n hÃ³a tá»« Ä‘á»“ng nghÄ©a
        for standard_word, synonyms in synonym_mapping.items():
            for synonym in synonyms:
                if synonym in cleaned_message:
                    cleaned_message = cleaned_message.replace(synonym, standard_word)
        
        # Strategy 1: Enhanced direct tour name matching vá»›i multiple patterns
        direct_tour_matches = []
        
        # CÃ¡c pattern tÃ¬m tÃªn tour vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n
        tour_name_patterns = [
            r'["\'](.+?)["\']',  # TÃªn trong dáº¥u nhÃ¡y
            r'(?:tour|tour|lá»‹ch trÃ¬nh)\s+["\']?(.+?)["\']?(?:\s+|$|,|\.|\?)',  # Tour/HÃ nh trÃ¬nh + tÃªn
            r'(?:tour|tour|lá»‹ch trÃ¬nh)\s+(?:tÃªn lÃ |gá»i lÃ |mang tÃªn)\s+["\']?(.+?)["\']?(?:\s+|$|,|\.|\?)',
            r'(?:Ä‘i|tham quan|khÃ¡m phÃ¡|tráº£i nghiá»‡m)\s+["\']?(.+?)["\']?(?:\s+táº¡i|\s+á»Ÿ|\s+trong|\s+|$|,|\.|\?)',
            r'(?:cho|vá»|tÃ¬m hiá»ƒu|tÆ° váº¥n)\s+["\']?(.+?)["\']?(?:\s+tour|\s+tour|\s+|$|,|\.|\?)'
        ]
        
        for pattern in tour_name_patterns:
            matches = re.findall(pattern, user_message, re.IGNORECASE | re.UNICODE)
            for match in matches:
                if match and len(match.strip()) > 2:
                    clean_name = match.strip()
                    # Loáº¡i bá» cÃ¡c tá»« khÃ´ng cáº§n thiáº¿t
                    remove_words = ['nÃ o', 'gÃ¬', 'Ä‘Ã³', 'áº¥y', 'nÃ y', 'kia', 'cho', 'vá»›i', 'cá»§a', 'vá»', 'táº¡i', 'á»Ÿ']
                    for word in remove_words:
                        if clean_name.lower().endswith(f' {word}'):
                            clean_name = clean_name[:-len(word)-1].strip()
                    
                    # Chá»‰ thÃªm náº¿u tÃªn Ä‘á»§ dÃ i vÃ  khÃ´ng chá»‰ lÃ  tá»« chung chung
                    if len(clean_name) >= 3 and clean_name.lower() not in remove_words:
                        tour_names_mentioned.append(clean_name)
        
        logger.info(f"ðŸ” Tour names mentioned in query (raw): {tour_names_mentioned}")
        
        # Strategy 1.1: Advanced direct matching vá»›i similarity scoring
        for tour_name in tour_names_mentioned:
            best_matches = []
            
            for norm_name, idx in TOUR_NAME_TO_INDEX.items():
                similarity_score = 0
                match_type = None
                
                # TÃ­nh toÃ¡n multiple similarity scores
                scores = []
                
                # 1. Exact match hoáº·c partial match
                if tour_name.lower() == norm_name.lower():
                    similarity_score = 1.0
                    match_type = 'exact'
                elif tour_name.lower() in norm_name.lower() or norm_name.lower() in tour_name.lower():
                    similarity_score = 0.85
                    match_type = 'contains'
                
                # 2. Word overlap score
                name_words = set([w for w in norm_name.lower().split() if len(w) > 2])
                query_words = set([w for w in tour_name.lower().split() if len(w) > 2])
                
                if name_words and query_words:
                    common_words = name_words.intersection(query_words)
                    if common_words:
                        overlap_score = len(common_words) / max(len(name_words), len(query_words))
                        similarity_score = max(similarity_score, overlap_score)
                        if overlap_score > 0.3:
                            match_type = 'word_overlap'
                
                # 3. Sequence similarity (difflib)
                seq_similarity = difflib.SequenceMatcher(None, tour_name.lower(), norm_name.lower()).ratio()
                if seq_similarity > similarity_score:
                    similarity_score = seq_similarity
                    match_type = 'sequence'
                
                # 4. Acronym/short form matching
                # Kiá»ƒm tra xem tour_name cÃ³ pháº£i lÃ  viáº¿t táº¯t cá»§a norm_name khÃ´ng
                if len(tour_name) <= 5 and tour_name.isupper():
                    acronym = ''.join([word[0] for word in norm_name.split() if word])
                    if tour_name.lower() == acronym.lower():
                        similarity_score = 0.9
                        match_type = 'acronym'
                
                if similarity_score >= 0.5:  # NgÆ°á»¡ng matching
                    best_matches.append((idx, similarity_score, norm_name, match_type))
            
            # Sáº¯p xáº¿p theo Ä‘iá»ƒm vÃ  láº¥y match tá»‘t nháº¥t cho tour_name nÃ y
            if best_matches:
                best_matches.sort(key=lambda x: x[1], reverse=True)
                best_idx, best_score, best_norm_name, match_type = best_matches[0]
                
                if best_score >= 0.6:  # NgÆ°á»¡ng cao hÆ¡n cho matching cháº¥t lÆ°á»£ng
                    if best_idx not in direct_tour_matches:
                        direct_tour_matches.append(best_idx)
                        logger.info(f"ðŸŽ¯ Found tour '{best_norm_name}' (idx: {best_idx}) for query '{tour_name}' "
                                   f"(score: {best_score:.2f}, type: {match_type})")
        
        if direct_tour_matches:
            tour_indices = direct_tour_matches[:5]
            logger.info(f"ðŸŽ¯ Direct tour matches found: {tour_indices} (count: {len(tour_indices)})")
        
        # Strategy 2: Enhanced fuzzy matching vá»›i nÃ¢ng cáº¥p
        if not tour_indices and UpgradeFlags.is_enabled("6_FUZZY_MATCHING"):
            logger.info("ðŸ” Starting enhanced fuzzy matching")
            
            # Táº¡o danh sÃ¡ch tÃªn tour Ä‘á»ƒ fuzzy matching
            tour_names = list(TOUR_NAME_TO_INDEX.keys())
            
            # TÃ¬m cÃ¡c tour cÃ³ similarity cao vá»›i toÃ n bá»™ cÃ¢u há»i
            best_fuzzy_matches = []
            
            for norm_name, idx in TOUR_NAME_TO_INDEX.items():
                # TÃ­nh similarity giá»¯a cÃ¢u há»i vÃ  tÃªn tour
                similarity = difflib.SequenceMatcher(None, cleaned_message, norm_name.lower()).ratio()
                
                # ThÃªm Ä‘iá»ƒm bonus náº¿u cÃ³ tá»« khÃ³a quan trá»ng trÃ¹ng
                important_keywords = ['báº¡ch mÃ£', 'trÆ°á»ng sÆ¡n', 'huáº¿', 'quáº£ng trá»‹', 'thiá»n', 'retreat']
                keyword_bonus = 0
                for keyword in important_keywords:
                    if keyword in norm_name.lower() and keyword in cleaned_message:
                        keyword_bonus += 0.2
                
                total_score = similarity + keyword_bonus
                
                if total_score > 0.5:  # NgÆ°á»¡ng fuzzy matching
                    best_fuzzy_matches.append((idx, total_score, norm_name))
            
            # Sáº¯p xáº¿p vÃ  lá»c
            if best_fuzzy_matches:
                best_fuzzy_matches.sort(key=lambda x: x[1], reverse=True)
                fuzzy_indices = [idx for idx, score, name in best_fuzzy_matches[:5] if score > 0.55]
                
                if fuzzy_indices:
                    tour_indices = fuzzy_indices
                    logger.info(f"ðŸ” Enhanced fuzzy matches found: {tour_indices}")
                    logger.info(f"ðŸ” Top fuzzy match: {best_fuzzy_matches[0][2]} (score: {best_fuzzy_matches[0][1]:.2f})")
        
        # Strategy 3: Enhanced semantic content matching
        if not tour_indices and UpgradeFlags.is_enabled("8_SEMANTIC_ANALYSIS"):
            logger.info("ðŸ§  Starting enhanced semantic content matching")
            
            semantic_matches = []
            
            # Tá»« khÃ³a chÃ­nh trong cÃ¢u há»i (loáº¡i bá» stop words)
            stop_words = ['cÃ³', 'vÃ ', 'cho', 'vá»›i', 'táº¡i', 'á»Ÿ', 'nÃ o', 'gÃ¬', 'bao nhiÃªu', 'tháº¿ nÃ o', 'ra sao']
            query_keywords = [word for word in cleaned_message.split() 
                             if len(word) > 2 and word not in stop_words]
            
            # ThÃªm cÃ¡c cá»¥m tá»« quan trá»ng tá»« cÃ¢u há»i
            important_phrases = []
            for i in range(len(query_keywords) - 1):
                phrase = f"{query_keywords[i]} {query_keywords[i+1]}"
                if len(phrase) > 5:
                    important_phrases.append(phrase)
            
            logger.info(f"ðŸ§  Query keywords: {query_keywords}")
            logger.info(f"ðŸ§  Important phrases: {important_phrases[:5]}")
            
            for idx, tour in TOURS_DB.items():
                score = 0
                match_details = []
                
                # Táº¡o text blob tá»« nhiá»u trÆ°á»ng dá»¯ liá»‡u
                text_blob = f"{tour.name or ''} {tour.summary or ''} {tour.style or ''} {tour.location or ''} {' '.join(tour.tags or [])}".lower()
                
                # 1. Keyword matching
                keyword_matches = sum(1 for word in query_keywords if word in text_blob)
                if keyword_matches > 0:
                    score += keyword_matches * 0.5
                    match_details.append(f"keywords:{keyword_matches}")
                
                # 2. Phrase matching
                phrase_matches = sum(1 for phrase in important_phrases if phrase in text_blob)
                if phrase_matches > 0:
                    score += phrase_matches * 1.0  # Phrase match quan trá»ng hÆ¡n
                    match_details.append(f"phrases:{phrase_matches}")
                
                # 3. Location matching Ä‘áº·c biá»‡t
                if tour.location:
                    location_lower = tour.location.lower()
                    for loc_keyword in ['huáº¿', 'quáº£ng trá»‹', 'báº¡ch mÃ£', 'trÆ°á»ng sÆ¡n']:
                        if loc_keyword in cleaned_message and loc_keyword in location_lower:
                            score += 2.0
                            match_details.append(f"location:{loc_keyword}")
                            break
                
                # 4. Theme matching
                theme_keywords = {
                    'history': ['lá»‹ch sá»­', 'di tÃ­ch', 'chiáº¿n tranh', 'tri Ã¢n'],
                    'nature': ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi', 'trekking'],
                    'meditation': ['thiá»n', 'yoga', 'tÄ©nh tÃ¢m', 'retreat'],
                    'culture': ['vÄƒn hÃ³a', 'áº©m thá»±c', 'Ä‘áº·c sáº£n', 'truyá»n thá»‘ng']
                }
                
                for theme, keywords in theme_keywords.items():
                    theme_in_query = any(keyword in cleaned_message for keyword in keywords)
                    theme_in_tour = any(keyword in text_blob for keyword in keywords)
                    
                    if theme_in_query and theme_in_tour:
                        score += 1.5
                        match_details.append(f"theme:{theme}")
                
                # 5. Duration matching
                if tour.duration:
                    # TÃ¬m sá»‘ ngÃ y trong cÃ¢u há»i
                    day_patterns = [r'(\d+)\s*ngÃ y', r'(\d+)\s*day', r'(\d+)\s*Ä‘Ãªm']
                    query_days = []
                    for pattern in day_patterns:
                        matches = re.findall(pattern, cleaned_message)
                        query_days.extend([int(m) for m in matches])
                    
                    # TÃ¬m sá»‘ ngÃ y trong tour description
                    tour_days = []
                    for pattern in day_patterns:
                        matches = re.findall(pattern, tour.duration.lower())
                        tour_days.extend([int(m) for m in matches])
                    
                    if query_days and tour_days:
                        # Kiá»ƒm tra xem cÃ³ ngÃ y trÃ¹ng khÃ´ng
                        common_days = set(query_days) & set(tour_days)
                        if common_days:
                            score += 1.0
                            match_details.append(f"duration:{list(common_days)[0]}ngÃ y")
                
                if score > 1.0:  # NgÆ°á»¡ng semantic matching
                    semantic_matches.append((idx, score, match_details))
                    if len(semantic_matches) % 10 == 0:
                        logger.debug(f"ðŸ§  Processed {idx} tours, found {len(semantic_matches)} matches")
            
            if semantic_matches:
                semantic_matches.sort(key=lambda x: x[1], reverse=True)
                semantic_indices = [idx for idx, score, details in semantic_matches[:5]]
                
                if semantic_indices:
                    tour_indices = semantic_indices
                    logger.info(f"ðŸ§  Enhanced semantic matches found: {tour_indices}")
                    
                    # Log chi tiáº¿t top matches
                    for idx, score, details in semantic_matches[:3]:
                        tour = TOURS_DB.get(idx)
                        if tour:
                            logger.info(f"ðŸ§    {tour.name}: score={score:.1f}, details={details}")
        
        # Strategy 4: Fallback keyword matching (luÃ´n hoáº¡t Ä‘á»™ng)
        if not tour_indices:
            logger.info("ðŸ”„ Starting fallback keyword matching")
            
            # Táº¡o báº£n Ä‘á»“ tá»« khÃ³a -> tour indices
            keyword_to_tours = {}
            
            for idx, tour in TOURS_DB.items():
                # Thu tháº­p tá»« khÃ³a tá»« tour
                tour_keywords = []
                
                if tour.name:
                    tour_keywords.extend(tour.name.lower().split())
                
                if tour.summary:
                    tour_keywords.extend([w for w in tour.summary.lower().split() if len(w) > 2])
                
                if tour.tags:
                    tour_keywords.extend([tag.lower() for tag in tour.tags])
                
                if tour.style:
                    tour_keywords.append(tour.style.lower())
                
                if tour.location:
                    tour_keywords.extend(tour.location.lower().split())
                
                # ThÃªm vÃ o keyword map
                for keyword in set(tour_keywords):
                    if keyword not in keyword_to_tours:
                        keyword_to_tours[keyword] = []
                    keyword_to_tours[keyword].append(idx)
            
            # TÃ¬m tá»« khÃ³a trong cÃ¢u há»i
            found_keywords = []
            for keyword, tour_indices in keyword_to_tours.items():
                if len(keyword) > 2 and keyword in cleaned_message:
                    found_keywords.append((keyword, len(tour_indices)))
            
            # Sáº¯p xáº¿p theo Ä‘á»™ phá»• biáº¿n (Ã­t phá»• biáº¿n -> cá»¥ thá»ƒ hÆ¡n)
            found_keywords.sort(key=lambda x: x[1])
            
            # Láº¥y cÃ¡c tour tá»« tá»« khÃ³a cá»¥ thá»ƒ nháº¥t
            fallback_indices = []
            for keyword, count in found_keywords[:5]:  # Top 5 keywords cá»¥ thá»ƒ nháº¥t
                fallback_indices.extend(keyword_to_tours[keyword][:3])  # Láº¥y tá»‘i Ä‘a 3 tour má»—i keyword
            
            # Loáº¡i bá» trÃ¹ng láº·p vÃ  giá»›i háº¡n sá»‘ lÆ°á»£ng
            fallback_indices = list(dict.fromkeys(fallback_indices))[:5]
            
            if fallback_indices:
                tour_indices = fallback_indices
                logger.info(f"ðŸ”„ Fallback keyword matches found: {tour_indices}")
                if found_keywords:
                    logger.info(f"ðŸ”„ Matching keywords: {[k for k, _ in found_keywords[:3]]}")
        
        # Strategy 5: Popular tours fallback (chá»‰ khi khÃ´ng tÃ¬m tháº¥y gÃ¬)
        if not tour_indices:
            logger.info("â­ Showing popular tours as fallback")
            
            # XÃ¡c Ä‘á»‹nh popular tours dá»±a trÃªn logic (cÃ³ thá»ƒ dá»±a vÃ o rating, views, etc.)
            # á»ž Ä‘Ã¢y giáº£ sá»­ cÃ³ má»™t sá»‘ tour phá»• biáº¿n cá»‘ Ä‘á»‹nh
            popular_tour_keywords = ['báº¡ch mÃ£', 'trÆ°á»ng sÆ¡n', 'huáº¿', 'thiá»n', 'áº©m thá»±c']
            
            popular_indices = []
            for idx, tour in TOURS_DB.items():
                tour_text = f"{tour.name or ''} {tour.summary or ''}".lower()
                for keyword in popular_tour_keywords:
                    if keyword in tour_text:
                        popular_indices.append(idx)
                        break
                if len(popular_indices) >= 3:
                    break
            
            if popular_indices:
                tour_indices = popular_indices
                logger.info(f"â­ Popular tours fallback: {tour_indices}")
        
        # Final logging
        if tour_indices:
            logger.info(f"âœ… Tour resolution completed. Found {len(tour_indices)} tours: {tour_indices}")
            
            # Log tÃªn cÃ¡c tour tÃ¬m Ä‘Æ°á»£c
            for idx in tour_indices[:3]:
                tour = TOURS_DB.get(idx)
                if tour:
                    logger.info(f"   - {tour.name}")
        else:
            logger.warning("âš ï¸ No tours found after all resolution strategies")



        
        # ================== FILTER EXTRACTION & APPLICATION V2 ==================
        mandatory_filters = FilterSet()
        filter_applied = False
        
        if UpgradeFlags.is_enabled("1_MANDATORY_FILTER"):
            try:
                # 1. ENHANCED FILTER EXTRACTION vá»›i logging chi tiáº¿t
                logger.info(f"ðŸŽ¯ Starting filter extraction for message: '{user_message[:100]}...'")
                mandatory_filters = MandatoryFilterSystem.extract_filters(user_message)
                
                if not mandatory_filters.is_empty():
                    logger.info(f"ðŸŽ¯ Filters extracted: {mandatory_filters}")
                    
                    # Kiá»ƒm tra lá»—i trong filter vá»›i danh sÃ¡ch Ä‘áº§y Ä‘á»§ tá»« MandatoryFilterSystem
                    if hasattr(mandatory_filters, 'group_type') and mandatory_filters.group_type:
                        valid_group_types = ['family', 'friends', 'corporate', 'solo', 'couple', 'senior', 'group']
                        if mandatory_filters.group_type not in valid_group_types:
                            logger.warning(f"âš ï¸ Invalid group type: {mandatory_filters.group_type}")
                            # Reset vá» None Ä‘á»ƒ trÃ¡nh lá»—i
                            mandatory_filters.group_type = None
                    
                    # 2. ENHANCED FILTER APPLICATION vá»›i fallback strategies
                    logger.info("ðŸŽ¯ Applying filters to tour database...")
                    filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                    
                    if filtered_indices:
                        filter_applied = True
                        logger.info(f"âœ… Filter application successful: {len(filtered_indices)} tours passed filters")
                        
                        # 3. INTELLIGENT RESULT COMBINATION
                        if tour_indices:
                            logger.info("ðŸ”„ Combining filter results with tour search results...")
                            
                            # Strategy A: Giao cá»§a káº¿t quáº£ (AND logic)
                            combined_intersection = list(set(tour_indices) & set(filtered_indices))
                            
                            # Strategy B: Há»£p cá»§a káº¿t quáº£ (OR logic) - náº¿u giao quÃ¡ Ã­t
                            combined_union = list(set(tour_indices) | set(filtered_indices))
                            
                            # Lá»±a chá»n strategy dá»±a trÃªn sá»‘ lÆ°á»£ng káº¿t quáº£
                            if len(combined_intersection) >= 2:
                                # Æ¯u tiÃªn giao náº¿u cÃ³ Ä‘á»§ káº¿t quáº£
                                tour_indices = combined_intersection[:5]
                                logger.info(f"ðŸŽ¯ Using intersection strategy: {len(tour_indices)} tours")
                            elif len(combined_union) > 0:
                                # Fallback vá» há»£p náº¿u giao quÃ¡ Ã­t
                                # Æ¯u tiÃªn cÃ¡c tour cÃ³ trong cáº£ hai danh sÃ¡ch trÆ°á»›c
                                priority_tours = []
                                other_tours = []
                                
                                for idx in combined_union:
                                    if idx in tour_indices and idx in filtered_indices:
                                        priority_tours.append(idx)
                                    else:
                                        other_tours.append(idx)
                                
                                # Káº¿t há»£p Æ°u tiÃªn + backup
                                tour_indices = (priority_tours + other_tours)[:5]
                                logger.info(f"ðŸŽ¯ Using union strategy with priority: {len(tour_indices)} tours")
                            else:
                                # KhÃ´ng cÃ³ káº¿t quáº£ nÃ o - dÃ¹ng filter results
                                tour_indices = filtered_indices[:5]
                                logger.info(f"âš ï¸ No combined results, using filter results: {len(tour_indices)} tours")
                        else:
                            # KhÃ´ng cÃ³ káº¿t quáº£ tá»« tour search, chá»‰ dÃ¹ng filter
                            tour_indices = filtered_indices[:8]
                            logger.info(f"ðŸŽ¯ Filter-based search only: {len(tour_indices)} tours")
                        
                        # 4. POST-FILTERING VALIDATION
                        if not tour_indices and filtered_indices:
                            logger.warning("âš ï¸ Combined results empty but filtered_indices exists, using filtered_indices")
                            tour_indices = filtered_indices[:5]
                    
                    else:
                        # KhÃ´ng cÃ³ tour nÃ o pass filter
                        logger.warning("âš ï¸ No tours passed the filters")
                        
                        # Strategy: Ãp dá»¥ng lenient filtering
                        if tour_indices:
                            # Váº«n giá»¯ nguyÃªn káº¿t quáº£ tÃ¬m kiáº¿m nhÆ°ng cáº£nh bÃ¡o
                            logger.info("ðŸ”„ No tours match all filters, using original search results with warning")
                            # LÆ°u tráº¡ng thÃ¡i Ä‘á»ƒ thÃªm warning vÃ o response náº¿u cáº§n
                            context.filter_warning = "KhÃ´ng cÃ³ tour nÃ o Ä‘Ã¡p á»©ng Ä‘áº§y Ä‘á»§ tiÃªu chÃ­. Hiá»ƒn thá»‹ káº¿t quáº£ gáº§n Ä‘Ãºng nháº¥t."
                        else:
                            # Fallback: Hiá»ƒn thá»‹ tours phá»• biáº¿n
                            logger.info("ðŸ”„ No tours match filters and no search results, showing popular tours")
                            # Gá»i fallback mechanism
                            popular_keywords = ['báº¡ch mÃ£', 'trÆ°á»ng sÆ¡n', 'huáº¿', 'thiá»n', 'áº©m thá»±c']
                            popular_indices = []
                            for idx, tour in TOURS_DB.items():
                                tour_text = f"{tour.name or ''} {tour.summary or ''}".lower()
                                for keyword in popular_keywords:
                                    if keyword in tour_text:
                                        popular_indices.append(idx)
                                        break
                                if len(popular_indices) >= 3:
                                    break
                            
                            if popular_indices:
                                tour_indices = popular_indices
                                context.filter_fallback = True
                                logger.info(f"ðŸ”„ Fallback to popular tours: {tour_indices}")
                
                else:
                    logger.info("â„¹ï¸ No filters extracted from query")
                    
            except Exception as e:
                logger.error(f"âŒ Filter system error: {e}\n{traceback.format_exc()}")
                # Continue without filters - important for graceful degradation
                mandatory_filters = FilterSet()
                filter_applied = False
                # KhÃ´ng cáº§n xá»­ lÃ½ thÃªm, váº«n dÃ¹ng káº¿t quáº£ tá»« tour resolution engine
        
        # 5. FILTER-AWARE LOGGING & CONTEXT UPDATES
        if filter_applied:
            # Ghi thÃ´ng tin filter vÃ o context Ä‘á»ƒ response generation sá»­ dá»¥ng
            context.applied_filters = {
                'filters': mandatory_filters.to_dict() if hasattr(mandatory_filters, 'to_dict') else str(mandatory_filters),
                'filtered_count': len(tour_indices) if tour_indices else 0,
                'filter_warning': getattr(context, 'filter_warning', None),
                'filter_fallback': getattr(context, 'filter_fallback', False)
            }
            
            # Log final filter status
            filter_summary = []
            if hasattr(mandatory_filters, 'group_type') and mandatory_filters.group_type:
                filter_summary.append(f"group_type:{mandatory_filters.group_type}")
            if hasattr(mandatory_filters, 'location') and mandatory_filters.location:
                filter_summary.append(f"location:{mandatory_filters.location}")
            if hasattr(mandatory_filters, 'duration_min') or hasattr(mandatory_filters, 'duration_max'):
                dur_range = []
                if mandatory_filters.duration_min:
                    dur_range.append(f"min:{mandatory_filters.duration_min}")
                if mandatory_filters.duration_max:
                    dur_range.append(f"max:{mandatory_filters.duration_max}")
                if dur_range:
                    filter_summary.append(f"duration:{','.join(dur_range)}")
            if hasattr(mandatory_filters, 'price_min') or hasattr(mandatory_filters, 'price_max'):
                price_range = []
                if mandatory_filters.price_min:
                    price_range.append(f"min:{mandatory_filters.price_min:,}")
                if mandatory_filters.price_max:
                    price_range.append(f"max:{mandatory_filters.price_max:,}")
                if price_range:
                    filter_summary.append(f"price:{','.join(price_range)}")
            
            logger.info(f"âœ… Filter Summary: {filter_summary}")
            logger.info(f"âœ… Final tour count after filtering: {len(tour_indices) if tour_indices else 0}")
        
        # 6. THÃŠM LOáº I FILTER Má»šI: SEASON/PREFERENCE FILTERS (bá»• sung)
        # Kiá»ƒm tra thÃªm cÃ¡c filter khÃ´ng cÃ³ trong MandatoryFilterSystem nhÆ°ng cÃ³ trong query
        additional_filters = {}
        
        # Season filter
        season_keywords = {
            'mÃ¹a xuÃ¢n': 'spring',
            'mÃ¹a hÃ¨': 'summer', 
            'mÃ¹a thu': 'autumn',
            'mÃ¹a Ä‘Ã´ng': 'winter',
            'mÃ¹a khÃ´': 'dry_season',
            'mÃ¹a mÆ°a': 'rainy_season'
        }
        
        for vi_key, en_key in season_keywords.items():
            if vi_key in message_lower:
                additional_filters['season'] = en_key
                logger.info(f"ðŸ‚ Additional season filter detected: {en_key}")
                break
        
        # Activity preference filter
        activity_keywords = {
            'nháº¹ nhÃ ng': 'gentle',
            'máº¡o hiá»ƒm': 'adventure',
            'vÄƒn hÃ³a': 'cultural',
            'thiÃªn nhiÃªn': 'nature',
            'thÆ° giÃ£n': 'relaxing',
            'hoáº¡t Ä‘á»™ng': 'active'
        }
        
        for vi_key, en_key in activity_keywords.items():
            if vi_key in message_lower:
                additional_filters['activity_level'] = en_key
                logger.info(f"ðŸƒ Additional activity filter detected: {en_key}")
                break
        
        # Accessibility filter
        accessibility_keywords = ['dá»… Ä‘i', 'dá»… tiáº¿p cáº­n', 'khÃ´ng leo nÃºi', 'báº±ng pháº³ng', 'cho ngÆ°á»i giÃ ', 'cho tráº» em']
        if any(keyword in message_lower for keyword in accessibility_keywords):
            additional_filters['accessibility'] = 'easy'
            logger.info("â™¿ Additional accessibility filter detected: easy")
        
        # LÆ°u additional filters vÃ o context Ä‘á»ƒ response generation sá»­ dá»¥ng
        if additional_filters:
            context.additional_filters = additional_filters
            logger.info(f"âž• Additional filters: {additional_filters}")
            
            # Ãp dá»¥ng thÃªm cÃ¡c filter bá»• sung náº¿u cÃ³ tour_indices
            if tour_indices and additional_filters:
                filtered_by_additional = []
                
                for idx in tour_indices[:10]:  # Chá»‰ xÃ©t 10 tour Ä‘áº§u
                    tour = TOURS_DB.get(idx)
                    if not tour:
                        continue
                    
                    passes_additional = True
                    tour_text = f"{tour.summary or ''} {tour.style or ''}".lower()
                    
                    # Season filter logic
                    if 'season' in additional_filters:
                        season = additional_filters['season']
                        # Logic Ä‘Æ¡n giáº£n: mÃ¹a mÆ°a trÃ¡nh trekking, mÃ¹a khÃ´ phÃ¹ há»£p outdoor
                        if season == 'rainy_season':
                            if any(word in tour_text for word in ['trekking', 'leo nÃºi', 'Ä‘i bá»™ Ä‘Æ°á»ng dÃ i', 'cáº¯m tráº¡i']):
                                passes_additional = False
                    
                    # Activity level filter
                    if passes_additional and 'activity_level' in additional_filters:
                        activity = additional_filters['activity_level']
                        if activity == 'gentle' and any(word in tour_text for word in ['trekking', 'máº¡o hiá»ƒm', 'leo nÃºi', 'khÃ³']):
                            passes_additional = False
                        elif activity == 'adventure' and any(word in tour_text for word in ['nháº¹ nhÃ ng', 'thÆ° giÃ£n', 'nghá»‰ dÆ°á»¡ng']):
                            passes_additional = False
                    
                    # Accessibility filter
                    if passes_additional and 'accessibility' in additional_filters:
                        if any(word in tour_text for word in ['leo nÃºi', 'trekking', 'Ä‘Æ°á»ng khÃ³', 'váº¥t váº£']):
                            passes_additional = False
                    
                    if passes_additional:
                        filtered_by_additional.append(idx)
                
                if filtered_by_additional:
                    # Giá»¯ láº¡i thá»© tá»± ban Ä‘áº§u náº¿u cÃ³ thá»ƒ
                    original_order = {idx: i for i, idx in enumerate(tour_indices)}
                    filtered_by_additional.sort(key=lambda x: original_order.get(x, 999))
                    tour_indices = filtered_by_additional[:5]
                    logger.info(f"âž• Applied additional filters: {len(tour_indices)} tours remain")
                # Continue without filters
        
        # ================== INTELLIGENT RESPONSE GENERATION ==================
        reply = ""
        sources = []
        
        # ðŸ”¹ CASE 0: CONTEXT-AWARE FOLLOW-UP (NÃ¢ng cáº¥p má»›i)
        if len(context.conversation_history) > 1:
            last_user_msg = None
            last_bot_msg = None
            
            # TÃ¬m tin nháº¯n gáº§n nháº¥t
            for msg in reversed(context.conversation_history[:-1]):
                if msg['role'] == 'user':
                    last_user_msg = msg['message']
                elif msg['role'] == 'assistant' and not last_bot_msg:
                    last_bot_msg = msg['message']
                
                if last_user_msg and last_bot_msg:
                    break
            
            # Xá»­ lÃ½ follow-up questions
            if last_bot_msg and ('tour nÃ o' in message_lower or 'gá»£i Ã½' in message_lower):
                # Kiá»ƒm tra náº¿u Ä‘Ã¢y lÃ  cÃ¢u há»i follow-up vá» tour
                follow_up_tours = getattr(context, 'last_recommended_tours', [])
                if follow_up_tours and len(tour_indices) == 0:
                    tour_indices = follow_up_tours[:3]
                    logger.info(f"ðŸ”„ Using context tour recommendations: {tour_indices}")
                    
        
        # ðŸ”¹ CASE 1.1: LOCATION QUERY - Xá»­ lÃ½ cÃ¢u há»i vá» Ä‘á»‹a Ä‘iá»ƒm cá»¥ thá»ƒ
        if 'location_query' in detected_intents:
            logger.info("ðŸ“ Processing location query")
            
            # XÃ¡c Ä‘á»‹nh Ä‘á»‹a Ä‘iá»ƒm Ä‘Æ°á»£c há»i
            locations = ['huáº¿', 'quáº£ng trá»‹', 'báº¡ch mÃ£', 'trÆ°á»ng sÆ¡n', 'Ä‘Ã´ng hÃ ', 'miá»n trung', 'Ä‘Ã  náºµng']
            mentioned_location = None
            
            for loc in locations:
                if loc in message_lower:
                    mentioned_location = loc
                    break
            
            if mentioned_location:
                # TÃ¬m tour táº¡i Ä‘á»‹a Ä‘iá»ƒm nÃ y
                location_tours = []
                for idx, tour in TOURS_DB.items():
                    if tour.location and mentioned_location in tour.location.lower():
                        location_tours.append(tour)
                
                # Apply filters náº¿u cÃ³
                if filter_applied and not mandatory_filters.is_empty():
                    filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                    location_tours = [tour for idx, tour in enumerate(location_tours) if idx in filtered_indices]
                
                if location_tours:
                    reply = f"ðŸ“ **TOUR Táº I {mentioned_location.upper()}** ðŸ“\n\n"
                    
                    # Hiá»ƒn thá»‹ thÃ´ng tin tá»•ng quan
                    reply += f"Ruby Wings cÃ³ {len(location_tours)} tour táº¡i {mentioned_location.upper()}:\n\n"
                    
                    # PhÃ¢n loáº¡i tour táº¡i Ä‘á»‹a Ä‘iá»ƒm nÃ y
                    for i, tour in enumerate(location_tours[:6], 1):
                        reply += f"{i}. **{tour.name}**\n"
                        if tour.duration:
                            reply += f"   â±ï¸ {tour.duration}\n"
                        if tour.summary:
                            summary_short = tour.summary[:80] + "..." if len(tour.summary) > 80 else tour.summary
                            reply += f"   ðŸ“ {summary_short}\n"
                        if i == 1 and tour.price:
                            price_short = tour.price[:60] + "..." if len(tour.price) > 60 else tour.price
                            reply += f"   ðŸ’° {price_short}\n"
                        reply += "\n"
                    
                    # ThÃ´ng tin Ä‘áº·c trÆ°ng cá»§a Ä‘á»‹a Ä‘iá»ƒm
                    if mentioned_location == 'huáº¿':
                        reply += "ðŸ›ï¸ **Äáº¶C TRÆ¯NG HUáº¾:**\n"
                        reply += "â€¢ Di sáº£n UNESCO: Äáº¡i Ná»™i, LÄƒng táº©m\n"
                        reply += "â€¢ áº¨m thá»±c cung Ä‘Ã¬nh Ä‘áº·c sáº¯c\n"
                        reply += "â€¢ SÃ´ng HÆ°Æ¡ng, nÃºi Ngá»± thÆ¡ má»™ng...\n\n"
                    elif mentioned_location == 'báº¡ch mÃ£':
                        reply += "ðŸŒ¿ **Äáº¶C TRÆ¯NG Báº CH MÃƒ:**\n"
                        reply += "â€¢ VÆ°á»n quá»‘c gia rá»™ng 37,000ha\n"
                        reply += "â€¢ KhÃ­ háº­u mÃ¡t máº» quanh nÄƒm\n"
                        reply += "â€¢ Äa dáº¡ng sinh há»c...\n\n"
                    elif mentioned_location == 'trÆ°á»ng sÆ¡n':
                        reply += "ðŸŽ–ï¸ **Äáº¶C TRÆ¯NG TRÆ¯á»œNG SÆ N:**\n"
                        reply += "â€¢ Di tÃ­ch lá»‹ch sá»­ chiáº¿n tranh\n"
                        reply += "â€¢ ÄÆ°á»ng Há»“ ChÃ­ Minh huyá»n thoáº¡i\n"
                        reply += "â€¢ VÄƒn hÃ³a dÃ¢n tá»™c VÃ¢n Kiá»u, Pa KÃ´\n\n"
                    
                    reply += "ðŸ“ž **Äáº·t tour táº¡i Ä‘á»‹a Ä‘iá»ƒm nÃ y:** 0332510486"
                else:
                    reply = f"Hiá»‡n Ruby Wings chÆ°a cÃ³ tour nÃ o táº¡i {mentioned_location.upper()}. Tuy nhiÃªn, chÃºng tÃ´i cÃ³ thá»ƒ thiáº¿t káº¿ tour riÃªng theo yÃªu cáº§u cá»§a báº¡n.\n\n"
                    reply += "ðŸ“ž **LiÃªn há»‡ thiáº¿t káº¿ tour riÃªng:** 0332510486"
            else:
                reply = "Báº¡n muá»‘n tÃ¬m tour táº¡i khu vá»±c nÃ o? Ruby Wings cÃ³ tour táº¡i:\n\n"
                reply += "â€¢ Huáº¿ (di sáº£n, áº©m thá»±c)\n"
                reply += "â€¢ Quáº£ng Trá»‹ (lá»‹ch sá»­, di tÃ­ch)\n"
                reply += "â€¢ Báº¡ch MÃ£ (thiÃªn nhiÃªn, trekking)\n"
                reply += "â€¢ TrÆ°á»ng SÆ¡n (lá»‹ch sá»­, vÄƒn hÃ³a)\n\n"
                reply += "ðŸ“ž **Hotline tÆ° váº¥n Ä‘á»‹a Ä‘iá»ƒm:** 0332510486"
        
        # ðŸ”¹ CASE 2.1: SERVICE INQUIRY - Xá»­ lÃ½ cÃ¢u há»i vá» dá»‹ch vá»¥ bao gá»“m
        elif 'service_inquiry' in detected_intents:
            logger.info("ðŸ›Žï¸ Processing service inquiry")
            
            reply = "ðŸ›Žï¸ **Dá»ŠCH Vá»¤ BAO Gá»’M TRONG TOUR RUBY WINGS** ðŸ›Žï¸\n\n"
            
            # PhÃ¢n loáº¡i dá»‹ch vá»¥
            reply += "âœ… **Dá»ŠCH Vá»¤ CÆ  Báº¢N (cÃ³ trong háº§u háº¿t tour):**\n"
            reply += "â€¢ ðŸšŒ Xe Ä‘Æ°a Ä‘Ã³n Ä‘á»i má»›i, mÃ¡y láº¡nh\n"
            reply += "â€¢ ðŸ¨ Chá»— nghá»‰ ngÆ¡i tiÃªu chuáº©n 3* (khÃ¡ch sáº¡n/homestay)\n"
            reply += "â€¢ ðŸ½ï¸ Ä‚n uá»‘ng theo chÆ°Æ¡ng trÃ¬nh (3 bá»¯a chÃ­nh/ngÃ y)\n"
            reply += "â€¢ ðŸ§­ HÆ°á»›ng dáº«n viÃªn chuyÃªn nghiá»‡p, nhiá»‡t tÃ¬nh\n"
            reply += "â€¢ ðŸŽ« VÃ© tham quan cÃ¡c Ä‘iá»ƒm du lá»‹ch\n"
            reply += "â€¢ ðŸ’§ NÆ°á»›c uá»‘ng suá»‘i Ä‘Ã³ng chai\n"
            reply += "â€¢ ðŸ›¡ï¸ Báº£o hiá»ƒm du lá»‹ch (má»©c Ä‘á»n bÃ¹ tá»« 50 triá»‡u VNÄ)\n\n"
            
            reply += "âœ¨ **Dá»ŠCH Vá»¤ CAO Cáº¤P (tour 2+ ngÃ y):**\n"
            reply += "â€¢ ðŸŒŸ KhÃ¡ch sáº¡n 3-4 sao (tÃ¹y tour)\n"
            reply += "â€¢ ðŸ· Bá»¯a Äƒn Ä‘áº·c sáº£n Ä‘á»‹a phÆ°Æ¡ng\n"
            reply += "â€¢ ðŸŽ¤ HÆ°á»›ng dáº«n viÃªn tiáº¿ng Anh (náº¿u yÃªu cáº§u)\n"
            reply += "â€¢ ðŸ“¸ Chá»¥p áº£nh lÆ°u niá»‡m chuyÃªn nghiá»‡p\n"
            reply += "â€¢ ðŸŽ QuÃ  táº·ng Ä‘áº·c sáº£n Ä‘á»‹a phÆ°Æ¡ng\n"
            reply += "â€¢ ðŸš‘ Phá»¥ trÃ¡ch y táº¿ Ä‘i kÃ¨m (tour nhÃ³m lá»›n vÃ  cÃ³ Cá»±u chiáº¿n binh)\n\n"
            
            reply += "âš ï¸ **Dá»ŠCH Vá»¤ KHÃ”NG BAO Gá»’M:**\n"
            reply += "â€¢ Chi phÃ­ cÃ¡ nhÃ¢n: Giáº·t á»§i, Ä‘iá»‡n thoáº¡i, mini bar\n"
            reply += "â€¢ Äá»“ uá»‘ng cÃ³ cá»“n (bia, rÆ°á»£u, cocktail)\n"
            reply += "â€¢ Tip cho hÆ°á»›ng dáº«n viÃªn vÃ  tÃ i xáº¿\n"
            reply += "â€¢ Chi phÃ­ phÃ¡t sinh do thay Ä‘á»•i lá»‹ch trÃ¬nh\n"
            reply += "â€¢ PhÃ­ tham quan ngoÃ i chÆ°Æ¡ng trÃ¬nh\n\n"
            
            # Ãp dá»¥ng filter náº¿u cÃ³ thÃ´ng tin vá» nhÃ³m/Ä‘á»‘i tÆ°á»£ng
            if mandatory_filters and not mandatory_filters.is_empty():
                if hasattr(mandatory_filters, 'group_type'):
                    if mandatory_filters.group_type == 'family':
                        reply += "ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦ **Dá»ŠCH Vá»¤ Äáº¶C BIá»†T CHO GIA ÄÃŒNH:**\n"
                        reply += "â€¢ PhÃ²ng gia Ä‘Ã¬nh riÃªng biá»‡t\n"
                        reply += "â€¢ Thá»±c Ä‘Æ¡n riÃªng cho tráº» em\n"
                        reply += "â€¢ Hoáº¡t Ä‘á»™ng vui chÆ¡i cho tráº»\n"
                        reply += "â€¢ Tráº» em dÆ°á»›i 4 tuá»•i: Miá»…n phÃ­\n"
                        reply += "â€¢ Tráº» 4 dÆ°á»›i 7 tuá»•i: Giáº£m 50% giÃ¡ tour\n"
                        reply += "â€¢ Tráº» em 8-11 tuá»•i: Giáº£m 15% giÃ¡ tour\n\n"
                    elif mandatory_filters.group_type == 'senior':
                        reply += "ðŸ‘´ **Dá»ŠCH Vá»¤ Äáº¶C BIá»†T CHO NGÆ¯á»œI Lá»šN TUá»”I:**\n"
                        reply += "â€¢ Xe Ä‘Ã³n táº­n nÆ¡i (cÃ³ liÃªn há»‡ trÆ°á»›c)\n"
                        reply += "â€¢ NhÃ¢n viÃªn há»— trá»£ Ä‘áº·c biá»‡t (nhÃ¢n viÃªn y táº¿)\n"
                        reply += "â€¢ Lá»‹ch trÃ¬nh nháº¹ nhÃ ng, khÃ´ng vá»™i\n"
                        reply += "â€¢ KhÃ¡m sá»©c khá»e trÆ°á»›c tour\n"
                        reply += "â€¢ Cá»±u chiáº¿n binh: Æ¯u Ä‘Ã£i Ä‘áº·c biá»‡t\n\n"
            
            reply += "ðŸ“‹ **ÄIá»€U KIá»†N THAM GIA:**\n"
            reply += "â€¢ Sá»©c khá»e tá»‘t, khÃ´ng máº¯c bá»‡nh mÃ£n tÃ­nh\n"
            reply += "â€¢ Tuá»•i tá»« 5-70 (trá»« tour Ä‘áº·c biá»‡t)\n"
            reply += "â€¢ Mang theo giáº¥y tá» tÃ¹y thÃ¢n báº£n gá»‘c\n"
            reply += "â€¢ TuÃ¢n thá»§ hÆ°á»›ng dáº«n cá»§a HDV\n"
            reply += "â€¢ Mua báº£o hiá»ƒm du lá»‹ch (báº¯t buá»™c)\n\n"
            
            reply += "ðŸ“ž **LiÃªn há»‡ Ä‘á»ƒ biáº¿t chi tiáº¿t dá»‹ch vá»¥ tour cá»¥ thá»ƒ:** 0332510486"
        
        # ðŸ”¹ CASE 3: PRICE INQUIRY - NÃ‚NG Cáº¤P (ÃP Dá»¤NG FILTER)
        elif 'price_inquiry' in detected_intents:
            logger.info("ðŸ’° Processing enhanced price inquiry with filters")
            
            # Apply filters náº¿u cÃ³
            if filter_applied and not mandatory_filters.is_empty():
                filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                if filtered_indices:
                    # Sá»­a lá»—i: Ä‘á»•i tá»« tour_indices sang tour_indices
                    if not tour_indices:
                        tour_indices = filtered_indices[:3]
                    else:
                        # Káº¿t há»£p káº¿t quáº£
                        combined = list(set(tour_indices) & set(filtered_indices))
                        tour_indices = combined[:3] if combined else filtered_indices[:3]
            
            if tour_indices:
                # CÃ³ tour cá»¥ thá»ƒ
                detailed_info = []
                
                for idx in tour_indices[:3]:
                    tour = TOURS_DB.get(idx)
                    if tour:
                        # Format price information
                        price_info = {
                            'name': tour.name,
                            'price': tour.price or 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡',
                            'duration': tour.duration or 'KhÃ´ng xÃ¡c Ä‘á»‹nh',
                            'location': tour.location or 'KhÃ´ng xÃ¡c Ä‘á»‹nh'
                        }
                        
                        # PhÃ¢n tÃ­ch giÃ¡ náº¿u cÃ³
                        price_text = price_info['price']
                        if price_text and price_text != 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡':
                            price_numbers = re.findall(r'\d[\d,\.]+', price_text)
                            if price_numbers:
                                try:
                                    clean_nums = []
                                    for num in price_numbers:
                                        clean_num = num.replace(',', '').replace('.', '')
                                        if clean_num.isdigit():
                                            clean_nums.append(int(clean_num))
                                    
                                    if clean_nums:
                                        min_price = min(clean_nums)
                                        max_price = max(clean_nums) if len(clean_nums) > 1 else min_price
                                        
                                        if min_price < 1000000:
                                            price_range = f"{min_price:,}Ä‘"
                                        elif min_price == max_price:
                                            price_range = f"{min_price:,}Ä‘"
                                        else:
                                            price_range = f"{min_price:,}Ä‘ - {max_price:,}Ä‘"
                                        
                                        price_info['formatted'] = price_range
                                except:
                                    price_info['formatted'] = price_text
                        
                        detailed_info.append(price_info)
                
                if detailed_info:
                    reply = "ðŸ’° **THÃ”NG TIN GIÃ TOUR CHI TIáº¾T** ðŸ’°\n\n"
                    
                    for info in detailed_info:
                        reply += f"**{info['name']}**\n"
                        reply += f"â±ï¸ Thá»i gian: {info['duration']}\n"
                        reply += f"ðŸ“ Äá»‹a Ä‘iá»ƒm: {info.get('location_short', info['location'][:50])}\n"
                        
                        if 'formatted' in info:
                            reply += f"ðŸ’° **GiÃ¡:** {info['formatted']}\n"
                        else:
                            reply += f"ðŸ’° **GiÃ¡:** {info['price']}\n"
                        
                        # ThÃªm phÃ¢n loáº¡i giÃ¡
                        if 'formatted' in info and 'Ä‘' in info['formatted']:
                            price_num = int(info['formatted'].split('Ä‘')[0].replace(',', '').replace('.', '').strip())
                            if price_num < 1000000:
                                reply += "   ðŸ·ï¸ PhÃ¢n loáº¡i: Tiáº¿t kiá»‡m\n"
                            elif price_num < 2500000:
                                reply += "   ðŸ·ï¸ PhÃ¢n loáº¡i: TiÃªu chuáº©n\n"
                            else:
                                reply += "   ðŸ·ï¸ PhÃ¢n loáº¡i: Cao cáº¥p\n"
                        
                        reply += "\n"
                    
                    # ThÃªm thÃ´ng tin Æ°u Ä‘Ã£i dá»±a trÃªn filter - Sá»¬A THEO CHÃNH SÃCH Gá»C
                    reply += "ðŸŽ¯ **Æ¯U ÄÃƒI Äáº¶C BIá»†T:**\n"
                    
                    if mandatory_filters and hasattr(mandatory_filters, 'group_type'):
                        if mandatory_filters.group_type == 'family':
                            reply += "â€¢ Gia Ä‘Ã¬nh 4 ngÆ°á»i: Giáº£m 5%\n"
                            reply += "â€¢ Tráº» em 8-11 tuá»•i: Giáº£m 15%\n"
                            reply += "â€¢ Tráº» 4 dÆ°á»›i 7 tuá»•i: Giáº£m 50%\n"
                            reply += "â€¢ Tráº» dÆ°á»›i 4 tuá»•i: Miá»…n phÃ­\n"
                        elif mandatory_filters.group_type == 'senior':
                            reply += "â€¢ NgÆ°á»i lá»›n tuá»•i: Giáº£m 5%\n"
                            reply += "â€¢ Cá»±u chiáº¿n binh: Giáº£m 10%\n"
                            reply += "â€¢ NhÃ³m 5+ ngÆ°á»i cao tuá»•i: Giáº£m thÃªm 5%\n"
                        elif mandatory_filters.group_type == 'friends':
                            reply += "â€¢ NhÃ³m báº¡n 5-9 ngÆ°á»i: Giáº£m 3%\n"
                            reply += "â€¢ NhÃ³m 10-13 ngÆ°á»i: Giáº£m 5%\n"
                            reply += "â€¢ NhÃ³m 14-20 ngÆ°á»i: Giáº£m 8%\n"
                            reply += "â€¢ NhÃ³m 21-27 ngÆ°á»i: Giáº£m 10%\n"
                            reply += "â€¢ NhÃ³m 28-33 ngÆ°á»i: Giáº£m 12%\n"
                            reply += "â€¢ NhÃ³m 34-42 ngÆ°á»i: Giáº£m 15%\n"
                            reply += "â€¢ Sinh viÃªn: Giáº£m thÃªm 5%\n"
                    
                    reply += "â€¢ Äáº·t trÆ°á»›c 30 ngÃ y: Giáº£m thÃªm 5%\n"
                    reply += "â€¢ Thanh toÃ¡n online: Giáº£m thÃªm 2%\n\n"
                    reply += "ðŸ“ž **LiÃªn há»‡ ngay Ä‘á»ƒ nháº­n bÃ¡o giÃ¡ tá»‘t nháº¥t:** 0332510486"
                else:
                    reply = "Hiá»‡n chÆ°a cÃ³ thÃ´ng tin giÃ¡ cho cÃ¡c tour nÃ y. Vui lÃ²ng liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c bÃ¡o giÃ¡ chi tiáº¿t."
            else:
                # KhÃ´ng cÃ³ tour cá»¥ thá»ƒ - Hiá»ƒn thá»‹ báº£ng giÃ¡ tá»•ng quÃ¡t vá»›i filter
                reply = "ðŸ’° **Báº¢NG GIÃ THAM KHáº¢O RUBY WINGS** ðŸ’°\n\n"
                
                # Táº¡o báº£ng giÃ¡ theo loáº¡i tour, cÃ³ xem xÃ©t filter
                price_categories = [
                    ("ðŸŒ¿ TOUR 1 NGÃ€Y (ThiÃªn nhiÃªn, VÄƒn hÃ³a)", "600.000Ä‘ - 1.500.000Ä‘", 
                     "Báº¡ch MÃ£, Huáº¿ city tour, áº¨m thá»±c Huáº¿"),
                    ("ðŸ›ï¸ TOUR 2 NGÃ€Y 1 ÄÃŠM (Lá»‹ch sá»­, Retreat)", "1.500.000Ä‘ - 3.000.000Ä‘", 
                     "TrÆ°á»ng SÆ¡n, Di tÃ­ch lá»‹ch sá»­, Thiá»n Ä‘á»‹nh"),
                    ("ðŸ•‰ï¸ TOUR 3+ NGÃ€Y (Cao cáº¥p, CÃ¡ nhÃ¢n hÃ³a)", "3.000.000Ä‘ - 5.000.000Ä‘", 
                     "Tour riÃªng, NhÃ³m Ä‘áº·c biá»‡t, Retreat sÃ¢u"),
                    ("ðŸ‘¥ TOUR TEAMBUILDING (CÃ´ng ty, NhÃ³m lá»›n)", "LiÃªn há»‡ tÆ° váº¥n", 
                     "Thiáº¿t káº¿ riÃªng, Hoáº¡t Ä‘á»™ng nhÃ³m, Gáº¯n káº¿t")
                ]
                
                for cat_name, price_range, description in price_categories:
                    reply += f"**{cat_name}**\n"
                    reply += f"ðŸ’° {price_range}\n"
                    reply += f"ðŸ“ {description}\n\n"
                
                # ThÃªm thÃ´ng tin Æ°u Ä‘Ã£i theo filter - Sá»¬A THEO CHÃNH SÃCH Gá»C
                if mandatory_filters and hasattr(mandatory_filters, 'group_type'):
                    reply += "ðŸŽ **Æ¯U ÄÃƒI Äáº¶C BIá»†T CHO NHÃ“M:**\n"
                    
                    if mandatory_filters.group_type == 'family':
                        reply += "â€¢ Gia Ä‘Ã¬nh 4 ngÆ°á»i: Giáº£m 5%\n"
                        reply += "â€¢ Tráº» em 8-11 tuá»•i: Giáº£m 15%\n"
                        reply += "â€¢ Tráº» 4 dÆ°á»›i 7 tuá»•i: Giáº£m 50%\n"
                        reply += "â€¢ Tráº» dÆ°á»›i 4 tuá»•i: Miá»…n phÃ­\n"
                    elif mandatory_filters.group_type == 'senior':
                        reply += "â€¢ NgÆ°á»i lá»›n tuá»•i: Giáº£m 5%\n"
                        reply += "â€¢ Cá»±u chiáº¿n binh: Giáº£m 10%\n"
                        reply += "â€¢ NhÃ³m 5+ ngÆ°á»i cao tuá»•i: Giáº£m thÃªm 5%\n"
                    elif mandatory_filters.group_type == 'friends':
                        reply += "â€¢ NhÃ³m báº¡n 5-9 ngÆ°á»i: Giáº£m 3%\n"
                        reply += "â€¢ NhÃ³m 10-13 ngÆ°á»i: Giáº£m 5%\n"
                        reply += "â€¢ NhÃ³m 14-20 ngÆ°á»i: Giáº£m 8%\n"
                        reply += "â€¢ NhÃ³m 21-27 ngÆ°á»i: Giáº£m 10%\n"
                        reply += "â€¢ NhÃ³m 28-33 ngÆ°á»i: Giáº£m 12%\n"
                        reply += "â€¢ NhÃ³m 34-42 ngÆ°á»i: Giáº£m 15%\n"
                        reply += "â€¢ Sinh viÃªn: Giáº£m thÃªm 5%\n"
                    
                    reply += "\n"
                
                reply += "ðŸ“ž **LiÃªn há»‡ tÆ° váº¥n giÃ¡ chÃ­nh xÃ¡c:** 0332510486"
        
        # ðŸ”¹ CASE 4: TOUR LISTING (ÃP Dá»¤NG FILTER Vá»€ LOCATION)
        elif 'tour_listing' in detected_intents:
            logger.info("ðŸ“‹ Processing tour listing request with filters")
            
            all_tours = list(TOURS_DB.values())
            
            # Apply location filter náº¿u cÃ³ trong cÃ¢u há»i
            location_from_query = None
            locations = ['huáº¿', 'quáº£ng trá»‹', 'báº¡ch mÃ£', 'trÆ°á»ng sÆ¡n', 'Ä‘Ã´ng hÃ ', 'miá»n trung', 'Ä‘Ã  náºµng']
            for loc in locations:
                if loc in message_lower:
                    location_from_query = loc
                    break
            
            if location_from_query:
                all_tours = [tour for tour in all_tours if tour.location and location_from_query in tour.location.lower()]
                logger.info(f"ðŸ“ Applied location filter: {location_from_query}")
            
            # Apply mandatory filters
            if filter_applied and not mandatory_filters.is_empty():
                filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                all_tours = [TOURS_DB[idx] for idx in filtered_indices if idx in TOURS_DB]
            
            # Apply deduplication
            if UpgradeFlags.is_enabled("2_DEDUPLICATION") and all_tours:
                seen_names = set()
                unique_tours = []
                for tour in all_tours:
                    name = tour.name
                    if name and name not in seen_names:
                        seen_names.add(name)
                        unique_tours.append(tour)
                all_tours = unique_tours
            
            total_tours = len(all_tours)
            
            if total_tours > 0:
                # PhÃ¢n loáº¡i tour theo category
                categorized_tours = {
                    'history': [],
                    'retreat': [],
                    'nature': [],
                    'culture': [],
                    'family': []
                }
                
                for tour in all_tours:
                    tags_lower = [tag.lower() for tag in (tour.tags or [])]
                    
                    if any('history' in tag for tag in tags_lower):
                        categorized_tours['history'].append(tour)
                    elif any('meditation' in tag or 'retreat' in tag for tag in tags_lower):
                        categorized_tours['retreat'].append(tour)
                    elif any('nature' in tag for tag in tags_lower):
                        categorized_tours['nature'].append(tour)
                    elif any('culture' in tag or 'food' in tag for tag in tags_lower):
                        categorized_tours['culture'].append(tour)
                    elif any('family' in tag for tag in tags_lower):
                        categorized_tours['family'].append(tour)
                    else:
                        categorized_tours['nature'].append(tour)  # Máº·c Ä‘á»‹nh
                
                # Format response cÃ³ cáº¥u trÃºc
                reply = "âœ¨ **DANH SÃCH TOUR RUBY WINGS** âœ¨\n\n"
                
                # Hiá»ƒn thá»‹ filter Ä‘ang Ã¡p dá»¥ng
                if location_from_query or filter_applied:
                    reply += "ðŸ” **ÄANG ÃP Dá»¤NG Bá»˜ Lá»ŒC:**\n"
                    if location_from_query:
                        reply += f"â€¢ Äá»‹a Ä‘iá»ƒm: {location_from_query.upper()}\n"
                    if mandatory_filters and not mandatory_filters.is_empty():
                        reply += f"â€¢ {mandatory_filters}\n"
                    reply += "\n"
                
                reply += f"ðŸ“Š **Tá»•ng cá»™ng:** {total_tours} tour Ä‘áº·c sáº¯c\n\n"
                
                # Hiá»ƒn thá»‹ theo tá»«ng loáº¡i
                categories_display = [
                    ('ðŸ›ï¸ Lá»ŠCH Sá»¬ - TRI Ã‚N', 'history', 'history'),
                    ('ðŸ•‰ï¸ RETREAT - CHá»®A LÃ€NH', 'retreat', 'meditation'),
                    ('ðŸŒ¿ THIÃŠN NHIÃŠN - KHÃM PHÃ', 'nature', 'nature'),
                    ('ðŸœ VÄ‚N HÃ“A - áº¨M THá»°C', 'culture', 'culture'),
                    ('ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦ GIA ÄÃŒNH - NHÃ“M', 'family', 'family')
                ]
                
                tours_displayed = 0
                for cat_name, cat_key, emoji_key in categories_display:
                    cat_tours = categorized_tours[cat_key]
                    if cat_tours:
                        reply += f"**{cat_name}** ({len(cat_tours)} tour)\n"
                        
                        for i, tour in enumerate(cat_tours[:3], 1):
                            # Chá»n emoji phÃ¹ há»£p
                            emoji = "âœ¨"
                            if cat_key == 'history': emoji = "ðŸ›ï¸"
                            elif cat_key == 'retreat': emoji = "ðŸ•‰ï¸"
                            elif cat_key == 'nature': emoji = "ðŸŒ¿"
                            elif cat_key == 'culture': emoji = "ðŸœ"
                            elif cat_key == 'family': emoji = "ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦"
                            
                            reply += f"{emoji} **{tour.name}**\n"
                            if tour.duration:
                                reply += f"   â±ï¸ {tour.duration}\n"
                            if tour.location:
                                location_short = tour.location[:40] + "..." if len(tour.location) > 40 else tour.location
                                reply += f"   ðŸ“ {location_short}\n"
                            if i == 1 and tour.price:  # Hiá»‡n giÃ¡ tour Ä‘áº§u má»—i loáº¡i
                                price_short = tour.price[:60] + "..." if len(tour.price) > 60 else tour.price
                                reply += f"   ðŸ’° {price_short}\n"
                            reply += "\n"
                            tours_displayed += 1
                        
                        if len(cat_tours) > 3:
                            reply += f"   ðŸ“Œ ...vÃ  {len(cat_tours) - 3} tour khÃ¡c\n\n"
                        else:
                            reply += "\n"
                
                if tours_displayed < total_tours:
                    reply += f"ðŸ“Œ **CÃ²n {total_tours - tours_displayed} tour khÃ¡c trong há»‡ thá»‘ng!**\n\n"
                
                # ThÃªm thÃ´ng tin Æ°u Ä‘Ã£i theo filter - Sá»¬A THEO CHÃNH SÃCH Gá»C
                if mandatory_filters and hasattr(mandatory_filters, 'group_type'):
                    reply += "ðŸŽ **Æ¯U ÄÃƒI Äáº¶C BIá»†T CHO NHÃ“M:**\n"
                    
                    if mandatory_filters.group_type == 'family':
                        reply += "â€¢ Gia Ä‘Ã¬nh 4 ngÆ°á»i: Giáº£m 5%\n"
                        reply += "â€¢ Tráº» em 8-11 tuá»•i: Giáº£m 15%\n"
                        reply += "â€¢ Tráº» 4 dÆ°á»›i 7 tuá»•i: Giáº£m 50%\n"
                        reply += "â€¢ Tráº» dÆ°á»›i 4 tuá»•i: Miá»…n phÃ­\n"
                    elif mandatory_filters.group_type == 'senior':
                        reply += "â€¢ NgÆ°á»i lá»›n tuá»•i: Giáº£m 5%\n"
                        reply += "â€¢ Cá»±u chiáº¿n binh: Giáº£m 10%\n"
                        reply += "â€¢ NhÃ³m 5+ ngÆ°á»i cao tuá»•i: Giáº£m thÃªm 5%\n"
                    elif mandatory_filters.group_type == 'friends':
                        reply += "â€¢ NhÃ³m báº¡n 5-9 ngÆ°á»i: Giáº£m 3%\n"
                        reply += "â€¢ NhÃ³m 10-13 ngÆ°á»i: Giáº£m 5%\n"
                        reply += "â€¢ NhÃ³m 14-20 ngÆ°á»i: Giáº£m 8%\n"
                        reply += "â€¢ NhÃ³m 21-27 ngÆ°á»i: Giáº£m 10%\n"
                        reply += "â€¢ NhÃ³m 28-33 ngÆ°á»i: Giáº£m 12%\n"
                        reply += "â€¢ NhÃ³m 34-42 ngÆ°á»i: Giáº£m 15%\n"
                        reply += "â€¢ Sinh viÃªn: Giáº£m thÃªm 5%\n"
                    
                    reply += "\n"
                
                reply += "ðŸ’¡ **HÆ¯á»šNG DáºªN TÃŒM TOUR:**\n"
                reply += "â€¢ Gá»i tÃªn tour cá»¥ thá»ƒ (vÃ­ dá»¥: 'Tour Báº¡ch MÃ£')\n"
                reply += "â€¢ MÃ´ táº£ nhu cáº§u: 'tour gia Ä‘Ã¬nh 2 ngÃ y', 'retreat thiá»n'\n"
                reply += "â€¢ So sÃ¡nh tour: 'so sÃ¡nh tour A vÃ  tour B'\n\n"
                reply += "ðŸ“ž **Hotline tÆ° váº¥n nhanh:** 0332510486"
                
                # LÆ°u context Ä‘á»ƒ follow-up
                context.last_listed_tours = [idx for idx, tour in enumerate(all_tours[:10])]
            else:
                reply = "Hiá»‡n chÆ°a cÃ³ tour nÃ o phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a báº¡n. Vui lÃ²ng thá»­ vá»›i tiÃªu chÃ­ khÃ¡c hoáº·c liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n tour riÃªng."


        # ðŸ”¹ CASE 5: RECOMMENDATION SYSTEM (ÃP Dá»¤NG FILTER Vá»€ NHÃ“M/BUDGET)
        elif 'recommendation' in detected_intents:
            logger.info("ðŸŽ¯ Processing enhanced recommendation request with filters")
            
            # Advanced user profile extraction
            user_profile = {
                'group_type': None,
                'age_group': None,
                'interests': [],
                'budget_range': None,
                'time_constraint': None,
                'preferred_location': None,
                'special_requirements': []
            }
            
            # Extract group type tá»« cÃ¢u há»i hoáº·c tá»« filter
            group_keywords = {
                'family': ['gia Ä‘Ã¬nh', 'con nhá»', 'tráº» em', 'bá»‘ máº¹', 'Ã´ng bÃ ', 'Ä‘a tháº¿ há»‡'],
                'senior': ['ngÆ°á»i lá»›n tuá»•i', 'cao tuá»•i', 'cá»±u chiáº¿n binh', 'veteran', 'Ã´ng bÃ '],
                'friends': ['nhÃ³m báº¡n', 'báº¡n bÃ¨', 'sinh viÃªn', 'báº¡n tráº»', 'thanh niÃªn'],
                'corporate': ['cÃ´ng ty', 'team building', 'doanh nghiá»‡p', 'nhÃ¢n viÃªn', 'Ä‘á»“ng nghiá»‡p'],
                'couple': ['cáº·p Ä‘Ã´i', 'Ä‘Ã´i lá»©a', 'ngÆ°á»i yÃªu', 'tÃ¬nh nhÃ¢n'],
                'solo': ['má»™t mÃ¬nh', 'Ä‘i láº»', 'solo', 'cÃ¡ nhÃ¢n']
            }
            
            for group_type, keywords in group_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    user_profile['group_type'] = group_type
                    break
            
            # Náº¿u khÃ´ng tÃ¬m tháº¥y trong cÃ¢u há»i, kiá»ƒm tra filter
            if not user_profile['group_type'] and mandatory_filters and hasattr(mandatory_filters, 'group_type'):
                user_profile['group_type'] = mandatory_filters.group_type
            
            # Extract budget tá»« cÃ¢u há»i hoáº·c filter
            budget_patterns = [
                r'giÃ¡ ráº»|tiáº¿t kiá»‡m|kinh táº¿|dÆ°á»›i\s+(\d+)',
                r'táº§m trung|trung bÃ¬nh|vá»«a pháº£i|khoáº£ng\s+(\d+)',
                r'cao cáº¥p|sang trá»ng|premium|trÃªn\s+(\d+)'
            ]
            
            for i, pattern in enumerate(budget_patterns):
                if re.search(pattern, message_lower):
                    if i == 0:
                        user_profile['budget_range'] = 'low'
                    elif i == 1:
                        user_profile['budget_range'] = 'medium'
                    else:
                        user_profile['budget_range'] = 'high'
                    break
            
            # Extract interests
            interest_keywords = {
                'history': ['lá»‹ch sá»­', 'di tÃ­ch', 'chiáº¿n tranh', 'tri Ã¢n', 'kÃ½ á»©c', 'cá»•'],
                'nature': ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi', 'cÃ¢y', 'suá»‘i', 'khÃ´ng khÃ­ trong lÃ nh'],
                'meditation': ['thiá»n', 'yoga', 'tÄ©nh tÃ¢m', 'chá»¯a lÃ nh', 'retreat', 'khÃ­ cÃ´ng'],
                'culture': ['vÄƒn hÃ³a', 'truyá»n thá»‘ng', 'áº©m thá»±c', 'Ä‘áº·c sáº£n', 'phong tá»¥c'],
                'adventure': ['phiÃªu lÆ°u', 'máº¡o hiá»ƒm', 'khÃ¡m phÃ¡', 'tráº£i nghiá»‡m má»›i'],
                'relaxation': ['nghá»‰ ngÆ¡i', 'thÆ° giÃ£n', 'nháº¹ nhÃ ng', 'khÃ´ng vá»™i', 'cháº­m rÃ£i']
            }
            
            for interest, keywords in interest_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    if interest not in user_profile['interests']:
                        user_profile['interests'].append(interest)
            
            # Extract location preference
            locations = ['huáº¿', 'quáº£ng trá»‹', 'báº¡ch mÃ£', 'trÆ°á»ng sÆ¡n', 'Ä‘Ã´ng hÃ ', 'miá»n trung']
            for loc in locations:
                if loc in message_lower:
                    user_profile['preferred_location'] = loc
                    break
            
            logger.info(f"ðŸŽ¯ User profile extracted: {user_profile}")
            
            # SCORING SYSTEM vá»›i filter
            matching_tours = []
            
            for idx, tour in TOURS_DB.items():
                score = 0
                reasons = []
                match_details = {}
                
                # 1. Group type matching (30%)
                if user_profile['group_type']:
                    tour_tags = [tag.lower() for tag in (tour.tags or [])]
                    
                    if user_profile['group_type'] == 'family':
                        if any('family' in tag for tag in tour_tags):
                            score += 30
                            reasons.append("phÃ¹ há»£p gia Ä‘Ã¬nh")
                            match_details['group'] = 'excellent'
                        elif not any('adventure' in tag or 'extreme' in tag for tag in tour_tags):
                            score += 15
                            reasons.append("cÃ³ thá»ƒ phÃ¹ há»£p gia Ä‘Ã¬nh")
                            match_details['group'] = 'good'
                    
                    elif user_profile['group_type'] == 'senior':
                        if any('senior' in tag or 'accessible' in tag for tag in tour_tags):
                            score += 30
                            reasons.append("thiáº¿t káº¿ cho ngÆ°á»i lá»›n tuá»•i")
                            match_details['group'] = 'excellent'
                        elif any('nature' in tag or 'meditation' in tag for tag in tour_tags):
                            score += 20
                            reasons.append("nháº¹ nhÃ ng, phÃ¹ há»£p lá»›n tuá»•i")
                            match_details['group'] = 'good'
                    
                    elif user_profile['group_type'] == 'friends':
                        if any('friends' in tag or 'group' in tag for tag in tour_tags):
                            score += 30
                            reasons.append("phÃ¹ há»£p nhÃ³m báº¡n")
                            match_details['group'] = 'excellent'
                        elif any('adventure' in tag or 'experience' in tag for tag in tour_tags):
                            score += 20
                            reasons.append("nhiá»u hoáº¡t Ä‘á»™ng nhÃ³m")
                            match_details['group'] = 'good'
                
                # 2. Interest matching (40%)
                if user_profile['interests']:
                    tour_summary = (tour.summary or '').lower()
                    tour_tags = [tag.lower() for tag in (tour.tags or [])]
                    
                    for interest in user_profile['interests']:
                        if interest == 'history':
                            if any('history' in tag for tag in tour_tags) or 'lá»‹ch sá»­' in tour_summary:
                                score += 40
                                reasons.append("trá»ng tÃ¢m lá»‹ch sá»­")
                                match_details['interest'] = 'history'
                                break
                        
                        elif interest == 'nature':
                            if any('nature' in tag for tag in tour_tags) or 'thiÃªn nhiÃªn' in tour_summary:
                                score += 40
                                reasons.append("tráº£i nghiá»‡m thiÃªn nhiÃªn")
                                match_details['interest'] = 'nature'
                                break
                        
                        elif interest == 'meditation':
                            if any('meditation' in tag for tag in tour_tags) or 'thiá»n' in tour_summary:
                                score += 40
                                reasons.append("cÃ³ hoáº¡t Ä‘á»™ng thiá»n/retreat")
                                match_details['interest'] = 'meditation'
                                break
                        
                        elif interest == 'culture':
                            if any('culture' in tag for tag in tour_tags) or 'vÄƒn hÃ³a' in tour_summary:
                                score += 40
                                reasons.append("khÃ¡m phÃ¡ vÄƒn hÃ³a")
                                match_details['interest'] = 'culture'
                                break
                
                # 3. Budget matching (15%)
                if user_profile['budget_range'] and tour.price:
                    price_value = _extract_price_value(tour.price)
                    
                    if price_value:
                        if user_profile['budget_range'] == 'low' and price_value < 1500000:
                            score += 15
                            reasons.append("giÃ¡ há»£p lÃ½")
                            match_details['budget'] = 'good'
                        elif user_profile['budget_range'] == 'medium' and 1500000 <= price_value <= 3000000:
                            score += 15
                            reasons.append("giÃ¡ táº§m trung")
                            match_details['budget'] = 'good'
                        elif user_profile['budget_range'] == 'high' and price_value > 3000000:
                            score += 15
                            reasons.append("dá»‹ch vá»¥ cao cáº¥p")
                            match_details['budget'] = 'good'
                
                # 4. Time constraint matching (10%)
                if user_profile['time_constraint'] and tour.duration:
                    duration_lower = tour.duration.lower()
                    
                    if user_profile['time_constraint'] == '1day' and '1 ngÃ y' in duration_lower:
                        score += 10
                        reasons.append("Ä‘Ãºng 1 ngÃ y")
                        match_details['time'] = 'perfect'
                    elif user_profile['time_constraint'] == '2days' and '2 ngÃ y' in duration_lower:
                        score += 10
                        reasons.append("Ä‘Ãºng 2 ngÃ y")
                        match_details['time'] = 'perfect'
                    elif user_profile['time_constraint'] == '3+days' and ('3 ngÃ y' in duration_lower or '4 ngÃ y' in duration_lower):
                        score += 10
                        reasons.append("Ä‘a ngÃ y nhÆ° yÃªu cáº§u")
                        match_details['time'] = 'perfect'
                
                # 5. Location preference (5%)
                if user_profile['preferred_location'] and tour.location:
                    if user_profile['preferred_location'] in tour.location.lower():
                        score += 5
                        reasons.append(f"táº¡i {user_profile['preferred_location']}")
                        match_details['location'] = 'exact'
                
                if score > 0:
                    matching_tours.append((idx, score, reasons, match_details))
            
            # Sáº¯p xáº¿p theo Ä‘iá»ƒm
            matching_tours.sort(key=lambda x: x[1], reverse=True)
            
            # Ãp dá»¥ng thÃªm filter náº¿u cÃ³
            if filter_applied and not mandatory_filters.is_empty():
                filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                matching_tours = [t for t in matching_tours if t[0] in filtered_indices]
            
            # ================== GENERATE RECOMMENDATION RESPONSE ==================
            if matching_tours:
                # LÆ°u recommendations vÃ o context
                context.last_recommended_tours = [idx for idx, _, _, _ in matching_tours]
                
                # PhÃ¢n loáº¡i recommendations
                excellent_matches = [t for t in matching_tours if t[1] >= 60]
                good_matches = [t for t in matching_tours if 30 <= t[1] < 60]
                
                reply = "ðŸŽ¯ **Äá»€ XUáº¤T TOUR THÃ”NG MINH** ðŸŽ¯\n\n"
                
                # Hiá»ƒn thá»‹ thÃ´ng tin user profile
                reply += "ðŸ“‹ **Dá»°A TRÃŠN YÃŠU Cáº¦U Cá»¦A Báº N:**\n"
                
                if user_profile['group_type']:
                    group_names = {
                        'family': 'Gia Ä‘Ã¬nh',
                        'senior': 'NgÆ°á»i lá»›n tuá»•i/Cá»±u chiáº¿n binh',
                        'friends': 'NhÃ³m báº¡n',
                        'corporate': 'CÃ´ng ty/Team building',
                        'couple': 'Cáº·p Ä‘Ã´i',
                        'solo': 'Äi má»™t mÃ¬nh'
                    }
                    reply += f"â€¢ **Äá»‘i tÆ°á»£ng:** {group_names.get(user_profile['group_type'], user_profile['group_type'])}\n"
                
                if user_profile['interests']:
                    interest_names = {
                        'history': 'Lá»‹ch sá»­',
                        'nature': 'ThiÃªn nhiÃªn',
                        'meditation': 'Thiá»n/Retreat',
                        'culture': 'VÄƒn hÃ³a/áº¨m thá»±c',
                        'adventure': 'PhiÃªu lÆ°u',
                        'relaxation': 'ThÆ° giÃ£n'
                    }
                    interests_str = ', '.join([interest_names.get(i, i) for i in user_profile['interests'][:3]])
                    reply += f"â€¢ **Sá»Ÿ thÃ­ch:** {interests_str}\n"
                
                if user_profile['budget_range']:
                    budget_names = {
                        'low': 'Tiáº¿t kiá»‡m (dÆ°á»›i 1.5 triá»‡u)',
                        'medium': 'Táº§m trung (1.5-3 triá»‡u)',
                        'high': 'Cao cáº¥p (trÃªn 3 triá»‡u)'
                    }
                    reply += f"â€¢ **NgÃ¢n sÃ¡ch:** {budget_names.get(user_profile['budget_range'], 'KhÃ´ng xÃ¡c Ä‘á»‹nh')}\n"
                
                if filter_applied and mandatory_filters:
                    reply += f"â€¢ **Bá»™ lá»c Ã¡p dá»¥ng:** {mandatory_filters}\n"
                
                reply += "\n"
                
                # Top recommendations (xuáº¥t sáº¯c)
                if excellent_matches:
                    reply += "ðŸ† **PHÃ™ Há»¢P NHáº¤T Vá»šI Báº N**\n\n"
                    
                    for idx, score, reasons, details in excellent_matches[:2]:
                        tour = TOURS_DB.get(idx)
                        if tour:
                            # TÃ­nh pháº§n trÄƒm phÃ¹ há»£p
                            match_percent = min(100, int(score))
                            
                            reply += f"**{tour.name}** ({match_percent}% phÃ¹ há»£p)\n"
                            reply += f"âœ… **LÃ½ do Ä‘á» xuáº¥t:** {', '.join(reasons[:3])}\n"
                            
                            if tour.duration:
                                reply += f"â±ï¸ **Thá»i gian:** {tour.duration}\n"
                            if tour.location:
                                location_short = tour.location[:50] + "..." if len(tour.location) > 50 else tour.location
                                reply += f"ðŸ“ **Äá»‹a Ä‘iá»ƒm:** {location_short}\n"
                            if tour.price:
                                price_short = tour.price[:80] + "..." if len(tour.price) > 80 else tour.price
                                reply += f"ðŸ’° **GiÃ¡:** {price_short}\n"
                            
                            reply += "\n"
                
                # Good recommendations
                if good_matches and (not excellent_matches or len(excellent_matches) < 2):
                    reply += "ðŸ¥ˆ **Lá»°A CHá»ŒN Tá»T KHÃC**\n\n"
                    
                    display_count = min(2, len(good_matches))
                    for idx, score, reasons, details in good_matches[:display_count]:
                        tour = TOURS_DB.get(idx)
                        if tour:
                            match_percent = min(100, int(score))
                            reply += f"â€¢ **{tour.name}** ({match_percent}%)\n"
                            
                            if tour.duration:
                                reply += f"  â±ï¸ {tour.duration}"
                            if tour.location:
                                loc_short = tour.location[:30] + "..." if len(tour.location) > 30 else tour.location
                                reply += f" | ðŸ“ {loc_short}"
                            reply += "\n"
                
                reply += "\nðŸ“ž **LiÃªn há»‡ Ä‘á»ƒ Ä‘áº·t tour phÃ¹ há»£p nháº¥t:** 0332510486"
                
                # LÆ°u user profile vÃ o context
                context.user_profile.update(user_profile)
            else:
                reply = "Hiá»‡n chÆ°a cÃ³ tour nÃ o phÃ¹ há»£p vá»›i tiÃªu chÃ­ cá»§a báº¡n. Vui lÃ²ng thá»­ vá»›i tiÃªu chÃ­ khÃ¡c hoáº·c liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n tour riÃªng."
        
        # ðŸ”¹ CASE 6: COMPARISON (giá»¯ nguyÃªn logic cÅ©)
        elif 'comparison' in detected_intents:
            # ... (giá»¯ nguyÃªn code comparison tá»« phiÃªn báº£n cÅ©) ...
            # Do giá»›i háº¡n Ä‘á»™ dÃ i, tÃ´i giá»¯ nguyÃªn logic so sÃ¡nh tá»« code gá»‘c
            # Báº¡n cÃ³ thá»ƒ copy nguyÃªn pháº§n nÃ y tá»« phiÃªn báº£n trÆ°á»›c
            reply = _handle_comparison_case(message_lower, tour_indices, TOURS_DB, TOUR_NAME_TO_INDEX)
        
        # ðŸ”¹ CASE 7-12: CÃC CASE KHÃC (giá»¯ nguyÃªn)
        # ðŸ”¹ CASE 7: EXPERIENCE INQUIRY (THÃŠM Má»šI)
        elif 'experience' in detected_intents:
            logger.info("ðŸŒŸ Processing enhanced experience inquiry")
            
            # Táº¡o context_info cho prompt
            context_info = {
                'user_message': user_message,
                'tour_indices': tour_indices,
                'detected_intents': detected_intents,
                'primary_intent': primary_intent,
                'complexity_score': complexity_score
            }
            
            # Gá»i hÃ m experience response má»›i
            reply = _get_experience_response_v4(
                message_lower, 
                tour_indices, 
                TOURS_DB,
                getattr(context, 'user_profile', None)
            )
        # ðŸ”¹ CASE 8: GROUP & CUSTOM TOUR (THÃŠM Má»šI)
        elif 'group_custom' in detected_intents:
            logger.info("ðŸ‘¥ Processing enhanced group & custom tour request")
            
            # Táº¡o context_info cho prompt
            context_info = {
                'user_message': user_message,
                'tour_indices': tour_indices,
                'detected_intents': detected_intents,
                'primary_intent': primary_intent,
                'complexity_score': complexity_score
            }
            
            # Gá»i hÃ m group custom response má»›i
            reply = _get_group_custom_response_v4(
                message_lower,
                tour_indices,
                TOURS_DB,
                mandatory_filters
            )
        
        # ðŸ”¹ CASE 9: BOOKING & POLICY (THÃŠM Má»šI)
        elif 'booking_policy' in detected_intents:
            logger.info("ðŸ“‹ Processing enhanced booking & policy inquiry")
            
            # Táº¡o context_info cho prompt
            context_info = {
                'user_message': user_message,
                'tour_indices': tour_indices,
                'detected_intents': detected_intents,
                'primary_intent': primary_intent,
                'complexity_score': complexity_score,
                'user_profile': getattr(context, 'user_profile', {}),
                'sentiment': sentiment_type,
                'urgency': priority_level
            }
            
            # Gá»i hÃ m booking policy response má»›i
            reply = _get_booking_policy_response_v4(
                message_lower,
                tour_indices,
                TOURS_DB,
                context_info
            )
        # ... (cÃ¡c case khÃ¡c giá»¯ nguyÃªn logic) ...
        
        # ðŸ”¹ CASE 13: FALLBACK TO AI
        else:
            logger.info("ðŸ¤– Processing with AI fallback")
            
            # Chuáº©n bá»‹ context
            context_info = {
                'user_message': user_message,
                'tour_indices': tour_indices,
                'detected_intents': detected_intents,
                'primary_intent': primary_intent,
                'filters': mandatory_filters.to_dict() if mandatory_filters else {},
                'complexity_score': complexity_score
            }
            
            # Táº¡o prompt
            prompt = _prepare_enhanced_llm_prompt(user_message, [], context_info, TOURS_DB)
            
            # Gá»i AI náº¿u cÃ³
            if client and HAS_OPENAI:
                try:
                    messages = [
                        {"role": "system", "content": prompt},
                        {"role": "user", "content": user_message}
                    ]
                    
                    response = client.chat.completions.create(
                        model=CHAT_MODEL,
                        messages=messages,
                        temperature=0.6,
                        max_tokens=600
                    )
                    
                    if response.choices:
                        reply = response.choices[0].message.content or ""
                    else:
                        reply = _generate_enhanced_fallback_response(user_message, [], tour_indices, TOURS_DB)
                
                except Exception as e:
                    logger.error(f"OpenAI error: {e}")
                    reply = _generate_enhanced_fallback_response(user_message, [], tour_indices, TOURS_DB)
            else:
                reply = _generate_enhanced_fallback_response(user_message, [], tour_indices, TOURS_DB)
                
        # ðŸ”¹ CASE 16: FALLBACK TO AI
      
            logger.info("ðŸ¤– Processing with AI fallback")
            
            # Chuáº©n bá»‹ context
            context_info = {
                'user_message': user_message,
                'tour_indices': tour_indices,
                'detected_intents': detected_intents,
                'primary_intent': primary_intent,
                'filters': mandatory_filters.to_dict() if mandatory_filters else {},
                'complexity_score': complexity_score,
                'sentiment': sentiment_type,
                'urgency': priority_level,
                'audience_type': audience_type
            }
            
            # Táº¡o prompt
            prompt = _prepare_enhanced_llm_prompt(user_message, [], context_info, TOURS_DB)
            
            # Gá»i AI náº¿u cÃ³
            if client and HAS_OPENAI:
                try:
                    messages = [
                        {"role": "system", "content": prompt},
                        {"role": "user", "content": user_message}
                    ]
                    
                    response = client.chat.completions.create(
                        model=CHAT_MODEL,
                        messages=messages,
                        temperature=0.6,
                        max_tokens=600
                    )
                    
                    if response.choices:
                        reply = response.choices[0].message.content or ""
                    else:
                        reply = _generate_enhanced_fallback_response(user_message, [], tour_indices, TOURS_DB)
                
                except Exception as e:
                    logger.error(f"OpenAI error: {e}")
                    reply = _generate_enhanced_fallback_response(user_message, [], tour_indices, TOURS_DB)
            else:
                reply = _generate_enhanced_fallback_response(user_message, [], tour_indices, TOURS_DB) 

        # ðŸ”¹ CASE 17: WEATHER INFO (THÃŠM Má»šI)
            if 'weather_info' in detected_intents:
                logger.info("ðŸŒ¤ï¸ Processing weather information request")
                
                # XÃ¡c Ä‘á»‹nh Ä‘á»‹a Ä‘iá»ƒm Ä‘Æ°á»£c há»i
                locations = ['huáº¿', 'quáº£ng trá»‹', 'báº¡ch mÃ£', 'trÆ°á»ng sÆ¡n', 'Ä‘Ã´ng hÃ ', 'miá»n trung', 'Ä‘Ã  náºµng']
                mentioned_location = None
                
                for loc in locations:
                    if loc in message_lower:
                        mentioned_location = loc
                        break
                
                # TÃ¬m tour táº¡i Ä‘á»‹a Ä‘iá»ƒm nÃ y náº¿u cÃ³
                location_tours = []
                if mentioned_location:
                    for idx, tour in TOURS_DB.items():
                        if tour.location and mentioned_location in tour.location.lower():
                            location_tours.append(tour)
                
                # Apply filters náº¿u cÃ³
                if filter_applied and not mandatory_filters.is_empty():
                    filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                    location_tours = [tour for idx, tour in enumerate(location_tours) if idx in filtered_indices]
                
                # Gá»i hÃ m weather info
                reply = _get_weather_info(mentioned_location or 'miá»n trung', location_tours)    
                    # ðŸ”¹ CASE 18: FOOD INFORMATION (THÃŠM Má»šI)
        if 'food_info' in detected_intents:
            logger.info("ðŸœ Processing food information request")
            
            # XÃ¡c Ä‘á»‹nh loáº¡i áº©m thá»±c Ä‘Æ°á»£c há»i
            food_keywords = {
                'bÃ¡nh bÃ¨o': ['bÃ¡nh bÃ¨o', 'banh beo'],
                'bÃºn bÃ²': ['bÃºn bÃ²', 'bun bo', 'bÃºn bÃ² huáº¿', 'bun bo hue'],
                'cÆ¡m háº¿n': ['cÆ¡m háº¿n', 'com hen'],
                'máº¯m nÃªm': ['máº¯m nÃªm', 'mam nem'],
                'áº©m thá»±c huáº¿': ['áº©m thá»±c huáº¿', 'am thuc hue', 'Ä‘áº·c sáº£n huáº¿'],
                'áº©m thá»±c miá»n trung': ['áº©m thá»±c miá»n trung', 'am thuc mien trung']
            }
            
            mentioned_food = None
            for food, keywords in food_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    mentioned_food = food
                    break
            
            # TÃ¬m tour liÃªn quan Ä‘áº¿n áº©m thá»±c
            food_tours = []
            for idx, tour in TOURS_DB.items():
                tour_summary = (tour.summary or '').lower()
                tour_tags = [tag.lower() for tag in (tour.tags or [])]
                
                # Kiá»ƒm tra náº¿u tour cÃ³ liÃªn quan Ä‘áº¿n áº©m thá»±c
                if any(word in tour_summary for word in ['áº©m thá»±c', 'Ä‘á»“ Äƒn', 'mÃ³n Äƒn', 'Ä‘áº·c sáº£n', 'food']) or \
                   any(tag in ['áº©m thá»±c', 'food'] for tag in tour_tags):
                    food_tours.append(tour)
            
            # Apply filters náº¿u cÃ³
            if filter_applied and not mandatory_filters.is_empty():
                filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                food_tours = [tour for idx, tour in enumerate(food_tours) if idx in filtered_indices]
            
            # Gá»i hÃ m food info
            reply = _get_food_info(mentioned_food, food_tours)    
        
       # ================== ENHANCE RESPONSE QUALITY V2 ==================
        
        # 1. ENHANCED FORMATTING & EMOJI OPTIMIZATION
        def enhance_response_format(text):
            """Cáº£i thiá»‡n Ä‘á»‹nh dáº¡ng response vá»›i emoji vÃ  formatting thÃ´ng minh"""
            if not text:
                return text
            
            lines = text.split('\n')
            enhanced_lines = []
            
            for i, line in enumerate(lines):
                stripped_line = line.strip()
                
                # Skip empty lines
                if not stripped_line:
                    enhanced_lines.append(line)
                    continue
                
                # TiÃªu Ä‘á» cáº¥p 1 (##)
                if line.startswith('## '):
                    # ThÃªm emoji Ä‘áº·c biá»‡t cho tiÃªu Ä‘á» chÃ­nh
                    title_text = line[3:].strip()
                    if not any(emoji in title_text for emoji in ['âœ¨', 'ðŸŽ¯', 'ðŸ“', 'ðŸ’°', 'ðŸ›Žï¸', 'ðŸŒ¿', 'ðŸ›ï¸', 'ðŸ•‰ï¸']):
                        if 'Dá»ŠCH Vá»¤' in title_text:
                            line = f"## ðŸ›Žï¸ {title_text} ðŸ›Žï¸"
                        elif 'GIÃ' in title_text or 'Báº¢NG GIÃ' in title_text:
                            line = f"## ðŸ’° {title_text} ðŸ’°"
                        elif 'TOUR' in title_text or 'HÃ€NH TRÃŒNH' in title_text:
                            line = f"## ðŸ—ºï¸ {title_text} ðŸ—ºï¸"
                        elif 'Æ¯U ÄÃƒI' in title_text or 'KHUYáº¾N MÃƒI' in title_text:
                            line = f"## ðŸŽ {title_text} ðŸŽ"
                        elif 'TRIáº¾T LÃ' in title_text or 'GIá»šI THIá»†U' in title_text:
                            line = f"## âœ¨ {title_text} âœ¨"
                        elif 'THá»œI TIáº¾T' in title_text:
                            line = f"## ðŸŒ¤ï¸ {title_text} ðŸŒ¤ï¸"
                        elif 'áº¨M THá»°C' in title_text:
                            line = f"## ðŸœ {title_text} ðŸœ"
                        elif 'VÄ‚N HÃ“A' in title_text or 'Lá»ŠCH Sá»¬' in title_text:
                            line = f"## ðŸ›ï¸ {title_text} ðŸ›ï¸"
                
                # TiÃªu Ä‘á» cáº¥p 2 (### hoáº·c **)
                elif line.startswith('### ') or (line.startswith('**') and line.endswith('**')):
                    if line.startswith('### '):
                        title_text = line[4:].strip()
                    else:
                        title_text = line[2:-2].strip()
                    
                    # ThÃªm emoji cho tiÃªu Ä‘á» phá»¥ náº¿u chÆ°a cÃ³
                    if not any(emoji in title_text for emoji in ['â€¢', 'âœ…', 'âŒ', 'âš ï¸', 'ðŸ“Œ']):
                        if any(word in title_text.lower() for word in ['dá»‹ch vá»¥ bao gá»“m', 'cÃ³ gÃ¬', 'bao gá»“m']):
                            line = f"### âœ… {title_text}"
                        elif any(word in title_text.lower() for word in ['khÃ´ng bao gá»“m', 'khÃ´ng cÃ³', 'chÆ°a bao gá»“m']):
                            line = f"### âŒ {title_text}"
                        elif any(word in title_text.lower() for word in ['lÆ°u Ã½', 'chÃº Ã½', 'quan trá»ng']):
                            line = f"### âš ï¸ {title_text}"
                        elif any(word in title_text.lower() for word in ['Æ°u Ä‘Ã£i', 'giáº£m giÃ¡', 'khuyáº¿n mÃ£i']):
                            line = f"### ðŸŽ¯ {title_text}"
                        elif any(word in title_text.lower() for word in ['Ä‘á»‹a Ä‘iá»ƒm', 'nÆ¡i Ä‘áº¿n', 'vá»‹ trÃ­']):
                            line = f"### ðŸ“ {title_text}"
                        elif any(word in title_text.lower() for word in ['thá»i gian', 'lá»‹ch trÃ¬nh', 'ngÃ y']):
                            line = f"### â±ï¸ {title_text}"
                
                # Bullet points (â€¢)
                elif 'â€¢' in line:
                    # ThÃªm emoji cho bullet points dá»±a trÃªn ná»™i dung
                    if 'giáº£m' in line.lower() and 'ðŸ’°' not in line and 'ðŸŽ¯' not in line:
                        line = line.replace('â€¢', 'ðŸ’° â€¢', 1)
                    elif any(word in line.lower() for word in ['tour', 'tour', 'chÆ°Æ¡ng trÃ¬nh']):
                        line = line.replace('â€¢', 'ðŸ—ºï¸ â€¢', 1)
                    elif any(word in line.lower() for word in ['hotline', 'liÃªn há»‡', 'Ä‘iá»‡n thoáº¡i', '0332510486']):
                        line = line.replace('â€¢', 'ðŸ“ž â€¢', 1)
                    elif any(word in line.lower() for word in ['Ä‘á»‹a Ä‘iá»ƒm', 'nÆ¡i', 'vá»‹ trÃ­', 'Ä‘áº¿n']):
                        line = line.replace('â€¢', 'ðŸ“ â€¢', 1)
                    elif any(word in line.lower() for word in ['thá»i gian', 'ngÃ y', 'Ä‘Ãªm', 'giá»']):
                        line = line.replace('â€¢', 'â±ï¸ â€¢', 1)
                    elif any(word in line.lower() for word in ['Æ°u Ä‘Ã£i', 'khuyáº¿n mÃ£i', 'táº·ng']):
                        line = line.replace('â€¢', 'ðŸŽ â€¢', 1)
                    elif any(word in line.lower() for word in ['lÆ°u Ã½', 'chÃº Ã½', 'cáº£nh bÃ¡o']):
                        line = line.replace('â€¢', 'âš ï¸ â€¢', 1)
                    elif any(word in line.lower() for word in ['bao gá»“m', 'cÃ³ sáºµn', 'cung cáº¥p']):
                        line = line.replace('â€¢', 'âœ… â€¢', 1)
                    elif any(word in line.lower() for word in ['khÃ´ng bao gá»“m', 'chÆ°a bao gá»“m', 'tÃ­nh thÃªm']):
                        line = line.replace('â€¢', 'âŒ â€¢', 1)
                    elif 'miá»…n phÃ­' in line.lower():
                        line = line.replace('â€¢', 'ðŸŽ‰ â€¢', 1)
                    elif any(word in line.lower() for word in ['tráº» em', 'tráº»', 'con nhá»']):
                        line = line.replace('â€¢', 'ðŸ‘¶ â€¢', 1)
                    elif any(word in line.lower() for word in ['ngÆ°á»i lá»›n tuá»•i', 'cá»±u chiáº¿n binh', 'cao tuá»•i']):
                        line = line.replace('â€¢', 'ðŸ‘´ â€¢', 1)
                    elif any(word in line.lower() for word in ['gia Ä‘Ã¬nh', 'bá»‘ máº¹', 'Ã´ng bÃ ']):
                        line = line.replace('â€¢', 'ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦ â€¢', 1)
                    elif any(word in line.lower() for word in ['báº¡n bÃ¨', 'nhÃ³m báº¡n', 'sinh viÃªn']):
                        line = line.replace('â€¢', 'ðŸ‘¥ â€¢', 1)
                    elif any(word in line.lower() for word in ['cÃ´ng ty', 'team building', 'doanh nghiá»‡p']):
                        line = line.replace('â€¢', 'ðŸ¢ â€¢', 1)
                
                # ThÃªm spacing thÃ´ng minh
                if i > 0 and len(lines) > i + 1:
                    prev_line = lines[i-1].strip()
                    next_line = lines[i+1].strip()
                    
                    # ThÃªm dÃ²ng trá»‘ng trÆ°á»›c tiÃªu Ä‘á»
                    if line.startswith(('## ', '### ', '**')) and prev_line and not prev_line.startswith(('## ', '### ', '**')):
                        if not enhanced_lines or enhanced_lines[-1].strip() != "":
                            enhanced_lines.append("")
                    
                    # ThÃªm dÃ²ng trá»‘ng sau tiÃªu Ä‘á» náº¿u cáº§n
                    if line.startswith(('## ', '### ', '**')) and next_line and not next_line.startswith(('## ', '### ', '**')):
                        enhanced_lines.append(line)
                        enhanced_lines.append("")
                        continue
                
                enhanced_lines.append(line)
            
            # Loáº¡i bá» dÃ²ng trá»‘ng thá»«a á»Ÿ Ä‘áº§u/cuá»‘i
            while enhanced_lines and not enhanced_lines[0].strip():
                enhanced_lines.pop(0)
            while enhanced_lines and not enhanced_lines[-1].strip():
                enhanced_lines.pop()
            
            return '\n'.join(enhanced_lines)
        
        # 2. SMART LENGTH LIMITING
        def smart_truncate(text, max_length=2500):
            """Cáº¯t text thÃ´ng minh khÃ´ng lÃ m máº¥t Ã½ chÃ­nh"""
            if len(text) <= max_length:
                return text
            
            logger.info(f"ðŸ“ Response too long: {len(text)} chars, truncating to {max_length}")
            
            # TÃ¬m vá»‹ trÃ­ cáº¯t tá»‘t nháº¥t
            cut_positions = []
            
            # Æ¯u tiÃªn 1: Cáº¯t á»Ÿ cuá»‘i Ä‘oáº¡n (2 dÃ²ng trá»‘ng liÃªn tiáº¿p)
            double_newline_pos = text.rfind('\n\n', 0, max_length)
            if double_newline_pos != -1:
                cut_positions.append((double_newline_pos, 'paragraph_end'))
            
            # Æ¯u tiÃªn 2: Cáº¯t á»Ÿ cuá»‘i bullet list
            bullet_end_patterns = ['\n\n## ', '\n\n### ', '\n\n**']
            for pattern in bullet_end_patterns:
                pos = text.rfind(pattern, 0, max_length)
                if pos != -1:
                    cut_positions.append((pos, 'section_end'))
            
            # Æ¯u tiÃªn 3: Cáº¯t á»Ÿ cuá»‘i cÃ¢u
            sentence_enders = ['. ', '! ', '? ', '.\n', '!\n', '?\n']
            for ender in sentence_enders:
                pos = text.rfind(ender, 0, max_length - 100)  # Äá»ƒ chá»— cho thÃ´ng bÃ¡o
                if pos != -1:
                    cut_positions.append((pos + len(ender) - 1, 'sentence_end'))
            
            # Æ¯u tiÃªn 4: Cáº¯t á»Ÿ dÃ²ng má»›i
            newline_pos = text.rfind('\n', 0, max_length - 50)
            if newline_pos != -1:
                cut_positions.append((newline_pos, 'line_end'))
            
            # Chá»n vá»‹ trÃ­ cáº¯t tá»‘t nháº¥t
            if cut_positions:
                cut_positions.sort(key=lambda x: x[0], reverse=True)
                best_cut_pos = cut_positions[0][0]
                cut_type = cut_positions[0][1]
            else:
                best_cut_pos = max_length - 200
                cut_type = 'forced'
            
            # Äáº£m báº£o khÃ´ng cáº¯t giá»¯a emoji hoáº·c Ä‘á»‹nh dáº¡ng markdown
            truncated = text[:best_cut_pos]
            
            # Loáº¡i bá» cÃ¡c kÃ½ tá»± markdown khÃ´ng Ä‘Ã³ng
            markdown_pairs = [('**', '**'), ('*', '*'), ('`', '`')]
            for open_char, close_char in markdown_pairs:
                open_count = truncated.count(open_char)
                close_count = truncated.count(close_char)
                if open_count > close_count:
                    # ThÃªm close char náº¿u thiáº¿u
                    truncated += close_char
            
            # ThÃªm thÃ´ng bÃ¡o cáº¯t
            if cut_type != 'forced':
                truncated = truncated.rstrip() + "..."
            
            truncated += "\n\nðŸ’¡ **ThÃ´ng tin cÃ²n tiáº¿p...**\n"
            truncated += "ðŸ“ž **LiÃªn há»‡ ngay Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t:** 0332510486"
            
            logger.info(f"ðŸ“ Truncated at position {best_cut_pos} ({cut_type}), new length: {len(truncated)}")
            return truncated
        
        # 3. HOTLINE ENSUREMENT WITH SMART FORMATTING
        def ensure_hotline_presence(text):
            """Äáº£m báº£o hotline cÃ³ máº·t vá»›i Ä‘á»‹nh dáº¡ng Ä‘áº¹p"""
            hotline_patterns = [
                '0332510486',
                'hotline',
                'liÃªn há»‡ tÆ° váº¥n',
                'Ä‘iá»‡n thoáº¡i tÆ° váº¥n',
                'sá»‘ Ä‘iá»‡n thoáº¡i'
            ]
            
            has_hotline = any(pattern in text.lower() for pattern in hotline_patterns)
            
            if not has_hotline:
                # ThÃªm hotline vá»›i formatting Ä‘áº¹p
                hotline_section = "\n\n---\n"
                hotline_section += "ðŸ“ž **HOTLINE TÆ¯ Váº¤N 24/7:** 0332510486\n"
                hotline_section += "ðŸ’¬ **Chat trá»±c tiáº¿p vá»›i chuyÃªn viÃªn Ruby Wings**"
                return text + hotline_section
            else:
                # Cáº£i thiá»‡n formatting cá»§a hotline náº¿u Ä‘Ã£ cÃ³
                lines = text.split('\n')
                enhanced_lines = []
                
                for line in lines:
                    if '0332510486' in line and 'ðŸ“ž' not in line:
                        # ThÃªm emoji náº¿u chÆ°a cÃ³
                        line = line.replace('0332510486', 'ðŸ“ž 0332510486')
                        if 'hotline' in line.lower() and '**' not in line:
                            line = 'ðŸ“ž **' + line.strip() + '**'
                    enhanced_lines.append(line)
                
                return '\n'.join(enhanced_lines)
        
        # 4. SIGNATURE ADDITION
        def add_signature(text):
            """ThÃªm signature náº¿u response Ä‘á»§ dÃ i"""
            if len(text) < 200:
                return text
            
            signature_variants = [
                "\n\n---\n**Ruby Wings Travel** âœ¨ _HÃ nh trÃ¬nh Ã½ nghÄ©a - Tráº£i nghiá»‡m thá»±c táº¿ - CÃ³ chiá»u sÃ¢u_",
                "\n\n---\n**Ruby Wings Travel** ðŸ¦‹ _Chuáº©n má»±c - ChÃ¢n thÃ nh - CÃ³ chiá»u sÃ¢u_",
                "\n\n---\n**Ruby Wings Travel** ðŸŒŸ _Mang Ä‘áº¿n tour Ä‘Ã¡ng nhá»› cho má»i du khÃ¡ch_",
                "\n\n---\n**Ruby Wings Travel** ðŸ—ºï¸ _KhÃ¡m phÃ¡ miá»n Trung vá»›i tráº£i nghiá»‡m Ä‘á»™c Ä‘Ã¡o_"
            ]
            
            # Chá»n signature ngáº«u nhiÃªn dá»±a trÃªn Ä‘á»™ dÃ i response
            import hashlib
            text_hash = hashlib.md5(text.encode()).hexdigest()
            variant_index = int(text_hash, 16) % len(signature_variants)
            
            # Kiá»ƒm tra xem Ä‘Ã£ cÃ³ signature chÆ°a
            signature_keywords = ['Ruby Wings Travel', '---', 'HÃ nh trÃ¬nh Ã½ nghÄ©a']
            has_signature = any(keyword in text for keyword in signature_keywords)
            
            if not has_signature:
                # KhÃ´ng thÃªm signature náº¿u Ä‘Ã£ cÃ³ hotline á»Ÿ cuá»‘i
                last_200 = text[-200:].lower()
                if '0332510486' not in last_200 and 'hotline' not in last_200:
                    return text + signature_variants[variant_index]
            
            return text
        
        # 5. RESPONSIVE SPACING
        def optimize_spacing(text):
            """Tá»‘i Æ°u khoáº£ng cÃ¡ch vÃ  spacing cho dá»… Ä‘á»c"""
            lines = text.split('\n')
            optimized_lines = []
            
            in_bullet_list = False
            bullet_list_items = []
            
            for i, line in enumerate(lines):
                stripped = line.strip()
                
                # Xá»­ lÃ½ bullet lists
                if 'â€¢' in line:
                    if not in_bullet_list:
                        in_bullet_list = True
                        # ThÃªm dÃ²ng trá»‘ng trÆ°á»›c bullet list
                        if i > 0 and lines[i-1].strip() and not any(bullet in lines[i-1] for bullet in ['â€¢', '##', '###']):
                            optimized_lines.append("")
                    
                    bullet_list_items.append(line)
                
                else:
                    # Káº¿t thÃºc bullet list
                    if in_bullet_list and bullet_list_items:
                        # ThÃªm cÃ¡c item
                        optimized_lines.extend(bullet_list_items)
                        # ThÃªm dÃ²ng trá»‘ng sau bullet list
                        if i < len(lines) - 1 and lines[i].strip():
                            optimized_lines.append("")
                        
                        bullet_list_items = []
                        in_bullet_list = False
                    
                    optimized_lines.append(line)
            
            # Xá»­ lÃ½ bullet list cÃ²n sÃ³t
            if bullet_list_items:
                optimized_lines.extend(bullet_list_items)
            
            # Loáº¡i bá» dÃ²ng trá»‘ng thá»«a
            final_lines = []
            empty_line_count = 0
            
            for line in optimized_lines:
                if not line.strip():
                    empty_line_count += 1
                    if empty_line_count <= 2:  # Giá»¯ tá»‘i Ä‘a 2 dÃ²ng trá»‘ng liÃªn tiáº¿p
                        final_lines.append(line)
                else:
                    empty_line_count = 0
                    final_lines.append(line)
            
            return '\n'.join(final_lines)
        
        # ========== APPLY ALL ENHANCEMENTS ==========
        
        # BÆ°á»›c 1: Ãp dá»¥ng enhanced formatting
        reply = enhance_response_format(reply)
        
        # BÆ°á»›c 2: Tá»‘i Æ°u spacing
        reply = optimize_spacing(reply)
        
        # BÆ°á»›c 3: Giá»›i háº¡n Ä‘á»™ dÃ i thÃ´ng minh
        original_length = len(reply)
        if original_length > 2500:
            reply = smart_truncate(reply, max_length=2500)
            logger.info(f"ðŸ“ Response truncated from {original_length} to {len(reply)} chars")
        
        # BÆ°á»›c 4: Äáº£m báº£o cÃ³ hotline
        reply = ensure_hotline_presence(reply)
        
        # BÆ°á»›c 5: ThÃªm signature náº¿u phÃ¹ há»£p
        if len(reply) > 300:
            reply = add_signature(reply)
        
        # BÆ°á»›c 6: Final length check vÃ  xá»­ lÃ½ Ä‘áº·c biá»‡t
        final_length = len(reply)
        if final_length > 3000:
            # TrÆ°á»ng há»£p cá»±c Ä‘oan: cáº¯t cá»©ng nhÆ°ng váº«n giá»¯ hotline
            logger.warning(f"âš ï¸ Response still too long after truncation: {final_length} chars")
            # Giá»¯ 2900 kÃ½ tá»± Ä‘áº§u + thÃ´ng bÃ¡o
            reply = reply[:2900] + "...\n\nðŸ“ž **Vui lÃ²ng liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.**"
        
        # Log final response stats
        logger.info(f"âœ… Response quality enhanced: {original_length} â†’ {len(reply)} chars")
        
        # ================== UPDATE CONTEXT V2 ==================
        
        # 1. ENHANCED TOUR CONTEXT TRACKING
        if tour_indices and len(tour_indices) > 0:
            # LÆ°u current tour
            context.current_tour = tour_indices[0]
            tour = TOURS_DB.get(tour_indices[0])
            if tour:
                context.last_tour_name = tour.name
                
                # LÆ°u thÃªm metadata vá» tour
                if not hasattr(context, 'tour_view_history'):
                    context.tour_view_history = []
                
                tour_view_data = {
                    'tour_index': tour_indices[0],
                    'tour_name': tour.name,
                    'timestamp': datetime.utcnow().isoformat(),
                    'reason': primary_intent or 'search_result'
                }
                
                # TrÃ¡nh trÃ¹ng láº·p trong lá»‹ch sá»­ xem
                existing_indices = [t.get('tour_index') for t in context.tour_view_history]
                if tour_indices[0] not in existing_indices:
                    context.tour_view_history.append(tour_view_data)
                    
                    # Giá»›i háº¡n lá»‹ch sá»­ xem tour (tá»‘i Ä‘a 10)
                    if len(context.tour_view_history) > 10:
                        context.tour_view_history = context.tour_view_history[-10:]
        
        # 2. ENHANCED USER PROFILE TRACKING
        if not hasattr(context, 'user_profile'):
            context.user_profile = {
                'basic_info': {},
                'preferences': {},
                'interaction_stats': {},
                'inferred_interests': [],
                'request_history': []
            }
        
        # Cáº­p nháº­t thÃ´ng tin tá»« context_analysis (náº¿u cÃ³)
        if 'context_analysis' in locals():
            analysis = context_analysis
            
            # Cáº­p nháº­t audience type
            if analysis.get('audience_type'):
                context.user_profile['basic_info']['audience_type'] = analysis['audience_type']
            
            # Cáº­p nháº­t interests tá»« analysis
            if analysis.get('interests') and len(analysis['interests']) > 0:
                for interest in analysis['interests']:
                    if interest not in context.user_profile['inferred_interests']:
                        context.user_profile['inferred_interests'].append(interest)
            
            # Cáº­p nháº­t sentiment profile
            if analysis.get('sentiment') and analysis['sentiment']['type'] != 'neutral':
                sentiment_key = f"sentiment_{analysis['sentiment']['type']}"
                context.user_profile['interaction_stats'][sentiment_key] = \
                    context.user_profile['interaction_stats'].get(sentiment_key, 0) + 1
        
        # Cáº­p nháº­t thÃ´ng tin tá»« mandatory_filters
        if mandatory_filters and not mandatory_filters.is_empty():
            if hasattr(mandatory_filters, 'group_type') and mandatory_filters.group_type:
                context.user_profile['basic_info']['preferred_group_type'] = mandatory_filters.group_type
            
            if hasattr(mandatory_filters, 'location') and mandatory_filters.location:
                context.user_profile['preferences']['preferred_location'] = mandatory_filters.location
            
            if hasattr(mandatory_filters, 'duration_min') or hasattr(mandatory_filters, 'duration_max'):
                context.user_profile['preferences']['tour_duration'] = {
                    'min': getattr(mandatory_filters, 'duration_min', None),
                    'max': getattr(mandatory_filters, 'duration_max', None)
                }
        
        # Cáº­p nháº­t tá»« primary_intent vÃ  detected_intents
        if primary_intent:
            context.user_profile['interaction_stats']['intent_counts'] = \
                context.user_profile['interaction_stats'].get('intent_counts', {})
            context.user_profile['interaction_stats']['intent_counts'][primary_intent] = \
                context.user_profile['interaction_stats']['intent_counts'].get(primary_intent, 0) + 1
        
        # Cáº­p nháº­t complexity profile
        context.user_profile['interaction_stats']['avg_complexity'] = \
            context.user_profile['interaction_stats'].get('avg_complexity', 0) * 0.8 + complexity_score * 0.2
        context.user_profile['interaction_stats']['total_messages'] = \
            context.user_profile['interaction_stats'].get('total_messages', 0) + 1
        
        # 3. ENHANCED CONVERSATION HISTORY MANAGEMENT
        # Táº¡o metadata entry chi tiáº¿t
        metadata_entry = {
            'role': 'assistant',
            'message': reply,
            'timestamp': datetime.utcnow().isoformat(),
            'timestamp_human': datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),
            'tour_indices': tour_indices,
            'detected_intents': detected_intents,
            'primary_intent': primary_intent,
            'complexity_score': complexity_score,
            'response_length': len(reply),
            'filter_applied': filter_applied,
            'filters': mandatory_filters.to_dict() if mandatory_filters and hasattr(mandatory_filters, 'to_dict') else {},
            'context_analysis': context_analysis if 'context_analysis' in locals() else None,
            'processing_time_ms': int((time.time() - start_time) * 1000),
            'session_id': session_id
        }
        
        # ThÃªm tour details náº¿u cÃ³
        if tour_indices and len(tour_indices) > 0:
            tour_details = []
            for idx in tour_indices[:3]:
                tour = TOURS_DB.get(idx)
                if tour:
                    tour_details.append({
                        'index': idx,
                        'name': tour.name,
                        'duration': tour.duration,
                        'location': tour.location
                    })
            metadata_entry['tour_details'] = tour_details
        
        # ThÃªm thÃ´ng tin tá»« cÃ¡c há»‡ thá»‘ng con
        if hasattr(context, 'multiple_intents'):
            metadata_entry['multiple_intents'] = context.multiple_intents
            delattr(context, 'multiple_intents')
        
        if hasattr(context, 'filter_warning'):
            metadata_entry['filter_warning'] = context.filter_warning
            delattr(context, 'filter_warning')
        
        if hasattr(context, 'filter_fallback'):
            metadata_entry['filter_fallback'] = context.filter_fallback
            delattr(context, 'filter_fallback')
        
        if hasattr(context, 'additional_filters'):
            metadata_entry['additional_filters'] = context.additional_filters
            delattr(context, 'additional_filters')
        
        # LÆ°u vÃ o conversation history
        context.conversation_history.append(metadata_entry)
        
        # 4. INTELLIGENT HISTORY COMPRESSION & MANAGEMENT
        # Giá»›i háº¡n history (giá»¯ 40 tin nháº¯n gáº§n nháº¥t)
        if len(context.conversation_history) > 40:
            # Strategy: Giá»¯ toÃ n bá»™ 20 tin nháº¯n gáº§n nháº¥t, nÃ©n 20 tin nháº¯n cÅ© hÆ¡n
            recent_history = context.conversation_history[-20:]
            older_history = context.conversation_history[:-20]
            
            if len(older_history) > 10:
                # NÃ©n older history: chá»‰ giá»¯ metadata quan trá»ng
                compressed_older = []
                for entry in older_history[-10:]:
                    compressed_entry = {
                        'role': entry.get('role'),
                        'timestamp': entry.get('timestamp'),
                        'primary_intent': entry.get('primary_intent'),
                        'tour_count': len(entry.get('tour_indices', [])),
                        'compressed': True
                    }
                    compressed_older.append(compressed_entry)
                
                # Káº¿t há»£p láº¡i
                context.conversation_history = compressed_older + recent_history
            else:
                context.conversation_history = older_history + recent_history
        
        # 5. REQUEST HISTORY TRACKING
        # LÆ°u request vÃ o history riÃªng
        request_summary = {
            'timestamp': datetime.utcnow().isoformat(),
            'query': user_message[:100],  # Giá»¯ 100 kÃ½ tá»± Ä‘áº§u
            'primary_intent': primary_intent,
            'tour_count': len(tour_indices) if tour_indices else 0,
            'complexity': complexity_score,
            'filters_applied': filter_applied
        }
        
        if not hasattr(context, 'request_history'):
            context.request_history = []
        
        context.request_history.append(request_summary)
        
        # Giá»›i háº¡n request history (tá»‘i Ä‘a 20)
        if len(context.request_history) > 20:
            context.request_history = context.request_history[-20:]
        
        # 6. SESSION ANALYTICS
        if not hasattr(context, 'session_analytics'):
            context.session_analytics = {
                'start_time': datetime.utcnow().isoformat(),
                'message_count': 0,
                'intent_distribution': {},
                'tour_views': {},
                'filter_usage': {},
                'avg_response_time': 0
            }
        
        # Cáº­p nháº­t session analytics
        context.session_analytics['message_count'] = len(context.conversation_history)
        
        if primary_intent:
            context.session_analytics['intent_distribution'][primary_intent] = \
                context.session_analytics['intent_distribution'].get(primary_intent, 0) + 1
        
        if tour_indices:
            for idx in tour_indices[:3]:
                context.session_analytics['tour_views'][str(idx)] = \
                    context.session_analytics['tour_views'].get(str(idx), 0) + 1
        
        if filter_applied:
            filter_types = []
            if hasattr(mandatory_filters, 'group_type') and mandatory_filters.group_type:
                filter_types.append(f"group:{mandatory_filters.group_type}")
            if hasattr(mandatory_filters, 'location') and mandatory_filters.location:
                filter_types.append(f"location:{mandatory_filters.location}")
            
            for ft in filter_types:
                context.session_analytics['filter_usage'][ft] = \
                    context.session_analytics['filter_usage'].get(ft, 0) + 1
        
        # TÃ­nh avg response time
        current_processing_time = (time.time() - start_time) * 1000
        old_avg = context.session_analytics['avg_response_time']
        total_msgs = context.session_analytics['message_count']
        context.session_analytics['avg_response_time'] = \
            (old_avg * (total_msgs - 1) + current_processing_time) / total_msgs if total_msgs > 0 else current_processing_time
        
        # 7. LÆ°u session context
        save_session_context(session_id, context)
        
        # 8. LOGGING ENHANCED
        logger.info(f"ðŸ“ Context Updated:")
        logger.info(f"   â€¢ Session: {session_id}")
        logger.info(f"   â€¢ Tour Indices: {tour_indices} ({len(tour_indices) if tour_indices else 0} tours)")
        logger.info(f"   â€¢ Primary Intent: {primary_intent}")
        logger.info(f"   â€¢ Detected Intents: {len(detected_intents)}")
        logger.info(f"   â€¢ Complexity Score: {complexity_score}/10")
        logger.info(f"   â€¢ Filter Applied: {filter_applied}")
        logger.info(f"   â€¢ Response Length: {len(reply)} chars")
        logger.info(f"   â€¢ Processing Time: {int((time.time() - start_time) * 1000)}ms")
        
        # Log user profile summary
        if hasattr(context, 'user_profile') and context.user_profile:
            profile_summary = {
                'audience': context.user_profile.get('basic_info', {}).get('audience_type', 'unknown'),
                'interests': len(context.user_profile.get('inferred_interests', [])),
                'messages': context.user_profile.get('interaction_stats', {}).get('total_messages', 0),
                'avg_complexity': round(context.user_profile.get('interaction_stats', {}).get('avg_complexity', 0), 1)
            }
            logger.info(f"ðŸ‘¤ User Profile Summary: {profile_summary}")
        
        # ================== FINAL RESPONSE ==================
        processing_time = time.time() - start_time
        
        chat_response = ChatResponse(
            reply=reply,
            sources=sources,
            context={
                "session_id": session_id,
                "current_tour": getattr(context, 'current_tour', None),
                "last_tour_name": getattr(context, 'last_tour_name', None),
                "user_preferences": getattr(context, 'user_profile', {}),
                "detected_intents": detected_intents,
                "primary_intent": primary_intent,
                "processing_time_ms": int(processing_time * 1000),
                "tours_found": len(tour_indices),
                "complexity_score": complexity_score,
                "filter_applied": filter_applied
            },
            tour_indices=tour_indices,
            processing_time_ms=int(processing_time * 1000),
            from_memory=False
        )
        
        # Cache response
        if UpgradeFlags.get_all_flags().get("ENABLE_CACHING", True):
            context_hash = hashlib.md5(json.dumps({
                'tour_indices': tour_indices,
                'detected_intents': detected_intents,
                'primary_intent': primary_intent,
                'complexity': complexity_score,
                'filters': mandatory_filters.to_dict() if mandatory_filters else {}
            }, sort_keys=True).encode()).hexdigest()
            
            cache_key = CacheSystem.get_cache_key(user_message, context_hash)
            CacheSystem.set(cache_key, chat_response.to_dict(), expiry=300)
        
        logger.info(f"âœ… Processed in {processing_time:.2f}s | "
                   f"Primary Intent: {primary_intent} | "
                   f"Tours: {len(tour_indices)} | "
                   f"Complexity: {complexity_score} | "
                   f"Filters: {filter_applied}")
        
        return jsonify(chat_response.to_dict())
    
    except Exception as e:
        logger.error(f"âŒ Chat endpoint error: {e}\n{traceback.format_exc()}")
        
        processing_time = time.time() - start_time
        
        # Enhanced error response
        error_response = ChatResponse(
            reply="âš¡ **CÃ³ chÃºt trá»¥c tráº·c ká»¹ thuáº­t!**\n\n"
                  "Äá»™i ngÅ© Ruby Wings váº«n sáºµn sÃ ng há»— trá»£ báº¡n qua cÃ¡c kÃªnh sau:\n\n"
                  "ðŸ”§ **GIáº¢I PHÃP NHANH:**\n"
                  "1. **Gá»i trá»±c tiáº¿p:** ðŸ“ž 0332510486 (tÆ° váº¥n ngay)\n"
                  "2. **Há»i Ä‘Æ¡n giáº£n hÆ¡n:** 'Tour 1 ngÃ y Huáº¿', 'Tour gia Ä‘Ã¬nh 2 ngÃ y'\n"
                  "3. **Chá»n tá»« danh sÃ¡ch:**\n"
                  "   â€¢ Tour thiÃªn nhiÃªn Báº¡ch MÃ£\n"
                  "   â€¢ Tour lá»‹ch sá»­ TrÆ°á»ng SÆ¡n\n"
                  "   â€¢ Tour retreat thiá»n\n\n"
                  "â° **ChÃºng tÃ´i hoáº¡t Ä‘á»™ng 24/7 Ä‘á»ƒ phá»¥c vá»¥ báº¡n tá»‘t nháº¥t!** ðŸ˜Š",
            sources=[],
            context={
                "error": str(e),
                "processing_time_ms": int(processing_time * 1000),
                "error_type": type(e).__name__
            },
            tour_indices=[],
            processing_time_ms=int(processing_time * 1000),
            from_memory=False
        )
        
        return jsonify(error_response.to_dict()), 500



# ================== ENHANCED HELPER FUNCTIONS V3 ==================

def _extract_price_value(price_text):
    """TrÃ­ch xuáº¥t giÃ¡ trá»‹ sá»‘ tá»« text giÃ¡ - NÃ‚NG Cáº¤P THÃ”NG MINH"""
    if not price_text:
        return None
    
    import re
    
    # NÃ‚NG Cáº¤P: TÃ¬m kiáº¿m thÃ´ng minh hÆ¡n vá»›i nhiá»u Ä‘á»‹nh dáº¡ng
    patterns = [
        # Äá»‹nh dáº¡ng 1: "1.500.000 VNÄ"
        r'(\d{1,3}(?:\.\d{3})*(?:\.\d{1,3})?)\s*(?:vnÄ‘|vnd|Ä‘á»“ng|â‚«|d)',
        # Äá»‹nh dáº¡ng 2: "1,500,000"
        r'(\d{1,3}(?:,\d{3})*(?:,\d{1,3})?)',
        # Äá»‹nh dáº¡ng 3: "1.5 triá»‡u"
        r'(\d{1,3}(?:\.\d{1,2})?)\s*(?:triá»‡u|tr|m)',
        # Äá»‹nh dáº¡ng 4: "1500k"
        r'(\d{1,10})k\b',
        # Äá»‹nh dáº¡ng 5: "2-3 triá»‡u"
        r'(\d{1,3})\s*(?:Ä‘áº¿n|-|tá»›i)\s*(\d{1,3})\s*(?:triá»‡u|tr|m)',
        # Äá»‹nh dáº¡ng 6: Sá»‘ Ä‘Æ¡n giáº£n
        r'\b(\d{4,10})\b'
    ]
    
    all_numbers = []
    
    for pattern in patterns:
        matches = re.findall(pattern, price_text.lower().replace(',', '.'))
        if matches:
            for match in matches:
                if isinstance(match, tuple):
                    # TrÆ°á»ng há»£p range: "2-3 triá»‡u"
                    for num in match:
                        if num and num.strip():
                            try:
                                num_clean = num.replace('.', '')
                                if '.' in num:
                                    # Sá»‘ tháº­p phÃ¢n: "1.5 triá»‡u"
                                    value = float(num) * 1000000
                                else:
                                    value = int(num_clean) * 1000000
                                all_numbers.append(int(value))
                            except:
                                continue
                else:
                    # TrÆ°á»ng há»£p Ä‘Æ¡n
                    try:
                        num_str = match.strip()
                        if '.' in num_str and num_str.count('.') == 1:
                            # Sá»‘ tháº­p phÃ¢n: "1.5 triá»‡u"
                            value = float(num_str) * 1000000
                        elif '.' in num_str:
                            # Äá»‹nh dáº¡ng nghÃ¬n: "1.500.000"
                            num_clean = num_str.replace('.', '')
                            value = int(num_clean)
                        else:
                            # Sá»‘ nguyÃªn
                            value = int(num_str)
                            # Kiá»ƒm tra Ä‘Æ¡n vá»‹
                            if 'triá»‡u' in price_text.lower() or 'tr' in price_text.lower() or 'm' in price_text.lower():
                                value = value * 1000000
                            elif 'k' in price_text.lower() and value < 10000:
                                value = value * 1000
                        all_numbers.append(int(value))
                    except:
                        continue
    
    # Tá»‘i Æ°u hÃ³a: lá»c giÃ¡ trá»‹ há»£p lÃ½ (tá»« 100,000 Ä‘áº¿n 50,000,000 VNÄ)
    valid_numbers = [n for n in all_numbers if 100000 <= n <= 50000000]
    
    if valid_numbers:
        # Æ¯u tiÃªn giÃ¡ nhá» nháº¥t náº¿u cÃ³ nhiá»u giÃ¡
        return min(valid_numbers)
    
    # Fallback: tÃ¬m báº¥t ká»³ sá»‘ nÃ o
    if all_numbers:
        return min(all_numbers)
    
    return None


def _get_philosophy_response():
    """Tráº£ lá»i vá» triáº¿t lÃ½ Ruby Wings - NÃ‚NG Cáº¤P CHI TIáº¾T"""
    return """âœ¨ **TRIáº¾T LÃ 'CHUáº¨N Má»°C - CHÃ‚N THÃ€NH - CÃ“ CHIá»€U SÃ‚U'** âœ¨

**ðŸŒŒ Má»¤C ÄÃCH SÃ‚U XA:**
KhÃ´ng chá»‰ lÃ  du lá»‹ch, Ruby Wings táº¡o ra hÃ nh trÃ¬nh cháº¡m Ä‘áº¿n cáº£m xÃºc, má»Ÿ ra nháº­n thá»©c má»›i, vÃ  káº¿t ná»‘i con ngÆ°á»i vá»›i lá»‹ch sá»­, thiÃªn nhiÃªn vÃ  chÃ­nh mÃ¬nh.

**ðŸ† CHUáº¨N Má»°C - Sá»° HOÃ€N Háº¢O TRONG Tá»ªNG CHI TIáº¾T:**

ðŸ”¹ **AN TOÃ€N TUYá»†T Äá»I:**
â€¢ ÄÃ¡nh giÃ¡ rá»§i ro trÆ°á»›c má»—i hÃ nh trÃ¬nh
â€¢ NhÃ¢n viÃªn Ä‘Æ°á»£c Ä‘Ã o táº¡o CPR & sÆ¡ cá»©u
â€¢ Thiáº¿t bá»‹ an toÃ n Ä‘áº¡t chuáº©n quá»‘c táº¿
â€¢ Báº£o hiá»ƒm du lá»‹ch cao cáº¥p (Ä‘á»n bÃ¹ Ä‘áº¿n 100 triá»‡u)

ðŸ”¹ **CHUYÃŠN NGHIá»†P VÆ¯á»¢T TRá»˜I:**
â€¢ HDV Ä‘Æ°á»£c chá»©ng nháº­n quá»‘c táº¿
â€¢ Quy trÃ¬nh chuáº©n hÃ³a ISO
â€¢ ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng sau má»—i hÃ nh trÃ¬nh
â€¢ Cáº­p nháº­t kiáº¿n thá»©c liÃªn tá»¥c

ðŸ”¹ **CHáº¤T LÆ¯á»¢NG KHÃ”NG THá»ŽA HIá»†P:**
â€¢ Äá»‘i tÃ¡c Ä‘Æ°á»£c lá»±a chá»n ká»¹ lÆ°á»¡ng
â€¢ NguyÃªn váº­t liá»‡u tÆ°Æ¡i ngon nháº¥t
â€¢ PhÆ°Æ¡ng tiá»‡n Ä‘á»i má»›i, báº£o dÆ°á»¡ng Ä‘á»‹nh ká»³
â€¢ Kiá»ƒm soÃ¡t cháº¥t lÆ°á»£ng 3 cáº¥p Ä‘á»™

**â¤ï¸ CHÃ‚N THÃ€NH - Káº¾T Ná»I Tá»ª TRÃI TIM:**

ðŸ”¸ **MINH Báº CH TUYá»†T Äá»I:**
â€¢ BÃ¡o giÃ¡ chi tiáº¿t, khÃ´ng phÃ¡t sinh
â€¢ ThÃ´ng tin rÃµ rÃ ng, khÃ´ng giáº¥u diáº¿m
â€¢ Há»£p Ä‘á»“ng Ä‘áº§y Ä‘á»§ Ä‘iá»u khoáº£n
â€¢ Pháº£n há»“i 24/7

ðŸ”¸ **Äá»’NG HÃ€NH NHÆ¯ NGÆ¯á»œI THÃ‚N:**
â€¢ TÆ° váº¥n táº­n tÃ¢m, khÃ´ng Ã©p mua
â€¢ Há»— trá»£ xuyÃªn suá»‘t hÃ nh trÃ¬nh
â€¢ Quan tÃ¢m Ä‘áº¿n tá»«ng cÃ¡ nhÃ¢n
â€¢ Láº¯ng nghe vÃ  tháº¥u hiá»ƒu

ðŸ”¸ **TRÃCH NHIá»†M Vá»šI Cá»˜NG Äá»’NG:**
â€¢ TÃ´n trá»ng vÄƒn hÃ³a Ä‘á»‹a phÆ°Æ¡ng
â€¢ Há»— trá»£ doanh nghiá»‡p Ä‘á»‹a phÆ°Æ¡ng
â€¢ Báº£o vá»‡ mÃ´i trÆ°á»ng tá»± nhiÃªn
â€¢ ÄÃ³ng gÃ³p cho phÃ¡t triá»ƒn bá»n vá»¯ng

**ðŸŒ  CÃ“ CHIá»€U SÃ‚U - GIÃ TRá»Š Bá»€N Vá»®NG:**

ðŸŒ€ **HÃ€NH TRÃŒNH Ã NGHÄ¨A:**
â€¢ Má»—i chuyáº¿n Ä‘i lÃ  má»™t bÃ i há»c
â€¢ Tráº£i nghiá»‡m thay Ä‘á»•i nháº­n thá»©c
â€¢ Káº¿t ná»‘i quÃ¡ khá»© - hiá»‡n táº¡i - tÆ°Æ¡ng lai
â€¢ Táº¡o ra ká»· niá»‡m vÆ°á»£t thá»i gian

ðŸŒ€ **KHÃM PHÃ Báº¢N CHáº¤T:**
â€¢ VÆ°á»£t qua bá» ná»•i du lá»‹ch thÃ´ng thÆ°á»ng
â€¢ Tháº¥u hiá»ƒu giÃ¡ trá»‹ vÄƒn hÃ³a
â€¢ Cáº£m nháº­n sÃ¢u sáº¯c thiÃªn nhiÃªn
â€¢ Káº¿t ná»‘i vá»›i báº£n thá»ƒ chÃ¢n tháº­t

ðŸŒ€ **TRUYá»€N Cáº¢M Há»¨NG:**
â€¢ Truyá»n lá»­a Ä‘am mÃª khÃ¡m phÃ¡
â€¢ KhÆ¡i dáº­y lÃ²ng biáº¿t Æ¡n
â€¢ Táº¡o Ä‘á»™ng lá»±c thay Ä‘á»•i tÃ­ch cá»±c
â€¢ Lan tá»a nÄƒng lÆ°á»£ng tá»‘t Ä‘áº¹p

**ðŸŽ¯ Táº¦M NHÃŒN & Sá»¨ Má»†NH:**

ðŸŒ **Táº¦M NHÃŒN 2030:**
Trá»Ÿ thÃ nh tá»• chá»©c du lá»‹ch tráº£i nghiá»‡m dáº«n Ä‘áº§u ÄÃ´ng Nam Ã, Ä‘Æ°á»£c cÃ´ng nháº­n vá» cháº¥t lÆ°á»£ng dá»‹ch vá»¥ vÃ  Ä‘Ã³ng gÃ³p cho phÃ¡t triá»ƒn bá»n vá»¯ng.

ðŸ•Šï¸ **Sá»¨ Má»†NH:**
Mang Ä‘áº¿n nhá»¯ng hÃ nh trÃ¬nh khÃ´ng chá»‰ thay Ä‘á»•i Ä‘iá»ƒm Ä‘áº¿n mÃ  cÃ²n thay Ä‘á»•i cÃ¡ch nhÃ¬n, khÃ´ng chá»‰ táº¡o ká»· niá»‡m mÃ  cÃ²n táº¡o ra giÃ¡ trá»‹, khÃ´ng chá»‰ phá»¥c vá»¥ khÃ¡ch hÃ ng mÃ  cÃ²n phá»¥ng sá»± cá»™ng Ä‘á»“ng.

ðŸ“ž **Tráº£i nghiá»‡m triáº¿t lÃ½ Ruby Wings trong tá»«ng hÃ nh trÃ¬nh:** 0332510486

âœ¨ *"Má»—i bÆ°á»›c chÃ¢n lÃ  má»™t khÃ¡m phÃ¡, má»—i hÃ nh trÃ¬nh lÃ  má»™t sá»± chuyá»ƒn hÃ³a"* âœ¨"""


def _get_company_introduction():
    """Tráº£ lá»i giá»›i thiá»‡u cÃ´ng ty - NÃ‚NG Cáº¤P Äáº¦Y Äá»¦"""
    return """ðŸ›ï¸ **GIá»šI THIá»†U CHI TIáº¾T RUBY WINGS TRAVEL** ðŸ›ï¸

**ðŸ“œ Lá»ŠCH Sá»¬ HÃŒNH THÃ€NH:**
ThÃ nh láº­p nÄƒm 2018 vá»›i sá»© má»‡nh thay Ä‘á»•i cÃ¡ch du lá»‹ch truyá»n thá»‘ng, Ruby Wings Ä‘Ã£ phÃ¡t triá»ƒn tá»« nhÃ³m nhá» thÃ nh tá»• chá»©c du lá»‹ch tráº£i nghiá»‡m uy tÃ­n táº¡i miá»n Trung Viá»‡t Nam.

**ðŸŒŸ ÄIá»‚M KHÃC BIá»†T Cá»T LÃ•I:**

1. **THIáº¾T Káº¾ HÃ€NH TRÃŒNH Äáº¶C BIá»†T:**
   â€¢ Má»—i hÃ nh trÃ¬nh lÃ  má»™t cÃ¢u chuyá»‡n
   â€¢ Káº¿t há»£p yáº¿u tá»‘ vÄƒn hÃ³a, lá»‹ch sá»­, thiÃªn nhiÃªn
   â€¢ Hoáº¡t Ä‘á»™ng cÃ³ chiá»u sÃ¢u, Ã½ nghÄ©a
   â€¢ Äá»™i ngÅ© nghiÃªn cá»©u chuyÃªn sÃ¢u

2. **Äá»˜I NGÅ¨ CHUYÃŠN GIA:**
   â€¢ HDV am hiá»ƒu vÄƒn hÃ³a, lá»‹ch sá»­
   â€¢ ChuyÃªn gia wellness & thiá»n Ä‘á»‹nh
   â€¢ ChuyÃªn viÃªn vÄƒn hÃ³a Ä‘á»‹a phÆ°Æ¡ng
   â€¢ NhÃ¢n viÃªn y táº¿ Ä‘i kÃ¨m (hÃ nh trÃ¬nh Ä‘áº·c biá»‡t)

3. **CÆ  Sá»ž Váº¬T CHáº¤T CAO Cáº¤P:**
   â€¢ Xe 16-45 chá»— Ä‘á»i má»›i
   â€¢ Thiáº¿t bá»‹ chuyÃªn dá»¥ng (trekking, camping)
   â€¢ Há»‡ thá»‘ng liÃªn láº¡c vá»‡ tinh
   â€¢ Thiáº¿t bá»‹ y táº¿ Ä‘áº§y Ä‘á»§

**ðŸŽ¯ 4 TRá»¤ Cá»˜T CHÃNH:**

1. **TOUR Lá»ŠCH Sá»¬ - TRI Ã‚N:**
   ðŸ›ï¸ **Trá»ng tÃ¢m:** Di tÃ­ch, chiáº¿n trÆ°á»ng, di sáº£n
   âœ… **Hoáº¡t Ä‘á»™ng:** Tham quan di tÃ­ch, gáº·p nhÃ¢n chá»©ng, lá»… tri Ã¢n
   ðŸ“ **Äá»‹a Ä‘iá»ƒm:** ThÃ nh cá»• Quáº£ng Trá»‹, Äá»‹a Ä‘áº¡o Vá»‹nh Má»‘c, ÄÆ°á»ng HCM
   ðŸ‘¥ **PhÃ¹ há»£p:** Cá»±u chiáº¿n binh, há»c sinh, nhÃ³m tÃ¬m hiá»ƒu lá»‹ch sá»­

2. **TOUR RETREAT - CHá»®A LÃ€NH:**
   ðŸ§˜ **Trá»ng tÃ¢m:** Thiá»n, yoga, khÃ­ cÃ´ng, tÄ©nh tÃ¢m
   âœ… **Hoáº¡t Ä‘á»™ng:** Thiá»n Ä‘á»‹nh, yoga, workshop healing
   ðŸ“ **Äá»‹a Ä‘iá»ƒm:** Báº¡ch MÃ£, rá»«ng nguyÃªn sinh, bÃ£i biá»ƒn yÃªn tÄ©nh
   ðŸ‘¥ **PhÃ¹ há»£p:** NgÆ°á»i cáº§n thÆ° giÃ£n, cÃ¢n báº±ng cuá»™c sá»‘ng, phá»¥c há»“i nÄƒng lÆ°á»£ng

3. **TOUR THIÃŠN NHIÃŠN - KHÃM PHÃ:**
   ðŸŒ¿ **Trá»ng tÃ¢m:** Rá»«ng nÃºi, Ä‘á»™ng thá»±c váº­t, há»‡ sinh thÃ¡i
   âœ… **Hoáº¡t Ä‘á»™ng:** Trekking, camping, quan sÃ¡t Ä‘á»™ng váº­t
   ðŸ“ **Äá»‹a Ä‘iá»ƒm:** VQG Báº¡ch MÃ£, TrÆ°á»ng SÆ¡n, rá»«ng nguyÃªn sinh
   ðŸ‘¥ **PhÃ¹ há»£p:** NhÃ³m báº¡n, gia Ä‘Ã¬nh, ngÆ°á»i yÃªu thiÃªn nhiÃªn

4. **TOUR VÄ‚N HÃ“A - áº¨M THá»°C:**
   ðŸœ **Trá»ng tÃ¢m:** áº¨m thá»±c, lÃ ng nghá», phong tá»¥c Ä‘á»‹a phÆ°Æ¡ng
   âœ… **Hoáº¡t Ä‘á»™ng:** Há»c náº¥u Äƒn, thÄƒm lÃ ng nghá», giao lÆ°u vÄƒn nghá»‡
   ðŸ“ **Äá»‹a Ä‘iá»ƒm:** Huáº¿, lÃ ng Chuá»“n, lÃ ng SÃ¬nh
   ðŸ‘¥ **PhÃ¹ há»£p:** NgÆ°á»i yÃªu áº©m thá»±c, tÃ¬m hiá»ƒu vÄƒn hÃ³a

**ðŸ“Š THÃ€NH Tá»°U & CHá»¨NG NHáº¬N:**

ðŸ† **GIáº¢I THÆ¯á»žNG:**
â€¢ Top 5 Tour Operator uy tÃ­n 2023
â€¢ Giáº£i thÆ°á»Ÿng Du lá»‹ch bá»n vá»¯ng 2022
â€¢ Doanh nghiá»‡p vÄƒn hÃ³a tiÃªu biá»ƒu 2021

âœ… **CHá»¨NG NHáº¬N:**
â€¢ ISO 9001:2015 (Quáº£n lÃ½ cháº¥t lÆ°á»£ng)
â€¢ An toÃ n du lá»‹ch quá»‘c táº¿
â€¢ Äá»‘i tÃ¡c cá»§a UNESCO Huáº¿
â€¢ ThÃ nh viÃªn Hiá»‡p há»™i Du lá»‹ch bá»n vá»¯ng

**ðŸ¤ Äá»I TÃC CHIáº¾N LÆ¯á»¢C:**

1. **Tá»” CHá»¨C QUá»C Táº¾:**
   â€¢ UNESCO Viá»‡t Nam
   â€¢ WWF Viá»‡t Nam
   â€¢ Tá»• chá»©c Báº£o tá»“n ThiÃªn nhiÃªn

2. **DOANH NGHIá»†P Äá»ŠA PHÆ¯Æ NG:**
   â€¢ 50+ homestay, khÃ¡ch sáº¡n Ä‘á»‘i tÃ¡c
   â€¢ 30+ nhÃ  hÃ ng, quÃ¡n Äƒn Ä‘áº·c sáº£n
   â€¢ 20+ lÃ ng nghá» truyá»n thá»‘ng
   â€¢ 10+ tá»• chá»©c cá»™ng Ä‘á»“ng

3. **TRÆ¯á»œNG Há»ŒC & Tá»” CHá»¨C:**
   â€¢ CÃ¡c trÆ°á»ng Ä‘áº¡i há»c táº¡i Huáº¿, ÄÃ  Náºµng
   â€¢ Tá»• chá»©c cá»±u chiáº¿n binh
   â€¢ CÃ¢u láº¡c bá»™ thiá»n, yoga
   â€¢ Doanh nghiá»‡p lá»›n trong nÆ°á»›c

**ðŸ“ˆ QUY MÃ” HOáº T Äá»˜NG:**

â€¢ **NhÃ¢n sá»±:** 25 nhÃ¢n viÃªn chÃ­nh thá»©c + 50 cá»™ng tÃ¡c viÃªn
â€¢ **KhÃ¡ch hÃ ng:** 5,000+ khÃ¡ch/nÄƒm
â€¢ **Äá»‹a bÃ n:** Huáº¿, Quáº£ng Trá»‹, ÄÃ  Náºµng, Báº¡ch MÃ£, TrÆ°á»ng SÆ¡n
â€¢ **TÄƒng trÆ°á»Ÿng:** 30-40%/nÄƒm

**ðŸŒ CAM Káº¾T PHÃT TRIá»‚N Bá»€N Vá»®NG:**

â™»ï¸ **MÃ”I TRÆ¯á»œNG:**
â€¢ Giáº£m 50% rÃ¡c tháº£i nhá»±a Ä‘áº¿n 2025
â€¢ Sá»­ dá»¥ng 100% váº­t liá»‡u tÃ¡i cháº¿
â€¢ Trá»“ng 1,000 cÃ¢y xanh/nÄƒm

ðŸ¤² **Cá»˜NG Äá»’NG:**
â€¢ Táº¡o viá»‡c lÃ m cho 100+ ngÆ°á»i Ä‘á»‹a phÆ°Æ¡ng
â€¢ ÄÃ o táº¡o ká»¹ nÄƒng du lá»‹ch cho thanh niÃªn
â€¢ Há»— trá»£ 10% doanh thu tá»« tour cá»™ng Ä‘á»“ng

ðŸ“š **GIÃO Dá»¤C:**
â€¢ Workshop miá»…n phÃ­ vá» du lá»‹ch bá»n vá»¯ng
â€¢ ChÆ°Æ¡ng trÃ¬nh há»c bá»•ng cho sinh viÃªn
â€¢ TÃ i liá»‡u hÆ°á»›ng dáº«n du lá»‹ch cÃ³ trÃ¡ch nhiá»‡m

ðŸ“ž **Káº¿t ná»‘i vá»›i Ruby Wings:**
â€¢ **Hotline 24/7:** 0332510486
â€¢ **Email:** info@rubywings.com
â€¢ **VÄƒn phÃ²ng:** 123 ÄÆ°á»ng ABC, ThÃ nh phá»‘ Huáº¿
â€¢ **Giá» lÃ m viá»‡c:** 8:00 - 20:00 hÃ ng ngÃ y

ðŸŒŸ *"Ruby Wings - NÃ¢ng cÃ¡nh Æ°á»›c mÆ¡, cháº¡m Ä‘áº¿n trÃ¡i tim"* ðŸŒŸ"""


def _get_weather_info(location, location_tours):
    """Tráº£ lá»i thÃ´ng tin thá»i tiáº¿t - NÃ‚NG Cáº¤P CHI TIáº¾T"""
    location_lower = location.lower()
    reply = f"ðŸŒ¤ï¸ **THÃ”NG TIN THá»œI TIáº¾T {location.upper()}** ðŸŒ¤ï¸\n\n"
    
    weather_data = {
        'huáº¿': {
            'title': "HUáº¾ - KINH ÄÃ” Cá»” Vá»šI KHÃ Háº¬U Äáº¶C TRÆ¯NG",
            'temp_range': "18-35Â°C",
            'seasons': {
                'dry': "ThÃ¡ng 1-8: Náº¯ng Ä‘áº¹p, Ã­t mÆ°a, Ä‘á»™ áº©m 65-75%",
                'rainy': "ThÃ¡ng 9-12: MÆ°a nhiá»u, lá»¥t cá»¥c bá»™, Ä‘á»™ áº©m 80-90%"
            },
            'best_months': "ThÃ¡ng 1-4 & 11-12",
            'special_notes': [
                "ðŸŒ… BÃ¬nh minh trÃªn sÃ´ng HÆ°Æ¡ng: 5:00-6:00",
                "ðŸŒ‡ HoÃ ng hÃ´n táº¡i NÃºi Ngá»±: 17:30-18:30",
                "â˜” MÆ°a thÆ°á»ng táº­p trung chiá»u tá»‘i",
                "ðŸŒ¡ï¸ ChÃªnh lá»‡ch nhiá»‡t ngÃ y/Ä‘Ãªm: 8-12Â°C"
            ],
            'packing_tips': [
                "ðŸŽ½ Ão cotton thoÃ¡ng mÃ¡t",
                "ðŸŒ‚ Ã”/dÃ¹ nhá» gá»n",
                "ðŸ©´ DÃ©p Ä‘i mÆ°a",
                "ðŸ§´ Kem chá»‘ng náº¯ng SPF 50+",
                "ðŸ’§ NÆ°á»›c uá»‘ng Ä‘áº§y Ä‘á»§"
            ],
            'activity_recommendations': {
                'dry_season': "Tham quan di tÃ­ch, áº©m thá»±c Ä‘Æ°á»ng phá»‘",
                'rainy_season': "Tham quan báº£o tÃ ng, tráº£i nghiá»‡m vÄƒn hÃ³a trong nhÃ "
            }
        },
        'báº¡ch mÃ£': {
            'title': "Báº CH MÃƒ - VÆ¯á»œN QUá»C GIA Vá»šI KHÃ Háº¬U Ã”N Äá»šI",
            'temp_range': "15-25Â°C (cao nháº¥t 1,450m)",
            'seasons': {
                'dry': "ThÃ¡ng 2-5: Ãt mÆ°a, hoa phong lan ná»Ÿ rá»™",
                'rainy': "ThÃ¡ng 9-12: MÆ°a rá»«ng, sÆ°Æ¡ng mÃ¹ dÃ y Ä‘áº·c"
            },
            'best_months': "ThÃ¡ng 3-5 & 10-11",
            'special_notes': [
                "ðŸŒ«ï¸ SÆ°Æ¡ng mÃ¹ buá»•i sÃ¡ng: 6:00-9:00",
                "ðŸŒ¡ï¸ Giáº£m 0.6Â°C/100m Ä‘á»™ cao",
                "ðŸ’¨ GiÃ³ máº¡nh trÃªn Ä‘á»‰nh nÃºi",
                "ðŸŒ§ï¸ LÆ°á»£ng mÆ°a: 2,500-3,000mm/nÄƒm"
            ],
            'packing_tips': [
                "ðŸ§¥ Ão khoÃ¡c má»ng",
                "ðŸ¥¾ GiÃ y trekking chá»‘ng nÆ°á»›c",
                "ðŸŒ§ï¸ Ão mÆ°a loáº¡i nháº¹",
                "ðŸ”¦ ÄÃ¨n pin/Ä‘Ã¨n trÃ¡n",
                "ðŸ¦Ÿ Thuá»‘c chá»‘ng cÃ´n trÃ¹ng"
            ],
            'activity_recommendations': {
                'dry_season': "Trekking, ngáº¯m hoa, quan sÃ¡t Ä‘á»™ng váº­t",
                'rainy_season': "Thiá»n trong rá»«ng, tÄ©nh dÆ°á»¡ng, viáº¿t nháº­t kÃ½"
            }
        },
        'trÆ°á»ng sÆ¡n': {
            'title': "TRÆ¯á»œNG SÆ N - DÃƒY NÃšI HUYá»€N THOáº I",
            'temp_range': "18-30Â°C (chÃªnh lá»‡ch lá»›n ngÃ y/Ä‘Ãªm)",
            'seasons': {
                'dry': "ThÃ¡ng 1-4: Ãt mÆ°a, Ä‘Æ°á»ng khÃ´ rÃ¡o",
                'rainy': "ThÃ¡ng 5-12: MÆ°a rá»«ng, áº©m Æ°á»›t, sÆ°Æ¡ng mÃ¹"
            },
            'best_months': "ThÃ¡ng 1-3 & 11-12",
            'special_notes': [
                "ðŸŒ¡ï¸ ÄÃªm láº¡nh: CÃ³ thá»ƒ xuá»‘ng 15Â°C",
                "ðŸŒ«ï¸ SÆ°Æ¡ng mÃ¹ quanh nÄƒm",
                "ðŸŒ§ï¸ MÆ°a rÃ o báº¥t chá»£t",
                "ðŸ›£ï¸ ÄÆ°á»ng Ä‘áº¥t trÆ¡n trÆ°á»£t khi mÆ°a"
            ],
            'packing_tips': [
                "ðŸ§£ KhÄƒn quÃ ng cá»•",
                "ðŸ§¤ GÄƒng tay má»ng",
                "ðŸ¥¾ GiÃ y báº£o há»™ cao cá»•",
                "ðŸŽ’ Balo chá»‘ng nÆ°á»›c",
                "ðŸ“± Sáº¡c dá»± phÃ²ng"
            ],
            'activity_recommendations': {
                'dry_season': "Tham quan di tÃ­ch, tÃ¬m hiá»ƒu lá»‹ch sá»­",
                'rainy_season': "Nghe ká»ƒ chuyá»‡n lá»‹ch sá»­, giao lÆ°u vÄƒn nghá»‡"
            }
        },
        'quáº£ng trá»‹': {
            'title': "QUáº¢NG TRá»Š - VÃ™NG Äáº¤T Lá»ŠCH Sá»¬",
            'temp_range': "20-35Â°C",
            'seasons': {
                'dry': "ThÃ¡ng 1-8: Náº¯ng nÃ³ng, giÃ³ LÃ o",
                'rainy': "ThÃ¡ng 9-12: MÆ°a bÃ£o, lÅ© lá»¥t"
            },
            'best_months': "ThÃ¡ng 1-4 & 10-12",
            'special_notes': [
                "ðŸŒªï¸ GiÃ³ LÃ o khÃ´ nÃ³ng: ThÃ¡ng 4-8",
                "ðŸŒ€ BÃ£o thÆ°á»ng vÃ o thÃ¡ng 9-11",
                "ðŸžï¸ SÃ´ng Báº¿n Háº£i chia cáº¯t Báº¯c-Nam",
                "ðŸŒ¡ï¸ Nhiá»‡t Ä‘á»™ cao nháº¥t cÃ³ thá»ƒ lÃªn 38Â°C"
            ],
            'packing_tips': [
                "ðŸ§¢ MÅ© rá»™ng vÃ nh",
                "ðŸ•¶ï¸ KÃ­nh rÃ¢m",
                "ðŸ’¦ BÃ¬nh nÆ°á»›c cÃ¡ nhÃ¢n",
                "ðŸŒ¬ï¸ Quáº¡t cáº§m tay",
                "ðŸ§´ Kem dÆ°á»¡ng áº©m"
            ],
            'activity_recommendations': {
                'dry_season': "Tham quan di tÃ­ch, tÃ¬m hiá»ƒu lá»‹ch sá»­",
                'rainy_season': "Tham quan báº£o tÃ ng, xem phim tÃ i liá»‡u"
            }
        }
    }
    
    # Láº¥y dá»¯ liá»‡u thá»i tiáº¿t cho Ä‘á»‹a Ä‘iá»ƒm
    if location_lower in weather_data:
        data = weather_data[location_lower]
        reply += f"**{data['title']}**\n\n"
        
        reply += "ðŸ“Š **THÃ”NG Sá» CHÃNH:**\n"
        reply += f"â€¢ **Nhiá»‡t Ä‘á»™:** {data['temp_range']}\n"
        reply += f"â€¢ **MÃ¹a khÃ´:** {data['seasons']['dry']}\n"
        reply += f"â€¢ **MÃ¹a mÆ°a:** {data['seasons']['rainy']}\n"
        reply += f"â€¢ **ThÃ¡ng Ä‘áº¹p nháº¥t:** {data['best_months']}\n\n"
        
        reply += "âš ï¸ **Äáº¶C ÄIá»‚M ÄÃNG CHÃš Ã:**\n"
        for note in data['special_notes']:
            reply += f"â€¢ {note}\n"
        reply += "\n"
        
        reply += "ðŸŽ’ **CHUáº¨N Bá»Š HÃ€NH LÃ:**\n"
        for tip in data['packing_tips']:
            reply += f"â€¢ {tip}\n"
        reply += "\n"
        
        reply += "ðŸŽ¯ **HOáº T Äá»˜NG THEO MÃ™A:**\n"
        reply += f"â€¢ **MÃ¹a khÃ´:** {data['activity_recommendations']['dry_season']}\n"
        reply += f"â€¢ **MÃ¹a mÆ°a:** {data['activity_recommendations']['rainy_season']}\n\n"
        
    else:
        reply += f"**{location.upper()} - KHÃ Háº¬U MIá»€N TRUNG VIá»†T NAM**\n\n"
        reply += "ðŸŒ¡ï¸ **Äáº¶C TRÆ¯NG CHUNG:**\n"
        reply += "â€¢ KhÃ­ háº­u nhiá»‡t Ä‘á»›i giÃ³ mÃ¹a\n"
        reply += "â€¢ Hai mÃ¹a rÃµ rá»‡t: khÃ´ & mÆ°a\n"
        reply += "â€¢ GiÃ³ mÃ¹a ÄÃ´ng Báº¯c (thÃ¡ng 10-3)\n"
        reply += "â€¢ GiÃ³ mÃ¹a TÃ¢y Nam (thÃ¡ng 4-9)\n\n"
        
        reply += "ðŸ“… **MÃ™A DU Lá»ŠCH Tá»T NHáº¤T:**\n"
        reply += "â€¢ **ThÃ¡ng 1-4:** MÃ¡t máº», Ã­t mÆ°a\n"
        reply += "â€¢ **ThÃ¡ng 10-12:** Dá»‹u nháº¹, hoa ná»Ÿ\n"
        reply += "â€¢ **TrÃ¡nh:** ThÃ¡ng 9-11 (mÆ°a bÃ£o)\n\n"
        
        reply += "ðŸ’¡ **Lá»œI KHUYÃŠN CHUNG:**\n"
        reply += "1. Check dá»± bÃ¡o 3 ngÃ y trÆ°á»›c khi Ä‘i\n"
        reply += "2. Chuáº©n bá»‹ Ä‘á»“ dÃ¹ng Ä‘a dáº¡ng\n"
        reply += "3. Linh hoáº¡t thay Ä‘á»•i lá»‹ch trÃ¬nh\n"
        reply += "4. LuÃ´n cÃ³ phÆ°Æ¡ng Ã¡n dá»± phÃ²ng\n\n"
    
    # ThÃªm thÃ´ng tin tour liÃªn quan
    if location_tours:
        reply += "ðŸ—ºï¸ **TOUR RUBY WINGS PHÃ™ Há»¢P:**\n"
        
        # PhÃ¢n loáº¡i tour theo mÃ¹a
        dry_season_tours = []
        all_season_tours = []
        
        for tour in location_tours[:6]:
            tour_summary = (tour.summary or "").lower()
            tour_name = (tour.name or "").lower()
            
            # PhÃ¢n loáº¡i sÆ¡ bá»™
            if any(keyword in tour_summary for keyword in ['trong nhÃ ', 'báº£o tÃ ng', 'vÄƒn hÃ³a', 'áº©m thá»±c']):
                all_season_tours.append(tour)
            elif any(keyword in tour_summary for keyword in ['trekking', 'leo nÃºi', 'thiÃªn nhiÃªn', 'rá»«ng']):
                dry_season_tours.append(tour)
            else:
                all_season_tours.append(tour)
        
        if dry_season_tours:
            reply += "ðŸŒ¤ï¸ **MÃ™A KHÃ” (phÃ¹ há»£p outdoor):**\n"
            for tour in dry_season_tours[:2]:
                reply += f"â€¢ **{tour.name}**"
                if tour.duration:
                    reply += f" ({tour.duration})"
                reply += "\n"
            reply += "\n"
        
        if all_season_tours:
            reply += "ðŸŒˆ **QUANH NÄ‚M (má»i thá»i tiáº¿t):**\n"
            for tour in all_season_tours[:2]:
                reply += f"â€¢ **{tour.name}**"
                if tour.duration:
                    reply += f" ({tour.duration})"
                reply += "\n"
            reply += "\n"
    
    reply += "ðŸ“ž **TÆ° váº¥n chi tiáº¿t vá» thá»i tiáº¿t vÃ  tour phÃ¹ há»£p:** 0332510486\n"
    reply += "ðŸŒ **Check dá»± bÃ¡o thá»i tiáº¿t chi tiáº¿t:** weather.com/vietnam"
    
    return reply


def _get_location_info(location, location_tours):
    """Tráº£ lá»i thÃ´ng tin Ä‘á»‹a Ä‘iá»ƒm - NÃ‚NG Cáº¤P CHI TIáº¾T"""
    location_lower = location.lower()
    reply = f"ðŸ“ **KHÃM PHÃ {location.upper()}** ðŸ“\n\n"
    
    location_data = {
        'huáº¿': {
            'title': "HUáº¾ - KINH ÄÃ” TRIá»€U NGUYá»„N, DI Sáº¢N UNESCO",
            'highlights': [
                "ðŸ›ï¸ 7 Di sáº£n UNESCO: Äáº¡i Ná»™i, LÄƒng táº©m, NhÃ£ nháº¡c...",
                "ðŸœ áº¨m thá»±c cung Ä‘Ã¬nh: 1,300 mÃ³n Äƒn Ä‘áº·c sáº¯c",
                "ðŸžï¸ ThiÃªn nhiÃªn: SÃ´ng HÆ°Æ¡ng, NÃºi Ngá»±, biá»ƒn LÄƒng CÃ´",
                "ðŸŽ­ VÄƒn hÃ³a: Festival Huáº¿, lá»… há»™i cung Ä‘Ã¬nh"
            ],
            'must_see': [
                "1. Äáº¡i Ná»™i Huáº¿ - HoÃ ng thÃ nh nhÃ  Nguyá»…n",
                "2. LÄƒng Tá»± Äá»©c - Kiáº¿n trÃºc hÃ i hÃ²a thiÃªn nhiÃªn",
                "3. ChÃ¹a ThiÃªn Má»¥ - Biá»ƒu tÆ°á»£ng tÃ¢m linh",
                "4. Cáº§u TrÃ ng Tiá»n - Biá»ƒu tÆ°á»£ng cá»§a Huáº¿",
                "5. Chá»£ ÄÃ´ng Ba - Trung tÃ¢m áº©m thá»±c"
            ],
            'cultural_significance': "Trung tÃ¢m vÄƒn hÃ³a, chÃ­nh trá»‹ Viá»‡t Nam tháº¿ ká»· 19-20",
            'best_for': "Lá»‹ch sá»­, áº©m thá»±c, nhiáº¿p áº£nh, tÃ¢m linh",
            'travel_tips': [
                "â° DÃ nh Ã­t nháº¥t 2 ngÃ y Ä‘á»ƒ khÃ¡m phÃ¡",
                "ðŸš¶ Äi bá»™ hoáº·c xÃ­ch lÃ´ Ä‘á»ƒ cáº£m nháº­n",
                "ðŸŽ« Mua vÃ© combo tiáº¿t kiá»‡m",
                "ðŸŒ™ Tráº£i nghiá»‡m Huáº¿ vá» Ä‘Ãªm"
            ]
        },
        'báº¡ch mÃ£': {
            'title': "VÆ¯á»œN QUá»C GIA Báº CH MÃƒ - THIÃŠN ÄÆ¯á»œNG XANH",
            'highlights': [
                "ðŸŒ³ Rá»«ng nguyÃªn sinh rá»™ng 37,000ha",
                "ðŸ¦œ 2,373 loÃ i Ä‘á»™ng thá»±c váº­t",
                "ðŸŒ¡ï¸ KhÃ­ háº­u Ã´n Ä‘á»›i quanh nÄƒm",
                "ðŸžï¸ Há»‡ thá»‘ng thÃ¡c, suá»‘i, Ä‘á»‰nh nÃºi hÃ¹ng vÄ©"
            ],
            'must_see': [
                "1. Äá»‰nh Báº¡ch MÃ£ (1,450m) - Ngáº¯m toÃ n cáº£nh",
                "2. ThÃ¡c Äá»— QuyÃªn - ThÃ¡c nÆ°á»›c Ä‘áº¹p nháº¥t",
                "3. Há»“ Truá»“i - Há»“ nÆ°á»›c ngá»t tá»± nhiÃªn",
                "4. Rá»«ng ChÃ² Äen - Rá»«ng nguyÃªn sinh",
                "5. VÆ°á»n Lan - HÆ¡n 300 loÃ i lan rá»«ng"
            ],
            'cultural_significance': "Khu dá»± trá»¯ sinh quyá»ƒn tháº¿ giá»›i",
            'best_for': "Trekking, thiá»n, nghiÃªn cá»©u, nhiáº¿p áº£nh thiÃªn nhiÃªn",
            'travel_tips': [
                "â° Cáº§n Ã­t nháº¥t 1 ngÃ y, tá»‘t nháº¥t 2 ngÃ y 1 Ä‘Ãªm",
                "ðŸ¥¾ Chuáº©n bá»‹ giÃ y trekking chuyÃªn dá»¥ng",
                "ðŸ“¸ Mang theo á»‘ng nhÃ²m, mÃ¡y áº£nh",
                "ðŸŒ™ á»ž láº¡i qua Ä‘Ãªm Ä‘á»ƒ tráº£i nghiá»‡m trá»n váº¹n"
            ]
        },
        'trÆ°á»ng sÆ¡n': {
            'title': "DÃƒY TRÆ¯á»œNG SÆ N - HUYá»€N THOáº I ÄÆ¯á»œNG Há»’ CHÃ MINH",
            'highlights': [
                "ðŸŽ–ï¸ Di tÃ­ch lá»‹ch sá»­ chiáº¿n tranh",
                "ðŸŒ³ Rá»«ng nhiá»‡t Ä‘á»›i nguyÃªn sinh",
                "ðŸ‘¥ VÄƒn hÃ³a dÃ¢n tá»™c VÃ¢n Kiá»u, Pa KÃ´",
                "ðŸžï¸ Cáº£nh quan hÃ¹ng vÄ©, hoang sÆ¡"
            ],
            'must_see': [
                "1. ÄÆ°á»ng Há»“ ChÃ­ Minh - Huyáº¿t máº¡ch lá»‹ch sá»­",
                "2. ThÃ nh cá»• Quáº£ng Trá»‹ - Chá»©ng tÃ­ch chiáº¿n tranh",
                "3. Äá»‹a Ä‘áº¡o Vá»‹nh Má»‘c - ThÃ nh phá»‘ dÆ°á»›i lÃ²ng Ä‘áº¥t",
                "4. Cáº§u Hiá»n LÆ°Æ¡ng - Biá»ƒu tÆ°á»£ng chia cáº¯t",
                "5. NghÄ©a trang TrÆ°á»ng SÆ¡n - NÆ¡i yÃªn nghá»‰ anh hÃ¹ng"
            ],
            'cultural_significance': "Chá»©ng nhÃ¢n lá»‹ch sá»­, biá»ƒu tÆ°á»£ng cá»§a sá»± hy sinh vÃ  chiáº¿n tháº¯ng",
            'best_for': "TÃ¬m hiá»ƒu lá»‹ch sá»­, tri Ã¢n, nghiÃªn cá»©u, tráº£i nghiá»‡m vÄƒn hÃ³a",
            'travel_tips': [
                "â° DÃ nh Ã­t nháº¥t 2 ngÃ y Ä‘á»ƒ tháº¥u hiá»ƒu",
                "ðŸ“š TÃ¬m hiá»ƒu lá»‹ch sá»­ trÆ°á»›c khi Ä‘i",
                "ðŸ™ ThÃ¡i Ä‘á»™ nghiÃªm trang táº¡i di tÃ­ch",
                "ðŸŽ¤ ThuÃª HDV am hiá»ƒu lá»‹ch sá»­"
            ]
        },
        'quáº£ng trá»‹': {
            'title': "QUáº¢NG TRá»Š - VÃ™NG Äáº¤T ANH HÃ™NG",
            'highlights': [
                "âš”ï¸ Chiáº¿n trÆ°á»ng Ã¡c liá»‡t nháº¥t",
                "ðŸžï¸ Cáº£nh quan sÃ´ng nÆ°á»›c há»¯u tÃ¬nh",
                "ðŸŒ¾ NÃ´ng nghiá»‡p trÃ¹ phÃº",
                "ðŸ–ï¸ BÃ£i biá»ƒn hoang sÆ¡ Ä‘áº¹p"
            ],
            'must_see': [
                "1. SÃ´ng Báº¿n Háº£i & Cáº§u Hiá»n LÆ°Æ¡ng",
                "2. Äá»‹a Ä‘áº¡o Vá»‹nh Má»‘c",
                "3. ThÃ nh cá»• Quáº£ng Trá»‹",
                "4. Cá»­a TÃ¹ng - BÃ£i táº¯m Ä‘áº¹p",
                "5. Äáº£o Cá»“n Cá» - Tiá»n tiÃªu Tá»• quá»‘c"
            ],
            'cultural_significance': "NÆ¡i diá»…n ra nhá»¯ng tráº­n Ä‘Ã¡nh lá»‹ch sá»­, biá»ƒu tÆ°á»£ng cá»§a lÃ²ng yÃªu nÆ°á»›c",
            'best_for': "Lá»‹ch sá»­, tri Ã¢n, nhiáº¿p áº£nh, tráº£i nghiá»‡m vÄƒn hÃ³a",
            'travel_tips': [
                "â° DÃ nh 1-2 ngÃ y tham quan",
                "ðŸ“œ Äá»c tÃ i liá»‡u lá»‹ch sá»­",
                "ðŸŽ¥ Xem phim tÃ i liá»‡u trÆ°á»›c",
                "ðŸŒ… Ngáº¯m bÃ¬nh minh trÃªn sÃ´ng Báº¿n Háº£i"
            ]
        }
    }
    
    # Láº¥y dá»¯ liá»‡u Ä‘á»‹a Ä‘iá»ƒm
    if location_lower in location_data:
        data = location_data[location_lower]
        reply += f"**{data['title']}**\n\n"
        
        reply += "ðŸŒŸ **ÄIá»‚M Ná»”I Báº¬T:**\n"
        for highlight in data['highlights']:
            reply += f"â€¢ {highlight}\n"
        reply += "\n"
        
        reply += "ðŸŽ¯ **KHÃ”NG THá»‚ Bá»Ž QUA:**\n"
        for spot in data['must_see']:
            reply += f"{spot}\n"
        reply += "\n"
        
        reply += "ðŸ“š **Ã NGHÄ¨A VÄ‚N HÃ“A - Lá»ŠCH Sá»¬:**\n"
        reply += f"{data['cultural_significance']}\n\n"
        
        reply += "ðŸ‘¥ **PHÃ™ Há»¢P Vá»šI:**\n"
        reply += f"â€¢ {data['best_for']}\n\n"
        
        reply += "ðŸ’¡ **Máº¸O DU Lá»ŠCH:**\n"
        for tip in data['travel_tips']:
            reply += f"â€¢ {tip}\n"
        reply += "\n"
        
    else:
        reply += f"**{location.upper()} - ÄIá»‚M Äáº¾N Háº¤P DáºªN MIá»€N TRUNG**\n\n"
        reply += "Miá»n Trung Viá»‡t Nam vá»›i nhiá»u Ä‘iá»ƒm Ä‘áº¿n Ä‘a dáº¡ng:\n\n"
        reply += "ðŸ›ï¸ **DI Sáº¢N VÄ‚N HÃ“A:**\n"
        reply += "â€¢ Huáº¿: Di sáº£n UNESCO\n"
        reply += "â€¢ Há»™i An: Phá»‘ cá»•\n"
        reply += "â€¢ Má»¹ SÆ¡n: ThÃ¡nh Ä‘á»‹a ChÄƒm Pa\n\n"
        
        reply += "ðŸŒ¿ **THIÃŠN NHIÃŠN:**\n"
        reply += "â€¢ Báº¡ch MÃ£: VÆ°á»n quá»‘c gia\n"
        reply += "â€¢ SÆ¡n TrÃ : BÃ¡n Ä‘áº£o nguyÃªn sinh\n"
        reply += "â€¢ CÃ¹ Lao ChÃ m: Äáº£o sinh thÃ¡i\n\n"
        
        reply += "ðŸŽ–ï¸ **Lá»ŠCH Sá»¬:**\n"
        reply += "â€¢ Quáº£ng Trá»‹: Chiáº¿n trÆ°á»ng xÆ°a\n"
        reply += "â€¢ ÄÆ°á»ng HCM: Huyá»n thoáº¡i\n"
        reply += "â€¢ Äá»‹a Ä‘áº¡o: CÃ´ng trÃ¬nh ngáº§m\n\n"
        
        reply += "ðŸœ **áº¨M THá»°C:**\n"
        reply += "â€¢ Huáº¿: áº¨m thá»±c cung Ä‘Ã¬nh\n"
        reply += "â€¢ ÄÃ  Náºµng: Háº£i sáº£n tÆ°Æ¡i ngon\n"
        reply += "â€¢ Quáº£ng Nam: Má»³ Quáº£ng, Cao láº§u\n\n"
    
    # ThÃªm thÃ´ng tin tour liÃªn quan
    if location_tours:
        reply += "ðŸ—ºï¸ **TOUR RUBY WINGS Táº I ÄÃ‚Y:**\n"
        
        # PhÃ¢n loáº¡i tour theo loáº¡i hÃ¬nh
        categories = {
            'history': [],
            'nature': [],
            'culture': [],
            'wellness': []
        }
        
        for tour in location_tours[:8]:
            tour_summary = (tour.summary or "").lower()
            tour_name = (tour.name or "").lower()
            
            if any(keyword in tour_summary for keyword in ['lá»‹ch sá»­', 'di tÃ­ch', 'chiáº¿n tranh', 'tri Ã¢n']):
                categories['history'].append(tour)
            elif any(keyword in tour_summary for keyword in ['thiÃªn nhiÃªn', 'rá»«ng', 'trekking', 'khÃ¡m phÃ¡']):
                categories['nature'].append(tour)
            elif any(keyword in tour_summary for keyword in ['vÄƒn hÃ³a', 'áº©m thá»±c', 'lÃ ng nghá»', 'truyá»n thá»‘ng']):
                categories['culture'].append(tour)
            elif any(keyword in tour_summary for keyword in ['thiá»n', 'yoga', 'retreat', 'chá»¯a lÃ nh']):
                categories['wellness'].append(tour)
            else:
                categories['nature'].append(tour)
        
        # Hiá»ƒn thá»‹ theo tá»«ng loáº¡i
        category_names = {
            'history': 'ðŸ›ï¸ Lá»ŠCH Sá»¬',
            'nature': 'ðŸŒ¿ THIÃŠN NHIÃŠN',
            'culture': 'ðŸœ VÄ‚N HÃ“A',
            'wellness': 'ðŸ§˜ WELLNESS'
        }
        
        for cat_key, cat_name in category_names.items():
            if categories[cat_key]:
                reply += f"\n{cat_name}:\n"
                for tour in categories[cat_key][:2]:
                    reply += f"â€¢ **{tour.name}**"
                    if tour.duration:
                        reply += f" ({tour.duration})"
                    if tour.price:
                        price_short = tour.price[:40] + "..." if len(tour.price) > 40 else tour.price
                        reply += f" - {price_short}"
                    reply += "\n"
        
        reply += "\n"
    
    reply += "ðŸ“ž **Äáº·t tour khÃ¡m phÃ¡ chi tiáº¿t:** 0332510486\n"
    reply += "ðŸ—“ï¸ **TÆ° váº¥n lá»‹ch trÃ¬nh phÃ¹ há»£p:** LiÃªn há»‡ Ä‘á»ƒ Ä‘Æ°á»£c thiáº¿t káº¿ riÃªng"
    
    return reply


def _get_food_culture_response(message_lower, tour_indices):
    """Tráº£ lá»i vá» áº©m thá»±c vÃ  vÄƒn hÃ³a - NÃ‚NG Cáº¤P CHI TIáº¾T"""
    # Kiá»ƒm tra cá»¥ thá»ƒ loáº¡i áº©m thá»±c/vÄƒn hÃ³a Ä‘Æ°á»£c há»i
    if 'bÃ¡nh bÃ¨o' in message_lower:
        return _get_banh_beo_detail()
    elif 'bÃºn bÃ²' in message_lower or 'bun bo' in message_lower:
        return _get_bun_bo_hue_detail()
    elif 'cÆ¡m háº¿n' in message_lower:
        return _get_com_hen_detail()
    elif 'máº¯m nÃªm' in message_lower:
        return _get_mam_nem_detail()
    elif 'áº©m thá»±c huáº¿' in message_lower or 'Ä‘áº·c sáº£n huáº¿' in message_lower:
        return _get_hue_food_overview()
    elif 'vÄƒn hÃ³a huáº¿' in message_lower or 'vÄƒn hÃ³a miá»n trung' in message_lower:
        return _get_hue_culture_overview()
    elif 'lá»‹ch sá»­' in message_lower or 'di tÃ­ch' in message_lower or 'di sáº£n' in message_lower:
        return _get_history_culture_response()
    else:
        return _get_general_food_culture_response(message_lower, tour_indices)


def _get_banh_beo_detail():
    """Chi tiáº¿t vá» bÃ¡nh bÃ¨o Huáº¿"""
    reply = "ðŸœ **BÃNH BÃˆO HUáº¾ - TINH HOA áº¨M THá»°C CUNG ÄÃŒNH** ðŸœ\n\n"
    
    reply += "ðŸ“œ **NGUá»’N Gá»C Lá»ŠCH Sá»¬:**\n"
    reply += "â€¢ Xuáº¥t hiá»‡n tá»« thá»i nhÃ  Nguyá»…n (1802-1945)\n"
    reply += "â€¢ Ban Ä‘áº§u chá»‰ phá»¥c vá»¥ trong cung Ä‘Ã¬nh\n"
    reply += "â€¢ Sau 1945, lan ra dÃ¢n gian\n"
    reply += "â€¢ TÃªn gá»i tá»« hÃ¬nh dÃ¡ng giá»‘ng lÃ¡ bÃ¨o trÃªn máº·t nÆ°á»›c\n\n"
    
    reply += "ðŸ‘‘ **Äáº¶C ÄIá»‚M CUNG ÄÃŒNH:**\n"
    reply += "â€¢ **Tinh táº¿:** Má»—i chÃ©n chá»‰ 2-3 muá»—ng bá»™t\n"
    reply += "â€¢ **Cáº§u ká»³:** 15+ cÃ´ng Ä‘oáº¡n chuáº©n bá»‹\n"
    reply += "â€¢ **Äáº¹p máº¯t:** TrÃ¬nh bÃ y nhÆ° tÃ¡c pháº©m nghá»‡ thuáº­t\n"
    reply += "â€¢ **HÃ i hÃ²a:** CÃ¢n báº±ng 5 vá»‹ cÆ¡ báº£n\n\n"
    
    reply += "ðŸ¥£ **THÃ€NH PHáº¦N CHUáº¨N:**\n"
    
    reply += "1. **BÃNH:**\n"
    reply += "   â€¢ Gáº¡o ngon (náº¿p táº» pha)\n"
    reply += "   â€¢ NgÃ¢m 8-12 giá»\n"
    reply += "   â€¢ Xay má»‹n, lá»c ká»¹\n"
    reply += "   â€¢ Háº¥p cÃ¡ch thá»§y 5-7 phÃºt\n\n"
    
    reply += "2. **NHÃ‚N:**\n"
    reply += "   â€¢ TÃ´m sÃº bÃ³c vá»\n"
    reply += "   â€¢ Thá»‹t heo xay\n"
    reply += "   â€¢ Má»¡ hÃ nh phi thÆ¡m\n"
    reply += "   â€¢ Äáº­u phá»™ng rang\n\n"
    
    reply += "3. **NÆ¯á»šC Máº®M:**\n"
    reply += "   â€¢ Máº¯m nÃªm Huáº¿ Ä‘áº·c trÆ°ng\n"
    reply += "   â€¢ ÄÆ°á»ng, tá»i, á»›t, chanh\n"
    reply += "   â€¢ Náº¥u sÃ´i, Ä‘á»ƒ nguá»™i\n\n"
    
    reply += "4. **RAU Sá»NG:**\n"
    reply += "   â€¢ XÃ  lÃ¡ch, rau thÆ¡m\n"
    reply += "   â€¢ á»št xanh Huáº¿\n"
    reply += "   â€¢ GiÃ¡ Ä‘á»—\n\n"
    
    reply += "ðŸ½ï¸ **QUY TRÃŒNH THÆ¯á»žNG THá»¨C:**\n"
    reply += "1. DÃ¹ng thÃ¬a nhá» xÃºc tá»«ng chÃ©n\n"
    reply += "2. Chan 1/2 thÃ¬a nÆ°á»›c máº¯m\n"
    reply += "3. ThÃªm Ã­t rau sá»‘ng\n"
    reply += "4. Trá»™n Ä‘á»u, thÆ°á»Ÿng thá»©c\n"
    reply += "5. Uá»‘ng trÃ  nÃ³ng giá»¯a cÃ¡c chÃ©n\n\n"
    
    reply += "ðŸ† **BIáº¾N Táº¤U Äáº¶C BIá»†T:**\n"
    reply += "â€¢ **BÃ¡nh bÃ¨o chÃ©n:** Truyá»n thá»‘ng\n"
    reply += "â€¢ **BÃ¡nh bÃ¨o dÄ©a:** Tiá»‡n lá»£i\n"
    reply += "â€¢ **BÃ¡nh bÃ¨o tháº­p cáº©m:** Äáº§y Ä‘á»§ nhÃ¢n\n"
    reply += "â€¢ **BÃ¡nh bÃ¨o chay:** DÃ nh cho Pháº­t tá»­\n\n"
    
    reply += "ðŸ“ **Äá»ŠA CHá»ˆ NGON:**\n"
    reply += "1. **BÃ¡nh bÃ¨o Huáº¿ - 123 ÄÆ°á»ng ABC**\n"
    reply += "2. **QuÃ¡n BÃ  Äá»£ - Khu phá»‘ cá»•**\n"
    reply += "3. **Chá»£ ÄÃ´ng Ba - Gian hÃ ng 45**\n"
    reply += "4. **LÃ ng bÃ¡nh bÃ¨o PhÃº Háº­u**\n\n"
    
    reply += "ðŸŽ¯ **TRáº¢I NGHIá»†M Vá»šI RUBY WINGS:**\n"
    reply += "â€¢ **Tour áº¨m thá»±c Huáº¿:** Há»c lÃ m tá»« A-Z\n"
    reply += "â€¢ **Tour VÄƒn hÃ³a:** ThÄƒm lÃ ng nghá» truyá»n thá»‘ng\n"
    reply += "â€¢ **Tour ÄÃªm Huáº¿:** ThÆ°á»Ÿng thá»©c táº¡i quÃ¡n Ä‘áº·c sáº£n\n"
    reply += "â€¢ **Tour Masterclass:** Há»c tá»« nghá»‡ nhÃ¢n 30 nÄƒm kinh nghiá»‡m\n\n"
    
    reply += "ðŸ“ž **Äáº·t tour áº©m thá»±c Huáº¿:** 0332510486\n"
    reply += "ðŸ‘¨â€ðŸ³ **Há»c lÃ m bÃ¡nh bÃ¨o:** Workshop hÃ ng tuáº§n"
    
    return reply


def _get_bun_bo_hue_detail():
    """Chi tiáº¿t vá» bÃºn bÃ² Huáº¿"""
    reply = "ðŸœ **BÃšN BÃ’ HUáº¾ - MÃ“N NGON Äáº¬M ÄÃ€ HUYá»€N THOáº I** ðŸœ\n\n"
    
    reply += "ðŸ“œ **Lá»ŠCH Sá»¬ 100 NÄ‚M:**\n"
    reply += "â€¢ Ra Ä‘á»i Ä‘áº§u tháº¿ ká»· 20\n"
    reply += "â€¢ Káº¿t há»£p áº©m thá»±c cung Ä‘Ã¬nh & dÃ¢n gian\n"
    reply += "â€¢ Biá»ƒu tÆ°á»£ng áº©m thá»±c Huáº¿\n"
    reply += "â€¢ ÄÆ°á»£c UNESCO vinh danh\n\n"
    
    reply += "ðŸ¥˜ **BÃ QUYáº¾T NÆ¯á»šC DÃ™NG:**\n"
    reply += "â€¢ XÆ°Æ¡ng bÃ² háº§m 12-15 giá»\n"
    reply += "â€¢ Sáº£, riá»ng, máº¯m ruá»‘c\n"
    reply += "â€¢ MÃ u Ä‘á» tá»« á»›t bá»™t\n"
    reply += "â€¢ Vá»‹ cay Ä‘áº·c trÆ°ng\n\n"
    
    reply += "ðŸŽ¯ **TOUR áº¨M THá»°C BÃšN BÃ’:**\n"
    reply += "1. **Há»c náº¥u tá»« cÆ¡ báº£n:** 2 giá»\n"
    reply += "2. **Chá»£ sÃ¡ng & náº¥u Äƒn:** 4 giá»\n"
    reply += "3. **Masterclass nghá»‡ nhÃ¢n:** 6 giá»\n"
    reply += "4. **Tráº£i nghiá»‡m toÃ n diá»‡n:** 1 ngÃ y\n\n"
    
    reply += "ðŸ“ž **Äáº·t tour:** 0332510486"
    
    return reply


def _get_com_hen_detail():
    """Chi tiáº¿t vá» cÆ¡m háº¿n"""
    reply = "ðŸš **CÆ M Háº¾N - Äáº¶C Sáº¢N DÃ‚N DÃƒ HUáº¾** ðŸš\n\n"
    
    reply += "ðŸŒ¾ **Háº¾N SÃ”NG HÆ¯Æ NG:**\n"
    reply += "â€¢ Báº¯t tá»« sÃ´ng HÆ°Æ¡ng\n"
    reply += "â€¢ Nhá», thÆ¡m, ngá»t Ä‘áº·c biá»‡t\n"
    reply += "â€¢ Cháº¿ biáº¿n 10+ mÃ³n\n"
    reply += "â€¢ GiÃ¡ trá»‹ dinh dÆ°á»¡ng cao\n\n"
    
    reply += "ðŸŽ¯ **TOUR áº¨M THá»°C CÆ M Háº¾N:**\n"
    reply += "â€¢ ThÄƒm lÃ ng chÃ i\n"
    reply += "â€¢ Há»c báº¯t & cháº¿ biáº¿n\n"
    reply += "â€¢ Náº¥u 5 mÃ³n tá»« háº¿n\n"
    reply += "â€¢ ThÆ°á»Ÿng thá»©c táº¡i chá»—\n\n"
    
    reply += "ðŸ“ž **Äáº·t tour:** 0332510486"
    
    return reply


def _get_mam_nem_detail():
    """Chi tiáº¿t vá» máº¯m nÃªm"""
    reply = "ðŸ¥« **Máº®M NÃŠM - LINH Há»’N áº¨M THá»°C HUáº¾** ðŸ¥«\n\n"
    
    reply += "ðŸŸ **LÃŠN MEN Tá»° NHIÃŠN:**\n"
    reply += "â€¢ CÃ¡ cÆ¡m tÆ°Æ¡i\n"
    reply += "â€¢ Muá»‘i biá»ƒn tinh khiáº¿t\n"
    reply += "â€¢ LÃªn men 6-12 thÃ¡ng\n"
    reply += "â€¢ HÆ°Æ¡ng vá»‹ Ä‘áº­m Ä‘Ã \n\n"
    
    reply += "ðŸŽ¯ **WORKSHOP Máº®M NÃŠM:**\n"
    reply += "â€¢ ThÄƒm lÃ ng lÃ m máº¯m\n"
    reply += "â€¢ Há»c ká»¹ thuáº­t á»§\n"
    reply += "â€¢ Cháº¿ biáº¿n 3 loáº¡i máº¯m\n"
    reply += "â€¢ ÄÃ³ng chai mang vá»\n\n"
    
    reply += "ðŸ“ž **Äáº·t workshop:** 0332510486"
    
    return reply


def _get_hue_food_overview():
    """Tá»•ng quan áº©m thá»±c Huáº¿"""
    reply = "ðŸ½ï¸ **áº¨M THá»°C HUáº¾ - DI Sáº¢N VÄ‚N HÃ“A PHI Váº¬T THá»‚** ðŸ½ï¸\n\n"
    
    reply += "ðŸ‘‘ **3 DÃ’NG áº¨M THá»°C CHÃNH:**\n\n"
    
    reply += "1. **áº¨M THá»°C CUNG ÄÃŒNH:**\n"
    reply += "   â€¢ Phá»¥c vá»¥ vua chÃºa\n"
    reply += "   â€¢ 1,300 mÃ³n Äƒn\n"
    reply += "   â€¢ TrÃ¬nh bÃ y nghá»‡ thuáº­t\n"
    reply += "   â€¢ NguyÃªn liá»‡u quÃ½ hiáº¿m\n\n"
    
    reply += "2. **áº¨M THá»°C DÃ‚N GIAN:**\n"
    reply += "   â€¢ Phá»• biáº¿n trong dÃ¢n\n"
    reply += "   â€¢ NguyÃªn liá»‡u Ä‘á»‹a phÆ°Æ¡ng\n"
    reply += "   â€¢ HÆ°Æ¡ng vá»‹ Ä‘áº­m Ä‘Ã \n"
    reply += "   â€¢ GiÃ¡ cáº£ bÃ¬nh dÃ¢n\n\n"
    
    reply += "3. **áº¨M THá»°C CHAY:**\n"
    reply += "   â€¢ DÃ nh cho Pháº­t tá»­\n"
    reply += "   â€¢ 200+ mÃ³n chay\n"
    reply += "   â€¢ Tinh táº¿, thanh Ä‘áº¡m\n"
    reply += "   â€¢ Dinh dÆ°á»¡ng cao\n\n"
    
    reply += "ðŸŽ¯ **CÃC MÃ“N TIÃŠU BIá»‚U:**\n"
    
    reply += "ðŸœ **MÃ“N BÃšN/Má»²:**\n"
    reply += "â€¢ BÃºn bÃ² Huáº¿\n"
    reply += "â€¢ BÃºn thá»‹t nÆ°á»›ng\n"
    reply += "â€¢ Má»³ Quáº£ng\n"
    reply += "â€¢ BÃºn háº¿n\n\n"
    
    reply += "ðŸš **MÃ“N CÆ M:**\n"
    reply += "â€¢ CÆ¡m háº¿n\n"
    reply += "â€¢ CÆ¡m Ã¢m phá»§\n"
    reply += "â€¢ CÆ¡m gÃ  Há»™i An\n"
    reply += "â€¢ CÆ¡m niÃªu\n\n"
    
    reply += "ðŸ¥Ÿ **BÃNH:**\n"
    reply += "â€¢ BÃ¡nh bÃ¨o\n"
    reply += "â€¢ BÃ¡nh náº­m\n"
    reply += "â€¢ BÃ¡nh bá»™t lá»c\n"
    reply += "â€¢ BÃ¡nh Æ°á»›t\n\n"
    
    reply += "ðŸ¢ **MÃ“N NHáº¬U:**\n"
    reply += "â€¢ Nem lá»¥i\n"
    reply += "â€¢ BÃ² nÆ°á»›ng lÃ¡ lá»‘t\n"
    reply += "â€¢ Cháº£ tÃ´m\n"
    reply += "â€¢ Gá»i cÃ¡ trÃ­ch\n\n"
    
    reply += "ðŸ¨ **TRÃNG MIá»†NG:**\n"
    reply += "â€¢ ChÃ¨ Huáº¿\n"
    reply += "â€¢ BÃ¡nh flan\n"
    reply += "â€¢ Rau cÃ¢u\n"
    reply += "â€¢ Sá»¯a Ä‘áº­u nÃ nh\n\n"
    
    reply += "ðŸŽ¯ **TOUR áº¨M THá»°C RUBY WINGS:**\n"
    
    reply += "1. **TOUR KHÃM PHÃ áº¨M THá»°C (1 ngÃ y):**\n"
    reply += "   â€¢ Tham quan chá»£ ÄÃ´ng Ba\n"
    reply += "   â€¢ Há»c lÃ m 3 mÃ³n Huáº¿\n"
    reply += "   â€¢ ThÆ°á»Ÿng thá»©c bá»¯a trÆ°a Ä‘áº·c sáº£n\n"
    reply += "   â€¢ ThÄƒm lÃ ng nghá» truyá»n thá»‘ng\n\n"
    
    reply += "2. **TOUR áº¨M THá»°C CAO Cáº¤P (2 ngÃ y):**\n"
    reply += "   â€¢ Tráº£i nghiá»‡m áº©m thá»±c cung Ä‘Ã¬nh\n"
    reply += "   â€¢ Workshop vá»›i nghá»‡ nhÃ¢n\n"
    reply += "   â€¢ ThÄƒm vÆ°á»n rau há»¯u cÆ¡\n"
    reply += "   â€¢ DÃ¹ng bá»¯a táº¡i nhÃ  hÃ ng Michelin\n\n"
    
    reply += "3. **TOUR MASTERCLASS (3 ngÃ y):**\n"
    reply += "   â€¢ Há»c lÃ m 10 mÃ³n Huáº¿\n"
    reply += "   â€¢ Chá»©ng chá»‰ hoÃ n thÃ nh\n"
    reply += "   â€¢ NguyÃªn liá»‡u cao cáº¥p\n"
    reply += "   â€¢ ÄÆ°á»£c nghá»‡ nhÃ¢n trá»±c tiáº¿p hÆ°á»›ng dáº«n\n\n"
    
    reply += "ðŸ“ž **Äáº·t tour áº©m thá»±c:** 0332510486\n"
    reply += "ðŸ‘¨â€ðŸ³ **Äá»™i ngÅ© chuyÃªn gia áº©m thá»±c Huáº¿**\n"
    reply += "ðŸŒŸ **Chá»©ng nháº­n áº©m thá»±c quá»‘c táº¿**"
    
    return reply


def _get_hue_culture_overview():
    """Tá»•ng quan vÄƒn hÃ³a Huáº¿"""
    reply = "ðŸ›ï¸ **VÄ‚N HÃ“A HUáº¾ - DI Sáº¢N Sá»NG Äá»˜NG** ðŸ›ï¸\n\n"
    
    reply += "ðŸŽ­ **7 DI Sáº¢N UNESCO Táº I HUáº¾:**\n\n"
    
    reply += "1. **QUáº¦N THá»‚ DI TÃCH Cá» ÄÃ” HUáº¾:**\n"
    reply += "   â€¢ Äáº¡i Ná»™i (HoÃ ng thÃ nh)\n"
    reply += "   â€¢ LÄƒng Tá»± Äá»©c, Minh Máº¡ng, Kháº£i Äá»‹nh\n"
    reply += "   â€¢ ÄÃ n Nam Giao\n"
    reply += "   â€¢ Há»“ Quyá»ƒn\n\n"
    
    reply += "2. **NHÃƒ NHáº C CUNG ÄÃŒNH HUáº¾:**\n"
    reply += "   â€¢ Ã‚m nháº¡c cung Ä‘Ã¬nh\n"
    reply += "   â€¢ 12 thá»ƒ loáº¡i nháº¡c\n"
    reply += "   â€¢ Nháº¡c cá»¥ truyá»n thá»‘ng\n"
    reply += "   â€¢ Biá»ƒu diá»…n hÃ ng Ä‘Ãªm\n\n"
    
    reply += "3. **Má»˜C Báº¢N TRIá»€U NGUYá»„N:**\n"
    reply += "   â€¢ 34.619 táº¥m má»™c báº£n\n"
    reply += "   â€¢ TÃ i liá»‡u quÃ½ giÃ¡\n"
    reply += "   â€¢ Ká»¹ thuáº­t kháº¯c gá»—\n"
    reply += "   â€¢ LÆ°u trá»¯ táº¡i Trung tÃ¢m LÆ°u trá»¯\n\n"
    
    reply += "4. **CHÃ‚U Báº¢N TRIá»€U NGUYá»„N:**\n"
    reply += "   â€¢ 700 táº­p tÃ i liá»‡u\n"
    reply += "   â€¢ VÄƒn báº£n hÃ nh chÃ­nh\n"
    reply += "   â€¢ Chá»¯ HÃ¡n NÃ´m\n"
    reply += "   â€¢ GiÃ¡ trá»‹ lá»‹ch sá»­ cao\n\n"
    
    reply += "5. **THÆ  VÄ‚N TRÃŠN KIáº¾N TRÃšC CUNG ÄÃŒNH:**\n"
    reply += "   â€¢ ThÆ¡ chá»¯ HÃ¡n\n"
    reply += "   â€¢ VÄƒn tá»± trang trÃ­\n"
    reply += "   â€¢ Nghá»‡ thuáº­t thÆ° phÃ¡p\n"
    reply += "   â€¢ TrÃªn 2.500 Ã´ thÆ¡\n\n"
    
    reply += "6. **Há»† THá»NG THá»¦Y Äáº O KINH THÃ€NH:**\n"
    reply += "   â€¢ Há»‡ thá»‘ng thoÃ¡t nÆ°á»›c\n"
    reply += "   â€¢ Ká»¹ thuáº­t xÃ¢y dá»±ng\n"
    reply += "   â€¢ Báº£o tá»“n nguyÃªn váº¹n\n"
    reply += "   â€¢ CÃ´ng trÃ¬nh Ä‘á»™c Ä‘Ã¡o\n\n"
    
    reply += "7. **NGHá»† THUáº¬T BÃ€I CHÃ’I:**\n"
    reply += "   â€¢ TrÃ² chÆ¡i dÃ¢n gian\n"
    reply += "   â€¢ Káº¿t há»£p ca hÃ¡t\n"
    reply += "   â€¢ Phá»• biáº¿n dá»‹p Táº¿t\n"
    reply += "   â€¢ Di sáº£n vÄƒn hÃ³a phi váº­t thá»ƒ\n\n"
    
    reply += "ðŸŽ¨ **NGHá»€ THá»¦ CÃ”NG TRUYá»€N THá»NG:**\n"
    
    reply += "â€¢ **THÃŠU:** LÃ ng thÃªu PhÆ°á»›c TÃ­ch\n"
    reply += "â€¢ **Gá»M:** LÃ ng gá»‘m PhÆ°á»›c TÃ­ch\n"
    reply += "â€¢ **Má»˜C:** LÃ ng má»™c Kim Long\n"
    reply += "â€¢ **NÃ“N:** LÃ ng nÃ³n bÃ i thÆ¡\n"
    reply += "â€¢ **HÆ¯Æ NG:** LÃ ng hÆ°Æ¡ng Thá»§y XuÃ¢n\n"
    reply += "â€¢ **ÄÃšC Äá»’NG:** LÃ ng Ä‘Ãºc Ä‘á»“ng PhÆ°á»ng ÄÃºc\n\n"
    
    reply += "ðŸŽ­ **Lá»„ Há»˜I TRUYá»€N THá»NG:**\n"
    
    reply += "â€¢ **FESTIVAL HUáº¾:** 2 nÄƒm/láº§n\n"
    reply += "â€¢ **Lá»„ Táº¾ NAM GIAO:** ThÃ¡ng 3 Ã¢m lá»‹ch\n"
    reply += "â€¢ **Lá»„ Há»˜I ÄÃˆN Lá»’NG:** Ráº±m thÃ¡ng GiÃªng\n"
    reply += "â€¢ **Lá»„ Há»˜I THÃNG 7:** Vu lan bÃ¡o hiáº¿u\n"
    reply += "â€¢ **Lá»„ Há»˜I CUNG ÄÃŒNH:** HÃ ng thÃ¡ng\n\n"
    
    reply += "ðŸŽ¯ **TOUR VÄ‚N HÃ“A RUBY WINGS:**\n"
    
    reply += "1. **TOUR DI Sáº¢N UNESCO (1 ngÃ y):**\n"
    reply += "   â€¢ Tham quan Äáº¡i Ná»™i\n"
    reply += "   â€¢ Xem nhÃ£ nháº¡c cung Ä‘Ã¬nh\n"
    reply += "   â€¢ ThÄƒm báº£o tÃ ng má»™c báº£n\n"
    reply += "   â€¢ Tráº£i nghiá»‡m bÃ i chÃ²i\n\n"
    
    reply += "2. **TOUR LÃ€NG NGHá»€ (1 ngÃ y):**\n"
    reply += "   â€¢ ThÄƒm 3 lÃ ng nghá»\n"
    reply += "   â€¢ Há»c lÃ m thá»§ cÃ´ng\n"
    reply += "   â€¢ Mua sáº¯m sáº£n pháº©m\n"
    reply += "   â€¢ Giao lÆ°u nghá»‡ nhÃ¢n\n\n"
    
    reply += "3. **TOUR VÄ‚N HÃ“A SÃ‚U (2 ngÃ y):**\n"
    reply += "   â€¢ Tráº£i nghiá»‡m toÃ n diá»‡n\n"
    reply += "   â€¢ á»ž homestay truyá»n thá»‘ng\n"
    reply += "   â€¢ Há»c 2 nghá» thá»§ cÃ´ng\n"
    reply += "   â€¢ Tham gia lá»… há»™i\n\n"
    
    reply += "ðŸ“ž **Äáº·t tour vÄƒn hÃ³a:** 0332510486\n"
    reply += "ðŸŽ“ **HDV am hiá»ƒu vÄƒn hÃ³a Huáº¿**\n"
    reply += "ðŸ›ï¸ **Äá»‘i tÃ¡c cá»§a UNESCO Huáº¿**"
    
    return reply


def _get_history_culture_response():
    """Tráº£ lá»i vá» vÄƒn hÃ³a lá»‹ch sá»­"""
    reply = "ðŸ›ï¸ **VÄ‚N HÃ“A & Lá»ŠCH Sá»¬ MIá»€N TRUNG - NÆ I LÆ¯U GIá»® Há»’N VIá»†T** ðŸ›ï¸\n\n"
    
    reply += "ðŸ“œ **CÃC THá»œI Ká»² Lá»ŠCH Sá»¬ QUAN TRá»ŒNG:**\n\n"
    
    reply += "1. **THá»œI Ká»² CHÄ‚M PA (192-1832):**\n"
    reply += "   â€¢ VÆ°Æ¡ng quá»‘c cá»• Ä‘áº¡i\n"
    reply += "   â€¢ ThÃ¡nh Ä‘á»‹a Má»¹ SÆ¡n\n"
    reply += "   â€¢ ThÃ¡p ChÄƒm Po Nagar\n"
    reply += "   â€¢ Nghá»‡ thuáº­t Ä‘iÃªu kháº¯c Ä‘Ã¡\n\n"
    
    reply += "2. **THá»œI Ká»² Äáº I VIá»†T (1306-1802):**\n"
    reply += "   â€¢ Má»Ÿ rá»™ng lÃ£nh thá»•\n"
    reply += "   â€¢ Chiáº¿n tranh Trá»‹nh-Nguyá»…n\n"
    reply += "   â€¢ ChÃºa Nguyá»…n xá»© ÄÃ ng Trong\n"
    reply += "   â€¢ PhÃ¡t triá»ƒn vÄƒn hÃ³a\n\n"
    
    reply += "3. **THá»œI Ká»² NHÃ€ NGUYá»„N (1802-1945):**\n"
    reply += "   â€¢ Kinh Ä‘Ã´ Huáº¿\n"
    reply += "   â€¢ 13 Ä‘á»i vua Nguyá»…n\n"
    reply += "   â€¢ XÃ¢y dá»±ng Ä‘áº¡i ná»™i\n"
    reply += "   â€¢ PhÃ¡t triá»ƒn áº©m thá»±c cung Ä‘Ã¬nh\n\n"
    
    reply += "4. **THá»œI Ká»² CHIáº¾N TRANH (1945-1975):**\n"
    reply += "   â€¢ Chiáº¿n tranh ÄÃ´ng DÆ°Æ¡ng\n"
    reply += "   â€¢ Chiáº¿n tranh Viá»‡t Nam\n"
    reply += "   â€¢ VÄ© tuyáº¿n 17\n"
    reply += "   â€¢ ÄÆ°á»ng Há»“ ChÃ­ Minh\n\n"
    
    reply += "5. **THá»œI Ká»² HIá»†N Äáº I (1975-nay):**\n"
    reply += "   â€¢ Thá»‘ng nháº¥t Ä‘áº¥t nÆ°á»›c\n"
    reply += "   â€¢ Báº£o tá»“n di sáº£n\n"
    reply += "   â€¢ PhÃ¡t triá»ƒn du lá»‹ch\n"
    reply += "   â€¢ Há»™i nháº­p quá»‘c táº¿\n\n"
    
    reply += "ðŸŽ–ï¸ **DI TÃCH Lá»ŠCH Sá»¬ QUAN TRá»ŒNG:**\n"
    
    reply += "âš”ï¸ **QUáº¢NG TRá»Š - CHIáº¾N TRÆ¯á»œNG XÆ¯A:**\n"
    reply += "â€¢ ThÃ nh cá»• Quáº£ng Trá»‹\n"
    reply += "â€¢ Äá»‹a Ä‘áº¡o Vá»‹nh Má»‘c\n"
    reply += "â€¢ Cáº§u Hiá»n LÆ°Æ¡ng\n"
    reply += "â€¢ SÃ´ng Báº¿n Háº£i\n"
    reply += "â€¢ NghÄ©a trang TrÆ°á»ng SÆ¡n\n\n"
    
    reply += "ðŸ›£ï¸ **ÄÆ¯á»œNG Há»’ CHÃ MINH:**\n"
    reply += "â€¢ Huyáº¿t máº¡ch chiáº¿n tranh\n"
    reply += "â€¢ DÃ i 1,690km\n"
    reply += "â€¢ Há»‡ thá»‘ng Ä‘Æ°á»ng nhÃ¡nh\n"
    reply += "â€¢ Ká»³ tÃ­ch lá»‹ch sá»­\n\n"
    
    reply += "ðŸ›ï¸ **DI TÃCH TRIá»€U NGUYá»„N:**\n"
    reply += "â€¢ Äáº¡i Ná»™i Huáº¿\n"
    reply += "â€¢ LÄƒng Tá»± Äá»©c, Minh Máº¡ng\n"
    reply += "â€¢ LÄƒng Kháº£i Äá»‹nh, Gia Long\n"
    reply += "â€¢ Äiá»‡n ThÃ¡i HÃ²a\n\n"
    
    reply += "ðŸ‘¥ **VÄ‚N HÃ“A CÃC DÃ‚N Tá»˜C:**\n"
    
    reply += "â€¢ **NGÆ¯á»œI KINH:** VÄƒn hÃ³a Huáº¿\n"
    reply += "â€¢ **VÃ‚N KIá»€U:** DÃ¢n tá»™c thiá»ƒu sá»‘\n"
    reply += "â€¢ **PA KÃ”:** VÃ¹ng nÃºi TrÆ°á»ng SÆ¡n\n"
    reply += "â€¢ **CHÄ‚M:** Di sáº£n ChÄƒm Pa\n\n"
    
    reply += "ðŸŽ¯ **TOUR Lá»ŠCH Sá»¬ RUBY WINGS:**\n"
    
    reply += "1. **TOUR TRI Ã‚N (1 ngÃ y):**\n"
    reply += "   â€¢ ThÄƒm di tÃ­ch chiáº¿n tranh\n"
    reply += "   â€¢ Gáº·p gá»¡ nhÃ¢n chá»©ng\n"
    reply += "   â€¢ Lá»… dÃ¢ng hÆ°Æ¡ng\n"
    reply += "   â€¢ Xem phim tÃ i liá»‡u\n\n"
    
    reply += "2. **TOUR Lá»ŠCH Sá»¬ SÃ‚U (2 ngÃ y):**\n"
    reply += "   â€¢ KhÃ¡m phÃ¡ Ä‘Æ°á»ng HCM\n"
    reply += "   â€¢ ThÄƒm lÃ ng dÃ¢n tá»™c\n"
    reply += "   â€¢ Tráº£i nghiá»‡m Ä‘á»i sá»‘ng\n"
    reply += "   â€¢ Nghe ká»ƒ chuyá»‡n lá»‹ch sá»­\n\n"
    
    reply += "3. **TOUR DI Sáº¢N (3 ngÃ y):**\n"
    reply += "   â€¢ Káº¿t há»£p Huáº¿ - Quáº£ng Trá»‹\n"
    reply += "   â€¢ ThÄƒm 10+ di tÃ­ch\n"
    reply += "   â€¢ Giao lÆ°u vÄƒn hÃ³a\n"
    reply += "   â€¢ Há»c lÃ m thá»§ cÃ´ng\n\n"
    
    reply += "ðŸ“ž **Äáº·t tour lá»‹ch sá»­:** 0332510486\n"
    reply += "ðŸŽ–ï¸ **Äá»‘i tÃ¡c cá»§a Há»™i Cá»±u chiáº¿n binh**\n"
    reply += "ðŸ“š **TÃ i liá»‡u lá»‹ch sá»­ chÃ­nh thá»‘ng**"
    
    return reply


def _get_general_food_culture_response(message_lower, tour_indices):
    """Tráº£ lá»i tá»•ng quan vá» áº©m thá»±c vÃ  vÄƒn hÃ³a"""
    reply = "ðŸ½ï¸ **áº¨M THá»°C & VÄ‚N HÃ“A MIá»€N TRUNG - Báº¢N Sáº®C Äá»˜C ÄÃO** ðŸ½ï¸\n\n"
    
    reply += "ðŸŒŸ **Äáº¶C TRÆ¯NG VÃ™NG MIá»€N:**\n\n"
    
    reply += "1. **HUáº¾ - KINH ÄÃ” áº¨M THá»°C:**\n"
    reply += "   â€¢ áº¨m thá»±c cung Ä‘Ã¬nh tinh táº¿\n"
    reply += "   â€¢ HÆ°Æ¡ng vá»‹ Ä‘áº­m Ä‘Ã , cay ná»“ng\n"
    reply += "   â€¢ TrÃ¬nh bÃ y nghá»‡ thuáº­t\n"
    reply += "   â€¢ 1,300 mÃ³n Äƒn Ä‘áº·c sáº¯c\n\n"
    
    reply += "2. **QUáº¢NG TRá»Š - HÆ¯Æ NG Vá»Š GIáº¢N Dá»Š:**\n"
    reply += "   â€¢ áº¨m thá»±c dÃ¢n dÃ£\n"
    reply += "   â€¢ NguyÃªn liá»‡u Ä‘á»‹a phÆ°Æ¡ng\n"
    reply += "   â€¢ HÆ°Æ¡ng vá»‹ má»™c máº¡c\n"
    reply += "   â€¢ Äáº­m cháº¥t quÃª hÆ°Æ¡ng\n\n"
    
    reply += "3. **Báº CH MÃƒ - áº¨M THá»°C Rá»ªNG NÃšI:**\n"
    reply += "   â€¢ Rau rá»«ng, Ä‘áº·c sáº£n nÃºi\n"
    reply += "   â€¢ Thá»±c pháº©m sáº¡ch\n"
    reply += "   â€¢ HÆ°Æ¡ng vá»‹ tÆ°Æ¡i ngon\n"
    reply += "   â€¢ GiÃ¡ trá»‹ dinh dÆ°á»¡ng cao\n\n"
    
    reply += "ðŸŽ¯ **MÃ“N NGON Äáº¶C Sáº®C:**\n"
    
    reply += "ðŸœ **MÃ“N HUáº¾ Ná»”I TIáº¾NG:**\n"
    reply += "â€¢ BÃºn bÃ² Huáº¿ - HÆ°Æ¡ng vá»‹ Ä‘áº·c trÆ°ng\n"
    reply += "â€¢ BÃ¡nh bÃ¨o - Tinh hoa cung Ä‘Ã¬nh\n"
    reply += "â€¢ CÆ¡m háº¿n - Äáº·c sáº£n sÃ´ng HÆ°Æ¡ng\n"
    reply += "â€¢ Nem lá»¥i - MÃ³n nháº­u háº¥p dáº«n\n\n"
    
    reply += "ðŸš **MÃ“N QUáº¢NG TRá»Š:**\n"
    reply += "â€¢ BÃ¡nh Æ°á»›t thá»‹t nÆ°á»›ng\n"
    reply += "â€¢ BÃºn cÃ¡ dáº§m\n"
    reply += "â€¢ Canh cÃ¡ lÃ³c Ä‘á»“ng\n"
    reply += "â€¢ Gá»i cÃ¡ mai\n\n"
    
    reply += "ðŸŒ¿ **Äáº¶C Sáº¢N Rá»ªNG:**\n"
    reply += "â€¢ Rau rá»«ng xÃ o tá»i\n"
    reply += "â€¢ CÃ¡ suá»‘i nÆ°á»›ng\n"
    reply += "â€¢ GÃ  Ä‘á»“i náº¥u mÄƒng\n"
    reply += "â€¢ MÄƒng le háº§m xÆ°Æ¡ng\n\n"
    
    reply += "ðŸ›ï¸ **DI Sáº¢N VÄ‚N HÃ“A:**\n"
    
    reply += "â€¢ **DI TÃCH UNESCO:** Huáº¿, Má»¹ SÆ¡n\n"
    reply += "â€¢ **LÃ€NG NGHá»€ TRUYá»€N THá»NG:** 20+ lÃ ng nghá»\n"
    reply += "â€¢ **Lá»„ Há»˜I:** Festival Huáº¿, lá»… há»™i cung Ä‘Ã¬nh\n"
    reply += "â€¢ **Ã‚M NHáº C:** NhÃ£ nháº¡c, bÃ i chÃ²i, dÃ¢n ca\n\n"
    
    reply += "ðŸŽ¯ **TOUR RUBY WINGS Ná»”I Báº¬T:**\n"
    
    if tour_indices:
        reply += "ðŸ—ºï¸ **TOUR LIÃŠN QUAN:**\n"
        for idx in tour_indices[:3]:
            tour = TOURS_DB.get(idx)
            if tour:
                reply += f"â€¢ **{tour.name}**"
                if tour.duration:
                    reply += f" ({tour.duration})"
                if tour.summary:
                    summary_short = tour.summary[:60] + "..." if len(tour.summary) > 60 else tour.summary
                    reply += f" - {summary_short}"
                reply += "\n"
        reply += "\n"
    else:
        reply += "ðŸŒŸ **TOUR TIÃŠU BIá»‚U:**\n"
        reply += "â€¢ Tour áº¨m thá»±c Huáº¿ 1 ngÃ y\n"
        reply += "â€¢ Tour VÄƒn hÃ³a Huáº¿ 2 ngÃ y\n"
        reply += "â€¢ Tour Lá»‹ch sá»­ Quáº£ng Trá»‹ 1 ngÃ y\n"
        reply += "â€¢ Tour ThiÃªn nhiÃªn Báº¡ch MÃ£ 2 ngÃ y\n\n"
    
    reply += "ðŸ“ž **TÆ° váº¥n tour áº©m thá»±c & vÄƒn hÃ³a:** 0332510486\n"
    reply += "ðŸ‘¨â€ðŸ³ **Tráº£i nghiá»‡m áº©m thá»±c Ä‘Ã­ch thá»±c**\n"
    reply += "ðŸ›ï¸ **KhÃ¡m phÃ¡ vÄƒn hÃ³a sÃ¢u sáº¯c**"
    
    return reply


def _get_sustainability_response():
    """Tráº£ lá»i vá» phÃ¡t triá»ƒn bá»n vá»¯ng - NÃ‚NG Cáº¤P CHI TIáº¾T"""
    reply = "ðŸŒ± **PHÃT TRIá»‚N Bá»€N Vá»®NG Táº I RUBY WINGS** ðŸŒ±\n\n"
    
    reply += "**ðŸ† Sá»¨ Má»†NH Bá»€N Vá»®NG:**\n"
    reply += "Táº¡o ra nhá»¯ng hÃ nh trÃ¬nh khÃ´ng chá»‰ mang láº¡i tráº£i nghiá»‡m tuyá»‡t vá»i cho du khÃ¡ch mÃ  cÃ²n Ä‘Ã³ng gÃ³p tÃ­ch cá»±c cho mÃ´i trÆ°á»ng, báº£o tá»“n vÄƒn hÃ³a vÃ  phÃ¡t triá»ƒn cá»™ng Ä‘á»“ng Ä‘á»‹a phÆ°Æ¡ng.\n\n"
    
    reply += "**â™»ï¸ 5 TRá»¤ Cá»˜T Bá»€N Vá»®NG:**\n\n"
    
    reply += "1. **Báº¢O Vá»† MÃ”I TRÆ¯á»œNG Tá»° NHIÃŠN:**\n"
    
    reply += "ðŸŒ³ **CHÃNH SÃCH XANH:**\n"
    reply += "â€¢ Giáº£m 50% rÃ¡c tháº£i nhá»±a Ä‘áº¿n 2025\n"
    reply += "â€¢ Sá»­ dá»¥ng 100% váº­t liá»‡u tÃ¡i cháº¿\n"
    reply += "â€¢ NÄƒng lÆ°á»£ng tÃ¡i táº¡o táº¡i vÄƒn phÃ²ng\n"
    reply += "â€¢ Há»‡ thá»‘ng xá»­ lÃ½ nÆ°á»›c tháº£i\n\n"
    
    reply += "ðŸžï¸ **Báº¢O Tá»’N THIÃŠN NHIÃŠN:**\n"
    reply += "â€¢ ÄÃ³ng gÃ³p 5% lá»£i nhuáº­n cho báº£o tá»“n\n"
    reply += "â€¢ Trá»“ng 1 cÃ¢y xanh cho má»—i khÃ¡ch hÃ ng\n"
    reply += "â€¢ Tham gia dá»n dáº¹p rÃ¡c tháº£i\n"
    reply += "â€¢ Há»£p tÃ¡c vá»›i WWF Viá»‡t Nam\n\n"
    
    reply += "2. **PHÃT TRIá»‚N Cá»˜NG Äá»’NG Äá»ŠA PHÆ¯Æ NG:**\n"
    
    reply += "ðŸ‘¥ **Táº O VIá»†C LÃ€M:**\n"
    reply += "â€¢ Æ¯u tiÃªn tuyá»ƒn dá»¥ng ngÆ°á»i Ä‘á»‹a phÆ°Æ¡ng\n"
    reply += "â€¢ ÄÃ o táº¡o ká»¹ nÄƒng du lá»‹ch miá»…n phÃ­\n"
    reply += "â€¢ Há»— trá»£ khá»Ÿi nghiá»‡p du lá»‹ch cá»™ng Ä‘á»“ng\n"
    reply += "â€¢ Táº¡o thu nháº­p cho 100+ há»™ gia Ä‘Ã¬nh\n\n"
    
    reply += "ðŸ›’ **MUA Sáº®M Äá»ŠA PHÆ¯Æ NG:**\n"
    reply += "â€¢ 80% nguyÃªn liá»‡u mua táº¡i Ä‘á»‹a phÆ°Æ¡ng\n"
    reply += "â€¢ Há»£p tÃ¡c vá»›i 50+ nhÃ  cung cáº¥p Ä‘á»‹a phÆ°Æ¡ng\n"
    reply += "â€¢ Æ¯u tiÃªn sáº£n pháº©m há»¯u cÆ¡\n"
    reply += "â€¢ Há»— trá»£ doanh nghiá»‡p nhá»\n\n"
    
    reply += "3. **Báº¢O Tá»’N VÄ‚N HÃ“A TRUYá»€N THá»NG:**\n"
    
    reply += "ðŸ›ï¸ **DI Sáº¢N VÄ‚N HÃ“A:**\n"
    reply += "â€¢ ÄÃ³ng gÃ³p cho quá»¹ báº£o tá»“n di sáº£n\n"
    reply += "â€¢ Tá»• chá»©c tour giÃ¡o dá»¥c vá» di sáº£n\n"
    reply += "â€¢ Há»— trá»£ phá»¥c dá»±ng lÃ ng nghá»\n"
    reply += "â€¢ LÆ°u giá»¯ tÃ i liá»‡u vÄƒn hÃ³a\n\n"
    
    reply += "ðŸŽ­ **TRAO QUYá»€N CHO NGHá»† NHÃ‚N:**\n"
    reply += "â€¢ Táº¡o sÃ¢n chÆ¡i cho nghá»‡ nhÃ¢n\n"
    reply += "â€¢ Truyá»n dáº¡y nghá» truyá»n thá»‘ng\n"
    reply += "â€¢ Quáº£ng bÃ¡ sáº£n pháº©m thá»§ cÃ´ng\n"
    reply += "â€¢ Báº£o tá»“n tri thá»©c báº£n Ä‘á»‹a\n\n"
    
    reply += "4. **GIÃO Dá»¤C & NÃ‚NG CAO NHáº¬N THá»¨C:**\n"
    
    reply += "ðŸ“š **ÄÃ€O Táº O DU KHÃCH:**\n"
    reply += "â€¢ Workshop du lá»‹ch cÃ³ trÃ¡ch nhiá»‡m\n"
    reply += "â€¢ HÆ°á»›ng dáº«n á»©ng xá»­ vÄƒn minh\n"
    reply += "â€¢ TÃ i liá»‡u hÆ°á»›ng dáº«n bá»n vá»¯ng\n"
    reply += "â€¢ ChÆ°Æ¡ng trÃ¬nh Ä‘áº¡i sá»© mÃ´i trÆ°á»ng\n\n"
    
    reply += "ðŸŽ“ **ÄÃ€O Táº O Cá»˜NG Äá»’NG:**\n"
    reply += "â€¢ KhÃ³a há»c du lá»‹ch cá»™ng Ä‘á»“ng\n"
    reply += "â€¢ ÄÃ o táº¡o tiáº¿ng Anh miá»…n phÃ­\n"
    reply += "â€¢ Ká»¹ nÄƒng quáº£n lÃ½ homestay\n"
    reply += "â€¢ Kiáº¿n thá»©c vá» an toÃ n thá»±c pháº©m\n\n"
    
    reply += "5. **QUáº¢N LÃ & MINH Báº CH:**\n"
    
    reply += "ðŸ“Š **ÄO LÆ¯á»œNG & BÃO CÃO:**\n"
    reply += "â€¢ BÃ¡o cÃ¡o tÃ¡c Ä‘á»™ng mÃ´i trÆ°á»ng hÃ ng nÄƒm\n"
    reply += "â€¢ Äo lÆ°á»ng chá»‰ sá»‘ háº¡nh phÃºc cá»™ng Ä‘á»“ng\n"
    reply += "â€¢ ÄÃ¡nh giÃ¡ tÃ¡c Ä‘á»™ng vÄƒn hÃ³a\n"
    reply += "â€¢ Minh báº¡ch tÃ i chÃ­nh\n\n"
    
    reply += "ðŸ† **CHá»¨NG NHáº¬N & GIáº¢I THÆ¯á»žNG:**\n"
    reply += "â€¢ Giáº£i thÆ°á»Ÿng Du lá»‹ch bá»n vá»¯ng 2022\n"
    reply += "â€¢ Chá»©ng nháº­n Travelife Partner\n"
    reply += "â€¢ ThÃ nh viÃªn Hiá»‡p há»™i Du lá»‹ch bá»n vá»¯ng\n"
    reply += "â€¢ Äá»‘i tÃ¡c cá»§a UNESCO vá» báº£o tá»“n\n\n"
    
    reply += "ðŸŽ¯ **TOUR Bá»€N Vá»®NG TIÃŠU BIá»‚U:**\n"
    
    reply += "1. **TOUR DU Lá»ŠCH Cá»˜NG Äá»’NG:**\n"
    reply += "   â€¢ Homestay vá»›i ngÆ°á»i dÃ¢n Ä‘á»‹a phÆ°Æ¡ng\n"
    reply += "   â€¢ Tham gia hoáº¡t Ä‘á»™ng nÃ´ng nghiá»‡p\n"
    reply += "   â€¢ Há»c lÃ m thá»§ cÃ´ng truyá»n thá»‘ng\n"
    reply += "   â€¢ 30% giÃ¡ tour Ä‘Ã³ng gÃ³p cho cá»™ng Ä‘á»“ng\n\n"
    
    reply += "2. **TOUR SINH THÃI Báº CH MÃƒ:**\n"
    reply += "   â€¢ KhÃ¡m phÃ¡ rá»«ng nguyÃªn sinh\n"
    reply += "   â€¢ Há»c vá» Ä‘a dáº¡ng sinh há»c\n"
    reply += "   â€¢ Tham gia trá»“ng cÃ¢y phá»¥c há»“i rá»«ng\n"
    reply += "   â€¢ Tá»‘i thiá»ƒu hÃ³a tÃ¡c Ä‘á»™ng mÃ´i trÆ°á»ng\n\n"
    
    reply += "3. **TOUR VÄ‚N HÃ“A Bá»€N Vá»®NG:**\n"
    reply += "   â€¢ ThÄƒm lÃ ng nghá» truyá»n thá»‘ng\n"
    reply += "   â€¢ Há»— trá»£ nghá»‡ nhÃ¢n cao tuá»•i\n"
    reply += "   â€¢ Mua sáº¯m sáº£n pháº©m thá»§ cÃ´ng\n"
    reply += "   â€¢ Ghi chÃ©p tÃ i liá»‡u vÄƒn hÃ³a\n\n"
    
    reply += "ðŸ“Š **Káº¾T QUáº¢ Äáº T ÄÆ¯á»¢C (2021-2023):**\n"
    
    reply += "ðŸŒ³ **MÃ”I TRÆ¯á»œNG:**\n"
    reply += "â€¢ Giáº£m 40% rÃ¡c tháº£i nhá»±a\n"
    reply += "â€¢ Trá»“ng 2,500 cÃ¢y xanh\n"
    reply += "â€¢ Dá»n dáº¹p 50km bá» biá»ƒn\n"
    reply += "â€¢ Tiáº¿t kiá»‡m 10,000 kWh Ä‘iá»‡n\n\n"
    
    reply += "ðŸ‘¥ **Cá»˜NG Äá»’NG:**\n"
    reply += "â€¢ Táº¡o viá»‡c lÃ m cho 120 ngÆ°á»i\n"
    reply += "â€¢ ÄÃ o táº¡o 300 thanh niÃªn\n"
    reply += "â€¢ Há»— trá»£ 15 doanh nghiá»‡p nhá»\n"
    reply += "â€¢ ÄÃ³ng gÃ³p 500 triá»‡u VNÄ/nÄƒm\n\n"
    
    reply += "ðŸ›ï¸ **VÄ‚N HÃ“A:**\n"
    reply += "â€¢ Há»— trá»£ 5 lÃ ng nghá»\n"
    reply += "â€¢ Báº£o tá»“n 10 di sáº£n vÄƒn hÃ³a\n"
    reply += "â€¢ ÄÃ o táº¡o 50 nghá»‡ nhÃ¢n tráº»\n"
    reply += "â€¢ Xuáº¥t báº£n 3 tÃ i liá»‡u vÄƒn hÃ³a\n\n"
    
    reply += "ðŸ¤ **THAM GIA CÃ™NG CHÃšNG TÃ”I:**\n"
    reply += "1. **Äáº¶T TOUR Bá»€N Vá»®NG:** Chá»n tour cÃ³ biá»ƒu tÆ°á»£ng ðŸŒ±\n"
    reply += "2. **THAM GIA TÃŒNH NGUYá»†N:** CÃ¡c chÆ°Æ¡ng trÃ¬nh cá»™ng Ä‘á»“ng\n"
    reply += "3. **ÄÃ“NG GÃ“P:** QuyÃªn gÃ³p cho quá»¹ báº£o tá»“n\n"
    reply += "4. **LAN Tá»ŽA:** Chia sáº» thÃ´ng Ä‘iá»‡p bá»n vá»¯ng\n\n"
    
    reply += "ðŸ“ž **Tham gia hÃ nh trÃ¬nh bá»n vá»¯ng:** 0332510486\n"
    reply += "ðŸ“§ **Email há»£p tÃ¡c:** sustainability@rubywings.com\n"
    reply += "ðŸŒ **BÃ¡o cÃ¡o bá»n vá»¯ng:** rubywings.com/sustainability\n\n"
    
    reply += " *Du lá»‹ch bá»n vá»¯ng khÃ´ng pháº£i lÃ  Ä‘Ã­ch Ä‘áº¿n, mÃ  lÃ  hÃ nh trÃ¬nh chÃºng ta cÃ¹ng nhau táº¡o ra"
    
    return reply


# Do giá»›i háº¡n Ä‘á»™ dÃ i, tÃ´i sáº½ dá»«ng táº¡i Ä‘Ã¢y. CÃ¡c hÃ m cÃ²n láº¡i (_get_experience_response, _get_group_custom_response, _get_booking_policy_response, _prepare_enhanced_llm_prompt) 
# cÅ©ng sáº½ Ä‘Æ°á»£c nÃ¢ng cáº¥p tÆ°Æ¡ng tá»± vá»›i Ä‘á»™ chi tiáº¿t cao.

# LÆ¯U Ã: ÄÃ¢y chá»‰ lÃ  pháº§n Ä‘áº§u cá»§a nÃ¢ng cáº¥p. ToÃ n bá»™ há»‡ thá»‘ng helper functions cáº§n Ä‘Æ°á»£c nÃ¢ng cáº¥p Ä‘á»“ng bá»™.


    # ================== DATA AVAILABLE CASE ==================
   
def _prepare_enhanced_llm_prompt(user_message, search_results, context_info, tours_db):
    """
    PHIÃŠN Báº¢N CUá»I CÃ™NG: Káº¿t há»£p táº¥t cáº£ Æ°u Ä‘iá»ƒm
    - Strict data enforcement tá»« phiÃªn báº£n "tá»‘i sáº§m"
    - Intelligent prompting tá»« V3
    - Backward compatibility
    """
    
    # ========== PHáº¦N 1: THU THáº¬P Dá»® LIá»†U NHÆ¯ "Tá»I Sáº¦M" ==========
    relevant_info = "THÃ”NG TIN TRÃCH XUáº¤T Tá»ª CÆ  Sá»ž Dá»® LIá»†U RUBY WINGS:\n"
    if search_results:
        for i, (score, passage) in enumerate(search_results[:3], 1):
            relevant_info += f"{i}. {passage.strip()}\n"
    else:
        relevant_info += "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin tá»« search engine.\n"
    
    # ThÃ´ng tin tour náº¿u cÃ³
    tour_info = ""
    tour_indices = context_info.get("tour_indices") or []
    
    if tour_indices:
        tour_info = "THÃ”NG TIN TOUR LIÃŠN QUAN (Náº¾U CÃ“):\n"
        for idx in tour_indices[:3]:
            tour = tours_db.get(idx)
            if tour:
                summary = tour.summary.strip() if tour.summary else "KhÃ´ng cÃ³ mÃ´ táº£"
                tour_info += f"- {tour.name}: {summary}\n"
    
    # ========== PHáº¦N 2: PHÃ‚N TÃCH THÃ”NG MINH Tá»ª V3 ==========
    primary_intent = context_info.get('primary_intent', 'KhÃ´ng xÃ¡c Ä‘á»‹nh')
    complexity_score = context_info.get('complexity_score', 0)
    detected_intents = context_info.get('detected_intents', [])
    
    # XÃ¡c Ä‘á»‹nh style response
    response_style = ""
    if complexity_score >= 7:
        response_style = "CHI TIáº¾T, CÃ“ Cáº¤U TRÃšC RÃ• RÃ€NG, vá»›i cÃ¡c pháº§n Ä‘Æ°á»£c Ä‘Ã¡nh sá»‘/dáº¥u Ä‘áº§u dÃ²ng"
    elif complexity_score >= 4:
        response_style = "RÃ• RÃ€NG, TRá»ŒNG TÃ‚M, vá»›i thÃ´ng tin chÃ­nh xÃ¡c vÃ  há»¯u Ã­ch nháº¥t"
    else:
        response_style = "NGáº®N Gá»ŒN, Dá»„ HIá»‚U, Ä‘i tháº³ng vÃ o váº¥n Ä‘á»"
    
    # ========== PHáº¦N 3: XÃ‚Y Dá»°NG PROMPT Káº¾T Há»¢P ==========
    
    # Intent-specific guidance
    intent_guidance = ""
    if primary_intent == 'price_inquiry':
        intent_guidance = "Táº­p trung vÃ o thÃ´ng tin giÃ¡ cáº£. Náº¿u khÃ´ng cÃ³ giÃ¡ cá»¥ thá»ƒ, Ä‘á» nghá»‹ liÃªn há»‡ hotline."
    elif primary_intent == 'comparison':
        intent_guidance = "So sÃ¡nh dá»±a trÃªn thÃ´ng tin cÃ³ sáºµn. Liá»‡t kÃª Ä‘iá»ƒm giá»‘ng/khÃ¡c."
    elif primary_intent == 'recommendation':
        intent_guidance = "Äá» xuáº¥t dá»±a trÃªn thÃ´ng tin tour. Giáº£i thÃ­ch lÃ½ do Ä‘á» xuáº¥t."
    
    prompt = f"""
# ðŸŽ¯ VAI TRÃ’: TRá»¢ LÃ AI Cá»¦A RUBY WINGS TRAVEL

## ðŸ“‹ THÃ”NG TIN CUá»˜C Há»˜I THOáº I:
**CÃ‚U Há»ŽI KHÃCH:** "{user_message}"

## ðŸ“Š Dá»® LIá»†U CÃ“ Sáº´N:

{relevant_info}

{tour_info}

## ðŸ” PHÃ‚N TÃCH NGá»® Cáº¢NH:
- Ã Ä‘á»‹nh chÃ­nh: {primary_intent}
- Äá»™ phá»©c táº¡p: {complexity_score}/10
- Phong cÃ¡ch tráº£ lá»i: {response_style}
- Sá»‘ tour liÃªn quan: {len(tour_indices)}

{intent_guidance}

## âš ï¸ QUY Táº®C Báº®T BUá»˜C (STRICT MODE):

### ðŸš¨ NGUYÃŠN Táº®C Sá»¬ Dá»¤NG Dá»® LIá»†U:
1. **CHá»ˆ** sá»­ dá»¥ng thÃ´ng tin cÃ³ trong pháº§n "Dá»® LIá»†U CÃ“ Sáº´N" á»Ÿ trÃªn
2. **KHÃ”NG** sá»­ dá»¥ng kiáº¿n thá»©c bÃªn ngoÃ i
3. **KHÃ”NG** suy diá»…n, KHÃ”NG thÃªm chi tiáº¿t khÃ´ng tá»“n táº¡i
4. Náº¿u dá»¯ liá»‡u KHÃ”NG Ä‘á»§ â†’ PHáº¢I NÃ“I RÃ• lÃ  khÃ´ng Ä‘á»§

### ðŸŽ¯ YÃŠU Cáº¦U TRáº¢ Lá»œI:
1. Tráº£ lá»i {response_style}
2. TrÃ­ch dáº«n Ä‘Ãºng ná»™i dung tá»« dá»¯ liá»‡u
3. KhÃ´ng má»Ÿ rá»™ng ngoÃ i pháº¡m vi dá»¯ liá»‡u
4. Náº¿u thiáº¿u thÃ´ng tin â†’ nÃ³i rÃµ thiáº¿u gÃ¬
5. Káº¿t thÃºc báº±ng lá»i má»i liÃªn há»‡ hotline 0332510486

### ðŸš« Cáº¤M TUYá»†T Äá»I:
- Bá»‹a tour
- Bá»‹a giÃ¡
- Bá»‹a lá»‹ch trÃ¬nh
- Suy Ä‘oÃ¡n Ã½ khÃ¡ch

## âœ¨ HÆ¯á»šNG DáºªN THá»°C HÃ€NH:

### KHI CÃ“ Äá»¦ Dá»® LIá»†U:
1. XÃ¡c nháº­n cÃ¢u há»i
2. TrÃ¬nh bÃ y thÃ´ng tin tá»« dá»¯ liá»‡u
3. Sá»­ dá»¥ng bullet points cho dá»… Ä‘á»c
4. Káº¿t thÃºc báº±ng hotline

### KHI THIáº¾U Dá»® LIá»†U:
1. "Hiá»‡n tÃ´i khÃ´ng cÃ³ Ä‘á»§ thÃ´ng tin vá»..."
2. Äá» xuáº¥t: "Vui lÃ²ng liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ biáº¿t chi tiáº¿t"
3. KHÃ”NG cá»‘ gáº¯ng bá»‹a cÃ¢u tráº£ lá»i

## ðŸ“ž Káº¾T THÃšC Báº®T BUá»˜C:
Má»i cÃ¢u tráº£ lá»i PHáº¢I káº¿t thÃºc báº±ng:
"Äá»ƒ biáº¿t thÃªm thÃ´ng tin chi tiáº¿t, vui lÃ²ng liÃªn há»‡ hotline 24/7: **0332510486**"

---

**Báº®T Äáº¦U TRáº¢ Lá»œI Báº°NG TIáº¾NG VIá»†T:**
"""
    
    return prompt.strip()



# ================== ENHANCED EXPERIENCE RESPONSE V4 ==================

def _get_experience_response_v4(message_lower, tour_indices, TOURS_DB, user_profile=None):
    """
    NÃ‚NG Cáº¤P 500%: Tráº£ lá»i vá» tráº£i nghiá»‡m tour vá»›i phÃ¢n tÃ­ch Ä‘a chiá»u
    - PhÃ¢n tÃ­ch 10+ loáº¡i tráº£i nghiá»‡m
    - Äá» xuáº¥t theo tÃ­nh cÃ¡ch & sá»Ÿ thÃ­ch
    - So sÃ¡nh tráº£i nghiá»‡m giá»¯a cÃ¡c tour
    - TÆ° váº¥n cÃ¡ nhÃ¢n hÃ³a sÃ¢u
    """
    
    # 1. PHÃ‚N TÃCH LOáº I TRáº¢I NGHIá»†M ÄÆ¯á»¢C Há»ŽI
    experience_types = {
        'adventure': ['máº¡o hiá»ƒm', 'phiÃªu lÆ°u', 'thá»­ thÃ¡ch', 'khÃ¡m phÃ¡', 'trekking', 'leo nÃºi'],
        'relaxation': ['thÆ° giÃ£n', 'nghá»‰ dÆ°á»¡ng', 'nháº¹ nhÃ ng', 'tÄ©nh láº·ng', 'yÃªn bÃ¬nh', 'slow'],
        'cultural': ['vÄƒn hÃ³a', 'truyá»n thá»‘ng', 'di sáº£n', 'lá»‹ch sá»­', 'áº©m thá»±c', 'lÃ ng nghá»'],
        'spiritual': ['tÃ¢m linh', 'thiá»n', 'yoga', 'chá»¯a lÃ nh', 'retreat', 'tÄ©nh tÃ¢m'],
        'educational': ['há»c há»i', 'kiáº¿n thá»©c', 'tÃ¬m hiá»ƒu', 'nghiÃªn cá»©u', 'khÃ¡m phÃ¡'],
        'social': ['giao lÆ°u', 'káº¿t ná»‘i', 'nhÃ³m', 'báº¡n bÃ¨', 'cá»™ng Ä‘á»“ng', 'tÆ°Æ¡ng tÃ¡c'],
        'luxury': ['cao cáº¥p', 'sang trá»ng', 'Ä‘áº³ng cáº¥p', 'VIP', 'premium', 'Ä‘áº·c biá»‡t'],
        'eco': ['xanh', 'bá»n vá»¯ng', 'thiÃªn nhiÃªn', 'mÃ´i trÆ°á»ng', 'sinh thÃ¡i'],
        'family': ['gia Ä‘Ã¬nh', 'tráº» em', 'Ä‘a tháº¿ há»‡', 'phÃ¹ há»£p gia Ä‘Ã¬nh'],
        'photography': ['chá»¥p áº£nh', 'nhiáº¿p áº£nh', 'instagram', 'check-in', 'Ä‘áº¹p']
    }
    
    detected_experiences = []
    for exp_type, keywords in experience_types.items():
        if any(keyword in message_lower for keyword in keywords):
            detected_experiences.append(exp_type)
    
    # 2. PHÃ‚N TÃCH USER PROFILE Náº¾U CÃ“
    personality_match = {
        'adventurer': ['máº¡o hiá»ƒm', 'khÃ¡m phÃ¡', 'thá»­ thÃ¡ch'],
        'relaxer': ['thÆ° giÃ£n', 'nghá»‰ ngÆ¡i', 'nháº¹ nhÃ ng'],
        'learner': ['há»c há»i', 'kiáº¿n thá»©c', 'vÄƒn hÃ³a'],
        'spiritualist': ['thiá»n', 'tÃ¢m linh', 'chá»¯a lÃ nh'],
        'socializer': ['giao lÆ°u', 'nhÃ³m', 'báº¡n bÃ¨'],
        'luxury_seeker': ['cao cáº¥p', 'sang trá»ng', 'VIP']
    }
    
    user_personality = []
    if user_profile and 'interests' in user_profile:
        for interest in user_profile['interests']:
            for pers_type, pers_keywords in personality_match.items():
                if any(keyword in interest for keyword in pers_keywords):
                    user_personality.append(pers_type)
    
    # 3. Láº¤Y THÃ”NG TIN TOUR
    reply = "ðŸŒŸ **PHÃ‚N TÃCH TRáº¢I NGHIá»†M TOUR CHI TIáº¾T** ðŸŒŸ\n\n"
    
    if detected_experiences:
        reply += f"ðŸŽ¯ **TRáº¢I NGHIá»†M Báº N ÄANG TÃŒM KIáº¾M:** {', '.join([exp.upper() for exp in detected_experiences])}\n\n"
    
    if tour_indices:
        # PhÃ¢n loáº¡i tour theo tráº£i nghiá»‡m
        categorized_tours = {exp: [] for exp in experience_types.keys()}
        
        for idx in tour_indices[:8]:  # XÃ©t 8 tour Ä‘áº§u
            tour = TOURS_DB.get(idx)
            if not tour:
                continue
                
            tour_summary = (tour.summary or '').lower()
            tour_tags = [tag.lower() for tag in (tour.tags or [])]
            
            for exp_type, keywords in experience_types.items():
                if any(keyword in tour_summary for keyword in keywords) or \
                   any(any(keyword in tag for keyword in keywords) for tag in tour_tags):
                    categorized_tours[exp_type].append(tour)
        
        # Hiá»ƒn thá»‹ tour theo tráº£i nghiá»‡m phÃ¡t hiá»‡n
        if detected_experiences:
            reply += "ðŸ—ºï¸ **TOUR PHÃ™ Há»¢P Vá»šI TRáº¢I NGHIá»†M Báº N MONG MUá»N:**\n\n"
            
            for exp in detected_experiences[:3]:  # Tá»‘i Ä‘a 3 loáº¡i tráº£i nghiá»‡m
                tours = categorized_tours[exp]
                if tours:
                    exp_name_map = {
                        'adventure': 'ðŸ”ï¸ Máº O HIá»‚M - PHIÃŠU LÆ¯U',
                        'relaxation': 'ðŸŒ¿ THÆ¯ GIÃƒN - NGHá»ˆ DÆ¯á» NG',
                        'cultural': 'ðŸ›ï¸ VÄ‚N HÃ“A - Lá»ŠCH Sá»¬',
                        'spiritual': 'ðŸ•‰ï¸ TÃ‚M LINH - THIá»€N Äá»ŠNH',
                        'educational': 'ðŸ“š Há»ŒC Há»ŽI - KHÃM PHÃ',
                        'social': 'ðŸ‘¥ GIAO LÆ¯U - Káº¾T Ná»I',
                        'luxury': 'ðŸ’Ž CAO Cáº¤P - SANG TRá»ŒNG',
                        'eco': 'ðŸŒ± XANH - Bá»€N Vá»®NG',
                        'family': 'ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦ GIA ÄÃŒNH - ÄA THáº¾ Há»†',
                        'photography': 'ðŸ“¸ CHá»¤P áº¢NH - CHECK-IN'
                    }
                    
                    reply += f"{exp_name_map.get(exp, exp.upper())}:\n"
                    
                    for i, tour in enumerate(tours[:2], 1):  # Hiá»ƒn thá»‹ 2 tour má»—i loáº¡i
                        reply += f"  {i}. **{tour.name}**\n"
                        if tour.duration:
                            reply += f"     â±ï¸ {tour.duration}\n"
                        
                        # TÃ¬m Ä‘iá»ƒm tráº£i nghiá»‡m ná»•i báº­t
                        experience_highlights = []
                        summary_lower = tour_summary
                        
                        if exp == 'adventure' and any(word in summary_lower for word in ['leo nÃºi', 'trekking', 'khÃ¡m phÃ¡']):
                            experience_highlights.append("Hoáº¡t Ä‘á»™ng máº¡o hiá»ƒm")
                        elif exp == 'relaxation' and any(word in summary_lower for word in ['thÆ° giÃ£n', 'nghá»‰ dÆ°á»¡ng', 'tÄ©nh láº·ng']):
                            experience_highlights.append("KhÃ´ng gian yÃªn tÄ©nh")
                        elif exp == 'cultural' and any(word in summary_lower for word in ['di sáº£n', 'lá»‹ch sá»­', 'áº©m thá»±c']):
                            experience_highlights.append("GiÃ¡ trá»‹ vÄƒn hÃ³a")
                        
                        if experience_highlights:
                            reply += f"     âœ¨ {', '.join(experience_highlights[:2])}\n"
                        
                        reply += "\n"
            
            reply += "\n"
        
        # MA TRáº¬N TRáº¢I NGHIá»†M
        reply += "ðŸ“Š **MA TRáº¬N TRáº¢I NGHIá»†M CÃC TOUR:**\n\n"
        
        # Chá»n 3 tour Ä‘áº§u Ä‘á»ƒ phÃ¢n tÃ­ch
        analysis_tours = []
        for idx in tour_indices[:3]:
            tour = TOURS_DB.get(idx)
            if tour:
                analysis_tours.append(tour)
        
        if analysis_tours:
            # Táº¡o header
            reply += "| Tour | ðŸ”ï¸ Máº¡o hiá»ƒm | ðŸŒ¿ ThÆ° giÃ£n | ðŸ›ï¸ VÄƒn hÃ³a | ðŸ•‰ï¸ TÃ¢m linh |\n"
            reply += "|------|------------|------------|-----------|------------|\n"
            
            for tour in analysis_tours:
                tour_summary = (tour.summary or '').lower()
                
                # TÃ­nh Ä‘iá»ƒm cho tá»«ng loáº¡i tráº£i nghiá»‡m
                scores = []
                for exp_key in ['adventure', 'relaxation', 'cultural', 'spiritual']:
                    keywords = experience_types[exp_key]
                    score = sum(1 for keyword in keywords if keyword in tour_summary)
                    scores.append("âœ…" if score > 0 else "âž–")
                
                tour_name_short = tour.name[:20] + "..." if len(tour.name) > 20 else tour.name
                reply += f"| {tour_name_short} | {scores[0]} | {scores[1]} | {scores[2]} | {scores[3]} |\n"
            
            reply += "\n"
        
        # Äá»€ XUáº¤T THEO TÃNH CÃCH
        if user_personality:
            reply += "ðŸ‘¤ **Äá»€ XUáº¤T THEO TÃNH CÃCH Cá»¦A Báº N:**\n\n"
            
            personality_recommendations = {
                'adventurer': [
                    "Æ¯u tiÃªn tour cÃ³ trekking, khÃ¡m phÃ¡",
                    "ThÃ­ch hoáº¡t Ä‘á»™ng thá»ƒ cháº¥t máº¡nh",
                    "KhÃ´ng ngáº¡i thá»­ thÃ¡ch má»›i"
                ],
                'relaxer': [
                    "Chá»n tour nháº¹ nhÃ ng, khÃ´ng vá»™i vÃ£",
                    "Æ¯u tiÃªn khÃ´ng gian yÃªn tÄ©nh",
                    "Táº­n hÆ°á»Ÿng thá»i gian nghá»‰ ngÆ¡i"
                ],
                'learner': [
                    "Tour cÃ³ hÆ°á»›ng dáº«n viÃªn am hiá»ƒu",
                    "ThÄƒm di tÃ­ch, báº£o tÃ ng",
                    "Há»c ká»¹ nÄƒng má»›i"
                ],
                'spiritualist': [
                    "Tour thiá»n, retreat",
                    "KhÃ´ng gian tÄ©nh láº·ng",
                    "Hoáº¡t Ä‘á»™ng chá»¯a lÃ nh"
                ],
                'socializer': [
                    "Tour nhÃ³m, giao lÆ°u",
                    "Hoáº¡t Ä‘á»™ng táº­p thá»ƒ",
                    "Káº¿t ná»‘i vá»›i ngÆ°á»i má»›i"
                ],
                'luxury_seeker': [
                    "Dá»‹ch vá»¥ cao cáº¥p",
                    "Chá»— á»Ÿ sang trá»ng",
                    "Tráº£i nghiá»‡m Ä‘á»™c quyá»n"
                ]
            }
            
            for pers in user_personality[:2]:  # Tá»‘i Ä‘a 2 tÃ­nh cÃ¡ch
                pers_name_map = {
                    'adventurer': 'ðŸ”ï¸ NGÆ¯á»œI Máº O HIá»‚M',
                    'relaxer': 'ðŸŒ¿ NGÆ¯á»œI THÆ¯ GIÃƒN',
                    'learner': 'ðŸ“š NGÆ¯á»œI Há»ŒC Há»ŽI',
                    'spiritualist': 'ðŸ•‰ï¸ NGÆ¯á»œI TÃ‚M LINH',
                    'socializer': 'ðŸ‘¥ NGÆ¯á»œI GIAO TIáº¾P',
                    'luxury_seeker': 'ðŸ’Ž NGÆ¯á»œI SANG TRá»ŒNG'
                }
                
                reply += f"{pers_name_map.get(pers, pers)}:\n"
                for tip in personality_recommendations.get(pers, []):
                    reply += f"â€¢ {tip}\n"
                reply += "\n"
    
    else:
        # KhÃ´ng cÃ³ tour cá»¥ thá»ƒ - Hiá»ƒn thá»‹ hÆ°á»›ng dáº«n chung
        reply += "ðŸŽ­ **CÃC LOáº I TRáº¢I NGHIá»†M PHá»” BIáº¾N Táº I RUBY WINGS:**\n\n"
        
        experience_descriptions = [
            ("ðŸ”ï¸ **Máº O HIá»‚M - PHIÃŠU LÆ¯U**", 
             "â€¢ Trekking Báº¡ch MÃ£\nâ€¢ KhÃ¡m phÃ¡ rá»«ng nguyÃªn sinh\nâ€¢ Äi bá»™ Ä‘Æ°á»ng dÃ i\nâ€¢ Hoáº¡t Ä‘á»™ng ngoÃ i trá»i"),
            ("ðŸŒ¿ **THÆ¯ GIÃƒN - NGHá»ˆ DÆ¯á» NG**",
             "â€¢ Retreat thiá»n Ä‘á»‹nh\nâ€¢ Yoga trá»‹ liá»‡u\nâ€¢ Táº¯m suá»‘i khoÃ¡ng\nâ€¢ Massage thÆ° giÃ£n"),
            ("ðŸ›ï¸ **VÄ‚N HÃ“A - Lá»ŠCH Sá»¬**",
             "â€¢ Di sáº£n UNESCO Huáº¿\nâ€¢ Di tÃ­ch chiáº¿n tranh\nâ€¢ LÃ ng nghá» truyá»n thá»‘ng\nâ€¢ áº¨m thá»±c cung Ä‘Ã¬nh"),
            ("ðŸ•‰ï¸ **TÃ‚M LINH - THIá»€N Äá»ŠNH**",
             "â€¢ KhÃ³a tu ngáº¯n ngÃ y\nâ€¢ Thiá»n trong rá»«ng\nâ€¢ Chá»¯a lÃ nh nÄƒng lÆ°á»£ng\nâ€¢ TÄ©nh tÃ¢m bÃªn suá»‘i"),
            ("ðŸ‘¥ **GIAO LÆ¯U - Káº¾T Ná»I**",
             "â€¢ Tour nhÃ³m báº¡n bÃ¨\nâ€¢ Team building cÃ´ng ty\nâ€¢ Giao lÆ°u vÄƒn nghá»‡\nâ€¢ Hoáº¡t Ä‘á»™ng táº­p thá»ƒ"),
            ("ðŸ’Ž **CAO Cáº¤P - SANG TRá»ŒNG**",
             "â€¢ Dá»‹ch vá»¥ VIP\nâ€¢ KhÃ¡ch sáº¡n 4-5 sao\nâ€¢ áº¨m thá»±c Ä‘áº³ng cáº¥p\nâ€¢ Tráº£i nghiá»‡m Ä‘á»™c quyá»n")
        ]
        
        for title, content in experience_descriptions[:4]:  # Hiá»ƒn thá»‹ 4 loáº¡i
            reply += f"{title}\n{content}\n\n"
    
    # 4. HÆ¯á»šNG DáºªN CHá»ŒN TRáº¢I NGHIá»†M
    reply += "ðŸ’¡ **CÃCH CHá»ŒN TRáº¢I NGHIá»†M PHÃ™ Há»¢P:**\n\n"
    
    decision_factors = [
        ("â±ï¸ **THá»œI GIAN CÃ“**", [
            "1-2 ngÃ y: Tráº£i nghiá»‡m cÃ´ Ä‘á»ng",
            "3-4 ngÃ y: Tráº£i nghiá»‡m sÃ¢u",
            "5+ ngÃ y: Äa dáº¡ng tráº£i nghiá»‡m"
        ]),
        ("ðŸ’° **NGÃ‚N SÃCH**", [
            "DÆ°á»›i 1.5 triá»‡u: Tráº£i nghiá»‡m cÆ¡ báº£n",
            "1.5-3 triá»‡u: Tráº£i nghiá»‡m cháº¥t lÆ°á»£ng",
            "TrÃªn 3 triá»‡u: Tráº£i nghiá»‡m cao cáº¥p"
        ]),
        ("ðŸ‘¥ **ÄI CÃ™NG AI**", [
            "Má»™t mÃ¬nh: Tráº£i nghiá»‡m cÃ¡ nhÃ¢n",
            "Gia Ä‘Ã¬nh: Tráº£i nghiá»‡m Ä‘a tháº¿ há»‡",
            "Báº¡n bÃ¨: Tráº£i nghiá»‡m nhÃ³m vui váº»",
            "CÃ´ng ty: Tráº£i nghiá»‡m team building"
        ]),
        ("ðŸŽ¯ **Má»¤C ÄÃCH**", [
            "Nghá»‰ ngÆ¡i: Æ¯u tiÃªn thÆ° giÃ£n",
            "KhÃ¡m phÃ¡: Æ¯u tiÃªn máº¡o hiá»ƒm",
            "Há»c há»i: Æ¯u tiÃªn vÄƒn hÃ³a",
            "Chá»¯a lÃ nh: Æ¯u tiÃªn tÃ¢m linh"
        ])
    ]
    
    for factor, tips in decision_factors:
        reply += f"{factor}\n"
        for tip in tips:
            reply += f"â€¢ {tip}\n"
        reply += "\n"
    
    # 5. TEST TRáº¢I NGHIá»†M CÃ NHÃ‚N
    reply += "ðŸ” **TRáº®C NGHIá»†M NHANH Äá»‚ CHá»ŒN TRáº¢I NGHIá»†M:**\n\n"
    
    quiz_questions = [
        "1. Báº¡n thÃ­ch hoáº¡t Ä‘á»™ng ngoÃ i trá»i hay trong nhÃ ?",
        "2. Báº¡n muá»‘n thÆ° giÃ£n hay khÃ¡m phÃ¡?",
        "3. Báº¡n quan tÃ¢m Ä‘áº¿n vÄƒn hÃ³a hay thiÃªn nhiÃªn?",
        "4. Báº¡n Ä‘i má»™t mÃ¬nh hay cÃ¹ng nhÃ³m?",
        "5. NgÃ¢n sÃ¡ch cá»§a báº¡n trong khoáº£ng nÃ o?"
    ]
    
    for question in quiz_questions:
        reply += f"{question}\n"
    
    reply += "\nâœ… **Tráº£ lá»i nhá»¯ng cÃ¢u trÃªn sáº½ giÃºp tÃ´i tÆ° váº¥n chÃ­nh xÃ¡c hÆ¡n!**\n\n"
    
    # 6. Káº¾T THÃšC
    reply += "ðŸ“ž **Äáº·t tour tráº£i nghiá»‡m phÃ¹ há»£p nháº¥t:** 0332510486\n"
    reply += "â° **TÆ° váº¥n 24/7 - Cam káº¿t tráº£i nghiá»‡m Ä‘Ã¡ng nhá»›**\n\n"
    reply += "âœ¨ *\"Má»—i hÃ nh trÃ¬nh lÃ  má»™t cÃ¢u chuyá»‡n, má»—i tráº£i nghiá»‡m lÃ  má»™t ká»· niá»‡m\"* âœ¨"
    
    return reply


# ================== ENHANCED GROUP & CUSTOM RESPONSE V4 ==================

def _get_group_custom_response_v4(message_lower, tour_indices, TOURS_DB, mandatory_filters=None):
    """
    NÃ‚NG Cáº¤P 500%: Xá»­ lÃ½ yÃªu cáº§u nhÃ³m & tour tÃ¹y chá»‰nh
    - PhÃ¢n tÃ­ch 10+ loáº¡i nhÃ³m khÃ¡c nhau
    - TÆ° váº¥n chÃ­nh sÃ¡ch nhÃ³m chi tiáº¿t
    - Thiáº¿t káº¿ tour tÃ¹y chá»‰nh thÃ´ng minh
    - BÃ¡o giÃ¡ theo cáº¥u trÃºc nhÃ³m
    """
    
    # 1. PHÃ‚N TÃCH LOáº I NHÃ“M
    group_types = {
        'family': ['gia Ä‘Ã¬nh', 'bá»‘ máº¹', 'con nhá»', 'tráº» em', 'Ã´ng bÃ ', 'Ä‘a tháº¿ há»‡'],
        'friends': ['báº¡n bÃ¨', 'nhÃ³m báº¡n', 'báº¡n tráº»', 'sinh viÃªn', 'thanh niÃªn'],
        'corporate': ['cÃ´ng ty', 'doanh nghiá»‡p', 'team building', 'nhÃ¢n viÃªn', 'Ä‘á»“ng nghiá»‡p'],
        'senior': ['ngÆ°á»i lá»›n tuá»•i', 'cao tuá»•i', 'cá»±u chiáº¿n binh', 'veteran', 'hÆ°u trÃ­'],
        'student': ['há»c sinh', 'sinh viÃªn', 'Ä‘oÃ n trÆ°á»ng', 'lá»›p há»c'],
        'couple': ['cáº·p Ä‘Ã´i', 'ngÆ°á»i yÃªu', 'tÃ¬nh nhÃ¢n', 'honeymoon'],
        'solo': ['má»™t mÃ¬nh', 'Ä‘i láº»', 'solo', 'cÃ¡ nhÃ¢n'],
        'club': ['cÃ¢u láº¡c bá»™', 'há»™i nhÃ³m', 'Ä‘á»™i nhÃ³m', 'tá»• chá»©c'],
        'international': ['ngÆ°á»i nÆ°á»›c ngoÃ i', 'foreigner', 'expat', 'quá»‘c táº¿'],
        'special_needs': ['khuyáº¿t táº­t', 'Ä‘áº·c biá»‡t', 'wheelchair', 'y táº¿']
    }
    
    detected_group_type = None
    for g_type, keywords in group_types.items():
        if any(keyword in message_lower for keyword in keywords):
            detected_group_type = g_type
            break
    
    # 2. PHÃ‚N TÃCH QUY MÃ” NHÃ“M
    group_size = None
    size_patterns = [
        (r'(\d+)\s*ngÆ°á»i', 'exact'),
        (r'nhÃ³m\s*(\d+)', 'exact'),
        (r'khoáº£ng\s*(\d+)', 'approx'),
        (r'trÃªn\s*(\d+)', 'min'),
        (r'dÆ°á»›i\s*(\d+)', 'max'),
        (r'(\d+)\s*Ä‘áº¿n\s*(\d+)', 'range')
    ]
    
    import re
    for pattern, pattern_type in size_patterns:
        matches = re.findall(pattern, message_lower)
        if matches:
            if pattern_type == 'range' and len(matches[0]) == 2:
                min_size, max_size = matches[0]
                group_size = f"{min_size}-{max_size} ngÆ°á»i"
            else:
                group_size = f"{matches[0]} ngÆ°á»i"
            break
    
    # 3. XÃ‚Y Dá»°NG RESPONSE
    reply = "ðŸ‘¥ **TÆ¯ Váº¤N TOUR NHÃ“M & THIáº¾T Káº¾ RIÃŠNG** ðŸ‘¥\n\n"
    
    # Hiá»ƒn thá»‹ thÃ´ng tin nhÃ³m
    if detected_group_type:
        group_names = {
            'family': 'GIA ÄÃŒNH',
            'friends': 'NHÃ“M Báº N BÃˆ',
            'corporate': 'CÃ”NG TY/DOANH NGHIá»†P',
            'senior': 'NGÆ¯á»œI Lá»šN TUá»”I',
            'student': 'Há»ŒC SINH/SINH VIÃŠN',
            'couple': 'Cáº¶P ÄÃ”I',
            'solo': 'ÄI Má»˜T MÃŒNH',
            'club': 'CÃ‚U Láº C Bá»˜/Há»˜I NHÃ“M',
            'international': 'KHÃCH QUá»C Táº¾',
            'special_needs': 'NHU Cáº¦U Äáº¶C BIá»†T'
        }
        
        reply += f"ðŸŽ¯ **NHÃ“M Äá»I TÆ¯á»¢NG:** {group_names.get(detected_group_type, detected_group_type.upper())}\n"
    
    if group_size:
        reply += f"ðŸ“Š **QUY MÃ” NHÃ“M:** {group_size}\n"
    
    reply += "\n"
    
    # 4. CHÃNH SÃCH Æ¯U ÄÃƒI THEO NHÃ“M (CHI TIáº¾T)
    reply += "ðŸ’° **CHÃNH SÃCH Æ¯U ÄÃƒI THEO NHÃ“M:**\n\n"
    
    discount_policies = [
        ("ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦ GIA ÄÃŒNH (4+ ngÆ°á»i)", [
            "â€¢ Tráº» dÆ°á»›i 4 tuá»•i: MIá»„N PHÃ",
            "â€¢ Tráº» 4-7 tuá»•i: GIáº¢M 50%",
            "â€¢ Tráº» 8-11 tuá»•i: GIáº¢M 15%",
            "â€¢ NgÆ°á»i lá»›n: GIáº¢M 5% cho nhÃ³m 4+",
            "â€¢ Táº·ng album áº£nh gia Ä‘Ã¬nh"
        ]),
        ("ðŸ‘¥ NHÃ“M Báº N BÃˆ", [
            "â€¢ 5-9 ngÆ°á»i: GIáº¢M 3%",
            "â€¢ 10-14 ngÆ°á»i: GIáº¢M 5%",
            "â€¢ 15-19 ngÆ°á»i: GIáº¢M 8%",
            "â€¢ 20-24 ngÆ°á»i: GIáº¢M 10%",
            "â€¢ 25-29 ngÆ°á»i: GIáº¢M 12%",
            "â€¢ 30+ ngÆ°á»i: GIáº¢M 15%",
            "â€¢ Sinh viÃªn: THÃŠM 5%"
        ]),
        ("ðŸ¢ CÃ”NG TY/TEAM BUILDING", [
            "â€¢ 10-19 ngÆ°á»i: GIáº¢M 8% + táº·ng 1 ngÆ°á»i",
            "â€¢ 20-29 ngÆ°á»i: GIáº¢M 10% + táº·ng 2 ngÆ°á»i",
            "â€¢ 30-39 ngÆ°á»i: GIáº¢M 12% + táº·ng 3 ngÆ°á»i",
            "â€¢ 40-49 ngÆ°á»i: GIáº¢M 15% + táº·ng 4 ngÆ°á»i",
            "â€¢ Miá»…n phÃ­ banner, backdrop",
            "â€¢ Chá»¥p áº£nh team chuyÃªn nghiá»‡p"
        ]),
        ("ðŸ‘´ NGÆ¯á»œI Lá»šN TUá»”I/Cá»°U CHIáº¾N BINH", [
            "â€¢ TrÃªn 60 tuá»•i: GIáº¢M 5%",
            "â€¢ Cá»±u chiáº¿n binh: GIáº¢M 10%",
            "â€¢ NhÃ³m 5+ ngÆ°á»i cao tuá»•i: THÃŠM 3%",
            "â€¢ Miá»…n phÃ­ nhÃ¢n viÃªn y táº¿ Ä‘i kÃ¨m",
            "â€¢ Xe Ä‘Æ°a Ä‘Ã³n táº­n nÆ¡i"
        ])
    ]
    
    for policy_title, benefits in discount_policies:
        reply += f"**{policy_title}**\n"
        for benefit in benefits:
            reply += f"{benefit}\n"
        reply += "\n"
    
    # 5. TOUR PHÃ™ Há»¢P CHO NHÃ“M
    if tour_indices:
        reply += "ðŸ—ºï¸ **TOUR Äá»€ XUáº¤T CHO NHÃ“M:**\n\n"
        
        # PhÃ¢n loáº¡i tour theo nhÃ³m
        group_suitable_tours = []
        
        for idx in tour_indices[:6]:
            tour = TOURS_DB.get(idx)
            if not tour:
                continue
                
            tour_summary = (tour.summary or '').lower()
            tour_name = (tour.name or '').lower()
            
            suitability_score = 0
            suitability_reasons = []
            
            if detected_group_type == 'family':
                if any(word in tour_summary for word in ['gia Ä‘Ã¬nh', 'tráº» em', 'nháº¹ nhÃ ng']):
                    suitability_score += 3
                    suitability_reasons.append("PhÃ¹ há»£p gia Ä‘Ã¬nh")
                if 'trekking' not in tour_summary and 'máº¡o hiá»ƒm' not in tour_summary:
                    suitability_score += 2
                    suitability_reasons.append("An toÃ n cho tráº» em")
                    
            elif detected_group_type == 'friends':
                if any(word in tour_summary for word in ['khÃ¡m phÃ¡', 'tráº£i nghiá»‡m', 'nhÃ³m']):
                    suitability_score += 3
                    suitability_reasons.append("Nhiá»u hoáº¡t Ä‘á»™ng nhÃ³m")
                if 'vui váº»' in tour_summary or 'thÃº vá»‹' in tour_summary:
                    suitability_score += 2
                    suitability_reasons.append("Táº¡o ká»· niá»‡m vui")
                    
            elif detected_group_type == 'corporate':
                if 'team building' in tour_summary or 'cÃ´ng ty' in tour_summary:
                    suitability_score += 4
                    suitability_reasons.append("Thiáº¿t káº¿ cho team building")
                if any(word in tour_summary for word in ['gáº¯n káº¿t', 'Ä‘oÃ n káº¿t', 'há»£p tÃ¡c']):
                    suitability_score += 2
                    suitability_reasons.append("TÄƒng cÆ°á»ng teamwork")
            
            if suitability_score > 0:
                group_suitable_tours.append({
                    'tour': tour,
                    'score': suitability_score,
                    'reasons': suitability_reasons[:2]
                })
        
        # Sáº¯p xáº¿p vÃ  hiá»ƒn thá»‹
        if group_suitable_tours:
            group_suitable_tours.sort(key=lambda x: x['score'], reverse=True)
            
            for i, item in enumerate(group_suitable_tours[:3], 1):
                tour = item['tour']
                reply += f"{i}. **{tour.name}**\n"
                
                if tour.duration:
                    reply += f"   â±ï¸ {tour.duration}\n"
                
                if item['reasons']:
                    reply += f"   âœ… {', '.join(item['reasons'])}\n"
                
                if tour.price:
                    price_info = _extract_price_value(tour.price)
                    if price_info and 'formatted' in price_info:
                        # TÃ­nh giÃ¡ nhÃ³m
                        if group_size and 'ngÆ°á»i' in group_size:
                            try:
                                size_num = int(group_size.split()[0])
                                if '-' in str(size_num):
                                    size_num = int(str(size_num).split('-')[0])
                                
                                group_price = price_info['value'] * size_num
                                discount = 0
                                
                                # TÃ­nh discount theo chÃ­nh sÃ¡ch
                                if detected_group_type == 'friends' and size_num >= 10:
                                    discount = 0.05
                                elif detected_group_type == 'corporate' and size_num >= 20:
                                    discount = 0.10
                                
                                if discount > 0:
                                    final_price = group_price * (1 - discount)
                                    reply += f"   ðŸ’° GiÃ¡ nhÃ³m {size_num} ngÆ°á»i: ~{_format_price(int(final_price), 'VND')} (Ä‘Ã£ giáº£m {int(discount*100)}%)\n"
                            except:
                                reply += f"   ðŸ’° {price_info['formatted']}\n"
                        else:
                            reply += f"   ðŸ’° {price_info['formatted']}\n"
                    else:
                        reply += f"   ðŸ’° {tour.price[:60]}...\n"
                
                reply += "\n"
            
            reply += "\n"
        else:
            reply += "ðŸŽ¯ **TOUR PHá»” BIáº¾N CHO NHÃ“M:**\n"
            reply += "â€¢ Tour team building TrÆ°á»ng SÆ¡n (2 ngÃ y)\n"
            reply += "â€¢ Tour gia Ä‘Ã¬nh Báº¡ch MÃ£ (1 ngÃ y)\n"
            reply += "â€¢ Tour nhÃ³m báº¡n Huáº¿ - áº¨m thá»±c (2 ngÃ y)\n\n"
    
    # 6. THIáº¾T Káº¾ TOUR TÃ™Y CHá»ˆNH
    reply += "ðŸŽ¨ **THIáº¾T Káº¾ TOUR RIÃŠNG THEO YÃŠU Cáº¦U:**\n\n"
    
    custom_options = [
        ("ðŸ“… **Lá»ŠCH TRÃŒNH LINH HOáº T**", [
            "â€¢ Chá»n ngÃ y khá»Ÿi hÃ nh mong muá»‘n",
            "â€¢ Äiá»u chá»‰nh thá»i gian cÃ¡c Ä‘iá»ƒm tham quan",
            "â€¢ ThÃªm/bá»›t Ä‘á»‹a Ä‘iá»ƒm theo sá»Ÿ thÃ­ch",
            "â€¢ Thiáº¿t káº¿ lá»™ trÃ¬nh Ä‘á»™c quyá»n"
        ]),
        ("ðŸ¨ **CHá»– á»ž CÃ NHÃ‚N HÃ“A**", [
            "â€¢ KhÃ¡ch sáº¡n 3-5 sao tÃ¹y chá»n",
            "â€¢ Homestay tráº£i nghiá»‡m Ä‘á»‹a phÆ°Æ¡ng",
            "â€¢ Resort cao cáº¥p",
            "â€¢ Káº¿t há»£p nhiá»u loáº¡i hÃ¬nh lÆ°u trÃº"
        ]),
        ("ðŸ½ï¸ **áº¨M THá»°C Äáº¶C BIá»†T**", [
            "â€¢ Set menu theo yÃªu cáº§u",
            "â€¢ áº¨m thá»±c chuyÃªn biá»‡t (chay, kiÃªng)",
            "â€¢ Bá»¯a tiá»‡c Ä‘áº·c biá»‡t",
            "â€¢ Tráº£i nghiá»‡m náº¥u Äƒn cÃ¹ng Ä‘áº§u báº¿p"
        ]),
        ("ðŸŽ­ **HOáº T Äá»˜NG RIÃŠNG**", [
            "â€¢ Team building thiáº¿t káº¿ riÃªng",
            "â€¢ Workshop Ä‘áº·c biá»‡t",
            "â€¢ Giao lÆ°u vÄƒn nghá»‡",
            "â€¢ Sá»± kiá»‡n riÃªng tÆ°"
        ]),
        ("ðŸšŒ **PHÆ¯Æ NG TIá»†N RIÃŠNG**", [
            "â€¢ Xe 4-45 chá»— tÃ¹y chá»n",
            "â€¢ Xe VIP cao cáº¥p",
            "â€¢ Xe cÃ³ trang thiáº¿t bá»‹ Ä‘áº·c biá»‡t",
            "â€¢ LÃ¡i xe riÃªng suá»‘t tour"
        ])
    ]
    
    for option_title, features in custom_options:
        reply += f"{option_title}\n"
        for feature in features:
            reply += f"{feature}\n"
        reply += "\n"
    
    # 7. QUY TRÃŒNH THIáº¾T Káº¾ TOUR RIÃŠNG
    reply += "ðŸ“‹ **QUY TRÃŒNH 5 BÆ¯á»šC THIáº¾T Káº¾ TOUR RIÃŠNG:**\n\n"
    
    process_steps = [
        ("1. ðŸ“ž **TIáº¾P NHáº¬N YÃŠU Cáº¦U**", "LiÃªn há»‡ hotline 0332510486, cung cáº¥p thÃ´ng tin nhÃ³m, thá»i gian, ngÃ¢n sÃ¡ch"),
        ("2. ðŸŽ¯ **TÆ¯ Váº¤N CHI TIáº¾T**", "ChuyÃªn viÃªn Ruby Wings phÃ¢n tÃ­ch vÃ  Ä‘á» xuáº¥t phÆ°Æ¡ng Ã¡n phÃ¹ há»£p"),
        ("3. ðŸ“ **THIáº¾T Káº¾ Lá»˜ TRÃŒNH**", "XÃ¢y dá»±ng lá»‹ch trÃ¬nh chi tiáº¿t, bÃ¡o giÃ¡ cá»¥ thá»ƒ tá»«ng háº¡ng má»¥c"),
        ("4. âœï¸ **CHá»ˆNH Sá»¬A & HOÃ€N THIá»†N**", "Äiá»u chá»‰nh theo yÃªu cáº§u, xÃ¡c nháº­n cuá»‘i cÃ¹ng"),
        ("5. âœ… **KÃ Há»¢P Äá»’NG & KHá»žI HÃ€NH**", "KÃ½ há»£p Ä‘á»“ng, thanh toÃ¡n, vÃ  báº¯t Ä‘áº§u hÃ nh trÃ¬nh")
    ]
    
    for step_num, step_desc in process_steps:
        reply += f"{step_num}\n{step_desc}\n\n"
    
    # 8. BÃO GIÃ MáºªU CHO NHÃ“M
    reply += "ðŸ’µ **BÃO GIÃ THAM KHáº¢O CHO NHÃ“M 20 NGÆ¯á»œI:**\n\n"
    
    sample_prices = [
        ("TOUR TEAM BUILDING 2 NGÃ€Y", [
            "â€¢ Xe 29 chá»— Ä‘á»i má»›i: 8,000,000 VNÄ",
            "â€¢ KhÃ¡ch sáº¡n 3 sao: 12,000,000 VNÄ/20 phÃ²ng",
            "â€¢ Ä‚n uá»‘ng (4 bá»¯a chÃ­nh): 150,000/suáº¥t VNÄ",
            "â€¢ VÃ© tham quan: tá»« 50,000 Ä‘áº¿n 200,000 VNÄ/ngÆ°á»i",
            "â€¢ HDV, báº£o hiá»ƒm, nÆ°á»›c uá»‘ng: Khoáº£ng3,000,000 VNÄ",
            "â€¢ **Tá»•ng cá»™ng: khoáº£ng 40,000,000 VNÄ**",
            "â€¢ **GiÃ¡/ngÆ°á»i: 1,900,000 VNÄ** (Ä‘Ã£ giáº£m 10%)"
        ]),
        ("TOUR GIA ÄÃŒNH 1 NGÃ€Y", [
            "â€¢ Xe 15 chá»—: 4,000,000 VNÄ",
            "â€¢ Ä‚n trÆ°a buffet: 150,000/suáº¥t VNÄ",
            "â€¢ VÃ© tham quan: tá»« 50,000 Ä‘áº¿n 200,000 VNÄ/ngÆ°á»i",
            "â€¢ Hoáº¡t Ä‘á»™ng gia Ä‘Ã¬nh: 2,000,000 VNÄ",
            "â€¢ **Tá»•ng cá»™ng: Khoáº£ng 20,000,000 VNÄ**",
            "â€¢ **Gia Ä‘Ã¬nh 4 ngÆ°á»i: Khoáº£ng 3,800,000 VNÄ** (Ä‘Ã£ giáº£m 5%)"
        ])
    ]
    
    for tour_title, price_details in sample_prices:
        reply += f"**{tour_title}**\n"
        for detail in price_details:
            reply += f"{detail}\n"
        reply += "\n"
    
    # 9. Káº¾T THÃšC
    reply += "ðŸ“ž **LiÃªn há»‡ thiáº¿t káº¿ tour nhÃ³m & tÆ° váº¥n chi tiáº¿t:** 0332510486\n"
    reply += "â° **Xá»­ lÃ½ yÃªu cáº§u trong 24h - Cam káº¿t giÃ¡ tá»‘t nháº¥t thá»‹ trÆ°á»ng**\n\n"
    reply += "âœ¨ *\"CÃ¹ng nhau khÃ¡m phÃ¡ - CÃ¹ng nhau tráº£i nghiá»‡m - CÃ¹ng nhau gáº¯n káº¿t\"* âœ¨"
    
    return reply


# ================== ENHANCED BOOKING & POLICY RESPONSE V4 ==================

def _get_booking_policy_response_v4(message_lower, tour_indices=None, TOURS_DB=None, context_info=None):
    """
    NÃ‚NG Cáº¤P 500%: Xá»­ lÃ½ Ä‘áº·t tour & chÃ­nh sÃ¡ch vá»›i Ä‘á»™ chi tiáº¿t cao
    - HÆ°á»›ng dáº«n Ä‘áº·t tour 5 bÆ°á»›c chi tiáº¿t
    - ChÃ­nh sÃ¡ch há»§y/Ä‘á»•i lá»‹ch Ä‘a cáº¥p Ä‘á»™
    - PhÆ°Æ¡ng thá»©c thanh toÃ¡n Ä‘a dáº¡ng
    - CÃ¢u há»i thÆ°á»ng gáº·p giáº£i Ä‘Ã¡p
    """
    
    # PHÃ‚N TÃCH LOáº I CÃ‚U Há»ŽI
    question_types = {
        'booking_process': ['Ä‘áº·t tour', 'Ä‘Äƒng kÃ½', 'booking', 'giá»¯ chá»—', 'cÃ¡ch Ä‘áº·t', 'lÃ m sao Ä‘á»ƒ Ä‘áº·t'],
        'cancellation': ['há»§y tour', 'há»§y Ä‘áº·t', 'hoÃ n tiá»n', 'khÃ´ng Ä‘i Ä‘Æ°á»£c', 'thay Ä‘á»•i káº¿ hoáº¡ch'],
        'reschedule': ['Ä‘á»•i lá»‹ch', 'dá»i lá»‹ch', 'thay Ä‘á»•i ngÃ y', 'chuyá»ƒn ngÃ y'],
        'payment': ['thanh toÃ¡n', 'chuyá»ƒn khoáº£n', 'tiá»n Ä‘áº·t cá»c', 'tráº£ gÃ³p', 'tháº» tÃ­n dá»¥ng'],
        'deposit': ['Ä‘áº·t cá»c', 'cá»c bao nhiÃªu', 'tiá»n cá»c', 'deposit'],
        'documents': ['giáº¥y tá»', 'há»™ chiáº¿u', 'CMND', 'giáº¥y tá» tÃ¹y thÃ¢n', 'thá»§ tá»¥c'],
        'confirmation': ['xÃ¡c nháº­n', 'Ä‘Ã£ Ä‘áº·t chÆ°a', 'kiá»ƒm tra Ä‘áº·t tour', 'mÃ£ Ä‘áº·t tour'],
        'refund': ['hoÃ n tiá»n', 'láº¥y láº¡i tiá»n', 'refund', 'tiá»n hoÃ n láº¡i'],
        'insurance': ['báº£o hiá»ƒm', 'mua báº£o hiá»ƒm', 'báº£o hiá»ƒm du lá»‹ch'],
        'child_policy': ['tráº» em', 'con nhá»', 'tráº» dÆ°á»›i', 'chÃ­nh sÃ¡ch tráº» em']
    }
    
    detected_question_types = []
    for q_type, keywords in question_types.items():
        if any(keyword in message_lower for keyword in keywords):
            detected_question_types.append(q_type)
    
    # XÃ‚Y Dá»°NG RESPONSE
    reply = "ðŸ“‹ **HÆ¯á»šNG DáºªN Äáº¶T TOUR & CHÃNH SÃCH CHI TIáº¾T** ðŸ“‹\n\n"
    
    # 1. QUY TRÃŒNH Äáº¶T TOUR 5 BÆ¯á»šC
    if 'booking_process' in detected_question_types or not detected_question_types:
        reply += "ðŸŽ¯ **QUY TRÃŒNH Äáº¶T TOUR 5 BÆ¯á»šC ÄÆ N GIáº¢N:**\n\n"
        
        booking_steps = [
            ("1. ðŸ“ž **LIÃŠN Há»† TÆ¯ Váº¤N**", 
             "Gá»i 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n tour phÃ¹ há»£p\nâ€¢ Thá»i gian: 24/7\nâ€¢ Nháº­n bÃ¡o giÃ¡ chi tiáº¿t trong 15 phÃºt"),
            
            ("2. ðŸ’° **Äáº¶T Cá»ŒC GIá»® CHá»–**",
             "Chuyá»ƒn khoáº£n 30% giÃ¡ tour\nâ€¢ NgÃ¢n hÃ ng: MB\nâ€¢ Sá»‘ TK: 98861886868\nâ€¢ Chá»§ TK: RUBY WINGS TRAVEL\nâ€¢ Ná»™i dung: TÃªn_SÄT_TÃªnTour"),
            
            ("3. ðŸ“ **HOÃ€N THIá»†N THá»¦ Tá»¤C**",
             "Cung cáº¥p thÃ´ng tin cÃ¡ nhÃ¢n:\nâ€¢ Há» tÃªn, ngÃ y thÃ¡ng nÄƒm sinh\nâ€¢ Sá»‘ CMND/CCCD/Há»™ chiáº¿u\nâ€¢ Sá»‘ Ä‘iá»‡n thoáº¡i, email\nâ€¢ ThÃ´ng tin ngÆ°á»i tham gia cÃ¹ng"),
            
            ("4. âœ… **NHáº¬N XÃC NHáº¬N**",
             "Nháº­n email xÃ¡c nháº­n Ä‘áº·t tour:\nâ€¢ MÃ£ Ä‘áº·t tour\nâ€¢ Lá»‹ch trÃ¬nh chi tiáº¿t\nâ€¢ HÆ°á»›ng dáº«n thanh toÃ¡n\nâ€¢ ThÃ´ng tin liÃªn há»‡ kháº©n cáº¥p"),
            
            ("5. ðŸšŒ **THANH TOÃN & KHá»žI HÃ€NH**",
             "Thanh toÃ¡n 70% cÃ²n láº¡i trÆ°á»›c 7 ngÃ y\nâ€¢ Nháº­n vÃ© Ä‘iá»‡n tá»­\nâ€¢ CÃ³ máº·t táº¡i Ä‘iá»ƒm táº­p trung Ä‘Ãºng giá»\nâ€¢ Mang theo giáº¥y tá» tÃ¹y thÃ¢n báº£n gá»‘c")
        ]
        
        for step_num, step_desc in booking_steps:
            reply += f"{step_num}\n{step_desc}\n\n"
    
    # 2. CHÃNH SÃCH Há»¦Y & Äá»”I Lá»ŠCH
    if any(q_type in detected_question_types for q_type in ['cancellation', 'reschedule', 'refund']):
        reply += "âš ï¸ **CHÃNH SÃCH Há»¦Y/Äá»”I Lá»ŠCH CHI TIáº¾T:**\n\n"
        
        cancellation_policy = [
            ("TRÆ¯á»šC 30 NGÃ€Y", "â€¢ HoÃ n 100% tiá»n Ä‘Ã£ thanh toÃ¡n\nâ€¢ Miá»…n phÃ­ Ä‘á»•i sang tour khÃ¡c\nâ€¢ Giá»¯ giÃ¡ Æ°u Ä‘Ã£i trong 6 thÃ¡ng"),
            
            ("TRÆ¯á»šC 15-29 NGÃ€Y", "â€¢ HoÃ n 80% tiá»n Ä‘Ã£ thanh toÃ¡n\nâ€¢ Äá»•i tour: PhÃ­ 5% giÃ¡ tour\nâ€¢ Giá»¯ giÃ¡ Æ°u Ä‘Ã£i trong 3 thÃ¡ng"),
            
            ("TRÆ¯á»šC 8-14 NGÃ€Y", "â€¢ HoÃ n 50% tiá»n Ä‘Ã£ thanh toÃ¡n\nâ€¢ Äá»•i tour: PhÃ­ 10% giÃ¡ tour\nâ€¢ Giá»¯ giÃ¡ Æ°u Ä‘Ã£i trong 1 thÃ¡ng"),
            
            ("TRÆ¯á»šC 4-7 NGÃ€Y", "â€¢ HoÃ n 30% tiá»n Ä‘Ã£ thanh toÃ¡n\nâ€¢ Äá»•i tour: PhÃ­ 20% giÃ¡ tour\nâ€¢ KhÃ´ng giá»¯ giÃ¡ Æ°u Ä‘Ã£i"),
            
            ("TRÆ¯á»šC 1-3 NGÃ€Y", "â€¢ HoÃ n 10% tiá»n Ä‘Ã£ thanh toÃ¡n\nâ€¢ Äá»•i tour: PhÃ­ 30% giÃ¡ tour\nâ€¢ Ãp dá»¥ng giÃ¡ má»›i"),
            
            ("TRONG NGÃ€Y KHá»žI HÃ€NH", "â€¢ KhÃ´ng hoÃ n tiá»n\nâ€¢ KhÃ´ng Ä‘á»•i lá»‹ch\nâ€¢ CÃ³ thá»ƒ chuyá»ƒn nhÆ°á»£ng cho ngÆ°á»i khÃ¡c")
        ]
        
        reply += "| Thá»i gian há»§y | ChÃ­nh sÃ¡ch hoÃ n tiá»n | PhÃ­ Ä‘á»•i tour |\n"
        reply += "|---------------|----------------------|--------------|\n"
        
        for timeframe, policy in cancellation_policy:
            lines = policy.split('\n')
            refund_policy = lines[0].replace('â€¢ ', '')
            change_policy = lines[1].replace('â€¢ ', '') if len(lines) > 1 else ""
            
            reply += f"| {timeframe} | {refund_policy} | {change_policy} |\n"
        
        reply += "\n"
        
        # ÄIá»€U KIá»†N Äáº¶C BIá»†T
        reply += "ðŸ’¡ **TRÆ¯á»œNG Há»¢P Äáº¶C BIá»†T (ÄÆ¯á»¢C MIá»„N PHÃ):**\n"
        reply += "â€¢ Bá»‡nh náº·ng cÃ³ giáº¥y tá» bá»‡nh viá»‡n\nâ€¢ Tai náº¡n, thiÃªn tai báº¥t kháº£ khÃ¡ng\nâ€¢ Tang láº¿ thÃ¢n nhÃ¢n trá»±c há»‡\nâ€¢ Thai sáº£n (cÃ³ xÃ¡c nháº­n bÃ¡c sÄ©)\n\n"
    
    # 3. PHÆ¯Æ NG THá»¨C THANH TOÃN
    if 'payment' in detected_question_types or 'deposit' in detected_question_types:
        reply += "ðŸ’³ **PHÆ¯Æ NG THá»¨C THANH TOÃN LINH HOáº T:**\n\n"
        
        payment_methods = [
            ("ðŸ’° **CHUYá»‚N KHOáº¢N NGÃ‚N HÃ€NG**", [
                "â€¢ MB: 98861886868 - RUBY WINGS TRAVEL",
                "â€¢ Techcombank: (cáº­p nháº­t sau) - RUBY WINGS TRAVEL",
                "â€¢ BIDV: (cáº­p nháº­t sau) - RUBY WINGS TRAVEL",
                "â€¢ Vietinbank: (cáº­p nháº­t sau) - RUBY WINGS TRAVEL",
                "â€¢ **Æ¯u Ä‘Ã£i: Giáº£m 2% khi thanh toÃ¡n online**"
            ]),
            
            ("ðŸ’³ **THáºº TÃN Dá»¤NG/THáºº GHI Ná»¢**", [
                "â€¢ Visa, MasterCard, JCB",
                "â€¢ Tháº» ná»™i Ä‘á»‹a (NAPAS)",
                "â€¢ QuÃ©t QR Code qua app ngÃ¢n hÃ ng",
                "â€¢ **PhÃ­: Miá»…n phÃ­**"
            ]),
            
            ("ðŸ§ **TIá»€N Máº¶T**", [
                "â€¢ Trá»±c tiáº¿p táº¡i vÄƒn phÃ²ng Ruby Wings",
                "â€¢ Äá»‹a chá»‰: 148 ÄÆ°á»ng TrÆ°Æ¡ng Gia MÃ´, TP Huáº¿",
                "â€¢ Thá»i gian: 8:00-20:00 hÃ ng ngÃ y",
                "â€¢ **Nháº­n hÃ³a Ä‘Æ¡n VAT Ä‘áº§y Ä‘á»§**"
            ]),
            
            ("ðŸ“± **VÃ ÄIá»†N Tá»¬**", [
                "â€¢ Momo: (cáº­p nháº­t sau)",
                "â€¢ ZaloPay: (cáº­p nháº­t sau)",
                "â€¢ VNPay: (cáº­p nháº­t sau)e",
                "â€¢ **XÃ¡c nháº­n ngay láº­p tá»©c**"
            ])
        ]
        
        for method_title, details in payment_methods:
            reply += f"{method_title}\n"
            for detail in details:
                reply += f"{detail}\n"
            reply += "\n"
    
    # 4. CHÃNH SÃCH TRáºº EM
    if 'child_policy' in detected_question_types:
        reply += "ðŸ‘¶ **CHÃNH SÃCH GIÃ TOUR CHO TRáºº EM:**\n\n"
        
        child_policy = [
            ("TRáºº DÆ¯á»šI 4 TUá»”I", [
                "â€¢ Miá»…n phÃ­ tour",
                "â€¢ Tá»± tÃºc vÃ© mÃ¡y bay (náº¿u cÃ³)",
                "â€¢ Phá»¥ thu phÃ²ng riÃªng (náº¿u cáº§n)",
                "â€¢ Ngá»§ chung giÆ°á»ng vá»›i bá»‘ máº¹"
            ]),
            
            ("TRáºº 4-7 TUá»”I", [
                "â€¢ GiÃ¡: 50% giÃ¡ tour ngÆ°á»i lá»›n",
                "â€¢ CÃ³ giÆ°á»ng riÃªng: +30%",
                "â€¢ Bao gá»“m: Ä‚n uá»‘ng, vÃ© tham quan",
                "â€¢ KhÃ´ng bao gá»“m: PhÃ²ng riÃªng"
            ]),
            
            ("TRáºº 8-11 TUá»”I", [
                "â€¢ GiÃ¡: 85% giÃ¡ tour ngÆ°á»i lá»›n",
                "â€¢ CÃ³ giÆ°á»ng riÃªng: +15%",
                "â€¢ Bao gá»“m Ä‘áº§y Ä‘á»§ dá»‹ch vá»¥",
                "â€¢ Ãp dá»¥ng má»i chÆ°Æ¡ng trÃ¬nh Æ°u Ä‘Ã£i"
            ]),
            
            ("TRáºº Tá»ª 12 TUá»”I", [
                "â€¢ TÃ­nh nhÆ° ngÆ°á»i lá»›n",
                "â€¢ Ãp dá»¥ng má»i Æ°u Ä‘Ã£i",
                "â€¢ Cáº§n giáº¥y tá» tÃ¹y thÃ¢n riÃªng",
                "â€¢ CÃ³ thá»ƒ Ä‘i tour 1 mÃ¬nh (cÃ³ giáº¥y á»§y quyá»n)"
            ])
        ]
        
        for age_group, policies in child_policy:
            reply += f"**{age_group}**\n"
            for policy in policies:
                reply += f"â€¢ {policy}\n"
            reply += "\n"
    
    # 5. Báº¢O HIá»‚M DU Lá»ŠCH
    if 'insurance' in detected_question_types:
        reply += "ðŸ›¡ï¸ **CHÃNH SÃCH Báº¢O HIá»‚M DU Lá»ŠCH:**\n\n"
        
        insurance_info = [
            ("**PHáº M VI Báº¢O HIá»‚M**", [
                "â€¢ Theo quy Ä‘á»‹nh Luáº­t Báº£o hiá»ƒm Viá»‡t Nam",
                "â€¢ Chi phÃ­ y táº¿: Max 60,000,000 VNÄ/ngÆ°á»i",
                "â€¢ Há»— trá»£ y táº¿ kháº©n cáº¥p: 24/7",
                "â€¢ Bá»“i thÆ°á»ng hÃ nh lÃ½: Max 5,000,000 VNÄ"
            ]),
            
            ("**ÄIá»€U KIá»†N ÃP Dá»¤NG**", [
                "â€¢ Tuá»•i tá»« 1-70 (ngoÃ i Ä‘á»™ tuá»•i: liÃªn há»‡)",
                "â€¢ KhÃ´ng cÃ³ bá»‡nh mÃ£n tÃ­nh náº·ng",
                "â€¢ KhÃ´ng tham gia hoáº¡t Ä‘á»™ng nguy hiá»ƒm trÃ¡i phÃ©p",
                "â€¢ TuÃ¢n thá»§ hÆ°á»›ng dáº«n an toÃ n"
            ]),
            
            ("**QUY TRÃŒNH Bá»’I THÆ¯á»œNG**", [
                "1. BÃ¡o ngay cho HDV trong 24h",
                "2. Láº­p biÃªn báº£n sá»± viá»‡c",
                "3. Thu tháº­p há»“ sÆ¡ y táº¿",
                "4. Nháº­n bá»“i thÆ°á»ng trong 15 ngÃ y"
            ])
        ]
        
        for title, details in insurance_info:
            reply += f"{title}\n"
            for detail in details:
                reply += f"{detail}\n"
            reply += "\n"
    
    # 6. THá»¦ Tá»¤C & GIáº¤Y Tá»œ
    if 'documents' in detected_question_types:
        reply += "ðŸ“„ **GIáº¤Y Tá»œ Cáº¦N THIáº¾T KHI ÄI TOUR:**\n\n"
        
        required_docs = [
            ("**Báº®T BUá»˜C**", [
                "â€¢ CMND/CCCD cÃ²n hiá»‡u lá»±c (báº£n gá»‘c)",
                "â€¢ Tráº» em: Giáº¥y khai sinh (báº£n sao cÃ´ng chá»©ng)",
                "â€¢ Há»™ chiáº¿u (Ä‘á»‘i vá»›i khÃ¡ch quá»‘c táº¿)",
                "â€¢ Visa (náº¿u Ä‘áº¿n vÃ¹ng biÃªn giá»›i)"
            ]),
            
            ("**KHUYáº¾N NGHá»Š**", [
                "â€¢ Tháº» báº£o hiá»ƒm y táº¿",
                "â€¢ ÄÆ¡n thuá»‘c (náº¿u Ä‘ang Ä‘iá»u trá»‹)",
                "â€¢ Giáº¥y xÃ¡c nháº­n tiÃªm chá»§ng",
                "â€¢ Tháº» há»c sinh/sinh viÃªn (Ä‘á»ƒ hÆ°á»Ÿng Æ°u Ä‘Ã£i)"
            ]),
            
            ("**Äáº¶C BIá»†T**", [
                "â€¢ Giáº¥y á»§y quyá»n (tráº» Ä‘i khÃ´ng bá»‘ máº¹)",
                "â€¢ Giáº¥y xÃ¡c nháº­n tÃ¬nh tráº¡ng sá»©c khá»e",
                "â€¢ Giáº¥y Ä‘Äƒng kÃ½ káº¿t hÃ´n (Ä‘Ã´i vá»£ chá»“ng)",
                "â€¢ Giáº¥y xÃ¡c nháº­n cÃ´ng tÃ¡c (náº¿u Ä‘i cÃ´ng tÃ¡c)"
            ])
        ]
        
        for doc_type, docs in required_docs:
            reply += f"{doc_type}\n"
            for doc in docs:
                reply += f"{doc}\n"
            reply += "\n"
    
    # 7. CÃ‚U Há»ŽI THÆ¯á»œNG Gáº¶P (FAQ)
    if not detected_question_types or len(detected_question_types) > 2:
        reply += "â“ **CÃ‚U Há»ŽI THÆ¯á»œNG Gáº¶P Vá»€ Äáº¶T TOUR:**\n\n"
        
        faqs = [
            ("**1. Äáº·t tour trÆ°á»›c bao lÃ¢u?**", 
             "â€¢ NÃªn Ä‘áº·t trÆ°á»›c Ã­t nháº¥t 7-14 ngÃ y\nâ€¢ Tour cao cáº¥p: Äáº·t trÆ°á»›c 30 ngÃ y\nâ€¢ Tour Táº¿t/lá»…: Äáº·t trÆ°á»›c 60 ngÃ y\nâ€¢ CÃ³ thá»ƒ Ä‘áº·t gáº¥p trong 24h (phá»¥ thu 10%)"),
            
            ("**2. LÃ m gÃ¬ khi bá»‹ máº¥t giáº¥y tá»?**",
             "â€¢ BÃ¡o ngay cho HDV vÃ  cÃ´ng an Ä‘á»‹a phÆ°Æ¡ng\nâ€¢ LÃ m giáº¥y xÃ¡c nháº­n máº¥t táº¡i cÃ´ng an\nâ€¢ Chá»¥p áº£nh giáº¥y tá» lÆ°u Ä‘iá»‡n tá»­ phÃ²ng ngá»«a\nâ€¢ Ruby Wings há»— trá»£ lÃ m thá»§ tá»¥c kháº©n"),
            
            ("**3. CÃ³ Ä‘Æ°á»£c mang theo váº­t nuÃ´i?**",
             "â€¢ KhÃ´ng Ä‘Æ°á»£c mang váº­t nuÃ´i lÃªn xe\nâ€¢ Má»™t sá»‘ resort cho phÃ©p (phá»¥ thu)\nâ€¢ Cáº§n thÃ´ng bÃ¡o trÆ°á»›c 7 ngÃ y\nâ€¢ Tá»± chá»‹u trÃ¡ch nhiá»‡m chÄƒm sÃ³c"),
            
            ("**4. Thay Ä‘á»•i ngÆ°á»i tham gia?**",
             "â€¢ ÄÆ°á»£c thay Ä‘á»•i trÆ°á»›c 7 ngÃ y\nâ€¢ PhÃ­ thay Ä‘á»•i: 10% giÃ¡ tour\nâ€¢ KhÃ´ng thay Ä‘á»•i trong 3 ngÃ y cuá»‘i\nâ€¢ NgÆ°á»i thay tháº¿ pháº£i Ä‘á»§ Ä‘iá»u kiá»‡n"),
            
            ("**5. Tour cÃ³ hÆ°á»›ng dáº«n viÃªn tiáº¿ng Anh?**",
             "â€¢ CÃ³, vá»›i phá»¥ thu 500,000 VNÄ/ngÃ y\nâ€¢ Äáº·t trÆ°á»›c 15 ngÃ y\nâ€¢ Cung cáº¥p CV HDV trÆ°á»›c chuyáº¿n Ä‘i\nâ€¢ Äáº£m báº£o cháº¥t lÆ°á»£ng chuyÃªn mÃ´n")
        ]
        
        for question, answer in faqs:
            reply += f"{question}\n{answer}\n\n"
    
    # 8. THÃ”NG TIN LIÃŠN Há»† & Há»– TRá»¢
    reply += "ðŸ“ž **THÃ”NG TIN Há»– TRá»¢ & LIÃŠN Há»†:**\n\n"
    
    contact_info = [
        ("**HOTLINE Äáº¶T TOUR**", "0332510486 (24/7)"),
        ("**EMAIL**", "rubywingslsa@gmail.com"),
        ("**VÄ‚N PHÃ’NG**", "148 ÄÆ°á»ng TrÆ°Æ¡ng Gia MÃ´, TP Huáº¿"),
        ("**GIá»œ LÃ€M VIá»†C**", "8:00 - 20:00 hÃ ng ngÃ y"),
        ("**Há»– TRá»¢ KHáº¨N**", "0912345678 (sá»± cá»‘ ngoÃ i giá»)"),
        ("**ZALO OA**", "@rubywings (chat tá»± Ä‘á»™ng 24/7)")
    ]
    
    for title, info in contact_info:
        reply += f"â€¢ **{title}:** {info}\n"
    
    reply += "\n"
    
    # 9. CAM Káº¾T Tá»ª RUBY WINGS
    reply += "âœ¨ **CAM Káº¾T Tá»ª RUBY WINGS:**\n"
    reply += "â€¢ Minh báº¡ch thÃ´ng tin, khÃ´ng phÃ¡t sinh chi phÃ­\n"
    reply += "â€¢ Há»— trá»£ 24/7 trong suá»‘t hÃ nh trÃ¬nh\n"
    reply += "â€¢ HoÃ n tiá»n 100% náº¿u khÃ´ng hÃ i lÃ²ng (cÃ³ Ä‘iá»u kiá»‡n)\n"
    reply += "â€¢ Æ¯u Ä‘Ã£i Ä‘áº·c biá»‡t cho khÃ¡ch hÃ ng thÃ¢n thiáº¿t\n\n"
    
    reply += "â° **Xá»­ lÃ½ yÃªu cáº§u trong vÃ²ng 15 phÃºt - Äáº£m báº£o quyá»n lá»£i khÃ¡ch hÃ ng**"
    
    return reply


# ================== BACKWARD COMPATIBILITY WRAPPERS ==================

def _get_experience_response(message_lower, tour_indices, TOURS_DB, user_profile=None):
    """Wrapper cho backward compatibility"""
    return _get_experience_response_v4(message_lower, tour_indices, TOURS_DB, user_profile)

def _get_group_custom_response(message_lower, tour_indices, TOURS_DB, mandatory_filters=None):
    """Wrapper cho backward compatibility"""
    return _get_group_custom_response_v4(message_lower, tour_indices, TOURS_DB, mandatory_filters)

def _get_booking_policy_response(message_lower, tour_indices=None, TOURS_DB=None, context_info=None):
    """Wrapper cho backward compatibility"""
    return _get_booking_policy_response_v4(message_lower, tour_indices, TOURS_DB, context_info)

# ================== INTEGRATION CHECKLIST ==================

"""
CÃCH TÃCH Há»¢P VÃ€O Há»† THá»NG:

1. SAO CHÃ‰P toÃ n bá»™ code trÃªn vÃ o file helper functions
2. Äáº¢M Báº¢O cÃ¡c hÃ m wrapper tá»“n táº¡i Ä‘á»ƒ khÃ´ng break code cÅ©
3. TRONG HÃ€M CHÃNH chat_endpoint_ultimate, thay tháº¿ cÃ¡c lá»i gá»i:

   Tá»«:
   if intent == 'experience':
       reply = _get_experience_response(message_lower, tour_indices, TOURS_DB)
   
   ThÃ nh:
   if intent == 'experience':
       reply = _get_experience_response_v4(message_lower, tour_indices, TOURS_DB, context.user_profile)

4. Cáº¬P NHáº¬T intent detection Ä‘á»ƒ nháº­n diá»‡n cÃ¡c intent má»›i:
   - 'experience': tráº£i nghiá»‡m tour
   - 'group_custom': nhÃ³m & tour tÃ¹y chá»‰nh  
   - 'booking_policy': Ä‘áº·t tour & chÃ­nh sÃ¡ch

5. TEST vá»›i cÃ¡c cÃ¢u há»i máº«u:
   - "Tour nÃ y cÃ³ tráº£i nghiá»‡m gÃ¬ Ä‘áº·c biá»‡t?"
   - "TÃ´i muá»‘n Ä‘áº·t tour cho nhÃ³m 15 ngÆ°á»i"
   - "ChÃ­nh sÃ¡ch há»§y tour tháº¿ nÃ o?"
"""

# ================== TEST FUNCTIONS ==================

def _test_all_enhanced_functions():
    """Test cÃ¡c hÃ m nÃ¢ng cáº¥p"""
    print("ðŸ§ª Testing enhanced helper functions V4...")
    
    # Mock data
    mock_tours_db = {
        1: type('Tour', (), {
            'name': 'Tour Báº¡ch MÃ£ Trekking',
            'duration': '2 ngÃ y 1 Ä‘Ãªm',
            'location': 'Báº¡ch MÃ£, Huáº¿',
            'price': '1,500,000 VNÄ',
            'summary': 'Tour trekking khÃ¡m phÃ¡ vÆ°á»n quá»‘c gia Báº¡ch MÃ£ vá»›i nhiá»u hoáº¡t Ä‘á»™ng máº¡o hiá»ƒm vÃ  tráº£i nghiá»‡m thiÃªn nhiÃªn. PhÃ¹ há»£p cho nhÃ³m báº¡n tráº» yÃªu thÃ­ch phiÃªu lÆ°u.',
            'tags': ['trekking', 'thiÃªn nhiÃªn', 'máº¡o hiá»ƒm'],
            'style': 'Adventure'
        })(),
        
        2: type('Tour', (), {
            'name': 'Tour Retreat Thiá»n Huáº¿',
            'duration': '3 ngÃ y 2 Ä‘Ãªm', 
            'location': 'Huáº¿',
            'price': '2,800,000 VNÄ',
            'summary': 'Retreat thiá»n Ä‘á»‹nh vÃ  yoga táº¡i khÃ´ng gian yÃªn tÄ©nh cá»§a Huáº¿. Tráº£i nghiá»‡m chá»¯a lÃ nh, tÄ©nh tÃ¢m vÃ  káº¿t ná»‘i ná»™i tÃ¢m.',
            'tags': ['thiá»n', 'yoga', 'retreat', 'chá»¯a lÃ nh'],
            'style': 'Wellness'
        })()
    }
    
    # Test 1: Experience Response
    print("\n1. Testing Experience Response...")
    exp_response = _get_experience_response_v4(
        "tour cÃ³ tráº£i nghiá»‡m máº¡o hiá»ƒm gÃ¬ khÃ´ng",
        [1, 2],
        mock_tours_db,
        {'interests': ['máº¡o hiá»ƒm', 'thiÃªn nhiÃªn']}
    )
    print(f"âœ… Experience Response Length: {len(exp_response)} chars")
    
    # Test 2: Group Custom Response  
    print("\n2. Testing Group Custom Response...")
    group_response = _get_group_custom_response_v4(
        "tÃ´i muá»‘n Ä‘áº·t tour cho nhÃ³m 20 ngÆ°á»i",
        [1, 2],
        mock_tours_db
    )
    print(f"âœ… Group Response Length: {len(group_response)} chars")
    
    # Test 3: Booking Policy Response
    print("\n3. Testing Booking Policy Response...")
    policy_response = _get_booking_policy_response_v4(
        "chÃ­nh sÃ¡ch há»§y tour tháº¿ nÃ o",
        [1, 2],
        mock_tours_db
    )
    print(f"âœ… Policy Response Length: {len(policy_response)} chars")
    
    print(f"\nðŸŽ‰ All tests passed! Total functions: 3")
    return True

# Auto-run tests if module is executed directly
if __name__ == "__main__":
    _test_all_enhanced_functions()





def _generate_enhanced_fallback_response(user_message, search_results, tour_indices, tours_db):
    """Táº¡o fallback response nÃ¢ng cao"""
    # Cá»‘ gáº¯ng táº¡o response tá»« thÃ´ng tin cÃ³ sáºµn
    if tour_indices:
        reply = "Dá»±a trÃªn cÃ¢u há»i cá»§a báº¡n, tÃ´i tÃ¬m tháº¥y má»™t sá»‘ tour cÃ³ thá»ƒ phÃ¹ há»£p:\n\n"
        
        for idx in tour_indices[:3]:
            tour = tours_db.get(idx)
            if tour:
                reply += f"**{tour.name}**\n"
                if tour.duration:
                    reply += f"â±ï¸ {tour.duration}\n"
                if tour.location:
                    location_short = tour.location[:50] + "..." if len(tour.location) > 50 else tour.location
                    reply += f"ðŸ“ {location_short}\n"
                if tour.summary:
                    summary_short = tour.summary[:100] + "..." if len(tour.summary) > 100 else tour.summary
                    reply += f"ðŸ“ {summary_short}\n"
                reply += "\n"
        
        reply += "Äá»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t hÆ¡n vá» cÃ¡c tour nÃ y hoáº·c tÃ¬m tour phÃ¹ há»£p nháº¥t vá»›i nhu cáº§u cá»§a báº¡n, vui lÃ²ng liÃªn há»‡ hotline 0332510486."
    elif search_results:
        reply = "Dá»±a trÃªn thÃ´ng tin tÃ´i cÃ³, Ä‘Ã¢y lÃ  má»™t sá»‘ thÃ´ng tin liÃªn quan:\n\n"
        
        for i, (score, passage) in enumerate(search_results[:2], 1):
            reply += f"{i}. {passage[:150]}...\n\n"
        
        reply += "Äá»ƒ cÃ³ thÃ´ng tin chÃ­nh xÃ¡c vÃ  Ä‘áº§y Ä‘á»§ hÆ¡n, vui lÃ²ng liÃªn há»‡ hotline 0332510486."
    else:
        reply = "Cáº£m Æ¡n cÃ¢u há»i cá»§a báº¡n. Äá»ƒ tÆ° váº¥n chÃ­nh xÃ¡c nháº¥t vá» cÃ¡c tour cá»§a Ruby Wings, báº¡n cÃ³ thá»ƒ:\n\n"
        reply += "1. Cung cáº¥p thÃªm thÃ´ng tin vá» nhu cáº§u cá»§a báº¡n\n"
        reply += "2. Gá»i trá»±c tiáº¿p hotline 0332510486\n"
        reply += "3. Tham kháº£o cÃ¡c tour phá»• biáº¿n:\n"
        reply += "   â€¢ Tour thiÃªn nhiÃªn Báº¡ch MÃ£ (1 ngÃ y)\n"
        reply += "   â€¢ Tour lá»‹ch sá»­ TrÆ°á»ng SÆ¡n (2 ngÃ y 1 Ä‘Ãªm)\n"
        reply += "   â€¢ Tour retreat thiá»n (1-2 ngÃ y)\n\n"
        reply += "ðŸ“ž **Hotline tÆ° váº¥n 24/7:** 0332510486"
    
    return reply


# ================== MODULE COMPATIBILITY CHECK ==================
# CÃ¡c module cáº§n nÃ¢ng cáº¥p Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch:

"""
1. MandatoryFilterSystem.apply_filters() cáº§n sá»­a lá»—i:
   - Lá»—i "khÃ´ng cÃ³ nhÃ³m nÃ o nhÆ° váº­y" 
   - ThÃªm xá»­ lÃ½ exception vÃ  fallback

2. FuzzyMatcher.find_similar_tours() cáº§n cáº£i thiá»‡n:
   - Giáº£m ngÆ°á»¡ng matching tá»« 0.7 xuá»‘ng 0.6
   - TÄƒng sá»‘ káº¿t quáº£ tráº£ vá»

3. CacheSystem cáº§n há»— trá»£:
   - Cache vá»›i expiry time
   - Key generation vá»›i nhiá»u tham sá»‘ hÆ¡n

4. DeduplicationEngine cáº§n:
   - Xá»­ lÃ½ tá»‘t hÆ¡n vá»›i cÃ¡c tour tÆ°Æ¡ng tá»±
   - Giá»¯ láº¡i tour cháº¥t lÆ°á»£ng cao hÆ¡n

5. QueryIndex cáº§n:
   - Tráº£ vá» nhiá»u káº¿t quáº£ hÆ¡n (tÄƒng TOP_K)
   - Cáº£i thiá»‡n relevance scoring
"""

# ThÃªm cÃ¡c hÃ m helper má»›i vÃ o cÃ¡c module tÆ°Æ¡ng á»©ng











# ThÃªm cÃ¡c hÃ m helper má»›i vÃ o cÃ¡c module tÆ°Æ¡ng á»©ng
# =========== OTHER ENDPOINTS ===========
@app.route("/")
def home():
    """Home endpoint"""
    return jsonify({
        "status": "ok",
        "version": "4.0",
        "upgrades": UpgradeFlags.get_all_flags(),
        "services": {
            "openai": "available" if client else "unavailable",
            "faiss": "available" if HAS_FAISS else "unavailable",
            "google_sheets": "available" if HAS_GOOGLE_SHEETS else "unavailable",
            "meta_capi": "available" if HAS_META_CAPI else "unavailable",
        },
        "counts": {
            "tours": len(TOURS_DB),
            "passages": len(FLAT_TEXTS),
            "tour_names": len(TOUR_NAME_TO_INDEX),
        }
    })

@app.route("/reindex", methods=["POST"])
def reindex():
    """Rebuild index endpoint"""
    secret = request.headers.get("X-RBW-ADMIN", "")
    if not secret and os.environ.get("RBW_ALLOW_REINDEX", "") != "1":
        return jsonify({"error": "reindex not allowed"}), 403
    
    load_knowledge()
    build_index(force_rebuild=True)
    
    return jsonify({
        "ok": True,
        "count": len(FLAT_TEXTS),
        "tours": len(TOURS_DB)
    })

# =========== GOOGLE SHEETS INTEGRATION ===========
_gsheet_client = None
_gsheet_client_lock = threading.Lock()

def get_gspread_client(force_refresh: bool = False):
    """Get Google Sheets client"""
    global _gsheet_client
    
    if not GOOGLE_SERVICE_ACCOUNT_JSON:
        logger.error("GOOGLE_SERVICE_ACCOUNT_JSON not set")
        return None
    
    with _gsheet_client_lock:
        if _gsheet_client is not None and not force_refresh:
            return _gsheet_client
        
        try:
            info = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
            scopes = [
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/drive",
            ]
            creds = Credentials.from_service_account_info(info, scopes=scopes)
            _gsheet_client = gspread.authorize(creds)
            logger.info("âœ… Google Sheets client initialized")
            return _gsheet_client
        except Exception as e:
            logger.error(f"âŒ Google Sheets client failed: {e}")
            return None

@app.route('/api/save-lead', methods=['POST', 'OPTIONS'])
def save_lead():
    """Save lead from form submission - Äáº¦Y Äá»¦ 9 TRÆ¯á»œNG (A-I)"""
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200
    
    try:
        data = request.get_json() or {}
        
        # Extract data
        phone = data.get('phone', '').strip()
        name = data.get('name', '').strip()
        email = data.get('email', '').strip()
        tour_interest = data.get('tour_interest', '').strip()
        page_url = data.get('page_url', '').strip()
        note = data.get('note', '').strip()
        
        if not phone:
            return jsonify({'error': 'Phone number is required'}), 400
        
        # Clean phone
        phone_clean = re.sub(r'[^\d+]', '', phone)
        
        # Validate phone
        if not re.match(r'^(0|\+?84)\d{9,10}$', phone_clean):
            return jsonify({'error': 'Invalid phone number format'}), 400
        
        # Timestamp
        timestamp = datetime.now().isoformat()
        
        # Create lead data
        lead_data = {
            'timestamp': timestamp,
            'phone': phone_clean,
            'name': name,
            'email': email,
            'tour_interest': tour_interest,
            'page_url': page_url,
            'note': note,
            'source': 'Lead Form'
        }
        
        # Send to Meta CAPI
        if ENABLE_META_CAPI_CALL and HAS_META_CAPI:
            try:
                result = send_meta_lead(
                    request,
                    phone=phone_clean,
                    contact_name=name,
                    email=email,
                    content_name=f"Tour: {tour_interest}" if tour_interest else "General Inquiry",
                    value=200000,
                    currency="VND"
                )
                increment_stat('meta_capi_calls')
                logger.info(f"âœ… Form lead sent to Meta CAPI: {phone_clean[:4]}***")
                if DEBUG and HAS_META_CAPI:
                    logger.debug(f"Meta CAPI result: {result}")
            except Exception as e:
                increment_stat('meta_capi_errors')
                logger.error(f"Meta CAPI error: {e}")
        
        # Save to Google Sheets - Äáº¦Y Äá»¦ 9 TRÆ¯á»œNG (A-I)
        if ENABLE_GOOGLE_SHEETS:
            try:
                import gspread
                from google.oauth2.service_account import Credentials
                
                if GOOGLE_SERVICE_ACCOUNT_JSON and GOOGLE_SHEET_ID:
                    creds_json = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
                    creds = Credentials.from_service_account_info(
                        creds_json,
                        scopes=['https://www.googleapis.com/auth/spreadsheets']
                    )
                    
                    gc = gspread.authorize(creds)
                    sh = gc.open_by_key(GOOGLE_SHEET_ID)
                    ws = sh.worksheet(GOOGLE_SHEET_NAME)
                    
                    # ÄÃšng 9 TRÆ¯á»œNG THEO THá»¨ Tá»° A-I:
                    # A: created_at (timestamp)
                    # B: source_channel
                    # C: action_type
                    # D: page_url
                    # E: contact_name
                    # F: phone
                    # G: service_interest
                    # H: note
                    # I: raw_status
                    row = [
                        timestamp,                          # A: created_at
                        'Website - Lead Form',              # B: source_channel
                        'Form Submission',                  # C: action_type
                        page_url or '',                     # D: page_url
                        name or '',                         # E: contact_name
                        phone_clean,                        # F: phone
                        tour_interest or '',                # G: service_interest
                        note or email or '',                # H: note (dÃ¹ng email náº¿u khÃ´ng cÃ³ note)
                        'New'                               # I: raw_status
                    ]
                    
                    ws.append_row(row)
                    logger.info("âœ… Form lead saved to Google Sheets (9 fields)")
            except Exception as e:
                logger.error(f"Google Sheets error: {e}")
        
        # Fallback storage
        if ENABLE_FALLBACK_STORAGE:
            try:
                if os.path.exists(FALLBACK_STORAGE_PATH):
                    with open(FALLBACK_STORAGE_PATH, 'r', encoding='utf-8') as f:
                        leads = json.load(f)
                else:
                    leads = []
                
                leads.append(lead_data)
                leads = leads[-1000:]
                
                with open(FALLBACK_STORAGE_PATH, 'w', encoding='utf-8') as f:
                    json.dump(leads, f, ensure_ascii=False, indent=2)
                
                logger.info("âœ… Form lead saved to fallback storage")
            except Exception as e:
                logger.error(f"Fallback storage error: {e}")
        
        # Update stats
        increment_stat('leads')
        
        return jsonify({
            'success': True,
            'message': 'Lead Ä‘Ã£ Ä‘Æ°á»£c lÆ°u! Äá»™i ngÅ© Ruby Wings sáº½ liÃªn há»‡ sá»›m nháº¥t. ðŸ“ž',
            'data': {
                'phone': phone_clean[:3] + '***' + phone_clean[-2:],
                'timestamp': timestamp
            }
        })
        
    except Exception as e:
        logger.error(f"âŒ Save lead error: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/call-button', methods=['POST', 'OPTIONS'])
def call_button():
    """Track call button click"""
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200
    
    try:
        data = request.get_json() or {}
        
        page_url = data.get('page_url', '')
        call_type = data.get('call_type', 'regular')
        
        # Send to Meta CAPI
        if ENABLE_META_CAPI_CALL and HAS_META_CAPI:
            try:
                result = send_meta_call_button(
                    request,
                    page_url=page_url,
                    call_type=call_type,
                    button_location='fixed_bottom_left',
                    button_text='Gá»i ngay'
                )
                increment_stat('meta_capi_calls')
                logger.info(f"ðŸ“ž Call button tracked: {call_type}")
                if DEBUG and HAS_META_CAPI:
                    logger.debug(f"Meta CAPI result: {result}")
            except Exception as e:
                increment_stat('meta_capi_errors')
                logger.error(f"Meta CAPI call error: {e}")
        
        return jsonify({
            'success': True,
            'message': 'Call tracked',
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Call button error: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    try:
        return jsonify({
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "services": {
                "chatbot": "running",
                "openai": "available" if client else "unavailable",
                "faiss": "available" if INDEX else "unavailable",
                "tours_db": len(TOURS_DB),
                "upgrades": {k: v for k, v in UpgradeFlags.get_all_flags().items() 
                           if k.startswith("UPGRADE_")}
            },
            "memory_profile": {
                "ram_profile": RAM_PROFILE,
                "is_low_ram": IS_LOW_RAM,
                "is_high_ram": IS_HIGH_RAM,
                "tour_count": len(TOURS_DB),
                "context_count": len(SESSION_CONTEXTS)
            }
        })
    except Exception as e:
        return jsonify({
            "status": "unhealthy",
            "error": str(e)
        }), 500

# =========== INITIALIZATION ===========
def initialize_app():
    """Initialize the application"""
    logger.info("ðŸš€ Starting Ruby Wings Chatbot v4.0 (Dataclass Rewrite)...")
    
    # Apply memory optimizations
    optimize_for_memory_profile()
    
    # Load knowledge base
    load_knowledge()
    
    # Load or build tours database
    if os.path.exists(FAISS_MAPPING_PATH):
        try:
            with open(FAISS_MAPPING_PATH, 'r', encoding='utf-8') as f:
                MAPPING[:] = json.load(f)
            FLAT_TEXTS[:] = [m.get('text', '') for m in MAPPING]
            logger.info(f"ðŸ“ Loaded {len(MAPPING)} mappings from disk")
        except Exception as e:
            logger.error(f"Failed to load mappings: {e}")
    
    # Build tour databases
    index_tour_names()
    build_tours_db()
    
    # Build index in background
    def build_index_background():
        time.sleep(2)
        success = build_index(force_rebuild=False)
        if success:
            logger.info("âœ… Index ready")
        else:
            logger.warning("âš ï¸ Index building failed")
    
    threading.Thread(target=build_index_background, daemon=True).start()
    
    # Initialize Google Sheets client
    if ENABLE_GOOGLE_SHEETS:
        threading.Thread(target=get_gspread_client, daemon=True).start()
    
    # Log active upgrades
    active_upgrades = [name for name, enabled in UpgradeFlags.get_all_flags().items() 
                      if enabled and name.startswith("UPGRADE_")]
    logger.info(f"ðŸ”§ Active upgrades: {len(active_upgrades)}")
    for upgrade in active_upgrades:
        logger.info(f"   â€¢ {upgrade}")
    
    # Log memory profile
    logger.info(f"ðŸ§  Memory Profile: {RAM_PROFILE}MB | Low RAM: {IS_LOW_RAM} | High RAM: {IS_HIGH_RAM}")
    logger.info(f"ðŸ“Š Tours Database: {len(TOURS_DB)} tours loaded")
    
    logger.info("âœ… Application initialized successfully with dataclasses")

# =========== APPLICATION START ===========
if __name__ == "__main__":
    initialize_app()
    
    # Save mappings if not exists
    if MAPPING and not os.path.exists(FAISS_MAPPING_PATH):
        try:
            with open(FAISS_MAPPING_PATH, 'w', encoding='utf-8') as f:
                json.dump(MAPPING, f, ensure_ascii=False, indent=2)
            logger.info(f"ðŸ’¾ Saved mappings to {FAISS_MAPPING_PATH}")
        except Exception as e:
            logger.error(f"Failed to save mappings: {e}")
    
    # Start server
    logger.info(f"ðŸŒ Starting server on {HOST}:{PORT}")
    app.run(host=HOST, port=PORT, debug=DEBUG, threaded=True)

else:
    # For WSGI
    initialize_app()