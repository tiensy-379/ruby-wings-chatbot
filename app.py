#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RUBY WINGS AI CHATBOT - PRODUCTION VERSION 6.0.1 (COMPLETE FIX)
Created: 2025-01-17
Author: Ruby Wings AI Team

FIX V6.0.1: URGENT FIX FOR OPENAI CLIENT INITIALIZATION
- FIXED: Client.__init__() kh√¥ng mong mu·ªën 'proxies' parameter
- FIXED: OpenAI client initialization trong c·∫£ SearchEngine v√† ResponseGenerator
- ENHANCED: Logging b·∫±ng ti·∫øng Vi·ªát cho d·ªÖ ƒë·ªçc
- OPTIMIZED: Performance v·ªõi minimal initialization
"""

# ==================== CORE IMPORTS ====================
import os
import sys
import json
import time
import threading
import logging
import re
import hashlib
import traceback
import random
import warnings
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union
from functools import lru_cache, wraps
from collections import defaultdict, OrderedDict

# Suppress warnings
warnings.filterwarnings("ignore")

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

# ==================== PLATFORM DETECTION ====================
import platform
IS_WINDOWS = platform.system().lower().startswith("win")
IS_RENDER = "RENDER" in os.environ
IS_PRODUCTION = os.environ.get("FLASK_ENV", "production") == "production"

# ==================== FLASK & WEB ====================
from flask import Flask, request, jsonify, g, session
from flask_cors import CORS
from werkzeug.middleware.proxy_fix import ProxyFix

# ==================== LOGGING ====================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('ruby_wings.log') if IS_PRODUCTION else logging.NullHandler()
    ]
)
logger = logging.getLogger("ruby-wings-v6.0.1-fixed")

# ==================== CONFIGURATION ====================
class Config:
    """Centralized configuration"""
    
    # RAM Profile
    RAM_PROFILE = os.getenv("RAM_PROFILE", "512")
    IS_LOW_RAM = RAM_PROFILE == "512"
    
    # Core API Keys
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
    META_CAPI_TOKEN = os.getenv("META_CAPI_TOKEN", "").strip()
    META_PIXEL_ID = os.getenv("META_PIXEL_ID", "").strip()
    SECRET_KEY = os.getenv("SECRET_KEY", "").strip() or os.urandom(24).hex()
    
    # File Paths
    KNOWLEDGE_PATH = os.getenv("KNOWLEDGE_PATH", "knowledge.json")
    FAISS_INDEX_PATH = os.getenv("FAISS_INDEX_PATH", "faiss_index.bin")
    FAISS_MAPPING_PATH = os.getenv("FAISS_MAPPING_PATH", "faiss_mapping.json")
    FALLBACK_VECTORS_PATH = os.getenv("FALLBACK_VECTORS_PATH", "vectors.npz")
    TOUR_ENTITIES_PATH = os.getenv("TOUR_ENTITIES_PATH", "tour_entities.json")
    FALLBACK_STORAGE_PATH = os.getenv("FALLBACK_STORAGE_PATH", "leads_fallback.json")
    
    # OpenAI Models
    EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
    CHAT_MODEL = os.getenv("CHAT_MODEL", "gpt-4o-mini")
    OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
    
    # Feature Toggles
    FAISS_ENABLED = os.getenv("FAISS_ENABLED", "false").lower() == "true"
    ENABLE_INTENT_DETECTION = os.getenv("ENABLE_INTENT_DETECTION", "true").lower() == "true"
    ENABLE_PHONE_DETECTION = os.getenv("ENABLE_PHONE_DETECTION", "true").lower() == "true"
    ENABLE_LEAD_CAPTURE = os.getenv("ENABLE_GOOGLE_SHEETS", "true").lower() == "true"
    ENABLE_LLM_FALLBACK = True
    ENABLE_CACHING = True
    ENABLE_GOOGLE_SHEETS = os.getenv("ENABLE_GOOGLE_SHEETS", "true").lower() == "true"
    ENABLE_META_CAPI = os.getenv("ENABLE_META_CAPI_LEAD", "true").lower() == "true"
    ENABLE_META_CAPI_CALL = os.getenv("ENABLE_META_CAPI_CALL", "true").lower() == "true"
    ENABLE_FALLBACK_STORAGE = os.getenv("ENABLE_FALLBACK_STORAGE", "true").lower() == "true"
    ENABLE_TOUR_FILTERING = os.getenv("ENABLE_TOUR_FILTERING", "true").lower() == "true"
    ENABLE_COMPANY_INFO = os.getenv("ENABLE_COMPANY_INFO", "true").lower() == "true"
    ENABLE_META_CAPI_LEAD = os.getenv("ENABLE_META_CAPI_LEAD", "false").lower() == "true"
    ENABLE_ADVANCED_INTENT = True
    
    # State Machine
    STATE_MACHINE_ENABLED = True
    ENABLE_LOCATION_FILTER = True
    ENABLE_SEMANTIC_ANALYSIS = True
    
    # Performance Settings
    TOP_K = int(os.getenv("TOP_K", "5" if IS_LOW_RAM else "10"))
    MAX_TOURS_PER_RESPONSE = 3
    CACHE_TTL_SECONDS = 300
    MAX_SESSIONS = 50 if IS_LOW_RAM else 100
    MAX_EMBEDDING_CACHE = 30 if IS_LOW_RAM else 50
    CONVERSATION_HISTORY_LIMIT = 5 if IS_LOW_RAM else 10
    
    # Server Config
    HOST = os.getenv("HOST", "0.0.0.0")
    PORT = int(os.getenv("PORT", "10000"))
    TIMEOUT = int(os.getenv("TIMEOUT", "60"))
    DEBUG = os.getenv("DEBUG", "false").lower() == "true"
    
    # CORS
    CORS_ORIGINS_RAW = os.getenv("CORS_ORIGINS", "*")
    CORS_ORIGINS = CORS_ORIGINS_RAW if CORS_ORIGINS_RAW == "*" else [
        o.strip() for o in CORS_ORIGINS_RAW.split(",") if o.strip()
    ]
    
    # Google Sheets
    GOOGLE_SERVICE_ACCOUNT_JSON = os.getenv("GOOGLE_SERVICE_ACCOUNT_JSON", "")
    GOOGLE_SHEET_ID = os.getenv("GOOGLE_SHEET_ID", "")
    GOOGLE_SHEET_NAME = os.getenv("GOOGLE_SHEET_NAME", "RBW_Lead_Raw_Inbox")
    
    # Meta CAPI
    META_CAPI_ENDPOINT = os.getenv("META_CAPI_ENDPOINT", "https://graph.facebook.com")
    META_TEST_EVENT_CODE = os.getenv("META_TEST_EVENT_CODE", "")
    DEBUG_META_CAPI = os.getenv("DEBUG_META_CAPI", "false").lower() == "true"
    
    # LLM Settings
    ENABLE_LLM_ADVICE = True
    LLM_TEMPERATURE = 0.7
    LLM_MAX_TOKENS = 800
    ENABLE_PROMPT_ENGINEERING = True
    
    @classmethod
    def log_config(cls):
        """Log configuration on startup"""
        logger.info("=" * 60)
        logger.info("üöÄ RUBY WINGS CHATBOT v6.0.1 (Fixed OpenAI Client)")
        logger.info("=" * 60)
        logger.info(f"üìä RAM Profile: {cls.RAM_PROFILE}MB")
        logger.info(f"üåç Environment: {'Production' if IS_PRODUCTION else 'Development'}")
        
        features = []
        if cls.STATE_MACHINE_ENABLED:
            features.append("State Machine")
        if cls.FAISS_ENABLED:
            features.append("FAISS")
        else:
            features.append("Numpy Fallback")
        if cls.ENABLE_META_CAPI:
            features.append("Meta CAPI")
        if cls.ENABLE_GOOGLE_SHEETS:
            features.append("Google Sheets")
        if cls.ENABLE_TOUR_FILTERING:
            features.append("Tour Filtering")
        if cls.ENABLE_COMPANY_INFO:
            features.append("Company Info")
        if cls.ENABLE_LLM_ADVICE:
            features.append("LLM Advisory")
        
        logger.info(f"üéØ Features: {', '.join(features)}")
        logger.info(f"üîë OpenAI: {'‚úÖ' if cls.OPENAI_API_KEY else '‚ùå'}")
        logger.info(f"üåê CORS: {cls.CORS_ORIGINS}")
        logger.info("=" * 60)

# ==================== ENUM INTENT FIX ====================
class Intent:
    """Fixed Intent Enum - Complete set"""
    GREETING = "GREETING"
    FAREWELL = "FAREWELL"
    SMALLTALK = "SMALLTALK"
    UNKNOWN = "UNKNOWN"
    TOUR_INQUIRY = "TOUR_INQUIRY"
    TOUR_LIST = "TOUR_LIST"
    TOUR_FILTER = "TOUR_FILTER"
    TOUR_DETAIL = "TOUR_DETAIL"
    TOUR_COMPARE = "TOUR_COMPARE"
    TOUR_RECOMMEND = "TOUR_RECOMMEND"
    TOUR_ADVICE = "TOUR_ADVICE"
    PRICE_ASK = "PRICE_ASK"
    PRICE_COMPARE = "PRICE_COMPARE"
    PRICE_RANGE = "PRICE_RANGE"
    BOOKING_REQUEST = "BOOKING_REQUEST"
    BOOKING_PROCESS = "BOOKING_PROCESS"
    BOOKING_CONDITION = "BOOKING_CONDITION"
    PROVIDE_PHONE = "PROVIDE_PHONE"
    CALLBACK_REQUEST = "CALLBACK_REQUEST"
    CONTACT_INFO = "CONTACT_INFO"
    ABOUT_COMPANY = "ABOUT_COMPANY"
    COMPANY_SERVICE = "COMPANY_SERVICE"
    COMPANY_MISSION = "COMPANY_MISSION"
    LEAD_CAPTURED = "LEAD_CAPTURED"

class ConversationStage:
    """Conversation stages"""
    EXPLORE = "explore"
    SUGGEST = "suggest"
    COMPARE = "compare"
    SELECT = "select"
    BOOK = "book"
    LEAD = "lead"
    CALLBACK = "callback"

def normalize_intent(intent_value: Any) -> str:
    """Normalize intent to string value"""
    if intent_value is None:
        return Intent.UNKNOWN
    
    if isinstance(intent_value, str):
        return intent_value
    
    if hasattr(intent_value, 'name'):
        return intent_value.name
    
    if hasattr(intent_value, 'value'):
        return intent_value.value
    
    return str(intent_value)

def is_intent_equal(intent1: Any, intent2: Any) -> bool:
    """Compare two intents safely"""
    intent1_str = normalize_intent(intent1)
    intent2_str = normalize_intent(intent2)
    
    return intent1_str == intent2_str

# ==================== LAZY IMPORTS ====================
def lazy_import_numpy():
    """Lazy import numpy"""
    try:
        import numpy as np
        return np, True
    except ImportError:
        logger.warning("‚ö†Ô∏è Numpy kh√¥ng kh·∫£ d·ª•ng")
        return None, False

def lazy_import_faiss():
    """Lazy import FAISS"""
    if not Config.FAISS_ENABLED:
        return None, False
    try:
        import faiss
        return faiss, True
    except ImportError:
        logger.warning("‚ö†Ô∏è FAISS kh√¥ng kh·∫£ d·ª•ng, s·ª≠ d·ª•ng numpy fallback")
        return None, False

def lazy_import_openai():
    """Lazy import OpenAI - FIXED: Kh√¥ng c√≥ proxies parameter"""
    try:
        from openai import OpenAI
        return OpenAI, True
    except ImportError:
        logger.error("‚ùå Th∆∞ vi·ªán OpenAI kh√¥ng kh·∫£ d·ª•ng")
        return None, False

# Initialize lazy imports
np, NUMPY_AVAILABLE = lazy_import_numpy()
faiss, FAISS_AVAILABLE = lazy_import_faiss()
OpenAI, OPENAI_AVAILABLE = lazy_import_openai()

# ==================== GLOBAL STATE INIT ====================
class GlobalState:
    """Global state with enhanced intent tracking"""
    
    _instance = None
    _lock = threading.RLock()
    
    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super().__new__(cls)
                cls._instance._initialize()
            return cls._instance
    
    def _initialize(self):
        """Initialize state"""
        self.tours_db: Dict[int, Dict] = {}
        self.tour_name_index: Dict[str, int] = {}
        self.tour_entities: List[Dict] = []
        self.about_company: Dict = {}
        self.session_contexts: Dict[str, Dict] = {}
        self.mapping: List[Dict] = []
        self.index = None
        self.vectors = None
        
        # Enhanced data structures
        self.tour_entities_dict: Dict[str, Dict] = {}
        self.tour_tags_index: Dict[str, List[int]] = defaultdict(list)
        self.tour_region_index: Dict[str, List[int]] = defaultdict(list)
        
        self.response_cache: OrderedDict = OrderedDict()
        self.embedding_cache: OrderedDict = OrderedDict()
        
        self.stats = {
            "requests": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "sessions": 0,
            "leads": 0,
            "errors": 0,
            "meta_capi_calls": 0,
            "meta_capi_errors": 0,
            "intent_counts": defaultdict(int),
            "llm_calls": 0,
            "llm_errors": 0,
            "start_time": datetime.now()
        }
        
        self._knowledge_loaded = False
        self._index_loaded = False
        self._tour_entities_loaded = False
        self._company_info_loaded = False
        
        self.search_engine = None
        self.response_generator = None
        self.chat_processor = None
        
        logger.info("üåê Global state ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o")
    
    def init_components(self):
        """Initialize components after knowledge loaded"""
        with self._lock:
            if self.search_engine is None:
                try:
                    from app import SearchEngine
                    self.search_engine = SearchEngine()
                    logger.info("‚úÖ SearchEngine ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o")
                except Exception as e:
                    logger.error(f"‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o SearchEngine: {e}")
            
            if self.response_generator is None:
                try:
                    from app import ResponseGenerator
                    self.response_generator = ResponseGenerator()
                    logger.info("‚úÖ ResponseGenerator ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o")
                except Exception as e:
                    logger.error(f"‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o ResponseGenerator: {e}")
            
            if self.chat_processor is None:
                try:
                    from app import ChatProcessor
                    self.chat_processor = ChatProcessor()
                    logger.info("‚úÖ ChatProcessor ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o")
                except Exception as e:
                    logger.error(f"‚ùå Kh√¥ng th·ªÉ kh·ªüi t·∫°o ChatProcessor: {e}")
    
    def get_search_engine(self):
        """Get or create search engine"""
        if self.search_engine is None:
            self.init_components()
        return self.search_engine
    
    def get_response_generator(self):
        """Get or create response generator"""
        if self.response_generator is None:
            self.init_components()
        return self.response_generator
    
    def get_chat_processor(self):
        """Get or create chat processor"""
        if self.chat_processor is None:
            self.init_components()
        return self.chat_processor

state = GlobalState()

# ==================== IMPORT CUSTOM MODULES ====================
try:
    from meta_capi import (
        send_meta_pageview,
        send_meta_lead,
        send_meta_lead_from_entities,
        send_meta_call_button,
        check_meta_capi_health,
        config as meta_config
    )
    META_CAPI_AVAILABLE = True
    logger.info("‚úÖ Meta CAPI module ƒë√£ ƒë∆∞·ª£c t·∫£i")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è meta_capi.py kh√¥ng kh·∫£ d·ª•ng: {e}")
    META_CAPI_AVAILABLE = False
    
    def send_meta_pageview(request): 
        pass
    
    def send_meta_lead(*args, **kwargs): 
        return {"status": "unavailable"}
    
    def send_meta_lead_from_entities(*args, **kwargs): 
        return {"status": "unavailable"}
    
    def send_meta_call_button(*args, **kwargs): 
        return {"status": "unavailable"}
    
    def check_meta_capi_health(): 
        return {"status": "unavailable", "message": "Meta CAPI module not loaded"}

try:
    from response_guard import validate_and_format_answer
    RESPONSE_GUARD_AVAILABLE = True
    logger.info("‚úÖ Response guard module ƒë√£ ƒë∆∞·ª£c t·∫£i")
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è response_guard.py kh√¥ng kh·∫£ d·ª•ng: {e}")
    RESPONSE_GUARD_AVAILABLE = False
    
    def validate_and_format_answer(llm_text, top_passages, **kwargs):
        return {
            "answer": llm_text or "T√¥i ƒëang t√¨m hi·ªÉu th√¥ng tin cho b·∫°n...",
            "sources": [],
            "guard_passed": True,
            "reason": "no_guard"
        }

# ==================== FLASK APP ====================
app = Flask(__name__)
app.secret_key = Config.SECRET_KEY
app.config['MAX_CONTENT_LENGTH'] = int(os.getenv("MAX_CONTENT_LENGTH", "1048576"))
app.config['JSON_AS_ASCII'] = False
app.config['JSON_SORT_KEYS'] = False

# Apply ProxyFix for Render
app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1)

# CORS
if Config.CORS_ORIGINS == "*":
    CORS(app, 
         origins="*",
         methods=["GET", "POST", "OPTIONS"],
         allow_headers=["Content-Type", "X-Admin-Key"],
         supports_credentials=True)
else:
    CORS(app, 
         origins=Config.CORS_ORIGINS,
         methods=["GET", "POST", "OPTIONS"],
         allow_headers=["Content-Type", "X-Admin-Key"],
         supports_credentials=True)

logger.info(f"‚úÖ CORS ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh cho: {Config.CORS_ORIGINS}")

# ==================== ENHANCED KNOWLEDGE LOADER ====================
def load_knowledge() -> bool:
    """Load knowledge base with tour entities"""
    
    if state._knowledge_loaded:
        logger.info("üìö Ki·∫øn th·ª©c ƒë√£ ƒë∆∞·ª£c t·∫£i, b·ªè qua")
        return True
    
    try:
        logger.info(f"üìö ƒêang t·∫£i ki·∫øn th·ª©c t·ª´ {Config.KNOWLEDGE_PATH}")
        
        if not os.path.exists(Config.KNOWLEDGE_PATH):
            logger.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file ki·∫øn th·ª©c: {Config.KNOWLEDGE_PATH}")
            return False
        
        with open(Config.KNOWLEDGE_PATH, 'r', encoding='utf-8') as f:
            knowledge = json.load(f)
        
        # Load company info
        state.about_company = knowledge.get('about_company', {})
        if state.about_company:
            logger.info(f"‚úÖ Th√¥ng tin c√¥ng ty ƒë√£ ƒë∆∞·ª£c t·∫£i")
            state._company_info_loaded = True
        
        # Load tours
        tours_data = knowledge.get('tours', [])
        
        for idx, tour_data in enumerate(tours_data):
            try:
                state.tours_db[idx] = tour_data
                name = tour_data.get('tour_name', '')
                if name:
                    state.tour_name_index[name.lower()] = idx
            except Exception as e:
                logger.error(f"‚ùå L·ªói khi t·∫£i tour {idx}: {e}")
                continue
        
        logger.info(f"‚úÖ Ki·∫øn th·ª©c ƒë√£ ƒë∆∞·ª£c t·∫£i: {len(state.tours_db)} tours")
        
        # Load or create mapping
        if os.path.exists(Config.FAISS_MAPPING_PATH):
            try:
                with open(Config.FAISS_MAPPING_PATH, 'r', encoding='utf-8') as f:
                    state.mapping = json.load(f)
                logger.info(f"‚úÖ B·∫£n ƒë·ªì ƒë√£ ƒë∆∞·ª£c t·∫£i: {len(state.mapping)} m·ª•c")
            except Exception as e:
                logger.error(f"‚ùå L·ªói khi t·∫£i b·∫£n ƒë·ªì: {e}")
                state.mapping = []
        
        # Load tour entities if available
        if os.path.exists(Config.TOUR_ENTITIES_PATH):
            try:
                with open(Config.TOUR_ENTITIES_PATH, 'r', encoding='utf-8') as f:
                    state.tour_entities_dict = json.load(f)
                
                # Build indices
                for tour_id, entity in state.tour_entities_dict.items():
                    tour_idx = entity.get('index')
                    if tour_idx is not None:
                        # Tag index
                        for tag in entity.get('tags', []):
                            state.tour_tags_index[tag].append(tour_idx)
                        # Region index
                        region = entity.get('region', '')
                        if region:
                            state.tour_region_index[region].append(tour_idx)
                
                logger.info(f"‚úÖ Tour entities ƒë√£ ƒë∆∞·ª£c t·∫£i: {len(state.tour_entities_dict)} entities")
                logger.info(f"   - Tags ƒë∆∞·ª£c l·∫≠p ch·ªâ m·ª•c: {len(state.tour_tags_index)}")
                logger.info(f"   - Regions ƒë∆∞·ª£c l·∫≠p ch·ªâ m·ª•c: {len(state.tour_region_index)}")
                state._tour_entities_loaded = True
            except Exception as e:
                logger.error(f"‚ùå L·ªói khi t·∫£i tour entities: {e}")
        
        state._knowledge_loaded = True
        
        # Initialize components after knowledge loaded
        state.init_components()
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Kh√¥ng th·ªÉ t·∫£i ki·∫øn th·ª©c: {e}")
        traceback.print_exc()
        return False

# ==================== FIXED SEARCH ENGINE ====================
class SearchEngine:
    """Search engine v·ªõi OpenAI client ƒë∆∞·ª£c fix"""
    
    def __init__(self):
        logger.info("üß† Kh·ªüi t·∫°o c√¥ng c·ª• t√¨m ki·∫øm")
        self.openai_client = None
        
        # FIXED: Ch·ªâ truy·ªÅn api_key, kh√¥ng c√≥ proxies
        if OPENAI_AVAILABLE and Config.OPENAI_API_KEY:
            try:
                # FIXED: Ch·ªâ truy·ªÅn api_key, kh√¥ng c√≥ base_url ho·∫∑c proxies
                self.openai_client = OpenAI(api_key=Config.OPENAI_API_KEY)
                logger.info("‚úÖ OpenAI client ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o")
            except Exception as e:
                logger.error(f"‚ùå Kh·ªüi t·∫°o OpenAI th·∫•t b·∫°i: {e}")
                logger.error(f"   L·ªói chi ti·∫øt: {str(e)}")
    
    def load_index(self) -> bool:
        """Load search index"""
        if state._index_loaded:
            return True
        
        try:
            if Config.FAISS_ENABLED and FAISS_AVAILABLE and os.path.exists(Config.FAISS_INDEX_PATH):
                logger.info(f"üì¶ ƒêang t·∫£i FAISS index")
                state.index = faiss.read_index(Config.FAISS_INDEX_PATH)
                logger.info(f"‚úÖ FAISS ƒë√£ ƒë∆∞·ª£c t·∫£i: {state.index.ntotal} vectors")
                state._index_loaded = True
                return True
            
            if NUMPY_AVAILABLE and os.path.exists(Config.FALLBACK_VECTORS_PATH):
                logger.info(f"üì¶ ƒêang t·∫£i numpy vectors")
                data = np.load(Config.FALLBACK_VECTORS_PATH)
                
                if 'mat' in data:
                    state.vectors = data['mat']
                elif 'vectors' in data:
                    state.vectors = data['vectors']
                
                if state.vectors is not None:
                    norms = np.linalg.norm(state.vectors, axis=1, keepdims=True)
                    state.vectors = state.vectors / (norms + 1e-12)
                
                logger.info(f"‚úÖ Numpy ƒë√£ ƒë∆∞·ª£c t·∫£i: {state.vectors.shape[0]} vectors")
                state._index_loaded = True
                return True
            
            logger.info("‚ÑπÔ∏è Kh√¥ng t√¨m th·∫•y vector index, s·ª≠ d·ª•ng text search")
            state._index_loaded = True
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Kh√¥ng th·ªÉ t·∫£i index: {e}")
            state._index_loaded = True
            return False

# ==================== FIXED RESPONSE GENERATOR ====================
class ResponseGenerator:
    """Response generator v·ªõi LLM client ƒë∆∞·ª£c fix"""
    
    def __init__(self):
        self.llm_client = None
        
        # FIXED: Ch·ªâ truy·ªÅn api_key, kh√¥ng c√≥ proxies
        if OPENAI_AVAILABLE and Config.OPENAI_API_KEY:
            try:
                # FIXED: Ch·ªâ truy·ªÅn api_key, kh√¥ng c√≥ base_url ho·∫∑c proxies
                self.llm_client = OpenAI(api_key=Config.OPENAI_API_KEY)
                logger.info("‚úÖ LLM client ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o")
            except Exception as e:
                logger.error(f"‚ùå Kh·ªüi t·∫°o LLM client th·∫•t b·∫°i: {e}")
                logger.error(f"   L·ªói chi ti·∫øt: {str(e)}")

# ==================== ENHANCED CHAT PROCESSOR ====================
class ChatProcessor:
    """Enhanced chat processor"""
    
    def __init__(self):
        self.response_generator = state.get_response_generator()
        self.search_engine = state.get_search_engine()
    
    def process(self, user_message: str, session_id: str) -> Dict[str, Any]:
        """Process user message"""
        start_time = time.time()
        
        try:
            # Load knowledge if needed
            if not state._knowledge_loaded:
                if not load_knowledge():
                    return {
                        'reply': "Xin l·ªói, h·ªá th·ªëng ƒëang kh·ªüi t·∫°o. Vui l√≤ng th·ª≠ l·∫°i sau! üôè",
                        'session_id': session_id,
                        'error': 'knowledge_not_loaded',
                        'processing_time_ms': int((time.time() - start_time) * 1000),
                        'timestamp': datetime.now().isoformat()
                    }
            
            # Get session context
            context = state.get_session(session_id)
            context['last_updated'] = datetime.now()
            
            # Check cache
            cache_key = f"{session_id}:{hashlib.md5(user_message.encode()).hexdigest()[:12]}"
            cached = state.get_cached_response(cache_key)
            if cached:
                logger.info(f"üíæ Cache hit: {session_id}")
                cached['processing_time_ms'] = int((time.time() - start_time) * 1000)
                cached['from_cache'] = True
                return cached
            
            # Detect intent (simplified)
            text_lower = user_message.lower().strip()
            
            # Simple intent detection
            if any(word in text_lower for word in ['xin ch√†o', 'ch√†o', 'hello', 'hi']):
                intent = Intent.GREETING
            elif 'tour' in text_lower or 'du l·ªãch' in text_lower:
                intent = Intent.TOUR_INQUIRY
            elif 'gi√°' in text_lower or 'bao nhi√™u' in text_lower:
                intent = Intent.PRICE_ASK
            elif 'ƒë·∫∑t' in text_lower or 'book' in text_lower:
                intent = Intent.BOOKING_REQUEST
            elif 'ruby wings' in text_lower or 'c√¥ng ty' in text_lower:
                intent = Intent.ABOUT_COMPANY
            else:
                intent = Intent.TOUR_INQUIRY  # Default to tour inquiry
            
            context['intent'] = normalize_intent(intent)
            
            # Generate response
            response_text = ""
            if self.response_generator and self.response_generator.llm_client and Config.ENABLE_LLM_ADVICE:
                # Try LLM first
                try:
                    response_text = self._generate_llm_response(user_message, intent)
                except Exception as e:
                    logger.error(f"LLM error: {e}")
                    response_text = self._generate_rule_based_response(intent)
            else:
                response_text = self._generate_rule_based_response(intent)
            
            # Build result
            result = {
                'reply': response_text,
                'session_id': session_id,
                'intent': {
                    'name': context['intent'],
                    'confidence': 0.9,
                    'metadata': {}
                },
                'processing_time_ms': int((time.time() - start_time) * 1000),
                'from_cache': False,
                'timestamp': datetime.now().isoformat()
            }
            
            # Cache result
            state.cache_response(cache_key, result)
            
            # Update stats
            state.stats['requests'] += 1
            state.stats['intent_counts'][context['intent']] += 1
            
            # Log
            processing_time = result['processing_time_ms']
            logger.info(f"‚è±Ô∏è ƒê√£ x·ª≠ l√Ω trong {processing_time}ms | "
                       f"√ù ƒë·ªãnh: {context['intent']} | "
                       f"K√Ω t·ª±: {len(response_text)}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói x·ª≠ l√Ω chat: {e}")
            traceback.print_exc()
            
            state.stats['errors'] += 1
            
            return {
                'reply': "Xin l·ªói, c√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c li√™n h·ªá **0332510486**! üôè",
                'session_id': session_id,
                'error': str(e),
                'processing_time_ms': int((time.time() - start_time) * 1000),
                'timestamp': datetime.now().isoformat()
            }
    
    def _generate_llm_response(self, user_message: str, intent: str) -> str:
        """Generate response using LLM"""
        try:
            llm_client = self.response_generator.llm_client
            
            # Prepare prompt
            prompt = f"""B·∫°n l√† tr·ª£ l√Ω AI c·ªßa Ruby Wings - chuy√™n t∆∞ v·∫•n du l·ªãch tr·∫£i nghi·ªám, retreat, thi·ªÅn, kh√≠ c√¥ng, h√†nh tr√¨nh ch·ªØa l√†nh.

H√£y tr·∫£ l·ªùi c√¢u h·ªèi: "{user_message}"

Y√™u c·∫ßu:
1. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, th√¢n thi·ªán, nhi·ªát t√¨nh
2. T·∫≠p trung v√†o gi√° tr·ªã ch·ªØa l√†nh, tr·∫£i nghi·ªám s√¢u
3. N·∫øu c√≥ tour ph√π h·ª£p, gi·ªõi thi·ªáu 2-3 tour
4. K·∫øt th√∫c b·∫±ng l·ªùi m·ªùi li√™n h·ªá hotline 0332510486

Tr·∫£ l·ªùi:"""
            
            response = llm_client.chat.completions.create(
                model=Config.CHAT_MODEL,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=Config.LLM_TEMPERATURE,
                max_tokens=Config.LLM_MAX_TOKENS
            )
            
            state.stats["llm_calls"] += 1
            
            answer = response.choices[0].message.content.strip()
            return answer
            
        except Exception as e:
            state.stats["llm_errors"] += 1
            raise e
    
    def _generate_rule_based_response(self, intent: str) -> str:
        """Generate rule-based response"""
        intent_str = normalize_intent(intent)
        
        if is_intent_equal(intent_str, Intent.GREETING):
            return self._generate_greeting()
        elif is_intent_equal(intent_str, Intent.ABOUT_COMPANY):
            return self._generate_about_company()
        elif is_intent_equal(intent_str, Intent.TOUR_INQUIRY):
            return self._generate_tour_inquiry()
        elif is_intent_equal(intent_str, Intent.PRICE_ASK):
            return self._generate_price_info()
        elif is_intent_equal(intent_str, Intent.BOOKING_REQUEST):
            return self._generate_booking_info()
        else:
            return self._generate_tour_inquiry()
    
    def _generate_greeting(self) -> str:
        return """Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI c·ªßa Ruby Wings üåø

T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:
‚Ä¢ T√¨m hi·ªÉu v·ªÅ c√°c tour tr·∫£i nghi·ªám, retreat
‚Ä¢ T∆∞ v·∫•n tour ph√π h·ª£p v·ªõi nhu c·∫ßu
‚Ä¢ Gi·∫£i ƒë√°p th√¥ng tin v·ªÅ Ruby Wings
‚Ä¢ H·ªó tr·ª£ ƒë·∫∑t tour

B·∫°n mu·ªën t√¨m hi·ªÉu v·ªÅ ƒëi·ªÅu g√¨ ·∫°? üòä"""
    
    def _generate_about_company(self) -> str:
        return """**Ruby Wings** - H√†nh tr√¨nh ch·ªØa l√†nh v√† tr·∫£i nghi·ªám s√¢u üåø

Ruby Wings l√† ƒë∆°n v·ªã ti√™n phong trong lƒ©nh v·ª±c du l·ªãch tr·∫£i nghi·ªám, retreat, v√† h√†nh tr√¨nh ch·ªØa l√†nh t·∫°i Mi·ªÅn Trung Vi·ªát Nam.

**Tri·∫øt l√Ω ho·∫°t ƒë·ªông:**
‚Ä¢ **4 c√°nh xanh l√°:** Th√¢n - T√¢m - Thi√™n nhi√™n - Ni·ªÅm tin
‚Ä¢ **Vi√™n ruby h·ªìng:** Tr√°i tim, s·ª± ch·ªØa l√†nh, t√¨nh y√™u th∆∞∆°ng
‚Ä¢ **V√≤ng tr√≤n k·∫øt n·ªëi:** S·ª± t√°i sinh, ho√†n thi·ªán b·∫£n th√¢n

**H·ªá sinh th√°i Ruby Wings:**
‚Ä¢ **Travel:** Du l·ªãch tr·∫£i nghi·ªám, retreat, h√†nh tr√¨nh ch·ªØa l√†nh
‚Ä¢ **Learn:** Gi√°o d·ª•c n·ªôi t√¢m, thi·ªÅn, kh√≠ c√¥ng
‚Ä¢ **Stay:** L∆∞u tr√∫ xanh, homestay c·ªông ƒë·ªìng
‚Ä¢ **Auto:** Di chuy·ªÉn c√¢n b·∫±ng, xe ƒëi·ªán, xe xanh

**S·ª© m·ªánh:** Lan t·ªèa gi√° tr·ªã s·ªëng chu·∫©n m·ª±c - ch√¢n th√†nh - c√≥ chi·ªÅu s√¢u

üëâ Kh√°m ph√° c√°c h√†nh tr√¨nh c·ªßa ch√∫ng t√¥i ho·∫∑c li√™n h·ªá **0332510486** ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n! üåà"""
    
    def _generate_tour_inquiry(self) -> str:
        return """**Ruby Wings c√≥ c√°c h√†nh tr√¨nh ƒëa d·∫°ng:** üèûÔ∏è

1. **Tour Retreat & Ch·ªØa l√†nh:**
   ‚Ä¢ Thi·ªÅn, kh√≠ c√¥ng, tƒ©nh t√¢m
   ‚Ä¢ H√†nh tr√¨nh n·ªôi t√¢m, c√¢n b·∫±ng c·∫£m x√∫c
   ‚Ä¢ Kh√°m ph√° b·∫£n th√¢n, t√¨m l·∫°i s·ª± b√¨nh an

2. **Tour Tr·∫£i nghi·ªám VƒÉn h√≥a:**
   ‚Ä¢ Kh√°m ph√° di s·∫£n Hu·∫ø, H·ªôi An
   ‚Ä¢ Giao l∆∞u c·ªông ƒë·ªìng b·∫£n ƒë·ªãa
   ‚Ä¢ Tr·∫£i nghi·ªám ·∫©m th·ª±c ƒë·∫∑c s·∫Øc

3. **Tour Thi√™n nhi√™n & M·∫°o hi·ªÉm:**
   ‚Ä¢ Trekking r·ª´ng B·∫°ch M√£
   ‚Ä¢ Kh√°m ph√° Phong Nha - K·∫ª B√†ng
   ‚Ä¢ H√†nh tr√¨nh xuy√™n r·ª´ng, v∆∞·ª£t su·ªëi

4. **Tour Team Building:**
   ‚Ä¢ G·∫Øn k·∫øt doanh nghi·ªáp, c√¥ng ty
   ‚Ä¢ Ho·∫°t ƒë·ªông teamwork s√°ng t·∫°o
   ‚Ä¢ Ph√°t tri·ªÉn k·ªπ nƒÉng l√£nh ƒë·∫°o

**∆Øu ƒë√£i ƒë·∫∑c bi·ªát:**
‚Ä¢ Gi·∫£m 5% cho nh√≥m t·ª´ 5 ng∆∞·ªùi
‚Ä¢ Gi·∫£m 10% cho ƒë·∫∑t tour tr∆∞·ªõc 15 ng√†y
‚Ä¢ Voucher 200.000 VNƒê cho l·∫ßn ƒë·∫∑t ti·∫øp theo

Li√™n h·ªá **0332510486** ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n tour ph√π h·ª£p nh·∫•t v·ªõi b·∫°n! üìû"""
    
    def _generate_price_info(self) -> str:
        return """üí∞ **Th√¥ng tin gi√° c√°c h√†nh tr√¨nh Ruby Wings**

Gi√° tour dao ƒë·ªông t·ª´ **890.000 VNƒê** ƒë·∫øn **3.500.000 VNƒê** t√πy theo:
‚Ä¢ Th·ªùi l∆∞·ª£ng (1 ng√†y, 2N1ƒê, 3N2ƒê)
‚Ä¢ Lo·∫°i h√¨nh (retreat, trekking, vƒÉn h√≥a)
‚Ä¢ D·ªãch v·ª• bao g·ªìm
‚Ä¢ S·ªë l∆∞·ª£ng ng∆∞·ªùi tham gia

**Gi√° ƒë√£ bao g·ªìm:**
‚úì Xe ƒë∆∞a ƒë√≥n ƒë·ªùi m·ªõi
‚úì H∆∞·ªõng d·∫´n vi√™n chuy√™n nghi·ªáp
‚úì B·ªØa ƒÉn theo ch∆∞∆°ng tr√¨nh
‚úì V√© tham quan c√°c ƒëi·ªÉm
‚úì B·∫£o hi·ªÉm du l·ªãch
‚úì N∆∞·ªõc u·ªëng, khƒÉn l·∫°nh

**Ch√≠nh s√°ch gi√° ∆∞u ƒë√£i:**
‚Ä¢ Gi·∫£m 5% cho nh√≥m t·ª´ 5 ng∆∞·ªùi tr·ªü l√™n
‚Ä¢ Gi·∫£m 10% cho ƒë·∫∑t tour tr∆∞·ªõc 15 ng√†y
‚Ä¢ ∆Øu ƒë√£i ƒë·∫∑c bi·ªát cho c√¥ng ty, ƒëo√†n th·ªÉ
‚Ä¢ Combo gia ƒë√¨nh (2 ng∆∞·ªùi l·ªõn + 1 tr·∫ª em)

Li√™n h·ªá **0332510486** ƒë·ªÉ bi·∫øt gi√° chi ti·∫øt v√† nh·∫≠n ∆∞u ƒë√£i ph√π h·ª£p! üìû"""
    
    def _generate_booking_info(self) -> str:
        return """üéØ **ƒê·∫∑t h√†nh tr√¨nh Ruby Wings - 4 b∆∞·ªõc ƒë∆°n gi·∫£n**

**B∆∞·ªõc 1:** Ch·ªçn h√†nh tr√¨nh ph√π h·ª£p
**B∆∞·ªõc 2:** Cung c·∫•p th√¥ng tin (s·ªë ng∆∞·ªùi, ng√†y ƒëi, y√™u c·∫ßu)
**B∆∞·ªõc 3:** X√°c nh·∫≠n & Thanh to√°n
**B∆∞·ªõc 4:** Chu·∫©n b·ªã h√†nh tr√¨nh

**C√°ch th·ª©c ƒë·∫∑t tour:**
1. üìû **G·ªçi hotline:** 0332510486 (8:00 - 22:00)
2. üí¨ **Nh·∫Øn tin Zalo:** 0332510486
3. üìß **Email:** info@rubywings.vn
4. üåê **Website:** rubywings.vn

Ch√∫ng t√¥i s·∫Ω x√°c nh·∫≠n trong v√≤ng 30 ph√∫t v√† ƒë·ªìng h√†nh c√πng b·∫°n su·ªët h√†nh tr√¨nh! üåà"""

# ==================== ROUTES ====================
@app.before_request
def before_request():
    """Before request handler"""
    g.start_time = time.time()
    
    if Config.ENABLE_META_CAPI and META_CAPI_AVAILABLE:
        try:
            if request.path not in ['/health', '/stats', '/favicon.ico']:
                send_meta_pageview(request)
                state.stats['meta_capi_calls'] += 1
        except Exception as e:
            state.stats['meta_capi_errors'] += 1
            logger.error(f"L·ªói Meta CAPI pageview: {e}")

@app.after_request
def after_request(response):
    """After request handler"""
    if hasattr(g, 'start_time'):
        elapsed = (time.time() - g.start_time) * 1000
        response.headers['X-Processing-Time'] = f"{elapsed:.2f}ms"
    
    return response

@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'version': '6.0.1-fixed',
        'timestamp': datetime.now().isoformat(),
        'knowledge': {
            'loaded': state._knowledge_loaded,
            'tours': len(state.tours_db),
            'company_info_loaded': state._company_info_loaded,
            'tour_entities_loaded': state._tour_entities_loaded
        },
        'modules': {
            'meta_capi': META_CAPI_AVAILABLE,
            'response_guard': RESPONSE_GUARD_AVAILABLE,
            'openai': OPENAI_AVAILABLE,
            'llm_enabled': Config.OPENAI_API_KEY != ""
        },
        'components': {
            'search_engine': state.search_engine is not None,
            'response_generator': state.response_generator is not None,
            'chat_processor': state.chat_processor is not None
        }
    })

@app.route('/', methods=['GET'])
def index():
    """Index route"""
    return jsonify({
        'service': 'Ruby Wings AI Chatbot',
        'version': '6.0.1 (Fixed OpenAI Client)',
        'status': 'running',
        'tours_available': len(state.tours_db),
        'features': {
            'llm_advisory': Config.ENABLE_LLM_ADVICE and Config.OPENAI_API_KEY != "",
            'intent_detection': Config.ENABLE_INTENT_DETECTION,
            'lead_capture': Config.ENABLE_LEAD_CAPTURE,
            'meta_capi': Config.ENABLE_META_CAPI
        },
        'endpoints': {
            'chat': '/api/chat',
            'save_lead': '/api/save-lead',
            'health': '/health',
            'stats': '/stats'
        }
    })

@app.route('/api/chat', methods=['POST', 'OPTIONS'])
def chat():
    """Main chat endpoint"""
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200
    
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        user_message = data.get('message', '').strip()
        session_id = data.get('session_id') or str(uuid.uuid4())
        
        if not user_message:
            return jsonify({'error': 'Message is required'}), 400
        
        chat_processor = state.get_chat_processor()
        if chat_processor is None:
            return jsonify({
                'error': 'Chat processor not initialized',
                'message': 'Xin l·ªói, h·ªá th·ªëng ƒëang kh·ªüi t·∫°o. Vui l√≤ng th·ª≠ l·∫°i sau!'
            }), 503
        
        result = chat_processor.process(user_message, session_id)
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"‚ùå Chat endpoint error: {e}")
        traceback.print_exc()
        state.stats['errors'] += 1
        
        return jsonify({
            'error': 'Internal server error',
            'message': 'Xin l·ªói, c√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i!'
        }), 500

@app.route('/chat', methods=['POST', 'OPTIONS'])
def chat_legacy():
    """Legacy /chat endpoint"""
    return chat()

@app.route('/api/save-lead', methods=['POST', 'OPTIONS'])
def save_lead():
    """Save lead from form submission"""
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200
    
    try:
        data = request.get_json() or {}
        
        phone = data.get('phone', '').strip()
        name = data.get('name', '').strip()
        email = data.get('email', '').strip()
        tour_interest = data.get('tour_interest', '').strip()
        note = data.get('note', '').strip()
        
        if not phone:
            return jsonify({'error': 'Phone number is required'}), 400
        
        phone_clean = re.sub(r'[^\d+]', '', phone)
        
        if not re.match(r'^(0|\+?84)\d{9,10}$', phone_clean):
            return jsonify({'error': 'Invalid phone number format'}), 400
        
        lead_data = {
            'timestamp': datetime.now().isoformat(),
            'contact_name': name or 'Kh√°ch y√™u c·∫ßu g·ªçi l·∫°i',
            'phone': phone_clean,
            'service_interest': tour_interest,
            'note': note,
            'status': 'New'
        }
        
        # Save to fallback storage
        if Config.ENABLE_FALLBACK_STORAGE:
            try:
                if os.path.exists(Config.FALLBACK_STORAGE_PATH):
                    with open(Config.FALLBACK_STORAGE_PATH, 'r', encoding='utf-8') as f:
                        leads = json.load(f)
                else:
                    leads = []
                
                leads.append(lead_data)
                leads = leads[-1000:]
                
                with open(Config.FALLBACK_STORAGE_PATH, 'w', encoding='utf-8') as f:
                    json.dump(leads, f, ensure_ascii=False, indent=2)
                
                logger.info("‚úÖ Lead saved to fallback storage")
            except Exception as e:
                logger.error(f"Fallback storage error: {e}")
        
        state.stats['leads'] += 1
        
        return jsonify({
            'success': True,
            'message': 'Th√¥ng tin ƒë√£ ƒë∆∞·ª£c l∆∞u! Ruby Wings s·∫Ω li√™n h·ªá s·ªõm nh·∫•t. üìû',
            'data': {
                'phone': phone_clean[:3] + '***' + phone_clean[-2:],
                'timestamp': lead_data['timestamp']
            }
        })
        
    except Exception as e:
        logger.error(f"‚ùå Save lead error: {e}")
        traceback.print_exc()
        state.stats['errors'] += 1
        return jsonify({'error': str(e)}), 500

@app.route('/stats', methods=['GET'])
def stats():
    """Statistics endpoint"""
    return jsonify({
        'status': 'ok',
        'requests': state.stats['requests'],
        'errors': state.stats['errors'],
        'leads': state.stats['leads'],
        'sessions': len(state.session_contexts),
        'tours': len(state.tours_db),
        'uptime_seconds': int((datetime.now() - state.stats['start_time']).total_seconds())
    })

# ==================== INITIALIZATION ====================
def initialize_app():
    """Initialize application"""
    try:
        logger.info("üöÄ Kh·ªüi ƒë·ªông Ruby Wings Chatbot v6.0.1...")
        
        Config.log_config()
        
        logger.info("üîç ƒêang t·∫£i ki·∫øn th·ª©c...")
        if load_knowledge():
            logger.info("‚úÖ Ki·∫øn th·ª©c ƒë√£ s·∫µn s√†ng")
        else:
            logger.error("‚ùå Kh√¥ng th·ªÉ t·∫£i ki·∫øn th·ª©c")
        
        logger.info("=" * 60)
        logger.info("‚úÖ RUBY WINGS CHATBOT S·∫¥N S√ÄNG!")
        logger.info(f"üìä Tours ƒë√£ t·∫£i: {len(state.tours_db)}")
        logger.info(f"üß† LLM Advisory: {'‚úÖ' if Config.ENABLE_LLM_ADVICE and Config.OPENAI_API_KEY else '‚ùå'}")
        logger.info(f"üåê Server: {Config.HOST}:{Config.PORT}")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"‚ùå Kh·ªüi t·∫°o th·∫•t b·∫°i: {e}")
        traceback.print_exc()

# ==================== APPLICATION ENTRY POINT ====================
if __name__ == '__main__':
    initialize_app()
    app.run(
        host=Config.HOST,
        port=Config.PORT,
        debug=Config.DEBUG,
        threaded=True,
        use_reloader=False
    )
else:
    # For Gunicorn
    initialize_app()

__all__ = ["app"]