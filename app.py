"""
RUBY WINGS CHATBOT v5.0 - C·∫¨P NH·∫¨T KNOWLEDGE.JSON
C·∫•u tr√∫c ho√†n ch·ªânh theo ƒë·ªÅ c∆∞∆°ng chu·∫©n h√≥a
"""

# ==================== PH·∫¶N 1: IMPORTS & CONFIG ====================
import json
import logging
import re
import hashlib
import time
import os
import threading
import traceback
import unicodedata
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, asdict, field
from enum import Enum
from datetime import datetime
from functools import lru_cache
from collections import defaultdict, deque
from difflib import SequenceMatcher

import numpy as np
from flask import Flask, request, jsonify, Response, stream_with_context
from flask_cors import CORS

# Try to import FAISS with fallback
try:
    import faiss
    HAS_FAISS = True
except ImportError:
    HAS_FAISS = False
    logger.warning("‚ö†Ô∏è FAISS not available, using fallback")

# C√°c bi·∫øn config
LLM_URL = "http://localhost:11434/api/generate"
EMBEDDING_MODEL = "nomic-embed-text"
KNOWLEDGE_PATH = "knowledge.json"
CAPI_ENABLED = True
CAPI_URL = "https://graph.facebook.com/v18.0/me/messages"
SESSION_TIMEOUT = 1800
CACHE_TTL = 300
MAX_TOURS_RETURN = 10
SEMANTIC_MIN_SCORE = 0.75
TOP_K = 10

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ruby_wings.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==================== PH·∫¶N 2: DATACLASSES & ENUMS ====================

class QuestionType(Enum):
    """C√°c lo·∫°i c√¢u h·ªèi - GI·ªÆ NGUY√äN t·ª´ app g·ªëc"""
    LIST_TOURS = "list_tours"
    TOUR_DETAIL = "tour_detail"
    COMPARISON = "comparison"
    RECOMMENDATION = "recommendation"
    GREETING = "greeting"
    FAREWELL = "farewell"
    GENERAL_INFO = "general_info"
    UNKNOWN = "unknown"

class ConversationState(Enum):
    """Tr·∫°ng th√°i h·ªôi tho·∫°i - GI·ªÆ NGUY√äN"""
    INITIAL = "initial"
    FILTERING = "filtering"
    DETAIL_VIEW = "detail_view"
    COMPARISON = "comparison"
    RECOMMENDING = "recommending"
    CLOSING = "closing"

@dataclass
class Tour:
    """
    TOUR OBJECT M·ªöI - T∆Ø∆†NG TH√çCH KNOWLEDGE.JSON
    K·∫ø th·ª´a t·∫•t c·∫£ field t·ª´ knowledge.json + th√™m computed fields
    """
    # Primary fields t·ª´ knowledge.json
    id: int
    tour_name: str
    summary: str
    location: str
    duration: str  # Gi·ªØ nguy√™n string format
    price: str     # Gi·ªØ nguy√™n string format
    includes: List[str]
    notes: str
    style: str
    transport: str
    accommodation: str
    meals: str
    event_support: str
    
    # Computed fields ƒë·ªÉ h·ªó tr·ª£ filter/search
    price_numeric: Optional[float] = None    # Gi√° ƒë√£ parse sang s·ªë
    duration_numeric: Optional[int] = None   # Th·ªùi gian ƒë√£ parse sang s·ªë ng√†y
    category: Optional[str] = None          # Lo·∫°i tour (auto-categorized)
    rating: Optional[float] = 4.5           # Rating m·∫∑c ƒë·ªãnh
    
    # Backward compatibility fields
    description: str = ""                   # Map t·ª´ summary
    highlights: List[str] = field(default_factory=list)  # Map t·ª´ includes
    name: str = ""                          # Alias cho tour_name
    tags: List[str] = field(default_factory=list)       # Auto-generated tags

@dataclass
class FilterSet:
    """B·ªô l·ªçc - TH√äM field style ƒë·ªÉ filter theo knowledge.json"""
    min_price: Optional[float] = None
    max_price: Optional[float] = None
    location: Optional[str] = None
    duration_min: Optional[int] = None
    duration_max: Optional[int] = None
    style: Optional[str] = None            # NEW: Filter theo field style
    category: Optional[str] = None
    include_keywords: Optional[List[str]] = None  # T√¨m trong includes
    group_type: Optional[str] = None
    
    def is_empty(self) -> bool:
        """Check if filter set is empty"""
        return all(
            value is None or (isinstance(value, list) and not value)
            for value in [
                self.min_price, self.max_price, self.location,
                self.duration_min, self.duration_max, self.style,
                self.category, self.include_keywords, self.group_type
            ]
        )

@dataclass
class ConversationContext:
    """Context h·ªôi tho·∫°i - GI·ªÆ NGUY√äN t·ª´ app g·ªëc"""
    session_id: str
    last_tours_mentioned: List[int] = field(default_factory=list)
    user_preferences: Dict[str, Any] = field(default_factory=dict)
    conversation_history: List[Dict] = field(default_factory=list)
    last_question_type: Optional[QuestionType] = None
    current_state: ConversationState = ConversationState.INITIAL
    active_filters: Optional[FilterSet] = None
    created_at: float = field(default_factory=time.time)
    last_activity: float = field(default_factory=time.time)
    
    # Additional fields for backward compatibility
    current_tours: List[int] = field(default_factory=list)
    last_successful_tours: List[int] = field(default_factory=list)
    mentioned_tours: List[int] = field(default_factory=list)
    
    def update(self, user_message: str, bot_response: str, tour_indices: List[int] = None):
        """Update conversation context"""
        self.last_activity = time.time()
        self.conversation_history.append({
            'timestamp': time.time(),
            'user': user_message,
            'bot': bot_response,
            'tours': tour_indices
        })
        
        if tour_indices:
            self.last_successful_tours = tour_indices
            self.current_tours = tour_indices
            self.mentioned_tours.extend(tour_indices)
            
            # Keep only recent tours
            if len(self.mentioned_tours) > 20:
                self.mentioned_tours = self.mentioned_tours[-20:]

@dataclass
class ChatResponse:
    """Response format - GI·ªÆ NGUY√äN t·ª´ app g·ªëc"""
    reply: str
    tour_name: Optional[str] = None
    tour_indices: Optional[List[int]] = None
    action: str = "continue"
    context: Optional[Dict] = None
    warnings: Optional[List[str]] = None
    metadata: Optional[Dict] = None

@dataclass  
class CacheEntry:
    """Cache entry - GI·ªÆ NGUY√äN t·ª´ app g·ªëc"""
    value: Any
    expiry: float
    created_at: float = field(default_factory=time.time)
    
    def is_expired(self) -> bool:
        """Check if cache entry is expired"""
        return time.time() > self.expiry

@dataclass
class LLMRequest:
    """LLM request - GI·ªÆ NGUY√äN t·ª´ app g·ªëc"""
    prompt: str
    model: str = "llama2"
    stream: bool = False
    temperature: float = 0.7
    max_tokens: int = 500

# ==================== PH·∫¶N 3: KNOWLEDGE PROCESSING ====================

class KnowledgeLoader:
    """H·ªá th·ªëng load v√† parse knowledge.json"""
    
    @staticmethod
    def load_knowledge_file(file_path: str = KNOWLEDGE_PATH) -> Dict:
        """Load raw JSON data t·ª´ knowledge.json"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Failed to load knowledge file: {e}")
            return {"tours": []}
    
    @staticmethod
    def parse_tour_data(raw_tour: Dict, tour_id: int) -> Tour:
        """Parse m·ªôt tour t·ª´ raw JSON data sang Tour object"""
        
        # Parse numeric values
        price_numeric = KnowledgeParser.parse_price_string(raw_tour.get('price', ''))
        duration_numeric = KnowledgeParser.parse_duration_string(raw_tour.get('duration', ''))
        
        # Auto-categorize
        category = KnowledgeParser.categorize_tour(raw_tour)
        
        # Create Tour object
        tour = Tour(
            id=tour_id,
            tour_name=raw_tour.get('tour_name', ''),
            summary=raw_tour.get('summary', ''),
            location=raw_tour.get('location', ''),
            duration=raw_tour.get('duration', ''),
            price=raw_tour.get('price', ''),
            includes=raw_tour.get('includes', []),
            notes=raw_tour.get('notes', ''),
            style=raw_tour.get('style', ''),
            transport=raw_tour.get('transport', ''),
            accommodation=raw_tour.get('accommodation', ''),
            meals=raw_tour.get('meals', ''),
            event_support=raw_tour.get('event_support', ''),
            price_numeric=price_numeric,
            duration_numeric=duration_numeric,
            category=category,
            description=raw_tour.get('summary', ''),
            highlights=raw_tour.get('includes', [])[:3],
            name=raw_tour.get('tour_name', ''),
            tags=KnowledgeParser.generate_tags(raw_tour)
        )
        
        return tour
    
    @classmethod
    def build_tours_database(cls) -> Dict[int, Tour]:
        """X√¢y d·ª±ng database tours t·ª´ knowledge.json"""
        knowledge_data = cls.load_knowledge_file()
        tours_db = {}
        
        for idx, tour_data in enumerate(knowledge_data.get('tours', [])):
            tour = cls.parse_tour_data(tour_data, idx)
            tours_db[idx] = tour
        
        logger.info(f"Loaded {len(tours_db)} tours from knowledge.json")
        return tours_db

class KnowledgeParser:
    """Parser utilities cho knowledge.json fields"""
    
    @staticmethod
    def parse_price_string(price_str: str) -> Optional[float]:
        """Parse chu·ªói gi√° sang s·ªë"""
        if not price_str or not isinstance(price_str, str):
            return None
        
        # T√¨m t·∫•t c·∫£ s·ªë trong chu·ªói (h·ªó tr·ª£ c·∫£ d·∫•u ph·∫©y v√† ch·∫•m)
        numbers = re.findall(r'(\d+(?:[.,]\d+)?)', price_str.replace(',', '.'))
        if numbers:
            try:
                value = float(numbers[0])
                # Gi·∫£ ƒë·ªãnh gi√° t√≠nh theo tri·ªáu VND
                return value * 1000000
            except ValueError:
                pass
        
        return None
    
    @staticmethod
    def parse_duration_string(duration_str: str) -> Optional[int]:
        """Parse chu·ªói th·ªùi gian sang s·ªë ng√†y"""
        if not duration_str or not isinstance(duration_str, str):
            return None
        
        numbers = re.findall(r'\d+', duration_str)
        if numbers:
            try:
                return int(numbers[0])
            except ValueError:
                pass
        
        return None
    
    @staticmethod
    def categorize_tour(tour_data: Dict) -> str:
        """Ph√¢n lo·∫°i tour t·ª± ƒë·ªông d·ª±a tr√™n style v√† location"""
        style = (tour_data.get('style') or '').lower()
        location = (tour_data.get('location') or '').lower()
        
        category_keywords = {
            'adventure': ['m·∫°o hi·ªÉm', 'kh√°m ph√°', 'trekking', 'leo n√∫i', 'ph∆∞·ª£t'],
            'relaxation': ['ngh·ªâ d∆∞·ª°ng', 'th∆∞ gi√£n', 'bi·ªÉn', 'spa', 'resort'],
            'cultural': ['vƒÉn h√≥a', 'l·ªãch s·ª≠', 'di s·∫£n', 'di t√≠ch', 'truy·ªÅn th·ªëng'],
            'culinary': ['·∫©m th·ª±c', 'ƒÉn u·ªëng', 'ƒë·∫∑c s·∫£n', 'food tour'],
            'event': ['s·ª± ki·ªán', 'team building', 'h·ªôi ngh·ªã', 't·ªï ch·ª©c'],
            'family': ['gia ƒë√¨nh', 'tr·∫ª em', 'tr·∫£i nghi·ªám gia ƒë√¨nh'],
            'luxury': ['cao c·∫•p', 'sang tr·ªçng', '5 sao', 'VIP']
        }
        
        for category, keywords in category_keywords.items():
            for keyword in keywords:
                if keyword in style or keyword in location:
                    return category
        
        return 'general'
    
    @staticmethod
    def generate_tags(tour_data: Dict) -> List[str]:
        """T·∫°o tags cho tour d·ª±a tr√™n d·ªØ li·ªáu"""
        tags = []
        
        # Location tags
        location = (tour_data.get('location') or '').lower()
        if location:
            for loc in ['hu·∫ø', 'qu·∫£ng tr·ªã', 'b·∫°ch m√£', 'tr∆∞·ªùng s∆°n']:
                if loc in location:
                    tags.append(f"location:{loc}")
        
        # Style tags
        style = (tour_data.get('style') or '').lower()
        if style:
            for st in ['thi·ªÅn', 'kh√≠ c√¥ng', 'retreat', 'l·ªãch s·ª≠', 'vƒÉn h√≥a']:
                if st in style:
                    tags.append(f"style:{st}")
        
        # Duration tags
        duration = (tour_data.get('duration') or '').lower()
        if '1 ng√†y' in duration:
            tags.append("duration:1day")
        elif '2 ng√†y' in duration:
            tags.append("duration:2day")
        elif '3 ng√†y' in duration:
            tags.append("duration:3day")
        
        # Price tags (if price available)
        price = tour_data.get('price', '')
        price_numeric = KnowledgeParser.parse_price_string(price)
        if price_numeric:
            if price_numeric < 1000000:
                tags.append("price:budget")
            elif price_numeric < 3000000:
                tags.append("price:midrange")
            else:
                tags.append("price:premium")
        
        return list(set(tags))

# ==================== PH·∫¶N 4: 10 UPGRADES SYSTEMS ====================

class MandatoryFilterSystemV2:
    """
    Upgrade 1: Mandatory Filter System
    C·∫¨P NH·∫¨T: H·ªó tr·ª£ c√°c field m·ªõi t·ª´ knowledge.json
    """
    
    @staticmethod
    def extract_filters(message: str) -> FilterSet:
        """Tr√≠ch xu·∫•t filter t·ª´ message v·ªõi knowledge.json fields"""
        filters = FilterSet()
        msg_lower = message.lower()
        
        # 1. Price filter
        price_patterns = [
            (r'gi√°\s*(?:d∆∞·ªõi|d∆∞·ªõi\s*)?\s*(\d+(?:[.,]\d+)?)\s*tr?i?·ªá?u?', 'max'),
            (r'gi√°\s*(?:tr√™n|tr√™n\s*)?\s*(\d+(?:[.,]\d+)?)\s*tr?i?·ªá?u?', 'min'),
            (r'(\d+(?:[.,]\d+)?)\s*-\s*(\d+(?:[.,]\d+)?)\s*tr?i?·ªá?u?', 'range'),
            (r'kho·∫£ng\s*(\d+(?:[.,]\d+)?)\s*tr?i?·ªá?u?', 'approx')
        ]
        
        for pattern, ptype in price_patterns:
            matches = re.findall(pattern, msg_lower)
            if matches:
                if ptype == 'max':
                    filters.max_price = float(matches[0].replace(',', '.')) * 1000000
                elif ptype == 'min':
                    filters.min_price = float(matches[0].replace(',', '.')) * 1000000
                elif ptype == 'range':
                    filters.min_price = float(matches[0][0].replace(',', '.')) * 1000000
                    filters.max_price = float(matches[0][1].replace(',', '.')) * 1000000
                elif ptype == 'approx':
                    price = float(matches[0].replace(',', '.')) * 1000000
                    filters.min_price = price * 0.8
                    filters.max_price = price * 1.2
                break
        
        # 2. Location filter
        common_locations = [
            'h√† n·ªôi', 'hanoi', 'sapa', 'h·∫° long', 'halong', 'nha trang',
            'ƒë√† n·∫µng', 'danang', 'h·ªôi an', 'hoian', 'ph√∫ qu·ªëc', 'phuquoc',
            'c·∫ßn th∆°', 'cantho', 'mi·ªÅn b·∫Øc', 'mi·ªÅn nam', 'mi·ªÅn trung',
            'hu·∫ø', 'qu·∫£ng tr·ªã', 'b·∫°ch m√£', 'tr∆∞·ªùng s∆°n', 'ƒë√¥ng h√†'
        ]
        for loc in common_locations:
            if loc in msg_lower:
                filters.location = loc
                break
        
        # 3. Duration filter
        duration_patterns = [
            r'(\d+)\s*ng√†y',
            r'(\d+)\s*-\s*(\d+)\s*ng√†y',
            r'kho·∫£ng\s*(\d+)\s*ng√†y'
        ]
        
        for pattern in duration_patterns:
            matches = re.findall(pattern, msg_lower)
            if matches:
                if isinstance(matches[0], tuple):
                    filters.duration_min = int(matches[0][0])
                    filters.duration_max = int(matches[0][1])
                else:
                    dur = int(matches[0])
                    filters.duration_min = dur
                    filters.duration_max = dur
                break
        
        # 4. NEW: Style filter (t·ª´ knowledge.json field "style")
        style_keywords = [
            'vƒÉn h√≥a', '·∫©m th·ª±c', 'ngh·ªâ d∆∞·ª°ng', 'm·∫°o hi·ªÉm', 'kh√°m ph√°',
            'gia ƒë√¨nh', 'c√° nh√¢n', 'nh√≥m', 'team building', 's·ª± ki·ªán',
            'thi·ªÅn', 'kh√≠ c√¥ng', 'retreat', 'ch·ªØa l√†nh'
        ]
        for style in style_keywords:
            if style in msg_lower:
                filters.style = style
                break
        
        # 5. Include keywords filter (t√¨m trong field "includes")
        include_keywords = ['ƒÉn s√°ng', 'v√© m√°y bay', 'kh√°ch s·∫°n', 'h∆∞·ªõng d·∫´n vi√™n', 'b·∫£o hi·ªÉm']
        found_includes = []
        for keyword in include_keywords:
            if keyword in msg_lower:
                found_includes.append(keyword)
        if found_includes:
            filters.include_keywords = found_includes
        
        # 6. Group type filter
        group_keywords = {
            'family': ['gia ƒë√¨nh', 'tr·∫ª em', 'con n√≠t', 'b·ªë m·∫π'],
            'friends': ['nh√≥m b·∫°n', 'b·∫°n b√®', 'b·∫°n tr·∫ª'],
            'corporate': ['c√¥ng ty', 'team building', 'doanh nghi·ªáp'],
            'solo': ['m·ªôt m√¨nh', 'ƒëi l·∫ª', 'solo'],
            'couple': ['c·∫∑p ƒë√¥i', 'ƒë√¥i l·ª©a', 'ng∆∞·ªùi y√™u']
        }
        
        for group_type, keywords in group_keywords.items():
            for keyword in keywords:
                if keyword in msg_lower:
                    filters.group_type = group_type
                    break
            if filters.group_type:
                break
        
        return filters
    
    @staticmethod
    def apply_filters(tours_db: Dict[int, Tour], filters: FilterSet) -> List[int]:
        """√Åp d·ª•ng filter l√™n tours database (h·ªó tr·ª£ knowledge.json fields)"""
        if filters.is_empty():
            return list(tours_db.keys())
        
        filtered_tours = []
        
        for tour_id, tour in tours_db.items():
            # 1. Price filter (s·ª≠ d·ª•ng price_numeric ƒë√£ parse)
            if filters.min_price is not None and tour.price_numeric is not None:
                if tour.price_numeric < filters.min_price:
                    continue
            
            if filters.max_price is not None and tour.price_numeric is not None:
                if tour.price_numeric > filters.max_price:
                    continue
            
            # 2. Location filter
            if filters.location:
                if filters.location.lower() not in tour.location.lower():
                    continue
            
            # 3. Duration filter (s·ª≠ d·ª•ng duration_numeric ƒë√£ parse)
            if filters.duration_min is not None and tour.duration_numeric is not None:
                if tour.duration_numeric < filters.duration_min:
                    continue
            
            if filters.duration_max is not None and tour.duration_numeric is not None:
                if tour.duration_numeric > filters.duration_max:
                    continue
            
            # 4. NEW: Style filter
            if filters.style and tour.style:
                if filters.style.lower() not in tour.style.lower():
                    continue
            
            # 5. NEW: Include keywords filter
            if filters.include_keywords:
                includes_lower = [inc.lower() for inc in tour.includes]
                found_all = all(
                    any(keyword in inc for inc in includes_lower)
                    for keyword in filters.include_keywords
                )
                if not found_all:
                    continue
            
            # 6. Category filter
            if filters.category and tour.category:
                if filters.category.lower() != tour.category.lower():
                    continue
            
            # 7. Group type filter
            if filters.group_type:
                if filters.group_type == 'family':
                    if not any(tag.startswith('style:') for tag in tour.tags):
                        continue
                elif filters.group_type == 'solo':
                    # Solo travelers might prefer certain styles
                    if tour.style and 'nh√≥m' in tour.style.lower():
                        continue
            
            filtered_tours.append(tour_id)
        
        return filtered_tours

class DeduplicationEngine:
    """
    Upgrade 2: Deduplication Engine - GI·ªÆ NGUY√äN
    """
    
    SIMILARITY_THRESHOLD = 0.85
    MIN_TEXT_LENGTH = 20
    
    @staticmethod
    def calculate_similarity(text1: str, text2: str) -> float:
        """Calculate text similarity using multiple methods"""
        if not text1 or not text2:
            return 0.0
        
        text1_norm = DeduplicationEngine._normalize_text(text1)
        text2_norm = DeduplicationEngine._normalize_text(text2)
        
        if len(text1_norm) < DeduplicationEngine.MIN_TEXT_LENGTH or len(text2_norm) < DeduplicationEngine.MIN_TEXT_LENGTH:
            return 0.0
        
        seq_ratio = SequenceMatcher(None, text1_norm, text2_norm).ratio()
        
        words1 = set(text1_norm.split())
        words2 = set(text2_norm.split())
        
        if not words1 or not words2:
            jaccard = 0.0
        else:
            intersection = words1.intersection(words2)
            union = words1.union(words2)
            jaccard = len(intersection) / len(union)
        
        prefix_len = min(50, min(len(text1_norm), len(text2_norm)))
        prefix1 = text1_norm[:prefix_len]
        prefix2 = text2_norm[:prefix_len]
        prefix_sim = SequenceMatcher(None, prefix1, prefix2).ratio()
        
        similarity = (seq_ratio * 0.5) + (jaccard * 0.3) + (prefix_sim * 0.2)
        
        return similarity
    
    @staticmethod
    def _normalize_text(text: str) -> str:
        """Normalize text for comparison"""
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        stopwords = {'v√†', 'c·ªßa', 'cho', 'v·ªõi', 't·∫°i', '·ªü', 'n√†y', 'ƒë√≥', 'kia', 'v·ªÅ', 'trong'}
        words = [word for word in text.split() if word not in stopwords]
        
        return ' '.join(words)
    
    @staticmethod
    def deduplicate_passages(passages: List[Tuple[float, Dict]], 
                            similarity_threshold: float = None) -> List[Tuple[float, Dict]]:
        """
        Remove duplicate passages from results
        """
        if len(passages) <= 1:
            return passages
        
        threshold = similarity_threshold or DeduplicationEngine.SIMILARITY_THRESHOLD
        unique_passages = []
        seen_passages = []
        
        sorted_passages = sorted(passages, key=lambda x: x[0], reverse=True)
        
        for score, passage in sorted_passages:
            text = passage.get('text', '').strip()
            path = passage.get('path', '')
            
            if not text or len(text) < DeduplicationEngine.MIN_TEXT_LENGTH:
                unique_passages.append((score, passage))
                continue
            
            is_duplicate = False
            for seen_text, seen_path in seen_passages:
                tour_match1 = re.search(r'tours\[(\d+)\]', path)
                tour_match2 = re.search(r'tours\[(\d+)\]', seen_path)
                
                if tour_match1 and tour_match2:
                    if tour_match1.group(1) == tour_match2.group(1):
                        field1 = path.split('.')[-1] if '.' in path else ''
                        field2 = seen_path.split('.')[-1] if '.' in seen_path else ''
                        if field1 == field2:
                            is_duplicate = True
                            break
                
                similarity = DeduplicationEngine.calculate_similarity(text, seen_text)
                if similarity > threshold:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_passages.append((score, passage))
                seen_passages.append((text, path))
        
        logger.info(f"üîÑ Deduplication: {len(passages)} ‚Üí {len(unique_passages)} passages")
        return unique_passages
    
    @staticmethod
    def merge_similar_tours(tour_indices: List[int], tours_db: Dict[int, Tour]) -> List[int]:
        """Merge tours that are essentially the same"""
        if len(tour_indices) <= 1:
            return tour_indices
        
        tour_groups = []
        processed = set()
        
        for i, idx1 in enumerate(tour_indices):
            if idx1 in processed:
                continue
            
            group = [idx1]
            tour1 = tours_db.get(idx1)
            name1 = (tour1.tour_name if tour1 else "").strip()
            
            if not name1:
                processed.add(idx1)
                tour_groups.append(group)
                continue
            
            for j, idx2 in enumerate(tour_indices[i+1:], i+1):
                if idx2 in processed:
                    continue
                
                tour2 = tours_db.get(idx2)
                name2 = (tour2.tour_name if tour2 else "").strip()
                
                if not name2:
                    continue
                
                similarity = DeduplicationEngine.calculate_similarity(name1, name2)
                if similarity > 0.9:
                    group.append(idx2)
                    processed.add(idx2)
            
            processed.add(idx1)
            tour_groups.append(group)
        
        best_tours = []
        for group in tour_groups:
            if not group:
                continue
            
            if len(group) == 1:
                best_tours.append(group[0])
                continue
            
            best_score = -1
            best_idx = group[0]
            
            for idx in group:
                tour = tours_db.get(idx)
                if not tour:
                    continue
                
                score = 0
                
                if tour.tour_name:
                    score += 2
                if tour.duration:
                    score += 2
                if tour.location:
                    score += 2
                if tour.price:
                    score += 3
                if tour.includes:
                    score += 2
                if tour.summary:
                    score += 1
                
                for field in [tour.includes, tour.summary, tour.notes]:
                    if isinstance(field, str) and len(field) > 50:
                        score += 1
                    elif isinstance(field, list) and field:
                        score += len(field)
                
                if score > best_score:
                    best_score = score
                    best_idx = idx
            
            best_tours.append(best_idx)
        
        logger.info(f"üîÑ Tour merging: {len(tour_indices)} ‚Üí {len(best_tours)} unique tours")
        return best_tours

class EnhancedFieldDetectorV2:
    """
    Upgrade 3: Enhanced Field Detector
    C·∫¨P NH·∫¨T: Detect c√°c field m·ªõi t·ª´ knowledge.json
    """
    
    @staticmethod
    def detect_field_with_confidence(message: str) -> Tuple[Optional[str], float, Dict]:
        """Ph√°t hi·ªán field ƒë∆∞·ª£c h·ªèi v·ªõi knowledge.json structure"""
        msg_lower = message.lower()
        
        # Field mapping: t·ª´ kh√≥a -> field trong knowledge.json
        field_mappings = {
            'tour_name': {
                'keywords': ['t√™n tour', 'tour n√†o', 'tour g√¨', 'tour t√™n l√†'],
                'weight': 1.0
            },
            'price': {
                'keywords': ['gi√°', 'gi√° c·∫£', 'chi ph√≠', 'bao nhi√™u ti·ªÅn', 'gi√° tour'],
                'weight': 1.0
            },
            'duration': {
                'keywords': ['th·ªùi gian', 'bao l√¢u', 'm·∫•y ng√†y', 'k√©o d√†i', 'duration'],
                'weight': 0.9
            },
            'location': {
                'keywords': ['ƒë·ªãa ƒëi·ªÉm', '·ªü ƒë√¢u', 'n∆°i n√†o', 'ƒëi·ªÉm ƒë·∫øn', 'location'],
                'weight': 0.9
            },
            'includes': {
                'keywords': ['bao g·ªìm', 'c√≥ g√¨', 'd·ªãch v·ª•', 'ti·ªán √≠ch', 'included'],
                'weight': 0.8
            },
            'style': {
                'keywords': ['phong c√°ch', 'lo·∫°i h√¨nh', 'd·∫°ng tour', 'ki·ªÉu tour', 'style'],
                'weight': 0.7
            },
            'transport': {
                'keywords': ['ph∆∞∆°ng ti·ªán', 'di chuy·ªÉn', 'xe c·ªô', 'v·∫≠n chuy·ªÉn', 'transport'],
                'weight': 0.6
            },
            'accommodation': {
                'keywords': ['ch·ªó ·ªü', 'kh√°ch s·∫°n', 'n∆°i ·ªü', 'l∆∞u tr√∫', 'accommodation'],
                'weight': 0.6
            },
            'meals': {
                'keywords': ['ƒÉn u·ªëng', 'b·ªØa ƒÉn', '·∫©m th·ª±c', 'ƒë·ªì ƒÉn', 'meals'],
                'weight': 0.6
            },
            'event_support': {
                'keywords': ['h·ªó tr·ª£ s·ª± ki·ªán', 't·ªï ch·ª©c event', 's·ª± ki·ªán', 'event support'],
                'weight': 0.5
            },
            'summary': {
                'keywords': ['t√≥m t·∫Øt', 'm√¥ t·∫£', 'gi·ªõi thi·ªáu', 'summary', 'overview'],
                'weight': 0.7
            },
            'notes': {
                'keywords': ['l∆∞u √Ω', 'ch√∫ √Ω', 'c·∫ßn bi·∫øt', 'notes', 'ghi ch√∫'],
                'weight': 0.5
            }
        }
        
        field_scores = {}
        for field, config in field_mappings.items():
            score = 0
            for keyword in config['keywords']:
                if keyword in msg_lower:
                    score += 1
            
            if score > 0:
                # T√≠nh confidence d·ª±a tr√™n s·ªë keyword match v√† weight
                base_confidence = min(0.3 + (score * 0.15), 0.9)
                weighted_confidence = base_confidence * config['weight']
                field_scores[field] = weighted_confidence
        
        if not field_scores:
            return None, 0.3, {}
        
        # T√¨m field c√≥ confidence cao nh·∫•t
        best_field = max(field_scores.items(), key=lambda x: x[1])
        return best_field[0], best_field[1], field_scores
    
    @staticmethod
    def get_field_value(tour: Tour, field_name: str) -> Any:
        """L·∫•y gi√° tr·ªã field t·ª´ Tour object"""
        if field_name == 'tour_name':
            return tour.tour_name
        elif field_name == 'price':
            return tour.price
        elif field_name == 'duration':
            return tour.duration
        elif field_name == 'location':
            return tour.location
        elif field_name == 'includes':
            return tour.includes
        elif field_name == 'style':
            return tour.style
        elif field_name == 'transport':
            return tour.transport
        elif field_name == 'accommodation':
            return tour.accommodation
        elif field_name == 'meals':
            return tour.meals
        elif field_name == 'event_support':
            return tour.event_support
        elif field_name == 'summary':
            return tour.summary
        elif field_name == 'notes':
            return tour.notes
        else:
            return None

class KnowledgeAwareQuestionPipeline:
    """
    Upgrade 4: Question Pipeline
    C·∫¨P NH·∫¨T: Hi·ªÉu c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn knowledge.json fields
    """
    
    @staticmethod
    def classify_question(message: str) -> Tuple[QuestionType, float, Dict]:
        """Ph√¢n lo·∫°i c√¢u h·ªèi v·ªõi knowledge.json context"""
        msg_lower = message.lower()
        
        # Ki·ªÉm tra greeting
        greetings = ['xin ch√†o', 'hello', 'hi', 'ch√†o b·∫°n', 'ch√†o']
        if any(g in msg_lower for g in greetings):
            return QuestionType.GREETING, 0.95, {'greeting_type': 'standard'}
        
        # Ki·ªÉm tra farewell
        farewells = ['t·∫°m bi·ªát', 'bye', 'c·∫£m ∆°n', 'thanks', 'k·∫øt th√∫c']
        if any(f in msg_lower for f in farewells):
            return QuestionType.FAREWELL, 0.95, {'farewell_type': 'standard'}
        
        # C√¢u h·ªèi li·ªát k√™ tour
        list_keywords = ['danh s√°ch', 'li·ªát k√™', 'c√≥ nh·ªØng tour n√†o', 'tour n√†o c√≥', 'c√°c tour']
        list_count = sum(1 for kw in list_keywords if kw in msg_lower)
        if list_count > 0:
            confidence = min(0.7 + (list_count * 0.1), 0.95)
            return QuestionType.LIST_TOURS, confidence, {'list_type': 'general'}
        
        # C√¢u h·ªèi chi ti·∫øt tour
        detail_keywords = ['chi ti·∫øt', 'th√¥ng tin', 'gi·ªõi thi·ªáu', 'm√¥ t·∫£', 'tour n√†y']
        detail_count = sum(1 for kw in detail_keywords if kw in msg_lower)
        if detail_count > 0:
            confidence = min(0.65 + (detail_count * 0.1), 0.9)
            return QuestionType.TOUR_DETAIL, confidence, {'detail_type': 'general'}
        
        # C√¢u h·ªèi so s√°nh
        compare_keywords = ['so s√°nh', 'kh√°c nhau', 'n√™n ch·ªçn', 'c√°i n√†o t·ªët', 'c√°i n√†o hay']
        compare_count = sum(1 for kw in compare_keywords if kw in msg_lower)
        if compare_count > 0:
            confidence = min(0.6 + (compare_count * 0.15), 0.9)
            return QuestionType.COMPARISON, confidence, {'compare_type': 'general'}
        
        # C√¢u h·ªèi ƒë·ªÅ xu·∫•t
        recommend_keywords = ['ƒë·ªÅ xu·∫•t', 'g·ª£i √Ω', 'n√™n ƒëi', 'ph√π h·ª£p', 't∆∞ v·∫•n']
        recommend_count = sum(1 for kw in recommend_keywords if kw in msg_lower)
        if recommend_count > 0:
            confidence = min(0.7 + (recommend_count * 0.1), 0.95)
            return QuestionType.RECOMMENDATION, confidence, {'recommend_type': 'general'}
        
        # C√¢u h·ªèi v·ªÅ field c·ª• th·ªÉ trong knowledge.json
        field_detector = EnhancedFieldDetectorV2()
        field_name, field_confidence, _ = field_detector.detect_field_with_confidence(message)
        if field_confidence > 0.6:
            return QuestionType.GENERAL_INFO, field_confidence, {'field_name': field_name}
        
        return QuestionType.UNKNOWN, 0.5, {'reason': 'no_keywords_matched'}

class ComplexQueryProcessor:
    """Upgrade 5: Complex Query Processor - GI·ªÆ NGUY√äN"""
    
    @staticmethod
    def split_query(query: str) -> List[Dict[str, Any]]:
        """Split complex query into sub-queries"""
        sub_queries = []
        
        # Simple implementation - can be enhanced
        if ' v√† ' in query or ',' in query:
            parts = re.split(r' v√† |,', query)
            for part in parts:
                if part.strip():
                    sub_queries.append({
                        'query': part.strip(),
                        'priority': 0.8,
                        'filters': {},
                        'focus': 'general'
                    })
        else:
            sub_queries.append({
                'query': query,
                'priority': 1.0,
                'filters': {},
                'focus': 'general'
            })
        
        return sub_queries

class FuzzyMatcher:
    """Upgrade 6: Fuzzy Matcher - GI·ªÆ NGUY√äN"""
    
    def __init__(self, tours_db: Dict[int, Tour]):
        self.tours_db = tours_db
    
    def find_similar_tours(self, query: str, tour_names: Dict[str, int]) -> List[Tuple[int, float]]:
        """Find tours with similar names"""
        matches = []
        query_norm = self.normalize_text(query)
        
        for name, idx in tour_names.items():
            name_norm = self.normalize_text(name)
            similarity = SequenceMatcher(None, query_norm, name_norm).ratio()
            
            if similarity > 0.6:
                matches.append((idx, similarity))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        return matches[:5]
    
    def find_tour_by_partial_name(self, partial_name: str) -> List[int]:
        """Find tours by partial name match"""
        partial_norm = self.normalize_text(partial_name)
        matches = []
        
        for idx, tour in self.tours_db.items():
            tour_name_norm = self.normalize_text(tour.tour_name)
            if partial_norm in tour_name_norm:
                matches.append(idx)
        
        return matches
    
    @staticmethod
    def normalize_text(text: str) -> str:
        """Normalize text for fuzzy matching"""
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text

class ConversationStateMachine:
    """Upgrade 7: Conversation State Machine - GI·ªÆ NGUY√äN"""
    
    def __init__(self, initial_state: ConversationState = ConversationState.INITIAL):
        self.current_state = initial_state
        self.state_history = []
    
    def update(self, user_message: str, bot_response: str, tour_indices: List[int] = None):
        """Update state based on interaction"""
        # Simple state transitions based on message content
        msg_lower = user_message.lower()
        
        if 'so s√°nh' in msg_lower:
            self.current_state = ConversationState.COMPARISON
        elif 'chi ti·∫øt' in msg_lower or 'th√¥ng tin' in msg_lower:
            self.current_state = ConversationState.DETAIL_VIEW
        elif 'ƒë·ªÅ xu·∫•t' in msg_lower or 'g·ª£i √Ω' in msg_lower:
            self.current_state = ConversationState.RECOMMENDING
        elif 't·∫°m bi·ªát' in msg_lower or 'bye' in msg_lower:
            self.current_state = ConversationState.CLOSING
        
        self.state_history.append({
            'timestamp': time.time(),
            'state': self.current_state.value,
            'message': user_message[:100]
        })
    
    def extract_reference(self, message: str) -> List[int]:
        """Extract tour reference from message"""
        # Simple implementation - look for tour names
        msg_lower = message.lower()
        references = []
        
        for idx, tour in tours_db.items():
            tour_name_lower = tour.tour_name.lower()
            if tour_name_lower in msg_lower:
                references.append(idx)
        
        return references

class SemanticAnalyzer:
    """Upgrade 8: Semantic Analyzer - GI·ªÆ NGUY√äN"""
    
    @staticmethod
    def analyze_user_profile(message: str, current_context: ConversationContext) -> Dict:
        """Analyze user profile from message"""
        profile = {
            'interests': [],
            'budget': None,
            'group_type': None,
            'preferred_duration': None
        }
        
        msg_lower = message.lower()
        
        # Detect interests
        interest_keywords = {
            'history': ['l·ªãch s·ª≠', 'chi·∫øn tranh', 'di t√≠ch'],
            'nature': ['thi√™n nhi√™n', 'r·ª´ng', 'n√∫i'],
            'wellness': ['thi·ªÅn', 'kh√≠ c√¥ng', 'ch·ªØa l√†nh'],
            'culture': ['vƒÉn h√≥a', '·∫©m th·ª±c', 'truy·ªÅn th·ªëng']
        }
        
        for interest, keywords in interest_keywords.items():
            for keyword in keywords:
                if keyword in msg_lower:
                    profile['interests'].append(interest)
                    break
        
        return profile
    
    @staticmethod
    def match_tours_to_profile(profile: Dict, tours_db: Dict[int, Tour]) -> List[Tuple]:
        """Match tours to user profile"""
        matches = []
        
        for idx, tour in tours_db.items():
            score = 0
            
            # Match interests with tour style
            if profile.get('interests') and tour.style:
                tour_style_lower = tour.style.lower()
                for interest in profile['interests']:
                    interest_keywords = {
                        'history': ['l·ªãch s·ª≠', 'chi·∫øn tranh'],
                        'nature': ['thi√™n nhi√™n', 'r·ª´ng'],
                        'wellness': ['thi·ªÅn', 'kh√≠ c√¥ng'],
                        'culture': ['vƒÉn h√≥a', '·∫©m th·ª±c']
                    }
                    
                    if any(keyword in tour_style_lower for keyword in interest_keywords.get(interest, [])):
                        score += 1
            
            # Match budget
            if profile.get('budget') and tour.price_numeric:
                if tour.price_numeric <= profile['budget']:
                    score += 1
            
            if score > 0:
                matches.append((idx, score))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        return matches

class AutoValidator:
    """Upgrade 9: Auto Validator - GI·ªÆ NGUY√äN"""
    
    @staticmethod
    def validate_response(response: str) -> str:
        """Validate and correct response"""
        # Simple validation - ensure hotline is included
        if '0332510486' not in response:
            response += "\n\nüìû Li√™n h·ªá hotline 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt!"
        
        return response
    
    @staticmethod
    def safe_validate(reply: dict) -> dict:
        """Safe validation wrapper"""
        try:
            if not isinstance(reply, dict):
                return reply
            
            if 'reply' in reply:
                reply['reply'] = AutoValidator.validate_response(reply['reply'])
            
            return reply
        except Exception as e:
            logger.error(f"Validation error: {e}")
            return reply

class KnowledgeTemplateSystem:
    """
    Upgrade 10: Template System
    C·∫¨P NH·∫¨T: Templates cho knowledge.json fields
    """
    
    TEMPLATES = {
        # General templates
        'greeting': """Xin ch√†o! üëã T√¥i l√† tr·ª£ l√Ω du l·ªãch c·ªßa Ruby Wings.

T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:
‚Ä¢ T√¨m ki·∫øm tour theo y√™u c·∫ßu
‚Ä¢ Cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ tour
‚Ä¢ So s√°nh c√°c tour v·ªõi nhau
‚Ä¢ ƒê·ªÅ xu·∫•t tour ph√π h·ª£p v·ªõi nhu c·∫ßu

B·∫°n ƒëang t√¨m ki·∫øm tour nh∆∞ th·∫ø n√†o?""",
        
        'farewell': """C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng d·ªãch v·ª• c·ªßa Ruby Wings! üåü

N·∫øu b·∫°n c·∫ßn th√™m th√¥ng tin v·ªÅ b·∫•t k·ª≥ tour n√†o, ƒë·ª´ng ng·∫ßn ng·∫°i quay l·∫°i.

Ch√∫c b·∫°n c√≥ m·ªôt chuy·∫øn ƒëi tuy·ªát v·ªùi! ‚úàÔ∏è""",
        
        # Tour list template
        'tour_list': """üéØ **T√¥i t√¨m th·∫•y {count} tour ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n:**

{tour_items}

üí° **G·ª£i √Ω:**
‚Ä¢ G√µ s·ªë th·ª© t·ª± ƒë·ªÉ xem chi ti·∫øt tour
‚Ä¢ Ho·∫∑c h·ªèi th√™m v·ªÅ ti√™u ch√≠ c·ª• th·ªÉ (gi√°, th·ªùi gian, ƒë·ªãa ƒëi·ªÉm)""",
        
        'tour_item': """{idx}. **{tour_name}**
   üìç {location} | ‚è± {duration} | üí∞ {price}
   üéØ {summary}""",
        
        # Tour detail template v·ªõi knowledge.json fields
        'tour_detail_full': """üåü **{tour_name}**

üìã **T√≥m t·∫Øt:** {summary}
üìç **ƒê·ªãa ƒëi·ªÉm:** {location}
‚è± **Th·ªùi gian:** {duration}
üí∞ **Gi√°:** {price}
üé® **Phong c√°ch:** {style}

üöå **Ph∆∞∆°ng ti·ªán di chuy·ªÉn:** {transport}
üè® **Ch·ªó ·ªü:** {accommodation}
üçΩ **ƒÇn u·ªëng:** {meals}

‚úÖ **D·ªãch v·ª• bao g·ªìm:**
{includes_formatted}

üìù **L∆∞u √Ω quan tr·ªçng:** {notes}

üé™ **H·ªó tr·ª£ s·ª± ki·ªán:** {event_support}

üíé **Lo·∫°i tour:** {category} | ‚≠ê **ƒê√°nh gi√°:** {rating}/5""",
        
        # Field-specific templates
        'field_price': """üí∞ **Gi√° tour {tour_name}:**
{price}

üí° *Gi√° ƒë√£ bao g·ªìm thu·∫ø v√† ph√≠ d·ªãch v·ª•*""",
        
        'field_includes': """‚úÖ **Tour {tour_name} bao g·ªìm:**

{includes_formatted}

üí° *T·∫•t c·∫£ d·ªãch v·ª• ƒë√£ ƒë∆∞·ª£c ki·ªÉm duy·ªát v√† ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng*""",
        
        'field_duration': """‚è± **Th·ªùi gian tour {tour_name}:**
{duration}

üìÖ *L·ªãch tr√¨nh chi ti·∫øt c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh theo y√™u c·∫ßu*""",
        
        'field_location': """üìç **ƒê·ªãa ƒëi·ªÉm tour {tour_name}:**
{location}

üó∫Ô∏è *B·∫£n ƒë·ªì v√† h∆∞·ªõng d·∫´n di chuy·ªÉn s·∫Ω ƒë∆∞·ª£c cung c·∫•p ƒë·∫ßy ƒë·ªß*""",
        
        # Comparison template
        'comparison': """üîÑ **So s√°nh {count} tour:**

{comparison_table}

üìä **T√≥m t·∫Øt:**
{summary}

üí° **G·ª£i √Ω:** {suggestion}""",
        
        # Recommendation template
        'recommendation': """üéØ **ƒê·ªÅ xu·∫•t ph√π h·ª£p v·ªõi b·∫°n:**

{recommended_tour}

üìà **L√Ω do ƒë·ªÅ xu·∫•t:**
{reasons}

ü§î **Tour kh√°c c√≥ th·ªÉ xem x√©t:**
{alternatives}""",
        
        # Error/fallback templates
        'no_results': """üòï **Kh√¥ng t√¨m th·∫•y tour ph√π h·ª£p**

T√¥i kh√¥ng t√¨m th·∫•y tour n√†o ƒë√°p ·ª©ng y√™u c·∫ßu c·ªßa b·∫°n. B·∫°n c√≥ th·ªÉ:

1. **M·ªü r·ªông ti√™u ch√≠ t√¨m ki·∫øm**
2. **Thay ƒë·ªïi ng√¢n s√°ch ho·∫∑c th·ªùi gian**
3. **Xem danh s√°ch t·∫•t c·∫£ tour c√≥ s·∫µn**

B·∫°n mu·ªën th·ª≠ c√°ch n√†o?""",
        
        'general_fallback': """ü§î **T√¥i hi·ªÉu b·∫°n ƒëang h·ªèi v·ªÅ:**
_{user_message}_

Hi·ªán t√¥i c√≥ th·ªÉ gi√∫p b·∫°n v·ªõi:
‚Ä¢ Th√¥ng tin v·ªÅ {available_fields}
‚Ä¢ So s√°nh c√°c tour
‚Ä¢ ƒê·ªÅ xu·∫•t tour ph√π h·ª£p

B·∫°n mu·ªën t√¨m hi·ªÉu c·ª• th·ªÉ v·ªÅ ƒëi·ªÅu g√¨?"""
    }
    
    @classmethod
    def render(cls, template_name: str, **kwargs) -> str:
        """Render template v·ªõi data"""
        template = cls.TEMPLATES.get(template_name)
        if not template:
            return f"Template '{template_name}' not found"
        
        try:
            # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho includes (chuy·ªÉn list -> string)
            if 'includes' in kwargs and isinstance(kwargs['includes'], list):
                includes_items = [f"‚Ä¢ {item}" for item in kwargs['includes']]
                kwargs['includes_formatted'] = "\n".join(includes_items)
            
            return template.format(**kwargs)
        except KeyError as e:
            logger.error(f"Template rendering error: {e}")
            return template

# ==================== PH·∫¶N 5: SUPPORT FUNCTIONS ====================

class CacheSystem:
    """Cache System"""
    
    def __init__(self):
        self.cache = {}
    
    def get_cache_key(self, query: str, context_hash: str = "") -> str:
        """Generate cache key"""
        key_parts = [query]
        if context_hash:
            key_parts.append(context_hash)
        return hashlib.md5("|".join(key_parts).encode()).hexdigest()
    
    def get(self, key: str) -> Optional[Any]:
        """Get item from cache"""
        if key in self.cache:
            entry = self.cache[key]
            if not entry.is_expired():
                logger.debug(f"üíæ Cache hit for key: {key[:20]}...")
                return entry.value
            else:
                del self.cache[key]
        return None
    
    def set(self, key: str, value: Any, expiry: int = None):
        """Set item in cache"""
        ttl = expiry or CACHE_TTL
        cache_entry = CacheEntry(
            value=value,
            expiry=time.time() + ttl
        )
        self.cache[key] = cache_entry
        
        # Clean up expired entries occasionally
        if len(self.cache) > 100:
            self._cleanup()
    
    def _cleanup(self):
        """Clean up expired cache entries"""
        expired_keys = []
        for key, entry in self.cache.items():
            if entry.is_expired():
                expired_keys.append(key)
        
        for key in expired_keys:
            del self.cache[key]
        
        if expired_keys:
            logger.debug(f"üßπ Cleaned up {len(expired_keys)} expired cache entries")

def get_session_context(session_id: str) -> ConversationContext:
    """L·∫•y context t·ª´ session"""
    with SESSION_LOCK:
        if session_id in sessions:
            context = sessions[session_id]
            # Check if session has expired
            if time.time() - context.last_activity > SESSION_TIMEOUT:
                logger.info(f"Session {session_id} expired, creating new")
                context = ConversationContext(session_id=session_id)
                sessions[session_id] = context
            return context
        else:
            context = ConversationContext(session_id=session_id)
            sessions[session_id] = context
            return context

def save_session_context(session_id: str, context: ConversationContext):
    """L∆∞u context v√†o session"""
    with SESSION_LOCK:
        sessions[session_id] = context

def extract_session_id(request_data: Dict, remote_addr: str) -> str:
    """Extract session ID"""
    session_id = request_data.get("session_id")
    if not session_id:
        ip = remote_addr or "0.0.0.0"
        current_hour = datetime.now().strftime("%Y%m%d%H")
        unique_str = f"{ip}_{current_hour}"
        session_id = hashlib.md5(unique_str.encode()).hexdigest()[:12]
    return f"session_{session_id}"

def llm_request(request_data: LLMRequest) -> str:
    """G·ª≠i request ƒë·∫øn LLM"""
    try:
        import requests
        response = requests.post(
            LLM_URL,
            json={
                "model": request_data.model,
                "prompt": request_data.prompt,
                "stream": request_data.stream,
                "temperature": request_data.temperature,
                "max_tokens": request_data.max_tokens
            },
            timeout=30
        )
        
        if response.status_code == 200:
            if request_data.stream:
                return response.text
            else:
                data = response.json()
                return data.get("response", "")
        else:
            logger.error(f"LLM request failed: {response.status_code}")
            return ""
    except Exception as e:
        logger.error(f"LLM request error: {e}")
        return ""

def parse_llm_response(llm_response: str) -> Dict:
    """Parse LLM response"""
    # Simple parsing - can be enhanced
    return {"reply": llm_response}

@lru_cache(maxsize=100)
def embed_text(text: str) -> Tuple[List[float], int]:
    """T·∫°o embedding cho text"""
    # Fallback embedding - can be replaced with actual embedding model
    if not text:
        return [], 0
    
    # Simple hash-based embedding for fallback
    h = hash(text) % (10 ** 12)
    dim = 1536  # OpenAI embedding dimension
    embedding = [(float((h >> (i % 32)) & 0xFF) + (i % 7)) / 255.0 
                 for i in range(dim)]
    
    return embedding, dim

class NumpyIndex:
    """Simple numpy-based index"""
    
    def __init__(self, mat=None):
        if mat is None:
            self.mat = np.empty((0, 0), dtype="float32")
        else:
            self.mat = np.asarray(mat, dtype="float32")
            if self.mat.ndim == 1:
                self.mat = self.mat.reshape(1, -1)
        
        if self.mat.shape[0] > 0 and self.mat.ndim == 2:
            self.dim = int(self.mat.shape[1])
        else:
            self.dim = 0
        self.size = int(self.mat.shape[0])
    
    def is_empty(self):
        return self.mat.shape[0] == 0
    
    def search(self, query_vec, k=5):
        if self.is_empty():
            return [], []
        
        q = np.asarray(query_vec, dtype="float32").reshape(1, -1)
        # Normalize for cosine similarity
        q_norm = q / (np.linalg.norm(q) + 1e-12)
        mat_norm = self.mat / (np.linalg.norm(self.mat, axis=1, keepdims=True) + 1e-12)
        
        sims = np.dot(mat_norm, q_norm.T).reshape(-1)
        topk = np.argsort(-sims)[:k]
        
        return sims[topk].tolist(), topk.tolist()
    
    def save(self, path):
        np.savez_compressed(path, mat=self.mat)
    
    @classmethod
    def load(cls, path):
        try:
            arr = np.load(path)
            return cls(arr['mat'])
        except Exception as e:
            logger.error(f"Failed to load numpy index: {e}")
            return cls()

def query_index(query: str, top_k: int = 5, min_score: float = SEMANTIC_MIN_SCORE) -> List[Tuple[float, Dict]]:
    """Semantic search"""
    if search_index is None:
        return []
    
    try:
        embedding, _ = embed_text(query)
        if not embedding:
            return []
        
        scores, indices = search_index.search(embedding, k=top_k)
        
        results = []
        for score, idx in zip(scores, indices):
            if score < min_score:
                continue
            
            if idx < len(MAPPING):
                passage = MAPPING[idx]
                results.append((float(score), passage))
        
        return results
    except Exception as e:
        logger.error(f"Search error: {e}")
        return []

def build_index(force_rebuild: bool = False) -> bool:
    """Build search index"""
    global search_index
    
    try:
        if not FLAT_TEXTS:
            logger.warning("No texts to index")
            return False
        
        logger.info(f"üî® Building index for {len(FLAT_TEXTS)} passages...")
        
        # Generate embeddings
        vectors = []
        for text in FLAT_TEXTS:
            emb, _ = embed_text(text)
            if emb:
                vectors.append(np.array(emb, dtype="float32"))
        
        if not vectors:
            logger.error("No embeddings generated")
            return False
        
        # Create index
        mat = np.vstack(vectors)
        mat = mat / (np.linalg.norm(mat, axis=1, keepdims=True) + 1e-12)
        
        if HAS_FAISS:
            import faiss
            index = faiss.IndexFlatIP(mat.shape[1])
            index.add(mat)
            search_index = index
            logger.info("‚úÖ Built FAISS index")
        else:
            search_index = NumpyIndex(mat)
            logger.info("‚úÖ Built numpy index")
        
        return True
    except Exception as e:
        logger.error(f"Index building error: {e}")
        return False

def send_capi_event(session_id: str, user_message: str, bot_response: str):
    """G·ª≠i event ƒë·∫øn CAPI"""
    if not CAPI_ENABLED:
        return
    
    try:
        # Implement CAPI sending logic here
        pass
    except Exception as e:
        logger.error(f"CAPI error: {e}")

def generate_session_id() -> str:
    """Generate session ID"""
    import uuid
    return f"session_{uuid.uuid4().hex[:12]}"

def cleanup_expired_sessions():
    """D·ªçn d·∫πp session h·∫øt h·∫°n"""
    with SESSION_LOCK:
        expired_keys = []
        current_time = time.time()
        
        for session_id, context in sessions.items():
            if current_time - context.last_activity > SESSION_TIMEOUT:
                expired_keys.append(session_id)
        
        for key in expired_keys:
            del sessions[key]
        
        if expired_keys:
            logger.info(f"üßπ Cleaned up {len(expired_keys)} expired sessions")

def _prepare_llm_prompt(user_message: str, search_results: List, context: Dict) -> str:
    """Chu·∫©n b·ªã prompt cho LLM"""
    prompt_parts = [
        "B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n du l·ªãch Ruby Wings - CHUY√äN NGHI·ªÜP, TH√îNG MINH, NHI·ªÜT T√åNH.",
        "",
        "‚ö†Ô∏è QUY T·∫ÆC NGHI√äM NG·∫∂T:",
        "1. LU√îN tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát",
        "2. Gi·ªØ th√°i ƒë·ªô nhi·ªát t√¨nh, th√¢n thi·ªán",
        "3. KH√îNG b·ªãa th√¥ng tin n·∫øu kh√¥ng bi·∫øt",
        "4. LU√îN ƒë·ªÅ c·∫≠p hotline 0332510486 khi k·∫øt th√∫c",
        "",
        "üìö TH√îNG TIN NG·ªÆ C·∫¢NH:",
    ]
    
    # Add context info
    if context.get('user_preferences'):
        prefs = context['user_preferences']
        prompt_parts.append(f"- S·ªü th√≠ch ng∆∞·ªùi d√πng: {prefs}")
    
    if context.get('current_tours'):
        tours_info = context['current_tours']
        prompt_parts.append(f"- Tour ƒëang n√≥i ƒë·∫øn: {tours_info}")
    
    # Add search results
    prompt_parts.append("")
    prompt_parts.append("üìù D·ªÆ LI·ªÜU T√åM TH·∫§Y:")
    
    if search_results:
        for i, (score, passage) in enumerate(search_results[:5], 1):
            text = passage.get('text', '')[:200]
            prompt_parts.append(f"[{i}] {text}")
    else:
        prompt_parts.append("(Kh√¥ng c√≥ d·ªØ li·ªáu c·ª• th·ªÉ)")
    
    # Add user message
    prompt_parts.append("")
    prompt_parts.append("üí¨ C√ÇU H·ªéI C·ª¶A KH√ÅCH:")
    prompt_parts.append(user_message)
    
    # Add instructions
    prompt_parts.append("")
    prompt_parts.append("üéØ H√ÉY TR·∫¢ L·ªúI:")
    prompt_parts.append("1. D·ª±a tr√™n d·ªØ li·ªáu c√≥ s·∫µn")
    prompt_parts.append("2. Ng·∫Øn g·ªçn, r√µ r√†ng")
    prompt_parts.append("3. K·∫øt th√∫c b·∫±ng hotline 0332510486")
    
    return "\n".join(prompt_parts)

def _generate_fallback_response(user_message: str, search_results: List, tour_indices: List[int] = None) -> str:
    """Generate fallback response"""
    # Use template system for fallback
    if tour_indices and tours_db:
        tour_list = []
        for idx in tour_indices[:3]:
            tour = tours_db.get(idx)
            if tour:
                tour_list.append(tour)
        
        if tour_list:
            tour_items = []
            for i, tour in enumerate(tour_list, 1):
                tour_items.append(
                    KnowledgeTemplateSystem.TEMPLATES['tour_item'].format(
                        idx=i,
                        tour_name=tour.tour_name,
                        location=tour.location,
                        duration=tour.duration,
                        price=tour.price,
                        summary=tour.summary[:100] + "..."
                    )
                )
            
            return KnowledgeTemplateSystem.TEMPLATES['tour_list'].format(
                count=len(tour_list),
                tour_items="\n\n".join(tour_items)
            )
    
    return KnowledgeTemplateSystem.TEMPLATES['general_fallback'].format(
        user_message=user_message,
        available_fields="gi√° c·∫£, th·ªùi gian, ƒë·ªãa ƒëi·ªÉm, d·ªãch v·ª• bao g·ªìm"
    )

# ==================== PH·∫¶N 6: GLOBAL VARIABLES & INITIALIZATION ====================

# Global variables
tours_db: Dict[int, Tour] = {}
tour_name_index: Dict[str, int] = {}
search_index = None
sessions: Dict[str, ConversationContext] = {}
SESSION_LOCK = threading.Lock()
cache_system = CacheSystem()

# Knowledge base state
KNOW: Dict = {}
FLAT_TEXTS: List[str] = []
MAPPING: List[Dict] = []

def initialize_system():
    """Kh·ªüi t·∫°o h·ªá th·ªëng - C·∫¨P NH·∫¨T v·ªõi knowledge.json"""
    global tours_db, tour_name_index, KNOW, FLAT_TEXTS, MAPPING
    
    # Load tours t·ª´ knowledge.json
    tours_db = KnowledgeLoader.build_tours_database()
    
    # Build tour name index
    tour_name_index = {}
    for tid, tour in tours_db.items():
        normalized_name = tour.tour_name.lower().strip()
        if normalized_name:
            tour_name_index[normalized_name] = tid
    
    # Load knowledge for indexing
    KNOW = KnowledgeLoader.load_knowledge_file()
    
    # Flatten knowledge for indexing
    def scan(obj, prefix="root"):
        if isinstance(obj, dict):
            for k, v in obj.items():
                scan(v, f"{prefix}.{k}")
        elif isinstance(obj, list):
            for i, v in enumerate(obj):
                scan(v, f"{prefix}[{i}]")
        elif isinstance(obj, str):
            t = obj.strip()
            if t:
                FLAT_TEXTS.append(t)
                MAPPING.append({"path": prefix, "text": t})
        else:
            try:
                s = str(obj).strip()
                if s:
                    FLAT_TEXTS.append(s)
                    MAPPING.append({"path": prefix, "text": s})
            except Exception:
                pass
    
    scan(KNOW)
    
    # Build search index
    build_index(force_rebuild=False)
    
    logger.info(f"‚úÖ System initialized with {len(tours_db)} tours, {len(FLAT_TEXTS)} passages")

# G·ªçi kh·ªüi t·∫°o
initialize_system()

# ==================== PH·∫¶N 7: FLASK APP ====================

app = Flask(__name__)
CORS(app)

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "chatbot": "running",
            "tours_db": len(tours_db),
            "knowledge_base": len(KNOW.get('tours', [])),
            "sessions": len(sessions)
        }
    })

@app.route('/api/tours', methods=['GET'])
def get_tours():
    """Get all tours"""
    try:
        tours_list = []
        for idx, tour in tours_db.items():
            tours_list.append({
                "id": idx,
                "tour_name": tour.tour_name,
                "summary": tour.summary,
                "location": tour.location,
                "duration": tour.duration,
                "price": tour.price,
                "category": tour.category,
                "style": tour.style
            })
        
        return jsonify({
            "success": True,
            "count": len(tours_list),
            "tours": tours_list
        })
    except Exception as e:
        logger.error(f"Error getting tours: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/tours/<int:tour_id>', methods=['GET'])
def get_tour_detail(tour_id: int):
    """Get tour details by ID"""
    try:
        tour = tours_db.get(tour_id)
        if not tour:
            return jsonify({"error": "Tour not found"}), 404
        
        return jsonify({
            "success": True,
            "tour": asdict(tour)
        })
    except Exception as e:
        logger.error(f"Error getting tour {tour_id}: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/search', methods=['POST'])
def search_tours():
    """Search tours by query"""
    try:
        data = request.get_json() or {}
        query = data.get('query', '').strip()
        
        if not query:
            return jsonify({"error": "Query is required"}), 400
        
        # Apply filters if provided
        filters_data = data.get('filters', {})
        filters = FilterSet(
            min_price=filters_data.get('min_price'),
            max_price=filters_data.get('max_price'),
            location=filters_data.get('location'),
            duration_min=filters_data.get('duration_min'),
            duration_max=filters_data.get('duration_max'),
            style=filters_data.get('style'),
            category=filters_data.get('category')
        )
        
        # First apply mandatory filters
        filtered_indices = MandatoryFilterSystemV2.apply_filters(tours_db, filters)
        
        # Then apply fuzzy matching if needed
        if query and filtered_indices:
            fuzzy_matcher = FuzzyMatcher(tours_db)
            filtered_tours_db = {idx: tours_db[idx] for idx in filtered_indices}
            
            # Create tour name index for filtered tours
            filtered_tour_names = {}
            for idx in filtered_indices:
                tour = tours_db[idx]
                normalized_name = tour.tour_name.lower().strip()
                if normalized_name:
                    filtered_tour_names[normalized_name] = idx
            
            # Find similar tours
            fuzzy_matches = fuzzy_matcher.find_similar_tours(query, filtered_tour_names)
            if fuzzy_matches:
                filtered_indices = [idx for idx, _ in fuzzy_matches]
        
        # Prepare results
        results = []
        for idx in filtered_indices[:MAX_TOURS_RETURN]:
            tour = tours_db[idx]
            results.append({
                "id": idx,
                "tour_name": tour.tour_name,
                "summary": tour.summary,
                "location": tour.location,
                "duration": tour.duration,
                "price": tour.price,
                "category": tour.category,
                "style": tour.style,
                "rating": tour.rating
            })
        
        return jsonify({
            "success": True,
            "count": len(results),
            "tours": results,
            "total_matches": len(filtered_indices)
        })
    except Exception as e:
        logger.error(f"Search error: {e}")
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

# ==================== PH·∫¶N 8: CHAT ENDPOINT (ƒê·ªÇ CH√àN TH·ª¶ C√îNG) ====================

# ==================== PH·∫¶N 8: MAIN CHAT ENDPOINT - PHI√äN B·∫¢N CAO C·∫§P ====================

@app.route("/chat", methods=["POST"])
def chat_endpoint():
    """
    TR·ª¢ L√ù AI TH√îNG MINH RUBY WINGS - PHI√äN B·∫¢N CAO C·∫§P
    T√≠ch h·ª£p ƒë·∫ßy ƒë·ªß 10 upgrades systems v·ªõi knowledge.json
    X·ª≠ l√Ω ƒëa t·∫ßng, context-aware, real-time optimization
    """
    # ========== KH·ªûI T·∫†O BI·∫æN TO√ÄN C·ª§C ==========
    start_time = time.time()
    session_id = None
    context = None
    user_message = ""
    processing_phase = "initialization"
    
    try:
        # ========== PHASE 1: REQUEST PROCESSING & VALIDATION ==========
        processing_phase = "request_processing"
        
        # 1.1 Parse v√† validate request
        request_data = request.get_json()
        if not request_data:
            logger.warning("Empty request received")
            return jsonify({
                "reply": "Vui l√≤ng g·ª≠i y√™u c·∫ßu d∆∞·ªõi d·∫°ng JSON v·ªõi tr∆∞·ªùng 'message'.",
                "tour_indices": [],
                "context": {"error": "invalid_request"},
                "processing_time_ms": int((time.time() - start_time) * 1000)
            }), 400
        
        user_message = request_data.get("message", "").strip()
        if not user_message:
            # Tr·∫£ v·ªÅ greeting template n·∫øu message r·ªóng
            greeting_response = KnowledgeTemplateSystem.render('greeting')
            return jsonify({
                "reply": greeting_response,
                "tour_indices": [],
                "context": {"session_id": generate_session_id(), "action": "greeting"},
                "processing_time_ms": int((time.time() - start_time) * 1000),
                "metadata": {"template": "greeting", "version": "4.2"}
            })
        
        # 1.2 Extract session information
        provided_session_id = request_data.get("session_id")
        client_ip = request.remote_addr
        user_agent = request.headers.get('User-Agent', 'Unknown')
        
        # 1.3 Generate or retrieve session ID
        session_id = extract_session_id(request_data, client_ip)
        logger.info(f"Session ID: {session_id}, Client IP: {client_ip}, User Agent: {user_agent[:50]}...")
        
        # ========== PHASE 2: SESSION & CONTEXT MANAGEMENT ==========
        processing_phase = "session_management"
        
        # 2.1 L·∫•y ho·∫∑c t·∫°o m·ªõi conversation context
        context = get_session_context(session_id)
        
        # 2.2 Kh·ªüi t·∫°o context n·∫øu ch∆∞a c√≥
        context_initialized = False
        if not hasattr(context, 'conversation_history'):
            context.conversation_history = []
            context_initialized = True
        
        if not hasattr(context, 'user_preferences'):
            context.user_preferences = {}
            context_initialized = True
        
        if not hasattr(context, 'last_tours_mentioned'):
            context.last_tours_mentioned = []
            context_initialized = True
        
        if not hasattr(context, 'current_state'):
            context.current_state = ConversationState.INITIAL
            context_initialized = True
        
        if context_initialized:
            logger.info(f"Initialized new context for session: {session_id}")
        
        # 2.3 Update activity tracking
        context.last_activity = time.time()
        context.session_id = session_id
        
        # 2.4 Add user message to conversation history v·ªõi metadata
        message_entry = {
            "role": "user",
            "message": user_message,
            "timestamp": datetime.now().isoformat(),
            "timestamp_readable": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "client_ip": client_ip,
            "user_agent": user_agent[:100]
        }
        
        context.conversation_history.append(message_entry)
        
        # 2.5 Limit conversation history ƒë·ªÉ tr√°nh memory leak
        if len(context.conversation_history) > 25:
            # Gi·ªØ l·∫°i 20 tin nh·∫Øn g·∫ßn nh·∫•t
            context.conversation_history = context.conversation_history[-20:]
            logger.debug(f"Trimmed conversation history for session {session_id}")
        
        # 2.6 Ki·ªÉm tra cache tr∆∞·ªõc khi x·ª≠ l√Ω
        cache_key = None
        cached_response = None
        
        if UpgradeFlags.is_enabled("ENABLE_CACHING"):
            # T·∫°o cache key t·ª´ message v√† context signature
            context_signature = hashlib.md5(
                json.dumps({
                    "last_tours": context.last_tours_mentioned[:3],
                    "state": context.current_state.value,
                    "preferences_hash": hashlib.md5(
                        json.dumps(context.user_preferences, sort_keys=True).encode()
                    ).hexdigest()[:8]
                }, sort_keys=True).encode()
            ).hexdigest()
            
            cache_key = cache_system.get_cache_key(user_message, context_signature)
            cached_response = cache_system.get(cache_key)
            
            if cached_response:
                logger.info(f"Cache hit for session {session_id}, key: {cache_key[:20]}...")
                # Update context v·ªõi cached response
                context.conversation_history.append({
                    "role": "assistant",
                    "message": cached_response.get('reply', '')[:200] + "...",
                    "timestamp": datetime.now().isoformat(),
                    "cached": True
                })
                
                # Update processing time
                cached_response['processing_time_ms'] = int((time.time() - start_time) * 1000)
                cached_response['metadata']['cache_hit'] = True
                
                return jsonify(cached_response)
        
        # ========== PHASE 3: ADVANCED QUESTION ANALYSIS ==========
        processing_phase = "question_analysis"
        
        # 3.1 Ph√¢n t√≠ch c√¢u h·ªèi v·ªõi multiple layers
        message_lower = user_message.lower()
        message_length = len(user_message)
        word_count = len(user_message.split())
        
        logger.info(f"Analyzing message: '{user_message[:100]}...' (length: {message_length}, words: {word_count})")
        
        # 3.2 Ph√¢n lo·∫°i c√¢u h·ªèi v·ªõi confidence scoring
        question_start_time = time.time()
        question_type, q_confidence, q_metadata = KnowledgeAwareQuestionPipeline.classify_question(user_message)
        question_analysis_time = int((time.time() - question_start_time) * 1000)
        
        context.last_question_type = question_type
        logger.info(f"Question classified as: {question_type.value} (confidence: {q_confidence:.2f}, time: {question_analysis_time}ms)")
        
        # 3.3 Tr√≠ch xu·∫•t filters v·ªõi knowledge.json support
        filter_start_time = time.time()
        filters = MandatoryFilterSystemV2.extract_filters(user_message)
        filter_analysis_time = int((time.time() - filter_start_time) * 1000)
        
        filter_applied = not filters.is_empty()
        if filter_applied:
            context.active_filters = filters
            logger.info(f"Filters extracted in {filter_analysis_time}ms: {filters}")
        
        # 3.4 Ph√°t hi·ªán field c·ª• th·ªÉ ƒë∆∞·ª£c h·ªèi
        field_start_time = time.time()
        field_name, field_confidence, field_scores = EnhancedFieldDetectorV2.detect_field_with_confidence(user_message)
        field_analysis_time = int((time.time() - field_start_time) * 1000)
        
        if field_name and field_confidence > 0.5:
            logger.info(f"Field detected: {field_name} (confidence: {field_confidence:.2f}, time: {field_analysis_time}ms)")
            context.last_field_asked = field_name
        
        # 3.5 Semantic analysis v√† user profiling
        semantic_profile = {}
        semantic_analysis_time = 0
        
        if UpgradeFlags.is_enabled("8_SEMANTIC_ANALYSIS"):
            semantic_start_time = time.time()
            try:
                semantic_profile = SemanticAnalyzer.analyze_user_profile(user_message, context)
                semantic_analysis_time = int((time.time() - semantic_start_time) * 1000)
                
                if semantic_profile:
                    # C·∫≠p nh·∫≠t user preferences v·ªõi semantic insights
                    for key, value in semantic_profile.items():
                        if isinstance(value, (str, int, float, bool, list, dict)):
                            context.user_preferences[key] = value
                    
                    logger.info(f"Semantic analysis completed in {semantic_analysis_time}ms, profile keys: {list(semantic_profile.keys())}")
            except Exception as e:
                logger.error(f"Semantic analysis error: {e}")
        
        # 3.6 Complexity analysis
        complexity_score = 0
        complexity_factors = {
            'word_count': min(word_count / 50, 2.0),  # Max 2 points
            'question_words': sum(1 for word in ['ai', 'g√¨', '·ªü ƒë√¢u', 't·∫°i sao', 'th·∫ø n√†o', 'bao nhi√™u'] if word in message_lower) * 0.3,
            'special_chars': len(re.findall(r'[?!]', user_message)) * 0.2,
            'multiple_clauses': len(re.findall(r'v√†|ho·∫∑c|nh∆∞ng|tuy nhi√™n', message_lower)) * 0.4
        }
        
        complexity_score = sum(complexity_factors.values())
        complexity_level = "SIMPLE" if complexity_score < 1.0 else "MODERATE" if complexity_score < 2.0 else "COMPLEX"
        
        logger.info(f"Complexity analysis: score={complexity_score:.2f}, level={complexity_level}")
        
        # ========== PHASE 4: INTELLIGENT TOUR SEARCH & MATCHING ==========
        processing_phase = "tour_search"
        
        tour_indices = []
        search_strategies = []
        search_metadata = {
            "strategies_used": [],
            "results_per_strategy": {},
            "total_time_ms": 0
        }
        
        search_start_time = time.time()
        
        # 4.1 STRATEGY 1: Direct Tour Name Matching (High Precision)
        strategy1_start = time.time()
        direct_matches = []
        
        # T√¨m ki·∫øm tr·ª±c ti·∫øp trong tour names
        for norm_name, idx in tour_name_index.items():
            # Ki·ªÉm tra exact match ho·∫∑c partial match
            if norm_name in message_lower:
                direct_matches.append(idx)
            else:
                # Ki·ªÉm tra t·ª´ng t·ª´ trong t√™n tour
                name_words = norm_name.split()
                if any(word in message_lower for word in name_words if len(word) > 2):
                    direct_matches.append(idx)
        
        if direct_matches:
            direct_matches = list(set(direct_matches))[:10]  # Deduplicate v√† gi·ªõi h·∫°n
            tour_indices.extend(direct_matches)
            search_strategies.append("direct_name_match")
            search_metadata["results_per_strategy"]["direct_name_match"] = len(direct_matches)
            logger.info(f"Strategy 1 (Direct Name Match): Found {len(direct_matches)} tours")
        
        strategy1_time = int((time.time() - strategy1_start) * 1000)
        
        # 4.2 STRATEGY 2: Fuzzy Matching v·ªõi n√¢ng c·∫•p
        if not tour_indices and UpgradeFlags.is_enabled("6_FUZZY_MATCHING"):
            strategy2_start = time.time()
            
            try:
                fuzzy_matcher = FuzzyMatcher(tours_db)
                
                # T√¨m ki·∫øm fuzzy trong t√™n tour
                fuzzy_results = fuzzy_matcher.find_similar_tours(user_message, tour_name_index)
                
                if fuzzy_results:
                    # L·ªçc v·ªõi threshold th·∫•p h∆°n cho fuzzy matching
                    fuzzy_indices = [idx for idx, score in fuzzy_results if score > 0.4]
                    fuzzy_indices = fuzzy_indices[:8]  # Gi·ªõi h·∫°n k·∫øt qu·∫£
                    
                    if fuzzy_indices:
                        tour_indices.extend(fuzzy_indices)
                        search_strategies.append("fuzzy_matching")
                        search_metadata["results_per_strategy"]["fuzzy_matching"] = len(fuzzy_indices)
                        logger.info(f"Strategy 2 (Fuzzy Matching): Found {len(fuzzy_indices)} tours")
            except Exception as e:
                logger.error(f"Fuzzy matching error: {e}")
            
            strategy2_time = int((time.time() - strategy2_start) * 1000)
        
        # 4.3 STRATEGY 3: Semantic Search v·ªõi FAISS
        if not tour_indices and search_index is not None:
            strategy3_start = time.time()
            
            try:
                semantic_results = query_index(
                    user_message, 
                    top_k=15,  # TƒÉng s·ªë l∆∞·ª£ng k·∫øt qu·∫£
                    min_score=max(SEMANTIC_MIN_SCORE, 0.65)  # ƒêi·ªÅu ch·ªânh threshold
                )
                
                if semantic_results:
                    semantic_indices = []
                    for score, passage in semantic_results:
                        if 'tour_id' in passage:
                            tour_id = passage['tour_id']
                            if tour_id not in semantic_indices:
                                semantic_indices.append(tour_id)
                    
                    if semantic_indices:
                        # ∆Øu ti√™n c√°c k·∫øt qu·∫£ c√≥ score cao
                        semantic_indices = semantic_indices[:10]
                        tour_indices.extend(semantic_indices)
                        search_strategies.append("semantic_search")
                        search_metadata["results_per_strategy"]["semantic_search"] = len(semantic_indices)
                        logger.info(f"Strategy 3 (Semantic Search): Found {len(semantic_indices)} tours, top score: {semantic_results[0][0]:.3f}")
            except Exception as e:
                logger.error(f"Semantic search error: {e}")
            
            strategy3_time = int((time.time() - strategy3_start) * 1000)
        
        # 4.4 STRATEGY 4: Knowledge.json Field Search
        if not tour_indices:
            strategy4_start = time.time()
            
            keyword_matches = []
            search_keywords = [word for word in message_lower.split() if len(word) > 2][:10]  # L·∫•y 10 t·ª´ kh√≥a
            
            if search_keywords:
                for idx, tour in tours_db.items():
                    match_score = 0
                    
                    # T√¨m ki·∫øm trong multiple fields c·ªßa knowledge.json
                    search_fields = [
                        tour.tour_name.lower(),
                        tour.summary.lower() if tour.summary else "",
                        tour.location.lower() if tour.location else "",
                        tour.style.lower() if tour.style else "",
                        " ".join(tour.includes).lower() if tour.includes else ""
                    ]
                    
                    field_weights = [2.0, 1.5, 1.2, 1.0, 0.8]  # Tr·ªçng s·ªë cho t·ª´ng field
                    
                    for keyword in search_keywords:
                        for i, field_content in enumerate(search_fields):
                            if keyword in field_content:
                                match_score += field_weights[i]
                    
                    if match_score > 1.5:  # Ng∆∞·ª°ng t·ªëi thi·ªÉu
                        keyword_matches.append((idx, match_score))
                
                if keyword_matches:
                    # S·∫Øp x·∫øp theo match score
                    keyword_matches.sort(key=lambda x: x[1], reverse=True)
                    keyword_indices = [idx for idx, score in keyword_matches[:12]]
                    
                    tour_indices.extend(keyword_indices)
                    search_strategies.append("keyword_field_search")
                    search_metadata["results_per_strategy"]["keyword_field_search"] = len(keyword_indices)
                    logger.info(f"Strategy 4 (Keyword Field Search): Found {len(keyword_indices)} tours")
            
            strategy4_time = int((time.time() - strategy4_start) * 1000)
        
        # 4.5 STRATEGY 5: Context-based Search (s·ª≠ d·ª•ng conversation history)
        if not tour_indices and len(context.conversation_history) > 1:
            strategy5_start = time.time()
            
            # T√¨m trong previous mentions
            if context.last_tours_mentioned:
                tour_indices.extend(context.last_tours_mentioned[:5])
                search_strategies.append("context_based")
                search_metadata["results_per_strategy"]["context_based"] = len(context.last_tours_mentioned[:5])
                logger.info(f"Strategy 5 (Context-based): Using {len(context.last_tours_mentioned[:5])} previously mentioned tours")
            
            strategy5_time = int((time.time() - strategy5_start) * 1000)
        
        # 4.6 STRATEGY 6: Popular Tours Fallback
        if not tour_indices:
            strategy6_start = time.time()
            
            # L·∫•y c√°c tour ph·ªï bi·∫øn (c√≥ th·ªÉ d·ª±a tr√™n rating ho·∫∑c predefined list)
            popular_tours = []
            for idx, tour in tours_db.items():
                # ∆Øu ti√™n tour c√≥ rating cao v√† price h·ª£p l√Ω
                if (tour.rating or 0) >= 4.0 and (tour.price_numeric or float('inf')) < 3000000:
                    popular_tours.append(idx)
            
            if popular_tours:
                # L·∫•y ng·∫´u nhi√™n 5 tour ph·ªï bi·∫øn
                import random
                random_seed = int(hashlib.md5(user_message.encode()).hexdigest(), 16) % 1000
                random.seed(random_seed)
                popular_sample = random.sample(popular_tours, min(5, len(popular_tours)))
                
                tour_indices.extend(popular_sample)
                search_strategies.append("popular_fallback")
                search_metadata["results_per_strategy"]["popular_fallback"] = len(popular_sample)
                logger.info(f"Strategy 6 (Popular Fallback): Using {len(popular_sample)} popular tours")
            
            strategy6_time = int((time.time() - strategy6_start) * 1000)
        
        # 4.7 √Åp d·ª•ng Mandatory Filters (n·∫øu c√≥)
        if filter_applied and filters and tour_indices:
            filter_start_time = time.time()
            
            try:
                # √Åp d·ª•ng filters l√™n c√°c tour ƒë√£ t√¨m ƒë∆∞·ª£c
                filtered_indices = MandatoryFilterSystemV2.apply_filters(tours_db, filters)
                
                if filtered_indices:
                    # T√¨m giao gi·ªØa k·∫øt qu·∫£ t√¨m ki·∫øm v√† filtered results
                    intersection = list(set(tour_indices) & set(filtered_indices))
                    
                    if intersection:
                        tour_indices = intersection[:MAX_TOURS_RETURN]
                        logger.info(f"Filter application: {len(intersection)} tours pass filters")
                        search_strategies.append("filter_applied")
                        search_metadata["filtered_from"] = len(tour_indices)
                        search_metadata["filtered_to"] = len(intersection)
                    else:
                        # N·∫øu kh√¥ng c√≥ giao, ∆∞u ti√™n filtered results
                        tour_indices = filtered_indices[:MAX_TOURS_RETURN]
                        logger.info(f"No intersection, using filter results: {len(tour_indices)} tours")
                else:
                    logger.warning("No tours passed the filters")
                    # V·∫´n gi·ªØ nguy√™n tour_indices nh∆∞ng s·∫Ω th√™m warning sau
            except Exception as e:
                logger.error(f"Filter application error: {e}")
                # Continue v·ªõi tour_indices hi·ªán t·∫°i
            
            filter_time = int((time.time() - filter_start_time) * 1000)
            search_metadata["filter_time_ms"] = filter_time
        
        # 4.8 Deduplication v√† Post-processing
        if tour_indices:
            # Remove duplicates
            tour_indices = list(dict.fromkeys(tour_indices))  # Gi·ªØ th·ª© t·ª±
            
            # Apply deduplication engine
            if UpgradeFlags.is_enabled("2_DEDUPLICATION") and len(tour_indices) > 3:
                try:
                    dedup_start = time.time()
                    deduplicated = DeduplicationEngine.merge_similar_tours(tour_indices, tours_db)
                    tour_indices = deduplicated[:MAX_TOURS_RETURN]
                    dedup_time = int((time.time() - dedup_start) * 1000)
                    search_metadata["deduplication_time_ms"] = dedup_time
                    logger.info(f"Deduplication: {len(tour_indices)} unique tours after dedup")
                except Exception as e:
                    logger.error(f"Deduplication error: {e}")
            
            # Sort by relevance (k·∫øt h·ª£p multiple factors)
            try:
                sort_start = time.time()
                
                def tour_relevance_score(idx):
                    tour = tours_db.get(idx)
                    if not tour:
                        return 0
                    
                    score = 0
                    
                    # Factor 1: Rating
                    score += (tour.rating or 3.5) * 100
                    
                    # Factor 2: Price (∆∞u ti√™n gi√° v·ª´a ph·∫£i)
                    if tour.price_numeric:
                        if 1000000 <= tour.price_numeric <= 3000000:
                            score += 50
                        elif tour.price_numeric < 1000000:
                            score += 30
                    
                    # Factor 3: Duration (∆∞u ti√™n tour 1-3 ng√†y)
                    if tour.duration_numeric:
                        if 1 <= tour.duration_numeric <= 3:
                            score += 40
                    
                    # Factor 4: Popularity (d·ª±a tr√™n position trong search results)
                    if idx in direct_matches:
                        score += 200
                    elif idx in tour_indices[:5]:
                        score += 100
                    
                    return score
                
                tour_indices.sort(key=tour_relevance_score, reverse=True)
                sort_time = int((time.time() - sort_start) * 1000)
                search_metadata["sorting_time_ms"] = sort_time
                
            except Exception as e:
                logger.error(f"Sorting error: {e}")
        
        # 4.9 Search performance logging
        total_search_time = int((time.time() - search_start_time) * 1000)
        search_metadata["total_time_ms"] = total_search_time
        search_metadata["strategies_used"] = search_strategies
        
        logger.info(f"""
        SEARCH PERFORMANCE SUMMARY:
        Total time: {total_search_time}ms
        Strategies used: {', '.join(search_strategies)}
        Total tours found: {len(tour_indices)}
        Final tour indices: {tour_indices[:10] if tour_indices else 'None'}
        """)
        
        # ========== PHASE 5: INTELLIGENT RESPONSE GENERATION ==========
        processing_phase = "response_generation"
        
        reply = ""
        warnings = []
        suggestions = []
        response_metadata = {
            "question_type": question_type.value,
            "question_confidence": q_confidence,
            "complexity_score": complexity_score,
            "complexity_level": complexity_level,
            "field_detected": field_name,
            "field_confidence": field_confidence,
            "filter_applied": filter_applied,
            "tours_found": len(tour_indices),
            "search_performance": search_metadata
        }
        
        response_start_time = time.time()
        
        # 5.1 X√°c ƒë·ªãnh response strategy d·ª±a tr√™n question type v√† context
        response_strategy = None
        
        if question_type == QuestionType.GREETING:
            response_strategy = "greeting_template"
            reply = KnowledgeTemplateSystem.render('greeting')
            context.current_state = ConversationState.INITIAL
            
        elif question_type == QuestionType.FAREWELL:
            response_strategy = "farewell_template"
            reply = KnowledgeTemplateSystem.render('farewell')
            context.current_state = ConversationState.CLOSING
            
        elif question_type == QuestionType.LIST_TOURS:
            response_strategy = "tour_listing"
            
            if not tour_indices:
                reply = KnowledgeTemplateSystem.render('no_results')
                warnings.append("Kh√¥ng t√¨m th·∫•y tour ph√π h·ª£p")
            else:
                # X√¢y d·ª±ng danh s√°ch tour chi ti·∫øt
                tour_items = []
                display_count = min(len(tour_indices), MAX_TOURS_RETURN)
                
                for i, idx in enumerate(tour_indices[:display_count], 1):
                    tour = tours_db.get(idx)
                    if tour:
                        # Format includes cho ƒë·∫πp
                        includes_preview = ", ".join(tour.includes[:3])
                        if len(tour.includes) > 3:
                            includes_preview += f" v√† {len(tour.includes) - 3} d·ªãch v·ª• kh√°c"
                        
                        # T·∫°o tour item v·ªõi ƒë·∫ßy ƒë·ªß th√¥ng tin t·ª´ knowledge.json
                        tour_item = KnowledgeTemplateSystem.render('tour_item',
                            idx=i,
                            tour_name=tour.tour_name,
                            location=tour.location,
                            duration=tour.duration,
                            price=tour.price,
                            summary=(tour.summary[:120] + "...") if len(tour.summary) > 120 else tour.summary,
                            includes_preview=includes_preview,
                            style=tour.style or "Kh√¥ng x√°c ƒë·ªãnh",
                            category=tour.category or "general"
                        )
                        tour_items.append(tour_item)
                
                if tour_items:
                    reply = KnowledgeTemplateSystem.render('tour_list',
                        count=len(tour_indices),
                        tour_items="\n\n".join(tour_items),
                        filter_summary=f"üìç **B·ªô l·ªçc √°p d·ª•ng:** {', '.join([f'{k}: {v}' for k, v in filters.__dict__.items() if v])}" if filter_applied else "",
                        suggestion="üí° **G·ª£i √Ω:** G√µ s·ªë th·ª© t·ª± ƒë·ªÉ xem chi ti·∫øt tour, ho·∫∑c h·ªèi th√™m v·ªÅ ti√™u ch√≠ c·ª• th·ªÉ."
                    )
                    
                    # C·∫≠p nh·∫≠t context
                    context.last_tours_mentioned = tour_indices[:display_count]
                    response_metadata["tours_displayed"] = display_count
                else:
                    reply = KnowledgeTemplateSystem.render('no_results')
        
        elif question_type == QuestionType.TOUR_DETAIL:
            response_strategy = "tour_detail"
            
            if not tour_indices:
                reply = KnowledgeTemplateSystem.render('no_results')
            else:
                # Hi·ªÉn th·ªã chi ti·∫øt ƒë·∫ßy ƒë·ªß cho tour ƒë·∫ßu ti√™n
                primary_idx = tour_indices[0]
                tour = tours_db.get(primary_idx)
                
                if tour:
                    # Format includes v·ªõi bullet points
                    includes_items = []
                    for i, item in enumerate(tour.includes, 1):
                        includes_items.append(f"{i}. {item}")
                    includes_formatted = "\n".join(includes_items)
                    
                    # Format additional information
                    additional_info = []
                    if tour.transport:
                        additional_info.append(f"üöå **Ph∆∞∆°ng ti·ªán:** {tour.transport}")
                    if tour.accommodation:
                        additional_info.append(f"üè® **Ch·ªó ·ªü:** {tour.accommodation}")
                    if tour.meals:
                        additional_info.append(f"üçΩÔ∏è **ƒÇn u·ªëng:** {tour.meals}")
                    if tour.event_support:
                        additional_info.append(f"üé™ **H·ªó tr·ª£ s·ª± ki·ªán:** {tour.event_support}")
                    
                    additional_formatted = "\n".join(additional_info)
                    
                    # Render template v·ªõi ƒë·∫ßy ƒë·ªß fields t·ª´ knowledge.json
                    reply = KnowledgeTemplateSystem.render('tour_detail_full',
                        tour_name=tour.tour_name,
                        summary=tour.summary,
                        location=tour.location,
                        duration=tour.duration,
                        price=tour.price,
                        style=tour.style or "ƒêa d·∫°ng",
                        transport=tour.transport or "Xe du l·ªãch ƒë·ªùi m·ªõi",
                        accommodation=tour.accommodation or "Kh√°ch s·∫°n 3 sao",
                        meals=tour.meals or "Theo ch∆∞∆°ng tr√¨nh",
                        includes_formatted=includes_formatted,
                        notes=tour.notes or "Vui l√≤ng li√™n h·ªá ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.",
                        event_support=tour.event_support or "C√≥ s·∫µn theo y√™u c·∫ßu",
                        category=tour.category or "general",
                        rating=tour.rating or 4.5,
                        additional_info=additional_formatted
                    )
                    
                    # Th√™m ƒë·ªÅ xu·∫•t tour t∆∞∆°ng t·ª± n·∫øu c√≥
                    if len(tour_indices) > 1:
                        reply += "\n\nüîç **TOUR T∆Ø∆†NG T·ª∞ C√ì TH·ªÇ B·∫†N QUAN T√ÇM:**\n"
                        for idx in tour_indices[1:4]:
                            similar_tour = tours_db.get(idx)
                            if similar_tour:
                                reply += f"‚Ä¢ **{similar_tour.tour_name}** ({similar_tour.duration}, {similar_tour.location})\n"
                    
                    # C·∫≠p nh·∫≠t context
                    context.current_tour = primary_idx
                    context.last_tours_mentioned = [primary_idx]
                    response_metadata["current_tour"] = primary_idx
                    response_metadata["tour_name"] = tour.tour_name
                else:
                    reply = "‚ùå **Kh√¥ng t√¨m th·∫•y th√¥ng tin chi ti·∫øt v·ªÅ tour n√†y.**\n\nVui l√≤ng ki·ªÉm tra l·∫°i t√™n tour ho·∫∑c li√™n h·ªá hotline 0332510486 ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£."
                    warnings.append("Tour not found in database")
        
        elif question_type == QuestionType.GENERAL_INFO:
            response_strategy = "field_specific_info"
            
            if field_name and field_confidence > 0.5 and tour_indices:
                # X·ª≠ l√Ω c√¢u h·ªèi v·ªÅ field c·ª• th·ªÉ
                field_responses = []
                
                for idx in tour_indices[:3]:  # Hi·ªÉn th·ªã cho 3 tour ƒë·∫ßu
                    tour = tours_db.get(idx)
                    if tour:
                        field_value = EnhancedFieldDetectorV2.get_field_value(tour, field_name)
                        
                        if field_value:
                            if isinstance(field_value, list):
                                if field_value:
                                    # Format list th√†nh string ƒë·∫πp
                                    if len(field_value) <= 5:
                                        value_str = ", ".join(field_value)
                                    else:
                                        value_str = ", ".join(field_value[:5]) + f" v√† {len(field_value) - 5} m·ª•c kh√°c"
                                else:
                                    value_str = "Kh√¥ng c√≥ th√¥ng tin"
                            else:
                                value_str = str(field_value)
                            
                            field_responses.append(f"**{tour.tour_name}:** {value_str}")
                
                if field_responses:
                    # S·ª≠ d·ª•ng field-specific template n·∫øu c√≥
                    template_key = f'field_{field_name}'
                    if template_key in KnowledgeTemplateSystem.TEMPLATES:
                        primary_tour = tours_db.get(tour_indices[0])
                        if primary_tour:
                            field_value = EnhancedFieldDetectorV2.get_field_value(primary_tour, field_name)
                            
                            if isinstance(field_value, list):
                                includes_formatted = "\n".join([f"‚Ä¢ {item}" for item in field_value])
                                reply = KnowledgeTemplateSystem.render(template_key,
                                    tour_name=primary_tour.tour_name,
                                    **{field_name: field_value},
                                    includes_formatted=includes_formatted
                                )
                            else:
                                reply = KnowledgeTemplateSystem.render(template_key,
                                    tour_name=primary_tour.tour_name,
                                    **{field_name: field_value}
                                )
                    else:
                        # Fallback to general field response
                        field_display_name = field_name.replace('_', ' ').title()
                        reply = f"üìã **TH√îNG TIN {field_display_name.upper()}**\n\n"
                        reply += "\n\n".join(field_responses)
                        
                        # Th√™m gi·∫£i th√≠ch v·ªÅ field n·∫øu c·∫ßn
                        field_explanations = {
                            'includes': "C√°c d·ªãch v·ª• ƒë√£ bao g·ªìm trong gi√° tour.",
                            'price': "Gi√° tour ƒë√£ bao g·ªìm thu·∫ø v√† ph√≠ d·ªãch v·ª•.",
                            'duration': "Th·ªùi gian t√≠nh t·ª´ l√∫c kh·ªüi h√†nh ƒë·∫øn khi k·∫øt th√∫c.",
                            'style': "Phong c√°ch v√† lo·∫°i h√¨nh c·ªßa tour."
                        }
                        
                        if field_name in field_explanations:
                            reply += f"\n\nüí° **L∆∞u √Ω:** {field_explanations[field_name]}"
                else:
                    reply = f"Kh√¥ng t√¨m th·∫•y th√¥ng tin v·ªÅ **{field_name}** cho c√°c tour ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p."
            else:
                # General information request
                response_strategy = "general_info_fallback"
                
                available_fields = [
                    "t√™n tour (tour_name)",
                    "gi√° (price)", 
                    "th·ªùi gian (duration)",
                    "ƒë·ªãa ƒëi·ªÉm (location)",
                    "d·ªãch v·ª• bao g·ªìm (includes)",
                    "phong c√°ch (style)",
                    "ph∆∞∆°ng ti·ªán (transport)",
                    "ch·ªó ·ªü (accommodation)",
                    "ƒÉn u·ªëng (meals)",
                    "ghi ch√∫ (notes)"
                ]
                
                reply = KnowledgeTemplateSystem.render('general_fallback',
                    user_message=user_message,
                    available_fields=", ".join(available_fields[:5]) + ", ...",
                    suggestion="Vui l√≤ng h·ªèi c·ª• th·ªÉ v·ªÅ m·ªôt field ho·∫∑c m·ªôt tour nh·∫•t ƒë·ªãnh."
                )
        
        elif question_type == QuestionType.COMPARISON:
            response_strategy = "tour_comparison"
            
            if len(tour_indices) >= 2:
                # So s√°nh 2-3 tour
                comparison_tours = []
                for idx in tour_indices[:3]:
                    tour = tours_db.get(idx)
                    if tour:
                        comparison_tours.append(tour)
                
                if len(comparison_tours) >= 2:
                    # T·∫°o b·∫£ng so s√°nh chi ti·∫øt
                    comparison_rows = []
                    
                    for i, tour in enumerate(comparison_tours, 1):
                        # Format includes cho ng·∫Øn g·ªçn
                        includes_preview = ", ".join(tour.includes[:2])
                        if len(tour.includes) > 2:
                            includes_preview += f" (+{len(tour.includes) - 2})"
                        
                        row = f"**{i}. {tour.tour_name}**\n"
                        row += f"   üìç **ƒê·ªãa ƒëi·ªÉm:** {tour.location}\n"
                        row += f"   ‚è± **Th·ªùi gian:** {tour.duration}\n"
                        row += f"   üí∞ **Gi√°:** {tour.price}\n"
                        row += f"   üé® **Phong c√°ch:** {tour.style or 'ƒêa d·∫°ng'}\n"
                        row += f"   ‚úÖ **Bao g·ªìm:** {includes_preview}\n"
                        
                        # Th√™m ƒëi·ªÉm ƒë·∫∑c bi·ªát n·∫øu c√≥
                        special_features = []
                        if tour.event_support and "c√≥" in tour.event_support.lower():
                            special_features.append("H·ªó tr·ª£ s·ª± ki·ªán")
                        if tour.accommodation and "resort" in tour.accommodation.lower():
                            special_features.append("Resort cao c·∫•p")
                        
                        if special_features:
                            row += f"   ‚ú® **ƒê·∫∑c ƒëi·ªÉm:** {', '.join(special_features)}"
                        
                        comparison_rows.append(row)
                    
                    # Ph√¢n t√≠ch ƒëi·ªÉm kh√°c bi·ªát
                    differences = []
                    
                    if len(comparison_tours) == 2:
                        t1, t2 = comparison_tours[0], comparison_tours[1]
                        
                        # So s√°nh gi√°
                        if t1.price_numeric and t2.price_numeric:
                            price_diff = abs(t1.price_numeric - t2.price_numeric)
                            if price_diff > 500000:  # Ch√™nh l·ªách > 500k
                                cheaper = t1 if t1.price_numeric < t2.price_numeric else t2
                                expensive = t2 if cheaper == t1 else t1
                                differences.append(f"üí∞ **Gi√° c·∫£:** {cheaper.tour_name} r·∫ª h∆°n {expensive.tour_name} kho·∫£ng {price_diff/1000000:.1f} tri·ªáu VND")
                        
                        # So s√°nh th·ªùi gian
                        if t1.duration_numeric and t2.duration_numeric:
                            if t1.duration_numeric != t2.duration_numeric:
                                differences.append(f"‚è± **Th·ªùi gian:** {t1.tour_name} ({t1.duration}) vs {t2.tour_name} ({t2.duration})")
                        
                        # So s√°nh phong c√°ch
                        if t1.style != t2.style:
                            differences.append(f"üé® **Phong c√°ch:** {t1.tour_name} ({t1.style}) vs {t2.tour_name} ({t2.style})")
                        
                        # So s√°nh ƒë·ªãa ƒëi·ªÉm
                        if t1.location != t2.location:
                            differences.append(f"üìç **ƒê·ªãa ƒëi·ªÉm:** {t1.tour_name} ({t1.location}) vs {t2.tour_name} ({t2.location})")
                    
                    # T·∫°o ƒë·ªÅ xu·∫•t th√¥ng minh
                    suggestion = ""
                    if comparison_tours:
                        # D·ª±a v√†o semantic profile n·∫øu c√≥
                        if semantic_profile:
                            if semantic_profile.get('preferred_budget') == 'low':
                                # T√¨m tour r·∫ª nh·∫•t
                                cheapest_tour = min(comparison_tours, 
                                                   key=lambda t: t.price_numeric or float('inf'))
                                suggestion = f"V·ªõi ng√¢n s√°ch th·∫•p, n√™n ch·ªçn **{cheapest_tour.tour_name}**."
                            elif semantic_profile.get('preferred_duration') == 'short':
                                # T√¨m tour ng·∫Øn nh·∫•t
                                shortest_tour = min(comparison_tours,
                                                   key=lambda t: t.duration_numeric or float('inf'))
                                suggestion = f"V·ªõi th·ªùi gian h·∫°n ch·∫ø, n√™n ch·ªçn **{shortest_tour.tour_name}**."
                            else:
                                suggestion = "N√™n ch·ªçn tour ph√π h·ª£p nh·∫•t v·ªõi s·ªü th√≠ch v√† ƒëi·ªÅu ki·ªán c·ªßa b·∫°n."
                        else:
                            suggestion = "üí° **G·ª£i √Ω:** Ch·ªçn tour ph√π h·ª£p v·ªõi ng√¢n s√°ch, th·ªùi gian v√† s·ªü th√≠ch c√° nh√¢n."
                    
                    reply = KnowledgeTemplateSystem.render('comparison',
                        count=len(comparison_tours),
                        comparison_table="\n\n".join(comparison_rows),
                        summary="\n".join(differences) if differences else "C√°c tour c√≥ ch·∫•t l∆∞·ª£ng d·ªãch v·ª• t∆∞∆°ng ƒë∆∞∆°ng, kh√°c bi·ªát ch·ªß y·∫øu v·ªÅ phong c√°ch v√† ƒë·ªãa ƒëi·ªÉm.",
                        suggestion=suggestion
                    )
                    
                    response_metadata["compared_tours"] = [tour.id for tour in comparison_tours]
                    response_metadata["comparison_points"] = len(differences)
                else:
                    reply = "‚ùå **C·∫ßn √≠t nh·∫•t 2 tour ƒë·ªÉ so s√°nh.**\n\nVui l√≤ng ch·ªâ ƒë·ªãnh t√™n tour c·ª• th·ªÉ (v√≠ d·ª•: 'so s√°nh tour A v√† tour B')."
            else:
                reply = "‚ùå **Kh√¥ng ƒë·ªß th√¥ng tin ƒë·ªÉ so s√°nh.**\n\nVui l√≤ng cung c·∫•p t√™n √≠t nh·∫•t 2 tour ho·∫∑c m√¥ t·∫£ r√µ h∆°n v·ªÅ c√°c tour b·∫°n mu·ªën so s√°nh."
        
        elif question_type == QuestionType.RECOMMENDATION:
            response_strategy = "smart_recommendation"
            
            if not tour_indices:
                # Th·ª≠ semantic recommendation n·∫øu kh√¥ng c√≥ k·∫øt qu·∫£ t√¨m ki·∫øm
                if semantic_profile and UpgradeFlags.is_enabled("8_SEMANTIC_ANALYSIS"):
                    try:
                        semantic_recommendations = SemanticAnalyzer.match_tours_to_profile(semantic_profile, tours_db)
                        if semantic_recommendations:
                            tour_indices = [idx for idx, score in semantic_recommendations[:5]]
                            logger.info(f"Semantic recommendations: {len(tour_indices)} tours")
                            response_metadata["recommendation_source"] = "semantic_analysis"
                    except Exception as e:
                        logger.error(f"Semantic recommendation error: {e}")
            
            if tour_indices:
                # L·∫•y tour ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t cao nh·∫•t
                primary_idx = tour_indices[0]
                primary_tour = tours_db.get(primary_idx)
                
                if primary_tour:
                    # T√¨m l√Ω do ƒë·ªÅ xu·∫•t th√¥ng minh
                    recommendation_reasons = []
                    
                    # Reason 1: Ph√π h·ª£p v·ªõi filters
                    if filters.location and filters.location.lower() in primary_tour.location.lower():
                        recommendation_reasons.append(f"üìç **ƒê·ªãa ƒëi·ªÉm ph√π h·ª£p:** {primary_tour.location}")
                    
                    if filters.style and filters.style.lower() in primary_tour.style.lower():
                        recommendation_reasons.append(f"üé® **Phong c√°ch ph√π h·ª£p:** {primary_tour.style}")
                    
                    if filters.include_keywords:
                        matched_includes = [inc for inc in filters.include_keywords 
                                          if any(inc in tour_inc.lower() for tour_inc in primary_tour.includes)]
                        if matched_includes:
                            recommendation_reasons.append(f"‚úÖ **C√≥ d·ªãch v·ª• b·∫°n c·∫ßn:** {', '.join(matched_includes)}")
                    
                    # Reason 2: Ph√π h·ª£p v·ªõi semantic profile
                    if semantic_profile:
                        if semantic_profile.get('preferred_budget') == 'low' and primary_tour.price_numeric and primary_tour.price_numeric < 2000000:
                            recommendation_reasons.append("üí∞ **Ng√¢n s√°ch ph√π h·ª£p:** Gi√° tour d∆∞·ªõi 2 tri·ªáu")
                        elif semantic_profile.get('preferred_budget') == 'high' and primary_tour.price_numeric and primary_tour.price_numeric > 3000000:
                            recommendation_reasons.append("üí∞ **D·ªãch v·ª• cao c·∫•p:** Gi√° tour tr√™n 3 tri·ªáu")
                    
                    # Reason 3: ∆Øu ƒëi·ªÉm c·ªßa tour
                    if not recommendation_reasons:
                        # Default reasons based on tour features
                        if primary_tour.rating and primary_tour.rating >= 4.5:
                            recommendation_reasons.append("‚≠ê **ƒê√°nh gi√° xu·∫•t s·∫Øc:** 4.5/5 t·ª´ kh√°ch h√†ng")
                        
                        if primary_tour.includes and len(primary_tour.includes) >= 5:
                            recommendation_reasons.append("‚úÖ **Nhi·ªÅu d·ªãch v·ª• bao g·ªìm:** ƒê·∫ßy ƒë·ªß ti·ªán nghi")
                        
                        if primary_tour.duration_numeric and 2 <= primary_tour.duration_numeric <= 4:
                            recommendation_reasons.append("‚è± **Th·ªùi gian l√Ω t∆∞·ªüng:** 2-4 ng√†y ph√π h·ª£p cho k·ª≥ ngh·ªâ")
                    
                    # T√¨m alternatives
                    alternative_tours = []
                    for idx in tour_indices[1:4]:
                        tour = tours_db.get(idx)
                        if tour:
                            alt_text = f"‚Ä¢ **{tour.tour_name}**"
                            if tour.duration:
                                alt_text += f" ({tour.duration})"
                            if tour.price:
                                price_preview = tour.price[:40] + "..." if len(tour.price) > 40 else tour.price
                                alt_text += f" - {price_preview}"
                            alternative_tours.append(alt_text)
                    
                    # T·∫°o recommended tour display
                    recommended_tour_display = KnowledgeTemplateSystem.render('tour_item',
                        idx=1,
                        tour_name=primary_tour.tour_name,
                        location=primary_tour.location,
                        duration=primary_tour.duration,
                        price=primary_tour.price,
                        summary=(primary_tour.summary[:100] + "...") if len(primary_tour.summary) > 100 else primary_tour.summary,
                        includes_preview=", ".join(primary_tour.includes[:3]) if primary_tour.includes else "Nhi·ªÅu d·ªãch v·ª•"
                    )
                    
                    reply = KnowledgeTemplateSystem.render('recommendation',
                        recommended_tour=recommended_tour_display,
                        reasons="\n".join(recommendation_reasons),
                        alternatives="\n".join(alternative_tours) if alternative_tours else "‚Ä¢ Li√™n h·ªá hotline ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n th√™m c√°c l·ª±a ch·ªçn kh√°c",
                        personal_note="D·ª±a tr√™n ph√¢n t√≠ch nhu c·∫ßu c·ªßa b·∫°n, t√¥i tin r√¢y ƒë√¢y l√† l·ª±a ch·ªçn t·ªët nh·∫•t."
                    )
                    
                    # C·∫≠p nh·∫≠t context
                    context.last_recommended_tours = tour_indices[:3]
                    response_metadata["recommendation_reasons"] = recommendation_reasons
                    response_metadata["recommendation_score"] = "high" if len(recommendation_reasons) >= 3 else "medium"
                else:
                    reply = KnowledgeTemplateSystem.render('no_results')
            else:
                reply = KnowledgeTemplateSystem.render('no_results')
        
        elif question_type == QuestionType.UNKNOWN:
            response_strategy = "llm_fallback"
            
            # S·ª≠ d·ª•ng LLM fallback v·ªõi context phong ph√∫
            try:
                # Chu·∫©n b·ªã rich context cho LLM
                llm_context = {
                    "user_message": user_message,
                    "detected_intent": "unknown",
                    "conversation_history": context.conversation_history[-3:],
                    "available_tours_count": len(tours_db),
                    "relevant_tours_found": len(tour_indices),
                    "filters_applied": filter_applied,
                    "field_detected": field_name,
                    "complexity_level": complexity_level,
                    "user_preferences": context.user_preferences
                }
                
                # Th√™m th√¥ng tin v·ªÅ tours n·∫øu c√≥
                if tour_indices:
                    tours_info = []
                    for idx in tour_indices[:3]:
                        tour = tours_db.get(idx)
                        if tour:
                            tours_info.append({
                                "name": tour.tour_name,
                                "summary": tour.summary[:150],
                                "price": tour.price,
                                "duration": tour.duration
                            })
                    llm_context["relevant_tours"] = tours_info
                
                # T·∫°o prompt th√¥ng minh
                prompt = _prepare_llm_prompt(user_message, [], llm_context)
                
                # G·ªçi LLM v·ªõi timeout
                llm_timeout = 10  # seconds
                llm_response = ""
                
                try:
                    llm_request_obj = LLMRequest(
                        prompt=prompt,
                        model="llama2",
                        temperature=0.7,
                        max_tokens=500,
                        stream=False
                    )
                    
                    # Trong th·ª±c t·∫ø, ƒë√¢y l√† n∆°i g·ªçi LLM API
                    # llm_response = call_llm_api(llm_request_obj, timeout=llm_timeout)
                    
                    # T·∫°m th·ªùi d√πng fallback response
                    llm_response = _generate_fallback_response(user_message, [], tour_indices)
                    
                except TimeoutError:
                    logger.warning(f"LLM timeout after {llm_timeout} seconds")
                    llm_response = _generate_fallback_response(user_message, [], tour_indices)
                except Exception as e:
                    logger.error(f"LLM API error: {e}")
                    llm_response = _generate_fallback_response(user_message, [], tour_indices)
                
                if llm_response:
                    # Parse v√† clean response
                    parsed_response = parse_llm_response(llm_response)
                    reply = parsed_response.get("reply", "").strip()
                    
                    # Auto-validation
                    if UpgradeFlags.is_enabled("9_AUTO_VALIDATION"):
                        validated = AutoValidator.validate_response(reply)
                        reply = validated
                    
                    # ƒê·∫£m b·∫£o response c√≥ ch·∫•t l∆∞·ª£ng
                    if len(reply) < 80 or "xin ch√†o" in reply.lower() and "tour" not in reply.lower():
                        # Fallback n·∫øu response qu√° ng·∫Øn ho·∫∑c kh√¥ng li√™n quan
                        reply = _generate_fallback_response(user_message, [], tour_indices)
                    
                    response_metadata["llm_used"] = True
                    response_metadata["llm_model"] = "llama2"
                    response_metadata["llm_fallback"] = True
                else:
                    reply = _generate_fallback_response(user_message, [], tour_indices)
                    response_metadata["llm_failed"] = True
                    
            except Exception as e:
                logger.error(f"LLM fallback system error: {e}")
                reply = _generate_fallback_response(user_message, [], tour_indices)
                response_metadata["error"] = str(e)[:100]
        
        # 5.2 Post-process response
        if reply:
            # Auto-validation
            if UpgradeFlags.is_enabled("9_AUTO_VALIDATION"):
                try:
                    validation_result = AutoValidator.safe_validate({
                        "reply": reply,
                        "tour_indices": tour_indices,
                        "question_type": question_type.value
                    })
                    
                    reply = validation_result.get("reply", reply)
                    
                    if validation_result.get("warnings"):
                        warnings.extend(validation_result["warnings"])
                    
                    if validation_result.get("suggestions"):
                        suggestions.extend(validation_result["suggestions"])
                        
                except Exception as e:
                    logger.error(f"Auto-validation error: {e}")
            
            # Ensure contact information is present
            if not any(keyword in reply.lower() for keyword in ["0332510486", "hotline", "li√™n h·ªá", "ƒëi·ªán tho·∫°i"]):
                reply += "\n\nüìû **Hotline t∆∞ v·∫•n 24/7: 0332510486**"
                response_metadata["contact_added"] = True
            
            if not any(keyword in reply.lower() for keyword in ["rubywings.vn", "website", "trang web"]):
                reply += "\nüåê **Website ch√≠nh th·ª©c: www.rubywings.vn**"
                response_metadata["website_added"] = True
            
            # Add filter summary if filters were applied
            if filter_applied and filters:
                filter_summary_parts = []
                if filters.location:
                    filter_summary_parts.append(f"üìç {filters.location}")
                if filters.style:
                    filter_summary_parts.append(f"üé® {filters.style}")
                if filters.min_price or filters.max_price:
                    price_range = []
                    if filters.min_price:
                        price_range.append(f"t·ª´ {filters.min_price:,.0f} VND")
                    if filters.max_price:
                        price_range.append(f"ƒë·∫øn {filters.max_price:,.0f} VND")
                    if price_range:
                        filter_summary_parts.append(f"üí∞ {' '.join(price_range)}")
                
                if filter_summary_parts:
                    reply += f"\n\nüîç **B·ªô l·ªçc ƒë√£ √°p d·ª•ng:** {', '.join(filter_summary_parts)}"
            
            # Add context-aware follow-up suggestions
            if len(tour_indices) > 0 and question_type not in [QuestionType.FAREWELL, QuestionType.GREETING]:
                # T·∫°o follow-up questions d·ª±a tr√™n context
                follow_up_suggestions = []
                
                if question_type == QuestionType.LIST_TOURS:
                    if len(tour_indices) > 1:
                        follow_up_suggestions.append("‚Ä¢ 'So s√°nh tour 1 v√† tour 2'")
                    follow_up_suggestions.append("‚Ä¢ 'Tour 1 gi√° bao nhi√™u?'")
                
                elif question_type == QuestionType.TOUR_DETAIL:
                    primary_tour = tours_db.get(tour_indices[0]) if tour_indices else None
                    if primary_tour:
                        follow_up_suggestions.append(f"‚Ä¢ 'Tour {primary_tour.tour_name} c√≥ nh·ªØng d·ªãch v·ª• g√¨?'")
                        follow_up_suggestions.append("‚Ä¢ 'C√≥ tour t∆∞∆°ng t·ª± n√†o kh√¥ng?'")
                
                if follow_up_suggestions:
                    reply += f"\n\nüí° **B·∫°n c≈©ng c√≥ th·ªÉ h·ªèi:**\n" + "\n".join(follow_up_suggestions)
            
            # Format v√† clean up response
            # Remove excessive empty lines
            import re
            reply = re.sub(r'\n{3,}', '\n\n', reply)
            
            # Ensure proper spacing
            reply = reply.strip()
            
            # Truncate if too long (rare case)
            max_response_length = 4000
            if len(reply) > max_response_length:
                logger.warning(f"Response too long: {len(reply)} chars, truncating...")
                
                # Try to cut at a paragraph boundary
                last_paragraph = reply.rfind('\n\n', 0, max_response_length - 200)
                if last_paragraph > max_response_length // 2:
                    reply = reply[:last_paragraph] + "\n\nüìû **Th√¥ng tin c√≤n ti·∫øp. Vui l√≤ng li√™n h·ªá hotline 0332510486 ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.**"
                else:
                    reply = reply[:max_response_length - 200] + "...\n\nüìû **Vui l√≤ng li√™n h·ªá hotline ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.**"
        
        response_time = int((time.time() - response_start_time) * 1000)
        response_metadata["response_generation_time_ms"] = response_time
        response_metadata["response_strategy"] = response_strategy
        
        logger.info(f"Response generated in {response_time}ms using strategy: {response_strategy}")
        
        # ========== PHASE 6: POST-PROCESSING & UPDATES ==========
        processing_phase = "post_processing"
        
        # 6.1 Update conversation state machine
        state_machine = ConversationStateMachine(context.current_state)
        state_machine.update(user_message, reply[:100] + "...", tour_indices)
        context.current_state = state_machine.current_state
        
        # 6.2 Add assistant response to conversation history
        assistant_entry = {
            "role": "assistant",
            "message": reply[:500] + "..." if len(reply) > 500 else reply,
            "timestamp": datetime.now().isoformat(),
            "tour_indices": tour_indices[:5],
            "question_type": question_type.value,
            "response_strategy": response_strategy,
            "processing_time_ms": int((time.time() - start_time) * 1000)
        }
        
        context.conversation_history.append(assistant_entry)
        
        # 6.3 Update last tours mentioned
        if tour_indices:
            context.last_tours_mentioned = tour_indices[:5]
        
        # 6.4 Update user preferences based on this interaction
        if question_type in [QuestionType.RECOMMENDATION, QuestionType.LIST_TOURS]:
            # Ghi nh·∫≠n lo·∫°i tour user quan t√¢m
            if tour_indices:
                tour_categories = []
                for idx in tour_indices[:3]:
                    tour = tours_db.get(idx)
                    if tour and tour.category:
                        if tour.category not in tour_categories:
                            tour_categories.append(tour.category)
                
                if tour_categories:
                    context.user_preferences['interested_categories'] = list(set(
                        context.user_preferences.get('interested_categories', []) + tour_categories
                    ))[:5]
        
        # 6.5 Save to cache
        if UpgradeFlags.is_enabled("ENABLE_CACHING") and cache_key:
            try:
                cache_entry = {
                    "reply": reply,
                    "tour_indices": tour_indices,
                    "context": {
                        "session_id": session_id,
                        "current_state": context.current_state.value,
                        "last_tours_mentioned": context.last_tours_mentioned[:3]
                    },
                    "metadata": response_metadata,
                    "warnings": warnings if warnings else None,
                    "suggestions": suggestions if suggestions else None,
                    "processing_time_ms": int((time.time() - start_time) * 1000),
                    "cached_at": time.time(),
                    "expiry": time.time() + CACHE_TTL
                }
                
                cache_system.set(cache_key, cache_entry, expiry=CACHE_TTL)
                logger.info(f"Response cached with key: {cache_key[:25]}... (expires in {CACHE_TTL}s)")
            except Exception as e:
                logger.error(f"Caching error: {e}")
        
        # 6.6 Save session context
        save_session_context(session_id, context)
        
        # 6.7 Send CAPI event if enabled
        if CAPI_ENABLED:
            try:
                capi_payload = {
                    "session_id": session_id,
                    "user_message": user_message[:200],
                    "bot_response": reply[:300],
                    "tour_count": len(tour_indices),
                    "question_type": question_type.value,
                    "timestamp": datetime.now().isoformat()
                }
                
                send_capi_event(session_id, user_message[:200], reply[:300])
                logger.info(f"CAPI event sent for session {session_id}")
            except Exception as e:
                logger.error(f"CAPI event error: {e}")
        
        # 6.8 Cleanup old sessions periodically
        if random.random() < 0.1:  # 10% chance on each request
            cleanup_expired_sessions()
        
        # ========== PHASE 7: FINAL RESPONSE PREPARATION ==========
        processing_phase = "final_preparation"
        
        total_processing_time = int((time.time() - start_time) * 1000)
        
        # 7.1 Prepare final response object
        final_response = {
            "reply": reply,
            "tour_indices": tour_indices,
            "action": "continue",
            "context": {
                "session_id": session_id,
                "current_state": context.current_state.value,
                "question_type": question_type.value,
                "tours_found": len(tour_indices),
                "processing_time_ms": total_processing_time,
                "conversation_length": len(context.conversation_history)
            },
            "warnings": warnings if warnings else None,
            "suggestions": suggestions if suggestions else None,
            "metadata": {
                **response_metadata,
                "total_processing_time_ms": total_processing_time,
                "cache_hit": False,
                "system_version": "RubyWings AI v4.2",
                "knowledge_base_version": "knowledge.json v2.0",
                "processing_phases": [
                    "request_processing",
                    "session_management", 
                    "question_analysis",
                    "tour_search",
                    "response_generation",
                    "post_processing",
                    "final_preparation"
                ],
                "performance_metrics": {
                    "question_analysis_ms": question_analysis_time,
                    "filter_analysis_ms": filter_analysis_time,
                    "field_analysis_ms": field_analysis_time,
                    "semantic_analysis_ms": semantic_analysis_time,
                    "search_total_ms": search_metadata.get("total_time_ms", 0),
                    "response_generation_ms": response_time,
                    "total_ms": total_processing_time
                }
            }
        }
        
        # 7.2 Log completion
        logger.info(f"""
        ‚úÖ CHAT ENDPOINT PROCESSING COMPLETE
        ‚è±  Total time: {total_processing_time}ms
        üë§ Session: {session_id[:12]}...
        ‚ùì Question: {question_type.value} (confidence: {q_confidence:.2f})
        üó∫Ô∏è  Tours found: {len(tour_indices)}
        üîç Search strategies: {', '.join(search_strategies)}
        üéØ Response strategy: {response_strategy}
        üìä Response length: {len(reply)} characters
        ‚ö†Ô∏è  Warnings: {len(warnings) if warnings else 0}
        üí° Suggestions: {len(suggestions) if suggestions else 0}
        """)
        
        # 7.3 Return final response
        return jsonify(final_response)
        
    except Exception as e:
        # ========== PHASE 8: ERROR HANDLING ==========
        error_time = time.time()
        total_processing_time = int((error_time - start_time) * 1000)
        
        logger.critical(f"""
        ‚ùå CRITICAL ERROR in chat endpoint
        Phase: {processing_phase}
        Error: {str(e)}
        Traceback: {traceback.format_exc()}
        Session ID: {session_id or 'Unknown'}
        User message: {user_message[:200] if user_message else 'Empty'}
        Processing time: {total_processing_time}ms
        """)
        
        # Prepare comprehensive error response
        error_id = hashlib.md5(f"{str(e)}{time.time()}".encode()).hexdigest()[:8]
        
        error_reply = f"""‚ö° **XIN L·ªñI V√å S·ª∞ B·∫§T TI·ªÜN**

H·ªá th·ªëng g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t khi x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n. ƒê·ªôi ng≈© k·ªπ thu·∫≠t ƒë√£ ƒë∆∞·ª£c th√¥ng b√°o.

**M√É L·ªñI:** RW-{error_id}
**TH·ªúI GIAN:** {datetime.now().strftime('%H:%M:%S %d/%m/%Y')}
**T√åNH TR·∫†NG:** ƒêang kh·∫Øc ph·ª•c

**VUI L√íNG TH·ª¨ M·ªòT TRONG C√ÅC C√ÅCH SAU:**

1. **üìû G·ªåI NGAY HOTLINE:** 0332510486
   ‚Ä¢ T∆∞ v·∫•n tr·ª±c ti·∫øp, nhanh ch√≥ng
   ‚Ä¢ H·ªó tr·ª£ 24/7, k·ªÉ c·∫£ cu·ªëi tu·∫ßn

2. **üåê TRUY C·∫¨P WEBSITE:** www.rubywings.vn
   ‚Ä¢ Xem danh s√°ch tour ƒë·∫ßy ƒë·ªß
   ‚Ä¢ ƒê·∫∑t tour tr·ª±c tuy·∫øn
   ‚Ä¢ T√¨m hi·ªÉu th√¥ng tin chi ti·∫øt

3. **üì± LI√äN H·ªÜ QUA ZALO:** @rubywings
   ‚Ä¢ Chat v·ªõi nh√¢n vi√™n t∆∞ v·∫•n
   ‚Ä¢ Nh·∫≠n b√°o gi√° nhanh

4. **üîÑ TH·ª¨ L·∫†I C√ÇU H·ªéI ƒê∆†N GI·∫¢N H∆†N:**
   ‚Ä¢ "Tour B·∫°ch M√£ gi√° bao nhi√™u?"
   ‚Ä¢ "C√≥ tour n√†o ƒëi Hu·∫ø 2 ng√†y kh√¥ng?"
   ‚Ä¢ "Tour gia ƒë√¨nh ph√π h·ª£p cho tr·∫ª em"

**TH√îNG TIN K·ª∏ THU·∫¨T (D√ÄNH CHO K·ª∏ THU·∫¨T VI√äN):**
‚Ä¢ L·ªói: {type(e).__name__}
‚Ä¢ Pha l·ªói: {processing_phase}
‚Ä¢ Th·ªùi gian x·ª≠ l√Ω: {total_processing_time}ms
‚Ä¢ Session: {session_id or 'N/A'}

Ch√∫ng t√¥i ch√¢n th√†nh xin l·ªói v√¨ s·ª± c·ªë n√†y v√† ƒëang n·ªó l·ª±c kh·∫Øc ph·ª•c trong th·ªùi gian s·ªõm nh·∫•t."""

        # Prepare error response object
        error_response = {
            "reply": error_reply,
            "tour_indices": [],
            "action": "error",
            "context": {
                "session_id": session_id or generate_session_id(),
                "error": True,
                "error_id": f"RW-{error_id}",
                "error_type": type(e).__name__,
                "processing_phase": processing_phase,
                "processing_time_ms": total_processing_time
            },
            "warnings": ["system_error", "technical_issue", "please_contact_support"],
            "suggestions": [
                "Th·ª≠ l·∫°i v·ªõi c√¢u h·ªèi ƒë∆°n gi·∫£n h∆°n",
                "G·ªçi hotline 0332510486 ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ ngay",
                "Truy c·∫≠p website www.rubywings.vn"
            ],
            "metadata": {
                "error_details": str(e)[:500],
                "error_timestamp": datetime.now().isoformat(),
                "system_status": "degraded",
                "recommended_action": "contact_support",
                "support_channels": ["hotline: 0332510486", "website: www.rubywings.vn", "zalo: @rubywings"]
            }
        }
        
        # Try to save error to error log
        try:
            error_log_entry = {
                "error_id": f"RW-{error_id}",
                "timestamp": datetime.now().isoformat(),
                "session_id": session_id,
                "processing_phase": processing_phase,
                "error_type": type(e).__name__,
                "error_message": str(e),
                "user_message": user_message[:500] if user_message else "",
                "traceback": traceback.format_exc()[:1000],
                "processing_time_ms": total_processing_time,
                "system_version": "RubyWings AI v4.2"
            }
            
            # In production, this would save to a database or error tracking service
            logger.critical(f"ERROR LOG ENTRY: {json.dumps(error_log_entry, ensure_ascii=False)}")
        except:
            pass
        
        return jsonify(error_response), 500

# ==================== PH·∫¶N 9: ADDITIONAL ENDPOINTS ====================

@app.route('/api/filters/extract', methods=['POST'])
def extract_filters():
    """Extract filters from message"""
    try:
        data = request.get_json() or {}
        message = data.get('message', '').strip()
        
        if not message:
            return jsonify({"error": "Message is required"}), 400
        
        filters = MandatoryFilterSystemV2.extract_filters(message)
        
        return jsonify({
            "success": True,
            "filters": asdict(filters)
        })
    except Exception as e:
        logger.error(f"Filter extraction error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/question/classify', methods=['POST'])
def classify_question():
    """Classify question type"""
    try:
        data = request.get_json() or {}
        message = data.get('message', '').strip()
        
        if not message:
            return jsonify({"error": "Message is required"}), 400
        
        qtype, confidence, metadata = KnowledgeAwareQuestionPipeline.classify_question(message)
        
        return jsonify({
            "success": True,
            "question_type": qtype.value,
            "confidence": confidence,
            "metadata": metadata
        })
    except Exception as e:
        logger.error(f"Question classification error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/cleanup', methods=['POST'])
def cleanup():
    """Cleanup expired sessions and cache"""
    try:
        cleanup_expired_sessions()
        cache_system._cleanup()
        
        return jsonify({
            "success": True,
            "message": f"Cleanup completed. Sessions: {len(sessions)}"
        })
    except Exception as e:
        logger.error(f"Cleanup error: {e}")
        return jsonify({"error": str(e)}), 500

# ==================== PH·∫¶N 10: ERROR HANDLERS ====================

@app.errorhandler(404)
def not_found(error):
    return jsonify({"error": "Not found"}), 404

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"Internal server error: {error}")
    return jsonify({"error": "Internal server error"}), 500

# ==================== MAIN ====================

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    debug = os.environ.get('DEBUG', 'False').lower() == 'true'
    
    logger.info(f"üöÄ Starting Ruby Wings Chatbot v5.0 on port {port}")
    logger.info(f"üìä Loaded {len(tours_db)} tours from knowledge.json")
    logger.info(f"üîç Search index ready: {search_index is not None}")
    
    # Start cleanup thread
    def cleanup_thread():
        while True:
            time.sleep(300)  # 5 minutes
            cleanup_expired_sessions()
            cache_system._cleanup()
    
    threading.Thread(target=cleanup_thread, daemon=True).start()
    
    app.run(host='0.0.0.0', port=port, debug=debug)