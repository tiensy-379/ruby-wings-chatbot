# app.py - Ruby Wings Chatbot v4.0 (Complete Rewrite with Dataclasses)
# =========== IMPORTS ===========
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("ruby-wings")
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from dataclasses import dataclass, field
import json
import threading
import re
import unicodedata
import traceback
import hashlib
import time
import random
from typing import List, Dict, Tuple, Any, Optional, Set, Union, Callable
from datetime import datetime, timedelta
from collections import defaultdict, deque
from difflib import SequenceMatcher
from enum import Enum
from functools import lru_cache, wraps

# Try to import numpy with detailed error handling
try:
    import numpy as np
    NUMPY_AVAILABLE = True
    logger.info("âœ… NumPy available")
except ImportError as e:
    logger.error(f"âŒ NumPy import failed: {e}")
    # Create a minimal numpy-like fallback for basic operations
    class NumpyFallback:
        def __init__(self):
            self.float32 = float
            self.int64 = int
        def array(self, data, dtype=None):
            # Simple list wrapper
            class SimpleArray:
                def __init__(self, data):
                    self.data = list(data)
                    self.shape = (len(data),) if isinstance(data[0], (int, float)) else (len(data), len(data[0]))
                def astype(self, dtype):
                    return self
                def reshape(self, shape):
                    return self
                def __getitem__(self, idx):
                    return self.data[idx]
                def __len__(self):
                    return len(self.data)
            return SimpleArray(data)
        def empty(self, shape, dtype):
            if len(shape) == 1:
                return [0.0] * shape[0]
            else:
                return [[0.0] * shape[1] for _ in range(shape[0])]
        def vstack(self, arrays):
            result = []
            for arr in arrays:
                if hasattr(arr, 'data'):
                    result.extend(arr.data)
                else:
                    result.extend(arr)
            return result
        def load(self, path):
            # Mock load function
            class MockNpz:
                def __init__(self):
                    self.files = ['mat']
                def __getitem__(self, key):
                    if key == 'mat':
                        return self.array([[0.0]])
                    return None
            return MockNpz()
        def savez_compressed(self, path, **kwargs):
            # Mock save function
            logger.warning(f"âš ï¸ NumPy fallback: Mock saving to {path}")
            return None
    np = NumpyFallback()
    NUMPY_AVAILABLE = False
    logger.warning("âš ï¸ Using NumPy fallback - limited functionality")

# FAISS
try:
    import faiss
    HAS_FAISS = True
except ImportError:
    HAS_FAISS = False
    logger.warning("âš ï¸ FAISS not available, using numpy fallback")

# OpenAI
HAS_OPENAI = False
client = None
try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    logger.warning("âš ï¸ OpenAI not available, using fallback responses")

# Google Sheets
try:
    import gspread
    from google.oauth2.service_account import Credentials
    from google.auth.exceptions import GoogleAuthError
    from gspread.exceptions import APIError, SpreadsheetNotFound, WorksheetNotFound
    HAS_GOOGLE_SHEETS = True
except ImportError:
    HAS_GOOGLE_SHEETS = False
    logger.warning("âš ï¸ Google Sheets not available")

# Meta CAPI
try:
    from meta_capi import send_meta_pageview, send_meta_lead
    HAS_META_CAPI = True
except Exception as e:
    HAS_META_CAPI = False
    logger.error(f"âŒ Meta CAPI init failed: {e}")

from meta_param_builder import MetaParamService
from flask import Flask, request, jsonify, g
from flask_cors import CORS

# =========== DATACLASS DEFINITIONS ===========
@dataclass
class Tour:
    """Tour dataclass with all required fields"""
    index: int = 0
    name: str = ""
    summary: str = ""
    location: str = ""
    duration: str = ""
    price: str = ""
    includes: List[str] = field(default_factory=list)
    notes: str = ""
    style: str = ""
    transport: str = ""
    accommodation: str = ""
    meals: str = ""
    tags: List[str] = field(default_factory=list)
    event_support: str = ""
    is_tour: bool = True
    completeness_score: float = 0.0

    def __str__(self):
        return f"Tour({self.name})"

@dataclass
class ConversationContext:
    """Conversation context using dataclass"""
    session_id: str = ""
    current_tour: Optional[int] = None
    current_tour_updated_at: Optional[str] = None
    last_tour_name: Optional[str] = None
    last_tour_indices: List[int] = field(default_factory=list)
    current_tours: List[int] = field(default_factory=list)
    mentioned_tours: Set[int] = field(default_factory=set)
    last_successful_tours: List[int] = field(default_factory=list)
    conversation_history: List[Dict] = field(default_factory=list)
    user_preferences: Dict = field(default_factory=dict)
    user_profile: Dict = field(default_factory=dict)

    def update(self, user_message: str, bot_response: str, tour_indices: List[int] = None):
        """Update context with new interaction"""
        if tour_indices:
            self.last_tour_indices = tour_indices
            self.current_tours = tour_indices
            for idx in tour_indices:
                self.mentioned_tours.add(idx)
            if tour_indices:
                self.last_successful_tours = tour_indices
                self.current_tour = tour_indices[0]
        self.conversation_history.append({
            'user': user_message,
            'bot': bot_response,
            'timestamp': datetime.utcnow().isoformat()
        })
        if len(self.conversation_history) > 10:
            self.conversation_history = self.conversation_history[-10:]

@dataclass
class FilterSet:
    """Filter criteria extracted from user query"""
    price_min: Optional[int] = None
    price_max: Optional[int] = None
    duration_min: Optional[int] = None
    duration_max: Optional[int] = None
    location: Optional[str] = None
    near_location: Optional[str] = None
    month: Optional[int] = None
    weekend: bool = False
    holiday: Optional[str] = None
    group_type: Optional[str] = None

    def is_empty(self) -> bool:
        return all(v is None for v in [
            self.price_min, self.price_max, self.duration_min, self.duration_max,
            self.location, self.near_location, self.month, self.holiday, self.group_type
        ]) and not self.weekend

    def to_dict(self) -> dict:
        return {k: v for k, v in self.__dict__.items() if v is not None}

@dataclass
class CacheEntry:
    """Cache entry with TTL"""
    key: str
    value: Any
    created_at: datetime
    ttl_seconds: int = 300

    def is_expired(self) -> bool:
        return (datetime.utcnow() - self.created_at).total_seconds() > self.ttl_seconds

@dataclass
class ChatResponse:
    """Standard chat response format"""
    reply: str
    sources: List[Dict]
    context: Dict
    tour_indices: List[int]
    processing_time_ms: int
    from_memory: bool = False

    def to_dict(self) -> Dict:
        return {
            'reply': self.reply,
            'sources': self.sources,
            'context': self.context,
            'tour_indices': self.tour_indices,
            'processing_time_ms': self.processing_time_ms,
            'from_memory': self.from_memory
        }

@dataclass
class UserProfile:
    """User profile for personalization"""
    age_group: str = ""
    group_type: str = ""
    interests: List[str] = field(default_factory=list)
    budget_level: str = ""
    physical_level: str = ""
    confidence_scores: Dict[str, float] = field(default_factory=dict)
    overall_confidence: float = 0.0

class EnhancedJSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if hasattr(obj, '__dict__'):
            return obj.__dict__
        return super().default(obj)
# =========== ENVIRONMENT VARIABLES ===========
# Memory Profile
RAM_PROFILE = os.environ.get("RAM_PROFILE", "512").strip()
IS_LOW_RAM = RAM_PROFILE == "512"
IS_HIGH_RAM = RAM_PROFILE == "2048"

# Core API Keys
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "").strip()
OPENAI_BASE_URL = os.environ.get("OPENAI_BASE_URL", "").strip()
GOOGLE_SERVICE_ACCOUNT_JSON = os.environ.get("GOOGLE_SERVICE_ACCOUNT_JSON", "").strip()

# Knowledge & Index
KNOWLEDGE_PATH = os.environ.get("KNOWLEDGE_PATH", "knowledge.json")
FAISS_INDEX_PATH = os.environ.get("FAISS_INDEX_PATH", "faiss_index.bin")
FAISS_MAPPING_PATH = os.environ.get("FAISS_MAPPING_PATH", "faiss_mapping.json")
FALLBACK_VECTORS_PATH = os.environ.get("FALLBACK_VECTORS_PATH", "vectors.npz")

# Models
EMBEDDING_MODEL = os.environ.get("EMBEDDING_MODEL", "text-embedding-3-small")
CHAT_MODEL = os.environ.get("CHAT_MODEL", "gpt-4o-mini")
TOP_K = int(os.environ.get("TOP_K", "5"))

# FAISS
FAISS_ENABLED = os.environ.get("FAISS_ENABLED", "true").lower() in ("1", "true", "yes") and not IS_LOW_RAM

# Google Sheets
GOOGLE_SHEET_ID = os.environ.get("GOOGLE_SHEET_ID", "1SdVbwkuxb8l1meEW--ddyfh4WmUvSXXMOPQ5bCyPkdk")
GOOGLE_SHEET_NAME = os.environ.get("GOOGLE_SHEET_NAME", "RBW_Lead_Raw_Inbox")
ENABLE_GOOGLE_SHEETS = os.environ.get("ENABLE_GOOGLE_SHEETS", "true").lower() in ("1", "true", "yes")

# Storage
ENABLE_FALLBACK_STORAGE = os.environ.get("ENABLE_FALLBACK_STORAGE", "true").lower() in ("1", "true", "yes")
FALLBACK_STORAGE_PATH = os.environ.get("FALLBACK_STORAGE_PATH", "leads_fallback.json")

# Meta CAPI
META_CAPI_TOKEN = os.environ.get("META_CAPI_TOKEN", "").strip()
META_PIXEL_ID = os.environ.get("META_PIXEL_ID", "").strip()
META_CAPI_ENDPOINT = os.environ.get("META_CAPI_ENDPOINT", "https://graph.facebook.com/v17.0/")
ENABLE_META_CAPI_CALL = os.environ.get("ENABLE_META_CAPI_CALL", "true").lower() in ("1", "true", "yes")
ENABLE_META_CAPI_LEAD = os.environ.get("ENABLE_META_CAPI_LEAD", "false").lower() == "true"

# Server
FLASK_ENV = os.environ.get("FLASK_ENV", "production")
DEBUG = os.environ.get("DEBUG", "false").lower() in ("1", "true", "yes")
SECRET_KEY = os.environ.get("SECRET_KEY", "ruby-wings-secret-key-2024")
CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "https://www.rubywings.vn,http://localhost:3000").split(",")
HOST = os.environ.get("HOST", "0.0.0.0")
PORT = int(os.environ.get("PORT", "10000"))

# =========== STATS TRACKING (FIX Lá»–I STATE) ===========
STATS_LOCK = threading.Lock()
GLOBAL_STATS = {
    'meta_capi_calls': 0,
    'meta_capi_errors': 0,
    'leads': 0,
    'errors': 0,
    'total_requests': 0
}

def increment_stat(stat_name: str, amount: int = 1):
    """Thread-safe stat increment"""
    with STATS_LOCK:
        if stat_name in GLOBAL_STATS:
            GLOBAL_STATS[stat_name] += amount
        else:
            GLOBAL_STATS[stat_name] = amount

def get_stats() -> dict:
    """Get current stats"""
    with STATS_LOCK:
        return GLOBAL_STATS.copy()

# =========== GLOBAL STATE (USING DATACLASSES) ===========
# OpenAI client (SDK 1.x safe)
def create_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY is not set")
    import httpx
    http_client = httpx.Client(timeout=60.0, follow_redirects=True)
    return OpenAI(api_key=api_key, http_client=http_client)

client = create_openai_client() if HAS_OPENAI else None

# Knowledge base state
KNOW: Dict = {}                      # Raw knowledge.json data
FLAT_TEXTS: List[str] = []           # All text passages for indexing
MAPPING: List[Dict] = []             # Mapping from text to original path
INDEX = None                         # FAISS or numpy index
INDEX_LOCK = threading.Lock()        # Thread safety for index operations

# Tour databases (USING Tour DATACLASS)
TOUR_NAME_TO_INDEX: Dict[str, int] = {}      # Normalized tour name â†’ index
TOURS_DB: Dict[int, Tour] = {}               # Structured tour database using Tour objects
TOUR_TAGS: Dict[int, List[str]] = {}         # Auto-generated tags for filtering

# Session management (USING ConversationContext DATACLASS)
SESSION_CONTEXTS: Dict[str, ConversationContext] = {}
SESSION_LOCK = threading.Lock()
SESSION_TIMEOUT = 1800  # 30 minutes

# Cache system
_response_cache: Dict[str, CacheEntry] = {}
_cache_lock = threading.Lock()

# Embedding cache (memory optimized)
_embedding_cache: Dict[str, Tuple[List[float], int]] = {}
_embedding_cache_lock = threading.Lock()
MAX_EMBEDDING_CACHE_SIZE = 1000  # Default, will be adjusted

# App initialization flag
APP_INITIALIZED = False

# =========== MEMORY OPTIMIZATION FUNCTIONS ===========
def optimize_for_memory_profile():
    """Apply memory optimizations based on RAM profile"""
    global FAISS_ENABLED, MAX_EMBEDDING_CACHE_SIZE
    if IS_LOW_RAM:
        logger.info("ðŸ§  Low RAM mode (512MB) - optimizing memory usage")
        FAISS_ENABLED = False
        MAX_EMBEDDING_CACHE_SIZE = 128
    elif IS_HIGH_RAM:
        logger.info("ðŸš€ High RAM mode (2GB) - enabling all features")
        FAISS_ENABLED = HAS_FAISS
        MAX_EMBEDDING_CACHE_SIZE = 1000

# =========== UPGRADE FEATURE FLAGS ===========
class UpgradeFlags:
    """Control all 10 upgrades with environment variables"""

    @staticmethod
    def get_all_flags():
        return {
            # CORE UPGRADES (Essential fixes)
            "UPGRADE_1_MANDATORY_FILTER": os.environ.get("UPGRADE_1_MANDATORY_FILTER", "true").lower() == "true",
            "UPGRADE_2_DEDUPLICATION": os.environ.get("UPGRADE_2_DEDUPLICATION", "true").lower() == "true",
            "UPGRADE_3_ENHANCED_FIELDS": os.environ.get("UPGRADE_3_ENHANCED_FIELDS", "true").lower() == "true",
            "UPGRADE_4_QUESTION_PIPELINE": os.environ.get("UPGRADE_4_QUESTION_PIPELINE", "true").lower() == "true",
            # ADVANCED UPGRADES
            "UPGRADE_5_QUERY_SPLITTER": os.environ.get("UPGRADE_5_QUERY_SPLITTER", "true").lower() == "true",
            "UPGRADE_6_FUZZY_MATCHING": os.environ.get("UPGRADE_6_FUZZY_MATCHING", "true").lower() == "true",
            "UPGRADE_7_STATE_MACHINE": os.environ.get("UPGRADE_7_STATE_MACHINE", "true").lower() == "true",
            "UPGRADE_8_SEMANTIC_ANALYSIS": os.environ.get("UPGRADE_8_SEMANTIC_ANALYSIS", "true").lower() == "true",
            "UPGRADE_9_AUTO_VALIDATION": os.environ.get("UPGRADE_9_AUTO_VALIDATION", "true").lower() == "true",
            "UPGRADE_10_TEMPLATE_SYSTEM": os.environ.get("UPGRADE_10_TEMPLATE_SYSTEM", "true").lower() == "true",
            # PERFORMANCE OPTIONS
            "ENABLE_CACHING": os.environ.get("ENABLE_CACHING", "true").lower() == "true",
            "CACHE_TTL_SECONDS": int(os.environ.get("CACHE_TTL_SECONDS", "300")),
            "ENABLE_QUERY_LOGGING": os.environ.get("ENABLE_QUERY_LOGGING", "true").lower() == "true",
            # MEMORY OPTIMIZATION
            "EMBEDDING_CACHE_SIZE": 100 if IS_LOW_RAM else 1000,
            "TOUR_CACHE_ENABLED": not IS_LOW_RAM,
            "PRELOAD_EMBEDDINGS": not IS_LOW_RAM,
        }

    @staticmethod
    def is_enabled(upgrade_name: str) -> bool:
        flags = UpgradeFlags.get_all_flags()
        return flags.get(f"UPGRADE_{upgrade_name}", False)

# =========== HELPER FUNCTIONS ===========
def normalize_tour_key(text: str) -> str:
    """Normalize tour name/text for stable matching & dedup."""
    if not text:
        return ""
    t = unicodedata.normalize("NFKD", str(text).lower())
    t = "".join(ch for ch in t if not unicodedata.combining(ch))
    t = re.sub(r"[^a-z0-9\s]", " ", t)
    t = re.sub(r"\s+", " ", t).strip()
    return t

def normalize_text_simple(s: str) -> str:
    """Basic text normalization"""
    if not s:
        return ""
    s = s.lower()
    s = unicodedata.normalize("NFD", s)
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
    s = re.sub(r"[^\w\s]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def resolve_best_tour_indices(query: str, top_k: int = 3) -> List[Tuple[int, float]]:
    """
    TÃ¬m index cá»§a tour phÃ¹ há»£p nháº¥t dá»±a trÃªn query.
    Returns list of (index, score) tuples.
    Chá»‰ xÃ©t cÃ¡c tour cÃ³ is_tour == True.
    """
    if not query:
        logger.warning("âš ï¸ resolve_best_tour_indices: empty query")
        return []

    normalized_query = normalize_tour_key(query)
    query_words = set(normalized_query.split())
    scores = []

    for norm_name, idx in TOUR_NAME_TO_INDEX.items():
        tour = TOURS_DB.get(idx)
        if not tour or not tour.is_tour:
            continue

        score = 0
        # 0. Phrase match (norm_name appears as continuous substring in normalized_query)
        if norm_name in normalized_query:
            score = 85
        # 1. Exact match
        elif normalized_query == norm_name:
            score = 100
        # 2. Query is substring of name
        elif normalized_query in norm_name:
            score = 80
        # 3. Word overlap
        else:
            name_words = set(norm_name.split())
            common = query_words.intersection(name_words)
            if common:
                score = 50 + len(common) * 5

        if score > 0:
            scores.append((score, len(norm_name), idx, norm_name))

    scores.sort(key=lambda x: (-x[0], -x[1]))
    result = [(idx, score) for score, _, idx, _ in scores[:top_k]]
    logger.info(f"ðŸŽ¯ resolve_best_tour_indices('{query}') â†’ {result}")
    return result

def extract_session_id(request_data: Dict, remote_addr: str) -> str:
    """Extract or create session ID"""
    session_id = request_data.get("session_id")
    if not session_id:
        ip = remote_addr or "0.0.0.0"
        current_hour = datetime.utcnow().strftime("%Y%m%d%H")
        unique_str = f"{ip}_{current_hour}"
        session_id = hashlib.md5(unique_str.encode()).hexdigest()[:12]
    return f"session_{session_id}"

def get_session_context(session_id: str) -> ConversationContext:
    """Get or create context for session using ConversationContext dataclass with auto-repair"""
    ctx = SESSION_CONTEXTS.get(session_id)
    if ctx is None:
        ctx = ConversationContext(session_id=session_id)
        SESSION_CONTEXTS[session_id] = ctx
        return ctx

    # ===== AUTO REPAIR FOR OLD CONTEXT OBJECTS =====
    if not hasattr(ctx, "last_tour_indices"):
        ctx.last_tour_indices = []
    if not hasattr(ctx, "current_tours"):
        ctx.current_tours = []
    if not hasattr(ctx, "mentioned_tours"):
        ctx.mentioned_tours = set()
    if not hasattr(ctx, "last_successful_tours"):
        ctx.last_successful_tours = []
    if not hasattr(ctx, "conversation_history"):
        ctx.conversation_history = []
    if not hasattr(ctx, "user_preferences"):
        ctx.user_preferences = {}
    if not hasattr(ctx, "user_profile"):
        ctx.user_profile = {}
    if not hasattr(ctx, "current_tour"):
        ctx.current_tour = None
    if not hasattr(ctx, "current_tour_updated_at"):
        ctx.current_tour_updated_at = None
    if not hasattr(ctx, "last_tour_name"):
        ctx.last_tour_name = None
    return ctx

# =========== UPGRADE 1: MANDATORY FILTER SYSTEM (DATACLASS COMPATIBLE) ===========
class MandatoryFilterSystem:
    """
    UPGRADE 1: Extract and apply mandatory filters BEFORE semantic search
    """

    FILTER_PATTERNS = {
        'duration': [
            (r'(?:thá»i gian|máº¥y ngÃ y|bao lÃ¢u|kÃ©o dÃ i)\s*(?:lÃ \s*)?(\d+)\s*(?:ngÃ y|Ä‘Ãªm)', 'exact_duration'),
            (r'(\d+)\s*ngÃ y\s*(?:vÃ \s*)?(\d+)?\s*Ä‘Ãªm', 'days_nights'),
            (r'(\d+)\s*ngÃ y\s*(?:trá»Ÿ lÃªn|trá»Ÿ xuá»‘ng)', 'duration_range'),
            (r'(?:tour|hÃ nh trÃ¬nh)\s*(?:khoáº£ng|táº§m|khoáº£ng)?\s*(\d+)\s*ngÃ y', 'approx_duration'),
        ],
        'price': [
            (r'dÆ°á»›i\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'max_price'),
            (r'trÃªn\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'min_price'),
            (r'khoáº£ng\s*(\d[\d,\.]*)\s*(?:Ä‘áº¿n|-)\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'price_range'),
            (r'giÃ¡\s*(?:tá»«\s*)?(\d[\d,\.]*)\s*(?:Ä‘áº¿n|-|tá»›i)\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'price_range'),
            (r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)\s*trá»Ÿ xuá»‘ng', 'max_price'),
            (r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)\s*trá»Ÿ lÃªn', 'min_price'),
        ],
        'location': [
            (r'(?:á»Ÿ|táº¡i|vá»|Ä‘áº¿n|thÄƒm)\s+([^.,!?\n]+?)(?:\s|$|\.|,|!|\?)', 'location'),
            (r'(?:Ä‘iá»ƒm Ä‘áº¿n|Ä‘á»‹a Ä‘iá»ƒm|nÆ¡i|vÃ¹ng)\s+(?:lÃ \s*)?([^.,!?\n]+)', 'location'),
            (r'(?:quanh|gáº§n|khu vá»±c)\s+([^.,!?\n]+)', 'near_location'),
        ],
        'date_time': [
            (r'(?:thÃ¡ng|vÃ o)\s*(\d{1,2})', 'month'),
            (r'(?:cuá»‘i tuáº§n|weekend)', 'weekend'),
            (r'(?:dá»‹p|lá»…|táº¿t)\s+([^.,!?\n]+)', 'holiday'),
        ],
        'group_type': [
            (r'(?:gia Ä‘Ã¬nh|family)', 'family'),
            (r'(?:cáº·p Ä‘Ã´i|couple|Ä‘Ã´i lá»©a)', 'couple'),
            (r'(?:nhÃ³m báº¡n|báº¡n bÃ¨|friends)', 'friends'),
            (r'(?:cÃ´ng ty|doanh nghiá»‡p|team building)', 'corporate'),
            (r'(?:má»™t mÃ¬nh|Ä‘i láº»|solo)', 'solo'),
        ],
    }

    @staticmethod
    def extract_filters(message: str) -> FilterSet:
        """
        Extract ALL mandatory filters from user message
        """
        filters = FilterSet()

        if not message:
            return filters

        message_lower = message.lower()

        # 1. DURATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['duration']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'exact_duration':
                    try:
                        days = int(match.group(1))
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'days_nights':
                    try:
                        days = int(match.group(1))
                        nights = int(match.group(2)) if match.group(2) else days
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass

        # 2. PRICE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['price']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                try:
                    if filter_type == 'max_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_max = amount
                            logger.info(f"ðŸ’° Extracted MAX price filter: {amount} VND")

                    elif filter_type == 'min_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_min = amount
                            logger.info(f"ðŸ’° Extracted MIN price filter: {amount} VND")

                    elif filter_type == 'price_range':
                        min_amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(3))
                        max_amount = MandatoryFilterSystem._parse_price(match.group(2), match.group(3))
                        if min_amount and max_amount:
                            filters.price_min = min_amount
                            filters.price_max = max_amount
                            logger.info(f"ðŸ’° Extracted PRICE RANGE: {min_amount} - {max_amount} VND")

                except (ValueError, IndexError, AttributeError):
                    continue

        # 3. LOCATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['location']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                location = match.group(1).strip()
                if location and len(location) > 1:
                    if filter_type == 'location':
                        filters.location = location
                    elif filter_type == 'near_location':
                        filters.near_location = location

        # 4. DATE/TIME FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['date_time']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'month':
                    try:
                        filters.month = int(match.group(1))
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'weekend':
                    filters.weekend = True
                elif filter_type == 'holiday':
                    filters.holiday = match.group(1).strip()

        # 5. GROUP TYPE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['group_type']:
            if re.search(pattern, message_lower):
                filters.group_type = filter_type

        # 6. SPECIAL KEYWORDS
        special_keywords = {
            'ráº»': ('price_max', 1500000),
            'giÃ¡ ráº»': ('price_max', 1500000),
            'tiáº¿t kiá»‡m': ('price_max', 1500000),
            'cao cáº¥p': ('price_min', 3000000),
            'sang trá»ng': ('price_min', 3000000),
            'premium': ('price_min', 3000000),
            'ngáº¯n ngÃ y': ('duration_max', 2),
            'dÃ i ngÃ y': ('duration_min', 3),
        }

        for keyword, (filter_key, value) in special_keywords.items():
            if keyword in message_lower:
                if filter_key == 'price_max':
                    filters.price_max = value
                elif filter_key == 'price_min':
                    filters.price_min = value
                elif filter_key == 'duration_max':
                    filters.duration_max = value
                elif filter_key == 'duration_min':
                    filters.duration_min = value

        logger.info(f"ðŸŽ¯ Extracted filters: {filters}")
        return filters

    @staticmethod
    def _parse_price(amount_str: str, unit: str) -> Optional[int]:
        """Parse price string like '1.5 triá»‡u' to integer VND"""
        if not amount_str:
            return None

        try:
            amount_str = amount_str.replace(',', '').replace('.', '')
            if not amount_str.isdigit():
                return None

            amount = int(amount_str)

            if unit in ['triá»‡u', 'tr']:
                return amount * 1000000
            elif unit == 'k':
                return amount * 1000
            elif unit == 'nghÃ¬n':
                return amount * 1000
            else:
                return amount if amount > 1000 else amount * 1000

        except (ValueError, AttributeError):
            return None

    @staticmethod
    def apply_filters(tours_db: Dict[int, Tour], filters: FilterSet) -> List[int]:
        """
        Apply mandatory filters to tour database
        Returns list of tour indices that pass ALL filters
        """
        if filters.is_empty() or not tours_db:
            return list(tours_db.keys())

        passing_tours = []

        try:
            for tour_idx, tour in tours_db.items():
                passes_all = True

                # PRICE FILTERING
                if passes_all and (filters.price_max is not None or filters.price_min is not None):
                    tour_price_text = tour.price or ""
                    if not tour_price_text:
                        if filters.price_max is not None or filters.price_min is not None:
                            passes_all = False
                    else:
                        tour_prices = MandatoryFilterSystem._extract_tour_prices(tour_price_text)
                        if not tour_prices:
                            passes_all = False
                        else:
                            min_tour_price = min(tour_prices)
                            max_tour_price = max(tour_prices)

                            if filters.price_max is not None and min_tour_price > filters.price_max:
                                passes_all = False
                            if filters.price_min is not None and max_tour_price < filters.price_min:
                                passes_all = False

                # DURATION FILTERING
                if passes_all and (filters.duration_min is not None or filters.duration_max is not None):
                    duration_text = (tour.duration or "").lower()
                    tour_duration = MandatoryFilterSystem._extract_duration_days(duration_text)

                    if tour_duration is not None:
                        if filters.duration_min is not None and tour_duration < filters.duration_min:
                            passes_all = False
                        if filters.duration_max is not None and tour_duration > filters.duration_max:
                            passes_all = False
                    else:
                        if filters.duration_min is not None or filters.duration_max is not None:
                            passes_all = False

                # LOCATION FILTERING
                if passes_all and (filters.location is not None or filters.near_location is not None):
                    tour_location = (tour.location or "").lower()
                    if filters.location is not None:
                        filter_location = filters.location.lower()
                        if filter_location not in tour_location:
                            passes_all = False
                    if filters.near_location is not None:
                        near_location = filters.near_location.lower()
                        if near_location not in tour_location:
                            passes_all = False

                if passes_all:
                    passing_tours.append(tour_idx)

            logger.info(f"ðŸ” After mandatory filtering: {len(passing_tours)}/{len(tours_db)} tours pass")
        except Exception as e:
            logger.error(f"âŒ Error in apply_filters: {e}")
            passing_tours = list(tours_db.keys())

        return passing_tours

    @staticmethod
    def _extract_tour_prices(price_text: str) -> List[int]:
        """Extract price numbers from tour price text"""
        prices = []

        number_patterns = [
            r'(\d[\d,\.]+)\s*(?:triá»‡u|tr)',
            r'(\d[\d,\.]+)\s*(?:k|nghÃ¬n)',
            r'(\d[\d,\.]+)\s*(?:Ä‘á»“ng|vnÄ‘|vnd)',
            r'(\d[\d,\.]+)\s*-\s*(\d[\d,\.]+)',
        ]

        for pattern in number_patterns:
            matches = re.finditer(pattern, price_text, re.IGNORECASE)
            for match in matches:
                try:
                    for i in range(1, 3):
                        if match.group(i):
                            num_str = match.group(i).replace(',', '').replace('.', '')
                            if num_str.isdigit():
                                num = int(num_str)

                                if 'triá»‡u' in match.group(0).lower() or 'tr' in match.group(0).lower():
                                    num = num * 1000000
                                elif 'k' in match.group(0).lower() or 'nghÃ¬n' in match.group(0).lower():
                                    num = num * 1000

                                prices.append(num)
                except (ValueError, AttributeError):
                    continue

        if not prices:
            raw_numbers = re.findall(r'\d[\d,\.]+', price_text)
            for num_str in raw_numbers[:2]:
                try:
                    num_str = num_str.replace(',', '').replace('.', '')
                    if num_str.isdigit():
                        num = int(num_str)
                        if 100 <= num <= 10000:
                            num = num * 1000
                        prices.append(num)
                except ValueError:
                    continue

        return prices

    @staticmethod
    def _extract_duration_days(duration_text: str) -> Optional[int]:
        """Extract duration in days from text"""
        if not duration_text:
            return None

        patterns = [
            r'(\d+)\s*ngÃ y',
            r'(\d+)\s*ngÃ y\s*\d*\s*Ä‘Ãªm',
            r'(\d+)\s*Ä‘Ãªm',
        ]

        for pattern in patterns:
            match = re.search(pattern, duration_text)
            if match:
                try:
                    return int(match.group(1))
                except (ValueError, IndexError):
                    continue

        return None

# =========== UPGRADE 2: DEDUPLICATION ENGINE (DATACLASS COMPATIBLE) ===========
class DeduplicationEngine:
    """
    UPGRADE 2: Remove duplicate and highly similar results
    """

    SIMILARITY_THRESHOLD = 0.85
    MIN_TEXT_LENGTH = 20

    @staticmethod
    def calculate_similarity(text1: str, text2: str) -> float:
        """Calculate text similarity using multiple methods"""
        if not text1 or not text2:
            return 0.0

        text1_norm = DeduplicationEngine._normalize_text(text1)
        text2_norm = DeduplicationEngine._normalize_text(text2)

        if len(text1_norm) < DeduplicationEngine.MIN_TEXT_LENGTH or len(text2_norm) < DeduplicationEngine.MIN_TEXT_LENGTH:
            return 0.0

        seq_ratio = SequenceMatcher(None, text1_norm, text2_norm).ratio()

        words1 = set(text1_norm.split())
        words2 = set(text2_norm.split())

        if not words1 or not words2:
            jaccard = 0.0
        else:
            intersection = words1.intersection(words2)
            union = words1.union(words2)
            jaccard = len(intersection) / len(union)

        prefix_len = min(50, min(len(text1_norm), len(text2_norm)))
        prefix1 = text1_norm[:prefix_len]
        prefix2 = text2_norm[:prefix_len]
        prefix_sim = SequenceMatcher(None, prefix1, prefix2).ratio()

        similarity = (seq_ratio * 0.5) + (jaccard * 0.3) + (prefix_sim * 0.2)

        return similarity

    @staticmethod
    def _normalize_text(text: str) -> str:
        """Normalize text for comparison"""
        if not text:
            return ""

        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()

        stopwords = {'vÃ ', 'cá»§a', 'cho', 'vá»›i', 'táº¡i', 'á»Ÿ', 'nÃ y', 'Ä‘Ã³', 'kia', 'vá»', 'trong'}
        words = [word for word in text.split() if word not in stopwords]

        return ' '.join(words)

    @staticmethod
    def deduplicate_passages(passages: List[Tuple[float, Dict]],
                             similarity_threshold: float = None) -> List[Tuple[float, Dict]]:
        """
        Remove duplicate passages from results
        """
        if len(passages) <= 1:
            return passages

        threshold = similarity_threshold or DeduplicationEngine.SIMILARITY_THRESHOLD
        unique_passages = []
        seen_passages = []

        sorted_passages = sorted(passages, key=lambda x: x[0], reverse=True)

        for score, passage in sorted_passages:
            text = passage.get('text', '').strip()
            path = passage.get('path', '')

            if not text or len(text) < DeduplicationEngine.MIN_TEXT_LENGTH:
                unique_passages.append((score, passage))
                continue

            is_duplicate = False
            for seen_text, seen_path in seen_passages:
                tour_match1 = re.search(r'tours\[(\d+)\]', path)
                tour_match2 = re.search(r'tours\[(\d+)\]', seen_path)

                if tour_match1 and tour_match2:
                    if tour_match1.group(1) == tour_match2.group(1):
                        field1 = path.split('.')[-1] if '.' in path else ''
                        field2 = seen_path.split('.')[-1] if '.' in seen_path else ''
                        if field1 == field2:
                            is_duplicate = True
                            break

                similarity = DeduplicationEngine.calculate_similarity(text, seen_text)
                if similarity > threshold:
                    is_duplicate = True
                    break

            if not is_duplicate:
                unique_passages.append((score, passage))
                seen_passages.append((text, path))

        logger.info(f"ðŸ”„ Deduplication: {len(passages)} â†’ {len(unique_passages)} passages")
        return unique_passages

    @staticmethod
    def merge_similar_tours(tour_indices: List[int], tours_db: Dict[int, Tour]) -> List[int]:
        """Merge tours that are essentially the same"""
        if len(tour_indices) <= 1:
            return tour_indices

        tour_groups = []
        processed = set()

        for i, idx1 in enumerate(tour_indices):
            if idx1 in processed:
                continue

            group = [idx1]
            tour1 = tours_db.get(idx1)
            name1 = (tour1.name if tour1 else "").strip()

            if not name1:
                processed.add(idx1)
                tour_groups.append(group)
                continue

            for j, idx2 in enumerate(tour_indices[i+1:], i+1):
                if idx2 in processed:
                    continue

                tour2 = tours_db.get(idx2)
                name2 = (tour2.name if tour2 else "").strip()

                if not name2:
                    continue

                similarity = DeduplicationEngine.calculate_similarity(name1, name2)
                if similarity > 0.9:
                    group.append(idx2)
                    processed.add(idx2)

            processed.add(idx1)
            tour_groups.append(group)

        best_tours = []
        for group in tour_groups:
            if not group:
                continue

            if len(group) == 1:
                best_tours.append(group[0])
                continue

            best_score = -1
            best_idx = group[0]

            for idx in group:
                tour = tours_db.get(idx)
                if not tour:
                    continue

                score = 0

                if tour.name:
                    score += 2
                if tour.duration:
                    score += 2
                if tour.location:
                    score += 2
                if tour.price:
                    score += 3
                if tour.includes:
                    score += 2
                if tour.summary:
                    score += 1

                for field in [tour.includes, tour.summary, tour.notes]:
                    if isinstance(field, str) and len(field) > 50:
                        score += 1
                    elif isinstance(field, list) and field:
                        score += len(field)

                if score > best_score:
                    best_score = score
                    best_idx = idx

            best_tours.append(best_idx)

        logger.info(f"ðŸ”„ Tour merging: {len(tour_indices)} â†’ {len(best_tours)} unique tours")
        return best_tours

# =========== UPGRADE 3: ENHANCED FIELD DETECTION (DATACLASS COMPATIBLE) ===========
class EnhancedFieldDetector:
    """
    UPGRADE 3: Better detection of what user is asking for
    """

    FIELD_DETECTION_RULES = [
        # TOUR LIST
        {
            "field": "tour_name",
            "patterns": [
                (r'liá»‡t kÃª.*tour|danh sÃ¡ch.*tour|cÃ¡c tour|cÃ³ nhá»¯ng tour nÃ o', 1.0),
                (r'tour nÃ o.*cÃ³|tour nÃ o.*hiá»‡n|tour nÃ o.*Ä‘ang', 0.9),
                (r'ká»ƒ tÃªn.*tour|nÃªu tÃªn.*tour|tÃªn cÃ¡c tour', 0.9),
                (r'cÃ³ máº¥y.*tour|bao nhiÃªu.*tour|sá»‘ lÆ°á»£ng.*tour', 0.8),
                (r'list tour|show tour|all tour|every tour', 0.8),
            ],
            "keywords": [
                ("liá»‡t kÃª", 0.9), ("danh sÃ¡ch", 0.9), ("cÃ¡c", 0.7),
                ("táº¥t cáº£", 0.8), ("má»i", 0.7), ("máº¥y", 0.6),
                ("bao nhiÃªu", 0.7), ("sá»‘ lÆ°á»£ng", 0.7),
            ]
        },

        # PRICE
        {
            "field": "price",
            "patterns": [
                (r'giÃ¡.*bao nhiÃªu|bao nhiÃªu tiá»n|chi phÃ­.*bao nhiÃªu', 1.0),
                (r'giÃ¡ tour|giÃ¡ cáº£|giÃ¡ thÃ nh|chi phÃ­ tour', 0.9),
                (r'tour.*giÃ¡.*bao nhiÃªu|tour.*bao nhiÃªu tiá»n', 0.95),
                (r'pháº£i tráº£.*bao nhiÃªu|tá»‘n.*bao nhiÃªu|máº¥t.*bao nhiÃªu', 0.8),
                (r'Ä‘Ã³ng.*bao nhiÃªu|thanh toÃ¡n.*bao nhiÃªu', 0.8),
            ],
            "keywords": [
                ("giÃ¡", 0.8), ("tiá»n", 0.7), ("chi phÃ­", 0.8),
                ("Ä‘Ã³ng", 0.6), ("tráº£", 0.6), ("tá»‘n", 0.6),
                ("phÃ­", 0.7), ("kinh phÃ­", 0.7), ("tá»•ng chi", 0.7),
            ]
        },

        # DURATION
        {
            "field": "duration",
            "patterns": [
                (r'thá»i gian.*bao lÃ¢u|máº¥y ngÃ y.*Ä‘i|bao lÃ¢u.*tour', 1.0),
                (r'tour.*bao nhiÃªu ngÃ y|máº¥y ngÃ y.*tour', 0.9),
                (r'Ä‘i trong.*bao lÃ¢u|kÃ©o dÃ i.*bao lÃ¢u', 0.9),
                (r'thá»i lÆ°á»£ng.*bao nhiÃªu|thá»i gian.*dÃ i bao lÃ¢u', 0.8),
            ],
            "keywords": [
                ("bao lÃ¢u", 0.9), ("máº¥y ngÃ y", 0.9), ("thá»i gian", 0.8),
                ("kÃ©o dÃ i", 0.7), ("thá»i lÆ°á»£ng", 0.8), ("ngÃ y", 0.6),
                ("Ä‘Ãªm", 0.6), ("thá»i háº¡n", 0.7),
            ]
        },

        # LOCATION
        {
            "field": "location",
            "patterns": [
                (r'á»Ÿ Ä‘Ã¢u|Ä‘i Ä‘Ã¢u|Ä‘áº¿n Ä‘Ã¢u|tá»›i Ä‘Ã¢u|thÄƒm quan Ä‘Ã¢u', 1.0),
                (r'Ä‘á»‹a Ä‘iá»ƒm.*nÃ o|nÆ¡i nÃ o|vÃ¹ng nÃ o|khu vá»±c nÃ o', 0.9),
                (r'tour.*á»Ÿ.*Ä‘Ã¢u|hÃ nh trÃ¬nh.*Ä‘i.*Ä‘Ã¢u', 0.9),
                (r'khÃ¡m phÃ¡.*Ä‘Ã¢u|thÄƒm.*Ä‘Ã¢u|ghÃ©.*Ä‘Ã¢u', 0.8),
            ],
            "keywords": [
                ("á»Ÿ Ä‘Ã¢u", 1.0), ("Ä‘i Ä‘Ã¢u", 1.0), ("Ä‘áº¿n Ä‘Ã¢u", 0.9),
                ("tá»›i Ä‘Ã¢u", 0.9), ("Ä‘á»‹a Ä‘iá»ƒm", 0.8), ("nÆ¡i", 0.7),
                ("vÃ¹ng", 0.7), ("khu vá»±c", 0.7),
            ]
        },

        # SUMMARY (tá»•ng quan)
        {
            "field": "summary",
            "patterns": [
                (r'cÃ³ gÃ¬ hay|cÃ³ gÃ¬ Ä‘áº·c biá»‡t|cÃ³ gÃ¬ thÃº vá»‹', 0.9),
                (r'tour nÃ y tháº¿ nÃ o|hÃ nh trÃ¬nh ra sao|chuyáº¿n Ä‘i nhÆ° nÃ o', 0.8),
                (r'giá»›i thiá»‡u.*tour|mÃ´ táº£.*tour|nÃ³i vá».*tour', 0.8),
                (r'tour.*cÃ³ gÃ¬|Ä‘i.*Ä‘Æ°á»£c gÃ¬|tráº£i nghiá»‡m.*gÃ¬', 0.7),
                (r'Ä‘iá»ƒm nháº¥n.*tour|ná»•i báº­t.*gÃ¬|Ä‘áº·c sáº¯c.*gÃ¬', 0.7),
            ],
            "keywords": [
                ("cÃ³ gÃ¬", 0.7), ("tháº¿ nÃ o", 0.6), ("ra sao", 0.6),
                ("giá»›i thiá»‡u", 0.7), ("mÃ´ táº£", 0.7), ("nÃ³i vá»", 0.6),
                ("Ä‘iá»ƒm nháº¥n", 0.7), ("ná»•i báº­t", 0.7), ("Ä‘áº·c sáº¯c", 0.7),
            ]
        },

        # INCLUDES (bao gá»“m / lá»‹ch trÃ¬nh)
        {
            "field": "includes",
            "patterns": [
                (r'lá»‹ch trÃ¬nh.*chi tiáº¿t|chÆ°Æ¡ng trÃ¬nh.*chi tiáº¿t', 0.9),
                (r'lÃ m gÃ¬.*tour|hoáº¡t Ä‘á»™ng.*gÃ¬|sinh hoáº¡t.*gÃ¬', 0.8),
                (r'tour.*gá»“m.*gÃ¬|bao gá»“m.*gÃ¬|gá»“m nhá»¯ng gÃ¬', 0.8),
                (r'Ä‘i Ä‘Ã¢u.*lÃ m gÃ¬|thÄƒm quan.*gÃ¬|khÃ¡m phÃ¡.*gÃ¬', 0.7),
            ],
            "keywords": [
                ("lá»‹ch trÃ¬nh", 0.8), ("chÆ°Æ¡ng trÃ¬nh", 0.8), ("lÃ m gÃ¬", 0.7),
                ("hoáº¡t Ä‘á»™ng", 0.7), ("sinh hoáº¡t", 0.6), ("gá»“m", 0.6),
                ("bao gá»“m", 0.7), ("gá»“m nhá»¯ng", 0.7),
            ]
        },

        # NOTES (lÆ°u Ã½)
        {
            "field": "notes",
            "patterns": [
                (r'lÆ°u Ã½.*gÃ¬|nhá»¯ng lÆ°u Ã½|cáº§n biáº¿t|chÃº Ã½', 0.9),
                (r'cÃ³ lÆ°u Ã½ gÃ¬ khÃ´ng|Ä‘iá»u kiá»‡n.*gÃ¬', 0.8),
                (r'khÃ´ng bao gá»“m|ngoáº¡i lá»‡|loáº¡i trá»«', 0.7),
                (r'chÃ­nh sÃ¡ch há»§y|há»§y tour|hoÃ n tiá»n', 0.8),
            ],
            "keywords": [
                ("lÆ°u Ã½", 0.9), ("chÃº Ã½", 0.8), ("cáº§n biáº¿t", 0.8),
                ("khÃ´ng bao gá»“m", 0.7), ("há»§y", 0.6), ("hoÃ n", 0.6),
            ]
        },

        # STYLE (phong cÃ¡ch)
        {
            "field": "style",
            "patterns": [
                (r'phong cÃ¡ch.*tour|kiá»ƒu.*tour|loáº¡i hÃ¬nh.*tour', 0.9),
                (r'tour.*phÃ¹ há»£p.*vá»›i ai|Ä‘á»‘i tÆ°á»£ng.*tour', 0.8),
                (r'chá»¯a lÃ nh|thiá»n|yoga|retreat|tráº£i nghiá»‡m sÃ¢u', 0.8),
                (r'nhá»‹p.*cháº­m|cháº­m.*sÃ¢u', 0.7),
            ],
            "keywords": [
                ("phong cÃ¡ch", 0.9), ("kiá»ƒu", 0.7), ("loáº¡i hÃ¬nh", 0.8),
                ("Ä‘á»‘i tÆ°á»£ng", 0.7), ("ai", 0.6), ("thiá»n", 0.8),
                ("chá»¯a lÃ nh", 0.9), ("retreat", 0.9),
            ]
        },

        # TRANSPORT (phÆ°Æ¡ng tiá»‡n)
        {
            "field": "transport",
            "patterns": [
                (r'phÆ°Æ¡ng tiá»‡n.*gÃ¬|di chuyá»ƒn.*báº±ng gÃ¬|xe gÃ¬', 1.0),
                (r'Ä‘i láº¡i.*tháº¿ nÃ o|Ä‘Æ°a Ä‘Ã³n.*khÃ´ng', 0.9),
                (r'xe du lá»‹ch|xe Ä‘á»i má»›i|Ã´ tÃ´', 0.8),
            ],
            "keywords": [
                ("xe", 0.7), ("phÆ°Æ¡ng tiá»‡n", 0.9), ("di chuyá»ƒn", 0.8),
                ("Ä‘Æ°a Ä‘Ã³n", 0.8), ("Ã´tÃ´", 0.7), ("bus", 0.6),
            ]
        },

        # ACCOMMODATION (nÆ¡i á»Ÿ)
        {
            "field": "accommodation",
            "patterns": [
                (r'á»Ÿ Ä‘Ã¢u|ngá»§ á»Ÿ Ä‘Ã¢u|chá»— á»Ÿ|khÃ¡ch sáº¡n|homestay', 1.0),
                (r'lÆ°u trÃº.*tháº¿ nÃ o|nghá»‰ Ä‘Ãªm.*á»Ÿ Ä‘Ã¢u', 0.9),
                (r'phÃ²ng.*máº¥y ngÆ°á»i|tiÃªu chuáº©n phÃ²ng', 0.8),
            ],
            "keywords": [
                ("á»Ÿ", 0.6), ("ngá»§", 0.7), ("chá»— á»Ÿ", 0.9),
                ("khÃ¡ch sáº¡n", 0.8), ("homestay", 0.8), ("lÆ°u trÃº", 0.8),
            ]
        },

        # MEALS (bá»¯a Äƒn)
        {
            "field": "meals",
            "patterns": [
                (r'Äƒn gÃ¬|bá»¯a Äƒn|Ä‘á»“ Äƒn|áº©m thá»±c|Ä‘áº·c sáº£n', 1.0),
                (r'bá»¯a sÃ¡ng|bá»¯a trÆ°a|bá»¯a tá»‘i|suáº¥t Äƒn', 0.9),
                (r'cÃ³ bao gá»“m Äƒn khÃ´ng|Äƒn uá»‘ng.*tháº¿ nÃ o', 0.8),
            ],
            "keywords": [
                ("Äƒn", 0.7), ("bá»¯a", 0.8), ("suáº¥t", 0.7),
                ("Ä‘á»“ Äƒn", 0.8), ("áº©m thá»±c", 0.7), ("Ä‘áº·c sáº£n", 0.7),
            ]
        },

        # EVENT_SUPPORT (há»— trá»£ Ä‘oÃ n)
        {
            "field": "event_support",
            "patterns": [
                (r'há»— trá»£.*gÃ¬|dá»‹ch vá»¥.*kÃ¨m theo|Ä‘i kÃ¨m', 0.8),
                (r'lá»­a tráº¡i|giao lÆ°u vÄƒn hÃ³a|chá»¥p áº£nh', 0.9),
                (r'hÆ°á»›ng dáº«n viÃªn|Ä‘iá»u phá»‘i|tá»• chá»©c', 0.7),
            ],
            "keywords": [
                ("há»— trá»£", 0.8), ("dá»‹ch vá»¥", 0.6), ("lá»­a tráº¡i", 0.9),
                ("giao lÆ°u", 0.8), ("chá»¥p áº£nh", 0.7), ("hÆ°á»›ng dáº«n", 0.7),
            ]
        },
    ]

    @staticmethod
    def detect_field_with_confidence(message: str) -> Tuple[Optional[str], float, Dict[str, float]]:
        """
        Detect which field user is asking about with confidence scores
        """
        if not message:
            return None, 0.0, {}

        message_lower = message.lower()
        scores = {}

        for rule in EnhancedFieldDetector.FIELD_DETECTION_RULES:
            field = rule["field"]
            field_score = 0.0

            for pattern, weight in rule["patterns"]:
                if re.search(pattern, message_lower):
                    field_score = max(field_score, weight)

            for keyword, weight in rule["keywords"]:
                if keyword in message_lower:
                    position = message_lower.find(keyword)
                    position_factor = 1.0 - (position / max(len(message_lower), 1))
                    adjusted_weight = weight * (0.7 + 0.3 * position_factor)
                    field_score = max(field_score, adjusted_weight)

            if field_score > 0:
                field_score = min(field_score * 1.1, 1.0)

            scores[field] = field_score

        best_field = None
        best_score = 0.0

        for field, score in scores.items():
            if score > best_score:
                best_score = score
                best_field = field

        if (best_score < 0.3 and
            ("cÃ³ gÃ¬" in message_lower or "tháº¿ nÃ o" in message_lower) and
            "tour" in message_lower):
            best_field = "summary"
            best_score = 0.6

        logger.info(f"ðŸ” Field detection: '{message}' â†’ {best_field} (confidence: {best_score:.2f})")
        return best_field, best_score, scores

# =========== UPGRADE 4: QUESTION PIPELINE (DATACLASS COMPATIBLE) ===========
class QuestionType(Enum):
    LISTING = "listing"
    COMPARISON = "comparison"
    RECOMMENDATION = "recommendation"
    GREETING = "greeting"
    FAREWELL = "farewell"
    CALCULATION = "calculation"
    COMPLEX = "complex"
    INFORMATION = "information"

class QuestionPipeline:
    """
    UPGRADE 4: Process different types of questions differently
    """

    @staticmethod
    def classify_question(message: str) -> Tuple[QuestionType, float, Dict]:
        """
        Classify question type with confidence and metadata
        """
        message_lower = message.lower()
        type_scores = defaultdict(float)
        metadata = {}

        # LISTING detection - CHá»ˆ khi yÃªu cáº§u rÃµ rÃ ng liá»‡t kÃª DANH SÃCH
        listing_patterns = [
            (r'liá»‡t kÃª.*táº¥t cáº£.*tour|danh sÃ¡ch.*táº¥t cáº£.*tour|táº¥t cáº£.*tour', 0.95),
            (r'liá»‡t kÃª.*tour|danh sÃ¡ch.*tour|list.*tour', 0.9),
            (r'ká»ƒ tÃªn.*tour|nÃªu tÃªn.*tour', 0.9),
            (r'cÃ³ nhá»¯ng.*tour nÃ o|cÃ³ máº¥y.*tour|máº¥y.*tour', 0.7),
            (r'bÃªn báº¡n.*cÃ³.*tour|hiá»‡n cÃ³.*tour', 0.75),
        ]

        for pattern, weight in listing_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.LISTING] = max(
                    type_scores[QuestionType.LISTING], weight
                )

        # COMPARISON detection
        comparison_patterns = [
            (r'so sÃ¡nh.*vÃ |Ä‘á»‘i chiáº¿u.*vÃ ', 0.95),
            (r'khÃ¡c nhau.*nÃ o|giá»‘ng nhau.*nÃ o', 0.9),
            (r'nÃªn chá»n.*nÃ o|tá»‘t hÆ¡n.*nÃ o|hÆ¡n kÃ©m.*nÃ o', 0.85),
            (r'tour.*vÃ .*tour', 0.8),
            (r'sÃ¡nh.*vá»›i|Ä‘á»‘i chiáº¿u.*vá»›i', 0.8),
        ]

        for pattern, weight in comparison_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.COMPARISON] = max(
                    type_scores[QuestionType.COMPARISON], weight
                )
                metadata['comparison_type'] = 'direct'

        # RECOMMENDATION detection
        recommendation_patterns = [
            (r'phÃ¹ há»£p.*vá»›i|nÃªn Ä‘i.*nÃ o|gá»£i Ã½.*tour', 0.95),
            (r'tour nÃ o.*phÃ¹ há»£p|phÃ¹ há»£p.*tour nÃ o', 0.95),
            (r'tour.*tá»‘t.*nháº¥t|hÃ nh trÃ¬nh.*hay nháº¥t|tour.*lÃ½ tÆ°á»Ÿng', 0.9),
            (r'Ä‘á» xuáº¥t.*tour|tÆ° váº¥n.*tour|chá»n.*tour nÃ o', 0.9),
            (r'tour nÃ o.*cho.*gia Ä‘Ã¬nh|tour.*gia Ä‘Ã¬nh|gia Ä‘Ã¬nh.*tour', 0.9),
            (r'tour nÃ o.*cho|dÃ nh cho.*tour|tour.*dÃ nh cho', 0.85),
            (r'nÃªn.*tour nÃ o|nÃªn chá»n.*tour|tour.*nÃªn', 0.85),
            (r'tour.*nháº¹ nhÃ ng|tour.*dá»…|tour.*phÃ¹ há»£p.*ngÆ°á»i', 0.85),
            (r'tour.*tráº» em|tour.*con nÃ­t|tour.*bÃ©', 0.85),
            (r'tour.*ngÆ°á»i lá»›n tuá»•i|tour.*cao tuá»•i|tour.*nghá»‰ dÆ°á»¡ng', 0.85),
            (r'chi phÃ­.*vá»«a pháº£i|giÃ¡.*phÃ¹ há»£p|giÃ¡.*há»£p lÃ½', 0.8),
            (r'cho.*tÃ´i|dÃ nh cho.*tÃ´i|há»£p vá»›i.*tÃ´i', 0.75),
            (r'náº¿u.*thÃ¬.*nÃªn.*tour|nÃªn chá»n.*tour', 0.8),
        ]

        for pattern, weight in recommendation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.RECOMMENDATION] = max(
                    type_scores[QuestionType.RECOMMENDATION], weight
                )

        # GREETING detection
        greeting_words = ['xin chÃ o', 'chÃ o', 'hello', 'hi', 'helo', 'chao']
        greeting_score = 0.0
        for word in greeting_words:
            if word in message_lower:
                if message_lower.startswith(word) or f" {word} " in message_lower or message_lower.endswith(f" {word}"):
                    greeting_score += 0.3

        other_intent_score = max([score for qtype, score in type_scores.items()
                                 if qtype != QuestionType.GREETING], default=0.0)

        if greeting_score > 0.8 and other_intent_score < 0.3:
            type_scores[QuestionType.GREETING] = min(greeting_score, 1.0)

        # FAREWELL detection
        farewell_words = ['táº¡m biá»‡t', 'cáº£m Æ¡n', 'thanks', 'thank you', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            type_scores[QuestionType.FAREWELL] = 0.95

        # CALCULATION detection
        calculation_patterns = [
            (r'tÃ­nh toÃ¡n|tÃ­nh.*bao nhiÃªu|tá»•ng.*bao nhiÃªu', 0.9),
            (r'cá»™ng.*láº¡i|nhÃ¢n.*lÃªn|chia.*ra', 0.8),
            (r'bao nhiÃªu.*ngÆ°á»i|máº¥y.*ngÆ°á»i|sá»‘ lÆ°á»£ng.*ngÆ°á»i', 0.7),
        ]

        for pattern, weight in calculation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.CALCULATION] = max(
                    type_scores[QuestionType.CALCULATION], weight
                )

        # COMPLEX question detection
        complex_indicators = [
            ('vÃ ', 0.3), ('rá»“i', 0.4), ('sau Ä‘Ã³', 0.5),
            ('tiáº¿p theo', 0.5), ('ngoÃ i ra', 0.4), ('thÃªm ná»¯a', 0.4),
        ]

        complex_score = 0.0
        for indicator, weight in complex_indicators:
            if indicator in message_lower:
                complex_score += weight

        if complex_score > 0.8:
            type_scores[QuestionType.COMPLEX] = min(complex_score / 2, 1.0)
            metadata['complex_parts'] = QuestionPipeline._split_complex_question(message)

        # DEFAULT: INFORMATION request
        if not type_scores:
            type_scores[QuestionType.INFORMATION] = 0.6
        else:
            info_keywords = ['lÃ  gÃ¬', 'bao nhiÃªu', 'á»Ÿ Ä‘Ã¢u', 'khi nÃ o', 'tháº¿ nÃ o', 'ai', 'táº¡i sao']
            if any(keyword in message_lower for keyword in info_keywords):
                type_scores[QuestionType.INFORMATION] = max(
                    type_scores.get(QuestionType.INFORMATION, 0),
                    0.5
                )

        # Determine best type
        best_type = QuestionType.INFORMATION
        best_score = 0.0

        for qtype, score in type_scores.items():
            if score > best_score:
                best_score = score
                best_type = qtype

        if best_score < 0.5:
            best_type = QuestionType.INFORMATION
            best_score = 0.5

        logger.info(f"ðŸŽ¯ Question classification: '{message}' â†’ {best_type.value} (score: {best_score:.2f})")
        return best_type, best_score, metadata

    @staticmethod
    def _split_complex_question(message: str) -> List[str]:
        """Split complex multi-part question into simpler parts"""
        split_patterns = [
            r'\s+vÃ \s+',
            r'\s+rá»“i\s+',
            r'\s+sau Ä‘Ã³\s+',
            r'\s+tiáº¿p theo\s+',
            r'\s+ngoÃ i ra\s+',
            r'\s+thÃªm ná»¯a\s+',
            r'\s+Ä‘á»“ng thá»i\s+',
            r'\s+cuá»‘i cÃ¹ng\s+',
        ]

        parts = [message]

        for pattern in split_patterns:
            new_parts = []
            for part in parts:
                split_result = re.split(pattern, part, flags=re.IGNORECASE)
                new_parts.extend([p.strip() for p in split_result if p.strip()])
            parts = new_parts

        return parts

    @staticmethod
    def process_comparison_question(tour_indices: List[int], tours_db: Dict[int, Tour],
                                  aspect: str = "", context: Dict = None) -> str:
        """
        Process comparison question between tours
        """
        if len(tour_indices) < 2:
            return "Cáº§n Ã­t nháº¥t 2 tour Ä‘á»ƒ so sÃ¡nh."

        tours_to_compare = []
        for idx in tour_indices[:3]:
            tour = tours_db.get(idx)
            if tour:
                tours_to_compare.append((idx, tour))

        if len(tours_to_compare) < 2:
            return "KhÃ´ng tÃ¬m tháº¥y Ä‘á»§ thÃ´ng tin tour Ä‘á»ƒ so sÃ¡nh."

        if not aspect:
            aspect = 'price'

        result_lines = []

        headers = ["TIÃŠU CHÃ"]
        for idx, tour in tours_to_compare:
            tour_name = tour.name or f'Tour #{idx}'
            headers.append(tour_name[:25])

        result_lines.append(" | ".join(headers))
        result_lines.append("-" * (len(headers) * 30))

        comparison_fields = [
            ('duration', 'â±ï¸ Thá»i gian'),
            ('location', 'ðŸ“ Äá»‹a Ä‘iá»ƒm'),
            ('price', 'ðŸ’° GiÃ¡ tour'),
            ('accommodation', 'ðŸ¨ Chá»— á»Ÿ'),
            ('meals', 'ðŸ½ï¸ Ä‚n uá»‘ng'),
            ('transport', 'ðŸš— Di chuyá»ƒn'),
            ('summary', 'ðŸ“ MÃ´ táº£'),
        ]

        for field, display_name in comparison_fields:
            if aspect and field != aspect and aspect not in ['all', 'táº¥t cáº£']:
                continue

            row = [display_name]
            all_values = []

            for idx, tour in tours_to_compare:
                value = getattr(tour, field, 'N/A')
                if isinstance(value, list):
                    value = ', '.join(value[:2])
                row.append(str(value)[:30])
                all_values.append(str(value).lower())

            if len(set(all_values)) > 1 or aspect == field:
                result_lines.append(" | ".join(row))

        result_lines.append("\n" + "="*50)
        result_lines.append("**ÄÃNH GIÃ & Gá»¢I Ã:**")

        durations = [tour.duration for _, tour in tours_to_compare]
        if any('1 ngÃ y' in d for d in durations) and any('2 ngÃ y' in d for d in durations):
            result_lines.append("â€¢ Náº¿u báº¡n cÃ³ Ã­t thá»i gian: Chá»n tour 1 ngÃ y")
            result_lines.append("â€¢ Náº¿u muá»‘n tráº£i nghiá»‡m sÃ¢u: Chá»n tour 2 ngÃ y")

        prices = []
        for _, tour in tours_to_compare:
            price_text = tour.price or ''
            price_nums = re.findall(r'\d[\d,\.]+', price_text)
            if price_nums:
                try:
                    price = int(price_nums[0].replace(',', '').replace('.', ''))
                    prices.append(price)
                except:
                    pass

        if len(prices) >= 2:
            min_price_idx = prices.index(min(prices))
            max_price_idx = prices.index(max(prices))

            if prices[max_price_idx] > prices[min_price_idx] * 1.5:
                result_lines.append(f"â€¢ Tiáº¿t kiá»‡m chi phÃ­: {headers[min_price_idx + 1]}")
                result_lines.append(f"â€¢ Tráº£i nghiá»‡m cao cáº¥p: {headers[max_price_idx + 1]}")

        result_lines.append("\nðŸ’¡ *LiÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t*")

        return "\n".join(result_lines)

# =========== UPGRADE 5: COMPLEX QUERY SPLITTER (DATACLASS COMPATIBLE) ===========
class ComplexQueryProcessor:
    """
    UPGRADE 5: Handle complex multi-condition queries
    """

    @staticmethod
    def split_query(query: str) -> List[Dict[str, Any]]:
        """
        Split complex query into sub-queries with priorities
        """
        sub_queries = []

        complexity_score = ComplexQueryProcessor._calculate_complexity(query)
        if complexity_score < 1.5:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': {},
                'focus': 'general'
            }]

        conditions = ComplexQueryProcessor._extract_conditions(query)

        if len(conditions) <= 1:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': conditions[0] if conditions else {},
                'focus': 'general'
            }]

        sub_queries.append({
            'query': query,
            'priority': 1.0,
            'filters': ComplexQueryProcessor._merge_conditions(conditions),
            'focus': 'specific'
        })

        location_conds = [c for c in conditions if 'location' in c]
        other_conds = [c for c in conditions if 'location' not in c]

        if location_conds and other_conds:
            for other_cond in other_conds[:2]:
                merged = ComplexQueryProcessor._merge_conditions(location_conds + [other_cond])
                sub_queries.append({
                    'query': f"{query} (focus on location + {list(other_cond.keys())[0]})",
                    'priority': 0.8,
                    'filters': merged,
                    'focus': list(other_cond.keys())[0]
                })

        important_conds = ['price', 'duration', 'location']
        for cond_type in important_conds:
            conds_of_type = [c for c in conditions if cond_type in c]
            if conds_of_type:
                sub_queries.append({
                    'query': f"{query} (focus on {cond_type})",
                    'priority': 0.6,
                    'filters': conds_of_type[0],
                    'focus': cond_type
                })

        sub_queries.sort(key=lambda x: x['priority'], reverse=True)

        logger.info(f"ðŸ”€ Split query into {len(sub_queries)} sub-queries")
        return sub_queries[:3]

    @staticmethod
    def _calculate_complexity(query: str) -> float:
        """Calculate how complex a query is"""
        complexity = 0.0

        aspects = {
            'price': ['giÃ¡', 'tiá»n', 'chi phÃ­', 'Ä‘áº¯t', 'ráº»'],
            'duration': ['ngÃ y', 'Ä‘Ãªm', 'bao lÃ¢u', 'thá»i gian'],
            'location': ['á»Ÿ', 'táº¡i', 'Ä‘áº¿n', 'vá»', 'Ä‘á»‹a Ä‘iá»ƒm'],
            'quality': ['tá»‘t', 'hay', 'Ä‘áº¹p', 'háº¥p dáº«n', 'thÃº vá»‹'],
            'type': ['thiá»n', 'khÃ­ cÃ´ng', 'retreat', 'chá»¯a lÃ nh'],
        }

        query_lower = query.lower()

        distinct_aspects = 0
        for aspect, keywords in aspects.items():
            if any(keyword in query_lower for keyword in keywords):
                distinct_aspects += 1

        complexity += distinct_aspects * 0.5
        complexity += min(len(query.split()) / 10, 1.0)

        conjunctions = ['vÃ ', 'vá»›i', 'cÃ³', 'cho', 'mÃ ', 'nhÆ°ng']
        for conj in conjunctions:
            if conj in query_lower:
                complexity += 0.3

        return complexity

    @staticmethod
    def _extract_conditions(query: str) -> List[Dict[str, Any]]:
        """Extract individual conditions from query"""
        conditions = []

        filters = MandatoryFilterSystem.extract_filters(query)

        if filters.price_min is not None or filters.price_max is not None:
            price_cond = {'price': {}}
            if filters.price_min is not None:
                price_cond['price']['min'] = filters.price_min
            if filters.price_max is not None:
                price_cond['price']['max'] = filters.price_max
            conditions.append(price_cond)

        if filters.duration_min is not None or filters.duration_max is not None:
            duration_cond = {'duration': {}}
            if filters.duration_min is not None:
                duration_cond['duration']['min'] = filters.duration_min
            if filters.duration_max is not None:
                duration_cond['duration']['max'] = filters.duration_max
            conditions.append(duration_cond)

        if filters.location:
            conditions.append({'location': filters.location})
        if filters.near_location:
            conditions.append({'near_location': filters.near_location})

        query_lower = query.lower()

        if any(word in query_lower for word in ['ráº»', 'giÃ¡ ráº»', 'tiáº¿t kiá»‡m']):
            conditions.append({'price_quality': 'budget'})
        if any(word in query_lower for word in ['cao cáº¥p', 'sang', 'premium']):
            conditions.append({'price_quality': 'premium'})

        if 'thiá»n' in query_lower:
            conditions.append({'activity_type': 'meditation'})
        if 'khÃ­ cÃ´ng' in query_lower:
            conditions.append({'activity_type': 'qigong'})
        if 'retreat' in query_lower:
            conditions.append({'activity_type': 'retreat'})
        if 'chá»¯a lÃ nh' in query_lower:
            conditions.append({'activity_type': 'healing'})

        tour_name_patterns = [
            r'tour\s+([^vÃ \s,]+)\s+vÃ \s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+vá»›i\s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+.*tour\s+([^\s,]+)',
        ]

        for pattern in tour_name_patterns:
            matches = re.finditer(pattern, query_lower)
            for match in matches:
                for i in range(1, 3):
                    if match.group(i):
                        tour_name = match.group(i).strip()
                        normalized_name = FuzzyMatcher.normalize_vietnamese(tour_name)
                        for name, idx in TOUR_NAME_TO_INDEX.items():
                            if normalized_name in name or name in normalized_name:
                                conditions.append({'specific_tour': idx})
                                logger.info(f"ðŸ” Extracted tour name from complex query: {tour_name} â†’ index {idx}")

        return conditions

    @staticmethod
    def _merge_conditions(conditions: List[Dict]) -> Dict[str, Any]:
        """Merge multiple conditions into one filter dict"""
        merged = {}

        for condition in conditions:
            for key, value in condition.items():
                if key in merged:
                    if isinstance(merged[key], dict) and isinstance(value, dict):
                        merged[key].update(value)
                    elif isinstance(merged[key], list) and isinstance(value, list):
                        merged[key].extend(value)
                    else:
                        if isinstance(value, dict) or (isinstance(value, str) and len(value) > len(str(merged[key]))):
                            merged[key] = value
                else:
                    merged[key] = value

        return merged

# =========== UPGRADE 6: FUZZY MATCHING (DATACLASS COMPATIBLE) ===========
class FuzzyMatcher:
    """
    UPGRADE 6: Handle misspellings and variations in tour names
    """

    SIMILARITY_THRESHOLD = 0.75

    @staticmethod
    def normalize_vietnamese(text: str) -> str:
        """
        Normalize Vietnamese text for fuzzy matching
        """
        if not text:
            return ""

        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')

        replacements = {
            'Ä‘': 'd',
            'khÃ´ng': 'ko',
            'khong': 'ko',
            'rá»“i': 'roi',
            'vá»›i': 'voi',
            'Ä‘Æ°á»£c': 'duoc',
            'má»™t': 'mot',
            'hai': '2',
            'ba': '3',
            'bá»‘n': '4',
            'nÄƒm': '5',
        }

        for old, new in replacements.items():
            text = text.replace(old, new)

        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()

        return text

    @staticmethod
    def find_similar_tours(query: str, tour_names: Dict[str, int]) -> List[Tuple[int, float]]:
        """
        Find tours with names similar to query
        """
        if not query or not tour_names:
            return []

        query_norm = FuzzyMatcher.normalize_vietnamese(query)
        if not query_norm:
            return []

        matches = []

        for tour_name, tour_idx in tour_names.items():
            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name)
            if not tour_norm:
                continue

            similarity = SequenceMatcher(None, query_norm, tour_norm).ratio()

            if query_norm in tour_norm or tour_norm in query_norm:
                similarity = min(similarity + 0.2, 1.0)

            query_words = set(query_norm.split())
            tour_words = set(tour_norm.split())
            common_words = query_words.intersection(tour_words)

            if common_words:
                word_boost = len(common_words) * 0.1
                similarity = min(similarity + word_boost, 1.0)

            if similarity >= FuzzyMatcher.SIMILARITY_THRESHOLD:
                matches.append((tour_idx, similarity))

        matches.sort(key=lambda x: x[1], reverse=True)

        logger.info(f"ðŸ” Fuzzy matching: '{query}' â†’ {len(matches)} matches")
        return matches

    @staticmethod
    def find_tour_by_partial_name(partial_name: str, tours_db: Dict[int, Tour]) -> List[int]:
        """
        Find tours by partial name match
        """
        if not partial_name or not tours_db:
            return []

        partial_norm = FuzzyMatcher.normalize_vietnamese(partial_name)
        matches = []

        for tour_idx, tour in tours_db.items():
            tour_name = tour.name or ""
            if not tour_name:
                continue

            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name)

            if partial_norm in tour_norm:
                match_ratio = len(partial_norm) / len(tour_norm) if tour_norm else 0
                matches.append((tour_idx, match_ratio))

        matches.sort(key=lambda x: x[1], reverse=True)

        return [idx for idx, _ in matches[:3]]

# =========== UPGRADE 7: STATE MACHINE (DATACLASS COMPATIBLE) ===========
class ConversationState(Enum):
    INITIAL = "initial"
    TOUR_SELECTED = "tour_selected"
    ASKING_DETAILS = "asking_details"
    COMPARING = "comparing"
    RECOMMENDATION = "recommendation"
    BOOKING = "booking"
    FAREWELL = "farewell"

class ConversationStateMachine:
    """
    UPGRADE 7: Track conversation state for better context
    """

    def __init__(self, session_id: str):
        self.session_id = session_id
        self.state = ConversationState.INITIAL
        self.context = ConversationContext(session_id=session_id)
        self.transitions = []
        self.created_at = datetime.utcnow()
        self.last_updated = datetime.utcnow()

    def update(self, user_message: str, bot_response: str, tour_indices: List[int] = None):
        """Update state based on new interaction"""
        self.last_updated = datetime.utcnow()
        self.context.update(user_message, bot_response, tour_indices)

        new_state = self._determine_state(user_message, bot_response)

        self.transitions.append({
            'timestamp': datetime.utcnow().isoformat(),
            'from': self.state.value,
            'to': new_state.value,
            'message': user_message[:100]
        })

        self.state = new_state

        logger.info(f"ðŸ”„ State update: {self.state.value} for session {self.session_id}")

    def _determine_state(self, user_message: str, bot_response: str) -> ConversationState:
        """Determine new state based on current interaction"""
        message_lower = user_message.lower()
        farewell_words = ['táº¡m biá»‡t', 'cáº£m Æ¡n', 'thanks', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            return ConversationState.FAREWELL

        tour_ref_patterns = [
            r'tour nÃ y', r'tour Ä‘Ã³', r'tour Ä‘ang nÃ³i', r'cÃ¡i tour',
            r'nÃ³', r'cÃ¡i Ä‘Ã³', r'cÃ¡i nÃ y', r'Ä‘áº¥y'
        ]

        if any(re.search(pattern, message_lower) for pattern in tour_ref_patterns):
            if self.context.current_tours:
                return ConversationState.TOUR_SELECTED
            elif self.context.last_successful_tours:
                self.context.current_tours = self.context.last_successful_tours
                return ConversationState.TOUR_SELECTED

        if 'so sÃ¡nh' in message_lower or 'sÃ¡nh' in message_lower:
            return ConversationState.COMPARING

        if any(word in message_lower for word in ['phÃ¹ há»£p', 'gá»£i Ã½', 'Ä‘á» xuáº¥t', 'tÆ° váº¥n', 'nÃªn chá»n']):
            return ConversationState.RECOMMENDATION

        if any(word in message_lower for word in ['Ä‘áº·t', 'booking', 'Ä‘Äƒng kÃ½', 'giá»¯ chá»—']):
            return ConversationState.BOOKING

        if self.context.current_tours:
            return ConversationState.ASKING_DETAILS

        return ConversationState.INITIAL

    def get_context_hint(self) -> str:
        """Get hint about current context for LLM prompt"""
        hints = []

        if self.state == ConversationState.TOUR_SELECTED and self.context.current_tours:
            tour_indices = self.context.current_tours
            if len(tour_indices) == 1:
                hints.append(f"User is asking about tour index {tour_indices[0]}")
            else:
                hints.append(f"User is asking about tours {tour_indices}")

        if self.context.user_preferences:
            prefs = []
            for key, value in self.context.user_preferences.items():
                prefs.append(f"{key}: {value}")
            if prefs:
                hints.append(f"User preferences: {', '.join(prefs)}")

        return "; ".join(hints) if hints else "No specific context"

    def extract_reference(self, message: str) -> List[int]:
        """Extract tour reference from message using conversation context"""
        message_lower = message.lower()

        if self.context.current_tours:
            for tour_idx in self.context.current_tours:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"ðŸ”„ State machine: Using current tour {tour_idx}")
                        return self.context.current_tours

        ref_patterns = [
            (r'tour nÃ y', 1.0),
            (r'tour Ä‘Ã³', 0.9),
            (r'tour Ä‘ang nÃ³i', 0.9),
            (r'cÃ¡i tour', 0.8),
            (r'nÃ³', 0.7),
            (r'Ä‘áº¥y', 0.7),
            (r'cÃ¡i Ä‘Ã³', 0.7),
        ]

        for pattern, confidence in ref_patterns:
            if re.search(pattern, message_lower):
                if self.context.current_tours:
                    logger.info(f"ðŸ”„ State machine: Resolved reference to {self.context.current_tours}")
                    return self.context.current_tours
                elif self.context.last_successful_tours:
                    logger.info(f"ðŸ”„ State machine: Using last successful tours {self.context.last_successful_tours}")
                    return self.context.last_successful_tours

        if self.context.mentioned_tours:
            recent_tours = list(self.context.mentioned_tours)
            for tour_idx in recent_tours[-3:]:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"ðŸ”„ State machine: Matched to recently mentioned tour {tour_idx}")
                        return [tour_idx]

        return []

# =========== UPGRADE 8: DEEP SEMANTIC ANALYSIS (DATACLASS COMPATIBLE) ===========
class SemanticAnalyzer:
    """
    UPGRADE 8: Deep understanding of user intent beyond keywords
    """

    USER_PROFILE_PATTERNS = {
        'age_group': [
            (r'ngÆ°á»i giÃ |ngÆ°á»i lá»›n tuá»•i|cao tuá»•i', 'senior'),
            (r'thanh niÃªn|tráº»|sinh viÃªn|há»c sinh', 'young'),
            (r'trung niÃªn|trung tuá»•i', 'middle_aged'),
            (r'gia Ä‘Ã¬nh.*tráº» em|tráº» nhá»|con nÃ­t', 'family_with_kids'),
        ],

        'group_type': [
            (r'má»™t mÃ¬nh|Ä‘i láº»|solo', 'solo'),
            (r'cáº·p Ä‘Ã´i|Ä‘Ã´i lá»©a|ngÆ°á»i yÃªu', 'couple'),
            (r'gia Ä‘Ã¬nh|bá»‘ máº¹ con', 'family'),
            (r'báº¡n bÃ¨|nhÃ³m báº¡n|há»™i báº¡n', 'friends'),
            (r'cÃ´ng ty|doanh nghiá»‡p|Ä‘á»“ng nghiá»‡p', 'corporate'),
        ],

        'interest_type': [
            (r'thiÃªn nhiÃªn|rá»«ng|cÃ¢y|cáº£nh quan', 'nature'),
            (r'lá»‹ch sá»­|di tÃ­ch|chiáº¿n tranh|tri Ã¢n', 'history'),
            (r'vÄƒn hÃ³a|cá»™ng Ä‘á»“ng|dÃ¢n tá»™c|truyá»n thá»‘ng', 'culture'),
            (r'thiá»n|tÃ¢m linh|tÄ©nh tÃ¢m|yoga', 'spiritual'),
            (r'khÃ­ cÃ´ng|sá»©c khá»e|chá»¯a lÃ nh|wellness', 'wellness'),
            (r'áº©m thá»±c|Ä‘á»“ Äƒn|mÃ³n ngon|Ä‘áº·c sáº£n', 'food'),
            (r'phiÃªu lÆ°u|máº¡o hiá»ƒm|khÃ¡m phÃ¡|tráº£i nghiá»‡m', 'adventure'),
        ],

        'budget_level': [
            (r'kinh táº¿|tiáº¿t kiá»‡m|ráº»|giÃ¡ tháº¥p', 'budget'),
            (r'trung bÃ¬nh|vá»«a pháº£i|pháº£i chÄƒng', 'midrange'),
            (r'cao cáº¥p|sang trá»ng|premium|Ä‘áº¯t', 'premium'),
        ],

        'physical_level': [
            (r'nháº¹ nhÃ ng|dá»… dÃ ng|khÃ´ng má»‡t', 'easy'),
            (r'vá»«a pháº£i|trung bÃ¬nh|bÃ¬nh thÆ°á»ng', 'moderate'),
            (r'thá»­ thÃ¡ch|khÃ³|má»‡t|leo nÃºi', 'challenging'),
        ],
    }

    @staticmethod
    def analyze_user_profile(message: str, current_context: ConversationContext = None) -> UserProfile:
        """
        Analyze message to build user profile
        """
        if current_context and hasattr(current_context, 'user_profile') and current_context.user_profile:
            profile = current_context.user_profile
        else:
            profile = UserProfile()

        message_lower = message.lower()

        for category, patterns in SemanticAnalyzer.USER_PROFILE_PATTERNS.items():
            for pattern, value in patterns:
                if re.search(pattern, message_lower):
                    if category == 'interests':
                        if value not in profile.interests:
                            profile.interests.append(value)
                            profile.confidence_scores[f'interest_{value}'] = 0.8
                    else:
                        setattr(profile, category, value)
                        profile.confidence_scores[category] = 0.8

        SemanticAnalyzer._infer_attributes(profile, message_lower)
        profile.overall_confidence = SemanticAnalyzer._calculate_confidence(profile)

        logger.info(f"ðŸ‘¤ User profile analysis: {profile}")
        return profile

    @staticmethod
    def _infer_attributes(profile: UserProfile, message_lower: str):
        """Infer additional attributes from context"""
        if not profile.age_group:
            if profile.group_type and 'family_with_kids' in profile.group_type:
                profile.age_group = 'middle_aged'
                profile.confidence_scores['age_group'] = 0.6
            elif 'senior' in message_lower or 'giÃ ' in message_lower:
                profile.age_group = 'senior'
                profile.confidence_scores['age_group'] = 0.7

        if not profile.physical_level:
            if 'adventure' in profile.interests:
                profile.physical_level = 'challenging'
                profile.confidence_scores['physical_level'] = 0.6
            elif 'spiritual' in profile.interests or 'wellness' in profile.interests:
                profile.physical_level = 'easy'
                profile.confidence_scores['physical_level'] = 0.6

        if not profile.budget_level:
            budget_keywords = {
                'budget': ['ráº»', 'tiáº¿t kiá»‡m', 'Ã­t tiá»n', 'kinh táº¿'],
                'premium': ['cao cáº¥p', 'sang', 'Ä‘áº¯t', 'premium']
            }

            for level, keywords in budget_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    profile.budget_level = level
                    profile.confidence_scores['budget_level'] = 0.7
                    break

    @staticmethod
    def _calculate_confidence(profile: UserProfile) -> float:
        """Calculate overall confidence in user profile"""
        if not profile.confidence_scores:
            return 0.0

        total = 0.0
        count = 0

        for key, score in profile.confidence_scores.items():
            total += score
            count += 1

        return total / max(count, 1)

    @staticmethod
    def match_tours_to_profile(profile: UserProfile, tours_db: Dict[int, Tour],
                              max_results: int = 5) -> List[Tuple[int, float, List[str]]]:
        """
        Match tours to user profile with explanation
        """
        matches = []

        for tour_idx, tour in tours_db.items():
            score = 0.0
            reasons = []

            tour_tags = tour.tags or []

            if profile.age_group:
                if profile.age_group == 'senior':
                    if any('easy' in tag for tag in tour_tags):
                        score += 0.3
                        reasons.append("phÃ¹ há»£p ngÆ°á»i lá»›n tuá»•i")
                    if any('nature' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("thiÃªn nhiÃªn nháº¹ nhÃ ng")

            if profile.interests:
                for interest in profile.interests:
                    tour_summary = (tour.summary or "").lower()
                    if (interest in tour_summary or
                        any(interest in tag for tag in tour_tags)):
                        score += 0.4
                        reasons.append(f"cÃ³ yáº¿u tá»‘ {interest}")

            if profile.budget_level:
                tour_price = tour.price or ""
                price_nums = re.findall(r'\d[\d,\.]+', tour_price)

                if price_nums:
                    try:
                        first_price = int(price_nums[0].replace(',', '').replace('.', ''))

                        if profile.budget_level == 'budget' and first_price < 2000000:
                            score += 0.3
                            reasons.append("giÃ¡ há»£p lÃ½")
                        elif profile.budget_level == 'premium' and first_price > 2500000:
                            score += 0.3
                            reasons.append("cao cáº¥p")
                        elif profile.budget_level == 'midrange' and 1500000 <= first_price <= 3000000:
                            score += 0.3
                            reasons.append("giÃ¡ vá»«a pháº£i")
                    except:
                        pass

            if profile.physical_level:
                if profile.physical_level == 'easy':
                    if any('easy' in tag or 'meditation' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng")

            if score > 0:
                matches.append((tour_idx, score, reasons))

        matches.sort(key=lambda x: x[1], reverse=True)

        return matches[:max_results]

# =========== UPGRADE 9: AUTO-VALIDATION SYSTEM (DATACLASS COMPATIBLE) ===========
class AutoValidator:
    """
    UPGRADE 9: Validate and correct information before returning
    """

    VALIDATION_RULES = {
        'duration': {
            'patterns': [
                r'(\d+)\s*ngÃ y\s*(\d+)\s*Ä‘Ãªm',
                r'(\d+)\s*ngÃ y',
                r'(\d+)\s*Ä‘Ãªm',
            ],
            'constraints': {
                'max_days': 7,
                'max_nights': 7,
                'valid_day_night_combos': [(1,0), (1,1), (2,1), (2,2), (3,2), (3,3)],
                'common_durations': ['1 ngÃ y', '2 ngÃ y 1 Ä‘Ãªm', '3 ngÃ y 2 Ä‘Ãªm']
            }
        },

        'price': {
            'patterns': [
                r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)',
                r'(\d[\d,\.]*)\s*-\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)?',
                r'(\d[\d,\.]*)\s*(Ä‘á»“ng|vnÄ‘|vnd)',
            ],
            'constraints': {
                'min_tour_price': 500000,
                'max_tour_price': 10000000,
                'common_ranges': [
                    (800000, 1500000),
                    (1500000, 2500000),
                    (2500000, 4000000),
                ]
            }
        },

        'location': {
            'patterns': [
                r'á»Ÿ\s+([^.,!?]+)',
                r'táº¡i\s+([^.,!?]+)',
                r'Ä‘áº¿n\s+([^.,!?]+)',
            ],
            'constraints': {
                'valid_locations': ['Huáº¿', 'Quáº£ng Trá»‹', 'Báº¡ch MÃ£', 'TrÆ°á»ng SÆ¡n', 'ÄÃ´ng HÃ ', 'Khe Sanh'],
                'max_length': 100
            }
        },
    }

    @staticmethod
    def validate_response(response: str) -> str:
        """
        Validate and correct response content
        """
        if not response:
            return response

        validated = response

        validated = AutoValidator._validate_duration(validated)
        validated = AutoValidator._validate_price(validated)
        validated = AutoValidator._validate_locations(validated)
        validated = AutoValidator._check_unrealistic_info(validated)

        if validated != response:
            validated = AutoValidator._add_validation_note(validated)

        return validated

    @staticmethod
    def _validate_duration(text: str) -> str:
        """Validate and correct duration information"""
        for pattern in AutoValidator.VALIDATION_RULES['duration']['patterns']:
            matches = list(re.finditer(pattern, text))
            for match in matches:
                try:
                    if match.lastindex == 2:
                        days = int(match.group(1))
                        nights = int(match.group(2))

                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']

                        valid_combos = constraints['valid_day_night_combos']
                        is_valid_combo = any(days == d2 and nights == n2 for d2, n2 in valid_combos)

                        if days > constraints['max_days'] or nights > constraints['max_nights']:
                            replacement = random.choice(constraints['common_durations'])
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"âš ï¸ Corrected unrealistic duration: {days} ngÃ y {nights} Ä‘Ãªm â†’ {replacement}")

                        elif not is_valid_combo:
                            valid_days = min(days, constraints['max_days'])
                            valid_nights = min(nights, constraints['max_nights'])
                            if abs(valid_days - valid_nights) > 1:
                                valid_nights = valid_days

                            replacement = f"{valid_days} ngÃ y {valid_nights} Ä‘Ãªm"
                            text = text.replace(match.group(0), replacement)
                            logger.info(f"ðŸ”„ Fixed duration combo: {replacement}")

                    elif match.lastindex == 1:
                        num = int(match.group(1))
                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']

                        if num > constraints['max_days']:
                            replacement = f"{constraints['max_days']} ngÃ y"
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"âš ï¸ Capped long duration: {num} â†’ {constraints['max_days']}")

                except (ValueError, IndexError):
                    continue

        return text

    @staticmethod
    def _validate_price(text: str) -> str:
        """Validate and correct price information"""
        for pattern in AutoValidator.VALIDATION_RULES['price']['patterns']:
            matches = list(re.finditer(pattern, text, re.IGNORECASE))
            for match in matches:
                try:
                    amount_str = match.group(1).replace(',', '').replace('.', '')
                    if not amount_str.isdigit():
                        continue

                    amount = int(amount_str)

                    unit = match.group(2).lower() if match.lastindex >= 2 else ''

                    if unit in ['triá»‡u', 'tr']:
                        amount = amount * 1000000
                    elif unit in ['k', 'nghÃ¬n']:
                        amount = amount * 1000

                    constraints = AutoValidator.VALIDATION_RULES['price']['constraints']

                    if amount < constraints['min_tour_price']:
                        replacement = "giÃ¡ há»£p lÃ½"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"âš ï¸ Corrected too-low price: {amount} â†’ {replacement}")

                    elif amount > constraints['max_tour_price']:
                        replacement = "giÃ¡ cao cáº¥p"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"âš ï¸ Corrected too-high price: {amount} â†’ {replacement}")

                except (ValueError, IndexError, AttributeError):
                    continue

        return text

    @staticmethod
    def _validate_locations(text: str) -> str:
        """Validate location names"""
        wrong_locations = {
            'hÃ  ná»™i': 'Huáº¿',
            'há»“ chÃ­ minh': 'Quáº£ng Trá»‹',
            'Ä‘Ã  náºµng': 'Báº¡ch MÃ£',
            'nha trang': 'TrÆ°á»ng SÆ¡n',
        }

        for wrong, correct in wrong_locations.items():
            if wrong in text.lower():
                text = text.replace(wrong, correct)
                text = text.replace(wrong.capitalize(), correct)
                logger.info(f"ðŸ”„ Corrected location: {wrong} â†’ {correct}")

        return text

    @staticmethod
    def _check_unrealistic_info(text: str) -> str:
        """Check for other unrealistic information"""
        unrealistic_patterns = [
            (r'\d+\s*giá»\s*bay', "thá»i gian di chuyá»ƒn"),
            (r'\d+\s*sao', "cháº¥t lÆ°á»£ng dá»‹ch vá»¥"),
            (r'\d+\s*táº§ng', "chá»— á»Ÿ"),
            (r'\d+\s*m\s*cao', "Ä‘á»‹a hÃ¬nh"),
        ]

        for pattern, replacement in unrealistic_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
                logger.info(f"ðŸ”„ Replaced unrealistic info with: {replacement}")

        return text

    @staticmethod
    def _add_validation_note(text: str) -> str:
        """Add note about information validation"""
        note = "\n\n*ThÃ´ng tin Ä‘Æ°á»£c cung cáº¥p dá»±a trÃªn dá»¯ liá»‡u hiá»‡n cÃ³. " \
               "Vui lÃ²ng liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ xÃ¡c nháº­n chi tiáº¿t chÃ­nh xÃ¡c nháº¥t.*"

        if note not in text:
            text += note

        return text

# =========== UPGRADE 10: TEMPLATE SYSTEM (DATACLASS COMPATIBLE) ===========
class TemplateSystem:
    """
    UPGRADE 10: Beautiful, structured responses for different question types
    """

    TEMPLATES = {
        'tour_list': {
            'header': "âœ¨ **DANH SÃCH TOUR RUBY WINGS** âœ¨\n\n",
            'item': "**{index}. {tour_name}** {emoji}\n"
                   "   ðŸ“… {duration}\n"
                   "   ðŸ“ {location}\n"
                   "   ðŸ’° {price}\n"
                   "   {summary}\n",
            'footer': "\nðŸ“ž **LiÃªn há»‡ Ä‘áº·t tour:** 0332510486\n"
                     "ðŸ“ **Ruby Wings Travel** - HÃ nh trÃ¬nh tráº£i nghiá»‡m Ä‘áº·c sáº¯c\n"
                     "ðŸ’¡ *Há»i chi tiáº¿t vá» báº¥t ká»³ tour nÃ o báº±ng cÃ¡ch nháº­p tÃªn tour*",
            'emoji_map': {
                '1 ngÃ y': 'ðŸŒ…',
                '2 ngÃ y': 'ðŸŒ„',
                '3 ngÃ y': 'ðŸ”ï¸',
                'default': 'âœ¨'
            }
        },

        'tour_detail': {
            'header': "ðŸŽ¯ **{tour_name}**\n\n",
            'sections': {
                'overview': "ðŸ“‹ **THÃ”NG TIN CHÃNH:**\n"
                          "   â±ï¸ Thá»i gian: {duration}\n"
                          "   ðŸ“ Äá»‹a Ä‘iá»ƒm: {location}\n"
                          "   ðŸ’° GiÃ¡ tour: {price}\n\n",
                'description': "ðŸ“– **MÃ” Táº¢ TOUR:**\n{summary}\n\n",
                'includes': "ðŸŽª **Lá»ŠCH TRÃŒNH & Dá»ŠCH Vá»¤:**\n{includes}\n\n",
                'accommodation': "ðŸ¨ **CHá»– á»ž:**\n{accommodation}\n\n",
                'meals': "ðŸ½ï¸ **Ä‚N Uá»NG:**\n{meals}\n\n",
                'transport': "ðŸš— **DI CHUYá»‚N:**\n{transport}\n\n",
                'notes': "ðŸ“ **GHI CHÃš:**\n{notes}\n\n",
            },
            'footer': "ðŸ“ž **Äáº¶T TOUR & TÆ¯ Váº¾N:** 0332510486\n"
                     "â­ *Tour phÃ¹ há»£p cho: {suitable_for}*",
            'default_values': {
                'duration': 'Äang cáº­p nháº­t',
                'location': 'Äang cáº­p nháº­t',
                'price': 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡',
                'summary': 'HÃ nh trÃ¬nh tráº£i nghiá»‡m Ä‘áº·c sáº¯c cá»§a Ruby Wings',
                'includes': 'Chi tiáº¿t lá»‹ch trÃ¬nh liÃªn há»‡ tÆ° váº¥n',
                'accommodation': 'Äang cáº­p nháº­t',
                'meals': 'Äang cáº­p nháº­t',
                'transport': 'Äang cáº­p nháº­t',
                'notes': 'Vui lÃ²ng liÃªn há»‡ Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t',
                'suitable_for': 'má»i Ä‘á»‘i tÆ°á»£ng',
            }
        },

        'comparison': {
            'header': "ðŸ“Š **SO SÃNH TOUR**\n\n",
            'table_header': "| TiÃªu chÃ­ | {tour1} | {tour2} |\n|----------|----------|----------|\n",
            'table_row': "| {criterion} | {value1} | {value2} |\n",
            'recommendation': "\nðŸ’¡ **Gá»¢I Ã Lá»°A CHá»ŒN:**\n{recommendations}\n",
            'footer': "\nðŸ“ž **TÆ° váº¥n chi tiáº¿t:** 0332510486\n"
                     "ðŸ¤” *Cáº§n so sÃ¡nh thÃªm tiÃªu chÃ­ nÃ o?*",
        },

        'recommendation': {
            'header': "ðŸŽ¯ **Äá»€ XUáº¤T TOUR PHÃ™ Há»¢P**\n\n",
            'top_recommendation': "ðŸ† **PHÃ™ Há»¢P NHáº¤T ({score}%)**\n"
                                "**{tour_name}**\n"
                                "   âœ… {reasons}\n"
                                "   ðŸ“… {duration} | ðŸ“ {location} | ðŸ’° {price}\n\n",
            'other_recommendations': "ðŸ“‹ **Lá»°A CHá»ŒN KHÃC:**\n",
            'other_item': "   â€¢ **{tour_name}** ({score}%)\n"
                         "     ðŸ“… {duration} | ðŸ“ {location}\n",
            'criteria': "\nðŸ” **TIÃŠU CHÃ Äá»€ XUáº¤T:**\n{criteria}\n",
            'footer': "\nðŸ“ž **LiÃªn há»‡ tÆ° váº¥n cÃ¡ nhÃ¢n hÃ³a:** 0332510486\n"
                     "ðŸ’¬ *Cho tÃ´i biáº¿t thÃªm sá»Ÿ thÃ­ch cá»§a báº¡n Ä‘á»ƒ Ä‘á» xuáº¥t chÃ­nh xÃ¡c hÆ¡n*",
        },

        'information': {
            'header': "â„¹ï¸ **THÃ”NG TIN:**\n\n",
            'content': "{content}\n",
            'sources': "\nðŸ“š *Nguá»“n thÃ´ng tin tá»« dá»¯ liá»‡u Ruby Wings*",
            'footer': "\nðŸ“ž **Hotline há»— trá»£:** 0332510486",
        },

        'greeting': {
            'template': "ðŸ‘‹ **Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI cá»§a Ruby Wings**\n\n"
                       "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:\n"
                       "â€¢ TÃ¬m hiá»ƒu vá» cÃ¡c tour tráº£i nghiá»‡m\n"
                       "â€¢ So sÃ¡nh cÃ¡c hÃ nh trÃ¬nh\n"
                       "â€¢ Äá» xuáº¥t tour phÃ¹ há»£p vá»›i báº¡n\n"
                       "â€¢ Cung cáº¥p thÃ´ng tin chi tiáº¿t vá» tour\n\n"
                       "ðŸ’¡ **VÃ­ dá»¥ báº¡n cÃ³ thá»ƒ há»i:**\n"
                       "- 'CÃ³ nhá»¯ng tour nÃ o?'\n"
                       "- 'Tour Báº¡ch MÃ£ giÃ¡ bao nhiÃªu?'\n"
                       "- 'Tour nÃ o phÃ¹ há»£p cho gia Ä‘Ã¬nh?'\n\n"
                       "HÃ£y cho tÃ´i biáº¿t báº¡n cáº§n gÃ¬ nhÃ©! ðŸ˜Š",
        },

        'farewell': {
            'template': "ðŸ™ **Cáº£m Æ¡n báº¡n Ä‘Ã£ trÃ² chuyá»‡n cÃ¹ng Ruby Wings!**\n\n"
                       "ChÃºc báº¡n má»™t ngÃ y trÃ n Ä‘áº§y nÄƒng lÆ°á»£ng vÃ  bÃ¬nh an.\n"
                       "Hy vá»ng sá»›m Ä‘Æ°á»£c Ä‘á»“ng hÃ nh cÃ¹ng báº¡n trong hÃ nh trÃ¬nh tráº£i nghiá»‡m sáº¯p tá»›i!\n\n"
                       "ðŸ“ž **LiÃªn há»‡ Ä‘áº·t tour:** 0332510486\n"
                       "ðŸŒ **Website:** rubywings.vn\n\n"
                       "Háº¹n gáº·p láº¡i! âœ¨",
        },
    }

    @staticmethod
    def render(template_name: str, **kwargs) -> str:
        """Render template with provided variables"""
        template_data = TemplateSystem.TEMPLATES.get(template_name)
        if not template_data:
            return kwargs.get('content', '')

        if template_name in ['greeting', 'farewell']:
            return template_data['template']

        response_parts = []

        if 'header' in template_data:
            header = template_data['header']
            for key, value in kwargs.items():
                header = header.replace(f'{{{key}}}', str(value))
            response_parts.append(header)

        if template_name == 'tour_list':
            response_parts.append(TemplateSystem._render_tour_list(template_data, kwargs))

        elif template_name == 'tour_detail':
            response_parts.append(TemplateSystem._render_tour_detail(template_data, kwargs))

        elif template_name == 'comparison':
            response_parts.append(TemplateSystem._render_comparison(template_data, kwargs))

        elif template_name == 'recommendation':
            response_parts.append(TemplateSystem._render_recommendation(template_data, kwargs))

        elif template_name == 'information':
            response_parts.append(TemplateSystem._render_information(template_data, kwargs))

        if 'footer' in template_data:
            footer = template_data['footer']
            for key, value in kwargs.items():
                footer = footer.replace(f'{{{key}}}', str(value))
            response_parts.append(footer)

        return '\n'.join(response_parts)

    @staticmethod
    def _render_tour_list(template_data: Dict, kwargs: Dict) -> str:
        """Render tour list template"""
        tours = kwargs.get('tours', [])
        if not tours:
            return "Hiá»‡n chÆ°a cÃ³ thÃ´ng tin tour."

        items = []
        for i, tour in enumerate(tours[:10], 1):
            duration = tour.duration or ''
            emoji = template_data['emoji_map'].get('default')
            for dur_pattern, dur_emoji in template_data['emoji_map'].items():
                if dur_pattern in duration.lower():
                    emoji = dur_emoji
                    break

            item_template = template_data['item']
            item = item_template.format(
                index=i,
                tour_name=tour.name or f'Tour #{i}',
                emoji=emoji or 'âœ¨',
                duration=duration or 'Äang cáº­p nháº­t',
                location=tour.location or 'Äang cáº­p nháº­t',
                price=tour.price or 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡',
                summary=(tour.summary or 'Tour tráº£i nghiá»‡m Ä‘áº·c sáº¯c')[:100] + '...'
            )
            items.append(item)

        return '\n'.join(items)

    @staticmethod
    def _render_tour_detail(template_data: Dict, kwargs: Dict) -> str:
        """Render tour detail template"""
        sections = []

        for section_name, section_template in template_data['sections'].items():
            value = kwargs.get(section_name, template_data['default_values'].get(section_name, ''))

            if value and value != template_data['default_values'].get(section_name):
                if isinstance(value, list):
                    if section_name == 'includes':
                        value = '\n'.join([f'   â€¢ {item}' for item in value[:5]])
                    else:
                        value = ', '.join(value[:3])

                section = section_template.format(**{section_name: value})
                sections.append(section)

        return '\n'.join(sections)

    @staticmethod
    def _render_comparison(template_data: Dict, kwargs: Dict) -> str:
        """Render comparison template"""
        comparison_table = []

        tour1_name = kwargs.get('tour1_name', 'Tour 1')[:20]
        tour2_name = kwargs.get('tour2_name', 'Tour 2')[:20]
        table_header = template_data['table_header'].format(tour1=tour1_name, tour2=tour2_name)
        comparison_table.append(table_header)

        criteria = kwargs.get('criteria', [])
        for criterion in criteria[:8]:
            row = template_data['table_row'].format(
                criterion=criterion.get('name', ''),
                value1=criterion.get('value1', 'N/A')[:20],
                value2=criterion.get('value2', 'N/A')[:20]
            )
            comparison_table.append(row)

        return '\n'.join(comparison_table)

    @staticmethod
    def _render_recommendation(template_data: Dict, kwargs: Dict) -> str:
        """Render recommendation template"""
        recommendation_text = []

        top_tour = kwargs.get('top_tour')
        if top_tour:
            top_text = template_data['top_recommendation'].format(
                score=int(top_tour.get('score', 0) * 100),
                tour_name=top_tour.get('name', ''),
                reasons=', '.join(top_tour.get('reasons', ['phÃ¹ há»£p'])[:3]),
                duration=top_tour.get('duration', ''),
                location=top_tour.get('location', ''),
                price=top_tour.get('price', 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡')
            )
            recommendation_text.append(top_text)

        other_tours = kwargs.get('other_tours', [])
        if other_tours:
            recommendation_text.append(template_data['other_recommendations'])

            for tour in other_tours[:2]:
                other_item = template_data['other_item'].format(
                    tour_name=tour.get('name', ''),
                    score=int(tour.get('score', 0) * 100),
                    duration=tour.get('duration', ''),
                    location=tour.get('location', '')
                )
                recommendation_text.append(other_item)

        return '\n'.join(recommendation_text)

    @staticmethod
    def _render_information(template_data: Dict, kwargs: Dict) -> str:
        """Render information template"""
        content = kwargs.get('content', '')
        if not content:
            return ""

        info_text = template_data['content'].format(content=content)

        if kwargs.get('has_sources'):
            info_text += template_data['sources']

        return info_text

# =========== TOUR DATABASE BUILDER (USING Tour DATACLASS) ===========
def load_knowledge():
    """Load knowledge base from JSON file with fallback"""
    global KNOW, TOURS_DB, TOUR_NAME_TO_INDEX, FLAT_TEXTS, MAPPING

    try:
        # Multiple possible paths
        possible_paths = [
            "data/knowledge.json",
            "knowledge.json",
            "src/data/knowledge.json",
            "/opt/render/project/src/data/knowledge.json",
            os.path.join(os.path.dirname(__file__), "data/knowledge.json"),
        ]

        knowledge_path = None
        for path in possible_paths:
            if os.path.exists(path):
                knowledge_path = path
                logger.info(f"ðŸ“‚ Found knowledge.json at: {path}")
                break

        if not knowledge_path:
            logger.error("âŒ Cannot find knowledge.json in any path")
            logger.error(f"   Current dir: {os.getcwd()}")
            logger.error(f"   Files in current dir: {os.listdir('.')}")
            if os.path.exists("data"):
                logger.error(f"   Files in data dir: {os.listdir('data')}")
            return

        # Load and parse JSON
        with open(knowledge_path, "r", encoding="utf-8") as f:
            KNOW = json.load(f)

        logger.info(f"ðŸ“Š Knowledge loaded: {len(KNOW.get('tours', []))} tours")

        # Reset databases
        TOURS_DB.clear()
        TOUR_NAME_TO_INDEX.clear()
        FLAT_TEXTS.clear()
        MAPPING.clear()

        # Process tours
        tours = KNOW.get("tours", [])
        for idx, tour_data in enumerate(tours):
            try:
                # Debug: Log first tour structure
                if idx == 0:
                    logger.info(f"ðŸ·ï¸ First tour data keys: {list(tour_data.keys())}")

                # Create Tour object vá»›i trÆ°á»ng index
                tour = Tour(
                    index=idx,
                    name=tour_data.get("tour_name", "").strip(),
                    summary=tour_data.get("summary", ""),
                    location=tour_data.get("location", ""),
                    duration=tour_data.get("duration", ""),
                    price=tour_data.get("price", ""),
                    includes=tour_data.get("includes", []),
                    notes=tour_data.get("notes", ""),
                    style=tour_data.get("style", ""),
                    transport=tour_data.get("transport", ""),
                    accommodation=tour_data.get("accommodation", ""),
                    meals=tour_data.get("meals", ""),
                    event_support=tour_data.get("event_support", ""),
                    tags=tour_data.get("tags", []),
                )

                # Äáº£m báº£o thuá»™c tÃ­nh is_tour tá»“n táº¡i (phÃ²ng trÆ°á»ng há»£p class Tour chÆ°a cÃ³ default)
                if not hasattr(tour, 'is_tour'):
                    tour.is_tour = True

                # ÄÃ¡nh dáº¥u tour áº£o (ná»™i dung giá»›i thiá»‡u, vÄƒn hoÃ¡ tá»• chá»©c, khÃ´ng pháº£i tour du lá»‹ch)
                if any(keyword in tour.name.lower() for keyword in [
                    "giá»›i thiá»‡u ruby wings",
                    "vÄƒn hoÃ¡ tá»• chá»©c",
                    "hÃ nh vi chuáº©n ruby wings",
                    "ná»™i dung vÄƒn hoÃ¡ â€“ khÃ´ng pháº£i tour",
                    "giá»›i thiá»‡u Ä‘Ã´i cÃ¡nh ruby"
                ]):
                    tour.is_tour = False
                    logger.info(f"ðŸš« Marked as non-tour: '{tour.name}' (idx={idx})")

                # Store in databases
                TOURS_DB[idx] = tour

                # Create normalized name mapping â€“ CHá»ˆ INDEX TOUR THáº¬T
                if tour.name and tour.is_tour:
                    norm_name = normalize_tour_key(tour.name)
                    TOUR_NAME_TO_INDEX[norm_name] = idx
                    logger.debug(f"ðŸ“Œ Indexed tour: '{norm_name}' -> idx {idx}")
                else:
                    logger.debug(f"â­ï¸ Skipped indexing non-tour: '{tour.name}'")

                # Add to flat texts for FAISS
                flat_data = flatten_json({"tours": [tour_data]})
                if flat_data:
                    FLAT_TEXTS.extend([item["text"] for item in flat_data])
                    MAPPING.extend(flat_data)

            except Exception as e:
                logger.error(f"âŒ Error processing tour {idx}: {e}")
                continue

        logger.info(f"âœ… Processed {len(TOURS_DB)} tours, {len(FLAT_TEXTS)} passages")
        # Log TOUR_NAME_TO_INDEX for debugging
        logger.info(f"âœ… TOUR_NAME_TO_INDEX initialized with {len(TOUR_NAME_TO_INDEX)} entries")
        # Log 5 tÃªn Ä‘áº§u tiÃªn
        for i, (name, idx) in enumerate(list(TOUR_NAME_TO_INDEX.items())[:5]):
            logger.info(f"   {i+1}. '{name}' -> tour index {idx}")

        if len(TOURS_DB) == 0:
            logger.error("âŒ NO tours loaded! Check knowledge.json structure")

    except Exception as e:
        logger.error(f"âŒ load_knowledge error: {e}")
        traceback.print_exc()

def flatten_json(obj: Any, path: str = "") -> List[Dict]:
    """Flatten JSON object for indexing"""
    items = []
    if isinstance(obj, dict):
        for key, value in obj.items():
            new_path = f"{path}.{key}" if path else key
            items.extend(flatten_json(value, new_path))
    elif isinstance(obj, list):
        for i, item in enumerate(obj):
            new_path = f"{path}[{i}]"
            items.extend(flatten_json(item, new_path))
    else:
        if obj and isinstance(obj, (str, int, float, bool)):
            items.append({"path": path, "text": str(obj)})
    return items

def index_tour_names():
    """Build tour name to index mapping"""
    global TOUR_NAME_TO_INDEX
    TOUR_NAME_TO_INDEX = {}

    for m in MAPPING:
        if not isinstance(m, dict):
            continue  # defensive only

        path = m.get("path", "")
        if path.endswith(".tour_name"):
            txt = m.get("text", "") or ""
            norm = normalize_text_simple(txt)
            if not norm:
                continue

            match = re.search(r"\[(\d+)\]", path)
            if match:
                idx = int(match.group(1))
                prev = TOUR_NAME_TO_INDEX.get(norm)
                if prev is None:
                    TOUR_NAME_TO_INDEX[norm] = idx
                else:
                    # tÃ¬m tour_name cÅ© Ä‘á»ƒ so Ä‘á»™ dÃ i text
                    existing_txt = ""
                    for m2 in MAPPING:
                        if not isinstance(m2, dict):
                            continue
                        p2 = m2.get("path", "")
                        if (
                            re.search(rf"\[{prev}\]", p2)
                            and ".tour_name" in p2
                        ):
                            existing_txt = m2.get("text", "")
                            break

                    if len(txt) > len(existing_txt):
                        TOUR_NAME_TO_INDEX[norm] = idx

    logger.info(f"ðŸ“ Indexed {len(TOUR_NAME_TO_INDEX)} tour names")

def build_tours_db():
    """Build structured tour database from MAPPING using Tour dataclass"""
    global TOURS_DB, TOUR_TAGS

    TOURS_DB.clear()
    TOUR_TAGS.clear()

    # First pass: collect all fields for each tour
    for m in MAPPING:
        if not isinstance(m, dict):
            continue  # defensive only

        path = m.get("path", "")
        text = m.get("text", "")

        if not path or not text:
            continue

        tour_match = re.search(r'tours\[(\d+)\]', path)
        if not tour_match:
            continue

        tour_idx = int(tour_match.group(1))

        field_match = re.search(
            r'tours\[\d+\]\.(\w+)(?:\[\d+\])?',
            path
        )
        if not field_match:
            continue

        field_name = field_match.group(1)

        # Initialize tour entry
        if tour_idx not in TOURS_DB:
            TOURS_DB[tour_idx] = Tour(index=tour_idx)

        # Update field in Tour object
        tour_obj = TOURS_DB[tour_idx]
        if field_name == 'tour_name':
            tour_obj.name = text
        elif field_name == 'duration':
            tour_obj.duration = text
        elif field_name == 'location':
            tour_obj.location = text
        elif field_name == 'price':
            tour_obj.price = text
        elif field_name == 'summary':
            tour_obj.summary = text
        elif field_name == 'includes':
            if isinstance(tour_obj.includes, list):
                tour_obj.includes.append(text)
            else:
                tour_obj.includes = [text]
        elif field_name == 'accommodation':
            tour_obj.accommodation = text
        elif field_name == 'meals':
            tour_obj.meals = text
        elif field_name == 'transport':
            tour_obj.transport = text
        elif field_name == 'notes':
            tour_obj.notes = text
        elif field_name == 'style':
            tour_obj.style = text

    # Second pass: generate tags and metadata
    for tour_idx, tour_obj in TOURS_DB.items():
        tags = []

        # Location tags
        if tour_obj.location:
            locations = [loc.strip() for loc in tour_obj.location.split(",") if loc.strip()]
            tags.extend([f"location:{loc}" for loc in locations[:2]])

        # Duration tags
        if tour_obj.duration:
            duration_lower = tour_obj.duration.lower()
            if "1 ngÃ y" in duration_lower:
                tags.append("duration:1day")
            elif "2 ngÃ y" in duration_lower:
                tags.append("duration:2day")
            elif "3 ngÃ y" in duration_lower:
                tags.append("duration:3day")
            else:
                day_match = re.search(r'(\d+)\s*ngÃ y', duration_lower)
                if day_match:
                    days = int(day_match.group(1))
                    tags.append(f"duration:{days}day")

        # Price tags
        if tour_obj.price:
            price_nums = re.findall(r'[\d,\.]+', tour_obj.price)
            if price_nums:
                try:
                    clean_nums = []
                    for p in price_nums[:2]:
                        p_clean = p.replace(',', '').replace('.', '')
                        if p_clean.isdigit():
                            clean_nums.append(int(p_clean))

                    if clean_nums:
                        avg_price = sum(clean_nums) / len(clean_nums)
                        if avg_price < 1000000:
                            tags.append("price:budget")
                        elif avg_price < 2000000:
                            tags.append("price:midrange")
                        else:
                            tags.append("price:premium")
                except:
                    pass

        # Style/theme tags
        text_to_check = (tour_obj.style + " " + (tour_obj.summary or '')).lower()

        theme_keywords = {
            'meditation': ['thiá»n', 'chÃ¡nh niá»‡m', 'tÃ¢m linh'],
            'history': ['lá»‹ch sá»­', 'di tÃ­ch', 'chiáº¿n tranh', 'tri Ã¢n'],
            'nature': ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi', 'cÃ¢y'],
            'culture': ['vÄƒn hÃ³a', 'cá»™ng Ä‘á»“ng', 'dÃ¢n tá»™c'],
            'wellness': ['khÃ­ cÃ´ng', 'sá»©c khá»e', 'chá»¯a lÃ nh'],
            'adventure': ['phiÃªu lÆ°u', 'máº¡o hiá»ƒm', 'khÃ¡m phÃ¡'],
        }

        for theme, keywords in theme_keywords.items():
            if any(keyword in text_to_check for keyword in keywords):
                tags.append(f"theme:{theme}")

        # Destination tags from tour name
        if tour_obj.name:
            name_lower = tour_obj.name.lower()
            if "báº¡ch mÃ£" in name_lower:
                tags.append("destination:bachma")
            if "trÆ°á»ng sÆ¡n" in name_lower:
                tags.append("destination:truongson")
            if "quáº£ng trá»‹" in name_lower:
                tags.append("destination:quangtri")
            if "huáº¿" in name_lower:
                tags.append("destination:hue")

        # Update Tour object tags
        tour_obj.tags = list(set(tags))
        TOUR_TAGS[tour_idx] = tour_obj.tags

        # Calculate completeness score
        completeness = 0
        important_fields = ['name', 'duration', 'location', 'price', 'summary']
        for field in important_fields:
            if getattr(tour_obj, field, None):
                completeness += 1

        tour_obj.completeness_score = completeness / len(important_fields)

    logger.info(f"âœ… Built tours database: {len(TOURS_DB)} tours with tags")

def get_passages_by_field(field_name: str, limit: int = 50,
                         tour_indices: Optional[List[int]] = None) -> List[Tuple[float, Dict]]:
    """
    Get passages for a specific field
    """
    exact_matches = []
    global_matches = []

    for m in MAPPING:
        if not isinstance(m, dict):
            continue  # defensive only

        path = m.get("path", "")
        if path.endswith(f".{field_name}") or f".{field_name}" in path:
            is_exact_match = False
            if tour_indices:
                for ti in tour_indices:
                    if f"[{ti}]" in path:
                        is_exact_match = True
                        break

            if is_exact_match:
                exact_matches.append((2.0, m))
            elif not tour_indices:
                global_matches.append((1.0, m))

    all_results = exact_matches + global_matches
    all_results.sort(key=lambda x: x[0], reverse=True)
    return all_results[:limit]

# =========== CACHE SYSTEM (DATACLASS COMPATIBLE) ===========
class CacheSystem:
    """Simple caching system for responses"""

    @staticmethod
    def get_cache_key(query: str, context_hash: str = "") -> str:
        """Generate cache key"""
        key_parts = [query]
        if context_hash:
            key_parts.append(context_hash)
        return hashlib.md5("|".join(key_parts).encode()).hexdigest()

    @staticmethod
    def get(key: str, ttl_seconds: int = 300):
        """Get item from cache"""
        with _cache_lock:
            if key in _response_cache:
                cache_entry = _response_cache[key]
                if not cache_entry.is_expired():
                    logger.info(f"ðŸ’¾ Cache hit for key: {key[:20]}...")
                    return cache_entry.value
                else:
                    del _response_cache[key]
            return None

    @staticmethod
    def set(key: str, value: Any):
        """Set item in cache"""
        with _cache_lock:
            cache_entry = CacheEntry(
                key=key,
                value=value,
                created_at=datetime.utcnow(),
                ttl_seconds=UpgradeFlags.get_all_flags().get("CACHE_TTL_SECONDS", 300)
            )
            _response_cache[key] = cache_entry

            if len(_response_cache) > 1000:
                sorted_items = sorted(_response_cache.items(),
                                     key=lambda x: x[1].created_at)
                for old_key in [k for k, _ in sorted_items[:200]]:
                    if old_key in _response_cache:
                        del _response_cache[old_key]

# =========== EMBEDDING FUNCTIONS (MEMORY OPTIMIZED) ===========
@lru_cache(maxsize=128 if IS_LOW_RAM else 1000)
def embed_text(text: str) -> Tuple[List[float], int]:
    """Embed text using OpenAI or fallback (with memory optimization)"""
    if not text:
        return [], 0

    text = text[:2000]

    if client:
        try:
            response = client.embeddings.create(
                model=EMBEDDING_MODEL,
                input=text
            )
            if response.data:
                embedding = response.data[0].embedding
                return embedding, len(embedding)
        except Exception as e:
            logger.error(f"OpenAI embedding error: {e}")

    # Fallback: deterministic hash-based embedding
    h = hash(text) % (10 ** 12)
    dim = 1536
    embedding = [(float((h >> (i % 32)) & 0xFF) + (i % 7)) / 255.0
                 for i in range(dim)]

    return embedding, dim

def query_index(query: str, top_k: int = TOP_K) -> List[Tuple[float, Dict]]:
    """Query the index"""
    if not query or INDEX is None:
        return []

    emb, _ = embed_text(query)
    if not emb:
        return []

    vec = np.array(emb, dtype="float32").reshape(1, -1)
    vec = vec / (np.linalg.norm(vec) + 1e-12)

    try:
        if HAS_FAISS and isinstance(INDEX, faiss.Index):
            D, I = INDEX.search(vec, top_k)
        else:
            D, I = INDEX.search(vec, top_k)

        results = []
        for score, idx in zip(D[0], I[0]):
            if 0 <= idx < len(MAPPING):
                m = MAPPING[idx]
                if isinstance(m, dict):        # defensive only
                    results.append((float(score), m))

        return results
    except Exception as e:
        logger.error(f"Index search error: {e}")
        return []

class NumpyIndex:
    """Simple numpy-based index with safe numpy handling"""

    def __init__(self, mat=None):
        if NUMPY_AVAILABLE:
            if mat is None:
                self.mat = np.empty((0, 0), dtype="float32")
            else:
                # Force numpy float32 2D
                self.mat = np.asarray(mat, dtype="float32")
                if self.mat.ndim == 1:
                    self.mat = self.mat.reshape(1, -1)
        else:
            self.mat = mat if mat is not None else []

        # SAFE dimension detection (no numpy truth check)
        if NUMPY_AVAILABLE:
            if self.mat.shape[0] > 0 and self.mat.ndim == 2:
                self.dim = int(self.mat.shape[1])
            else:
                self.dim = 0
            self.size = int(self.mat.shape[0])
        else:
            self.size = len(self.mat)
            self.dim = len(self.mat[0]) if self.size > 0 else 0

    def is_empty(self):
        if NUMPY_AVAILABLE:
            return self.mat.shape[0] == 0
        return len(self.mat) == 0

    def search(self, query_vec, k=5):
        if self.is_empty():
            return [], []

        if NUMPY_AVAILABLE:
            q = np.asarray(query_vec, dtype="float32").reshape(1, -1)
            sims = np.dot(self.mat, q.T).reshape(-1)
            topk = np.argsort(-sims)[:k]
            return sims[topk].tolist(), topk.tolist()
        else:
            return [], []

    def search(self, qvec, k):
        if not self.mat or (NUMPY_AVAILABLE and self.mat.shape[0] == 0) or (not NUMPY_AVAILABLE and len(self.mat) == 0):
            # Return empty results
            return np.array([[]]), np.array([[]], dtype=np.int64)

        q = np.array(qvec).flatten()

        if NUMPY_AVAILABLE:
            # Use numpy if available
            q = q / (np.linalg.norm(q) + 1e-12)
            m = self.mat / (np.linalg.norm(self.mat, axis=1, keepdims=True) + 1e-12)
            sims = np.dot(q, m.T)
            idx = np.argsort(-sims)[:k]
            scores = sims[idx]
        else:
            # Fallback calculation
            q_norm = q / (sum(x*x for x in q)**0.5 + 1e-12)
            scores = []
            for i, row in enumerate(self.mat):
                row_norm = row / (sum(x*x for x in row)**0.5 + 1e-12)
                sim = sum(q_norm[j] * row_norm[j] for j in range(min(len(q_norm), len(row_norm))))
                scores.append((sim, i))

            scores.sort(key=lambda x: x[0], reverse=True)
            top_k = scores[:k]
            if top_k:
                scores_arr = np.array([s[0] for s in top_k])
                idx_arr = np.array([s[1] for s in top_k])
            else:
                scores_arr = np.array([])
                idx_arr = np.array([], dtype=np.int64)

            return scores_arr.reshape(1, -1), idx_arr.reshape(1, -1)

        return scores.reshape(1, -1), idx.reshape(1, -1)

    def save(self, path):
        if NUMPY_AVAILABLE:
            np.savez_compressed(path, mat=self.mat)
        else:
            logger.warning(f"âš ï¸ Cannot save index without NumPy: {path}")

    @classmethod
    def load(cls, path):
        if NUMPY_AVAILABLE:
            try:
                arr = np.load(path)
                return cls(arr['mat'])
            except Exception as e:
                logger.error(f"Failed to load numpy index: {e}")
                return cls()
        else:
            logger.warning(f"âš ï¸ Cannot load index without NumPy: {path}")
            return cls()

def build_index(force_rebuild: bool = False) -> bool:
    """Build or load FAISS/numpy index"""
    global INDEX, EMBEDDING_MODEL

    with INDEX_LOCK:
        # Try to load existing index
        if not force_rebuild:
            if FAISS_ENABLED and HAS_FAISS and os.path.exists(FAISS_INDEX_PATH):
                try:
                    INDEX = faiss.read_index(FAISS_INDEX_PATH)
                    logger.info(f"âœ… Loaded FAISS index from {FAISS_INDEX_PATH}")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load FAISS index: {e}")

            # Try numpy fallback
            if os.path.exists(FALLBACK_VECTORS_PATH):
                try:
                    arr = np.load(FALLBACK_VECTORS_PATH)
                    INDEX = NumpyIndex(arr['mat'])
                    logger.info("âœ… Loaded numpy index")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load numpy index: {e}")

        # Build new index
        if not FLAT_TEXTS:
            logger.warning("No texts to index")
            return False

        logger.info(f"ðŸ”¨ Building index for {len(FLAT_TEXTS)} passages...")

        # Generate embeddings
        vectors = []
        dims = None

        for text in FLAT_TEXTS:
            emb, d = embed_text(text)
            if emb:
                if dims is None:
                    dims = len(emb)
                vectors.append(np.array(emb, dtype="float32"))

        if not vectors:
            logger.error("No embeddings generated")
            return False

        # Create index
        mat = np.vstack(vectors)
        mat = mat / (np.linalg.norm(mat, axis=1, keepdims=True) + 1e-12)

        if FAISS_ENABLED and HAS_FAISS:
            INDEX = faiss.IndexFlatIP(dims)
            INDEX.add(mat)
            try:
                faiss.write_index(INDEX, FAISS_INDEX_PATH)
                logger.info(f"âœ… Saved FAISS index to {FAISS_INDEX_PATH}")
            except Exception as e:
                logger.error(f"Failed to save FAISS index: {e}")
        else:
            INDEX = NumpyIndex(mat)
            try:
                INDEX.save(FALLBACK_VECTORS_PATH)
                logger.info(f"âœ… Saved numpy index to {FALLBACK_VECTORS_PATH}")
            except Exception as e:
                logger.error(f"Failed to save numpy index: {e}")

        logger.info(f"âœ… Index built: {len(vectors)} vectors, {dims} dimensions")
        return True

# =========== TOUR FIELD FORMATTERS ===========
def format_tour_price_response(tour):
    """Format price information for a tour"""
    logger.info(f"ðŸ”Ž format_tour_price_response called for tour index: {getattr(tour, 'index', 'N/A')}, name: '{getattr(tour, 'name', 'N/A')}'")
    price_value = getattr(tour, 'price', None)
    logger.info(f"   price attribute exists: {hasattr(tour, 'price')}, value: '{price_value}'")

    if hasattr(tour, 'price') and tour.price:
        logger.info(f"âœ… Price found, returning formatted response")
        return f"ðŸ’° **GIÃ TOUR: {tour.name}** ðŸ’°\n\n{tour.price}"

    logger.warning(f"âš ï¸ No price data for tour: {getattr(tour, 'name', 'Unknown')}")
    return None

def format_tour_program_response(tour) -> str:
    """Build detailed response from knowledge fields (12 fields + event_support)."""
    if not tour:
        return ""

    name = getattr(tour, 'name', '') or 'Tour'
    summary = getattr(tour, 'summary', '') or ''
    location = getattr(tour, 'location', '') or ''
    duration = getattr(tour, 'duration', '') or ''
    price = getattr(tour, 'price', '') or ''
    includes = getattr(tour, 'includes', []) or []
    notes = getattr(tour, 'notes', '') or ''
    style = getattr(tour, 'style', '') or ''
    transport = getattr(tour, 'transport', '') or ''
    accommodation = getattr(tour, 'accommodation', '') or ''
    meals = getattr(tour, 'meals', '') or ''
    event_support = getattr(tour, 'event_support', '') or ''

    lines = [f"ðŸ“˜ **CHÆ¯Æ NG TRÃŒNH: {name}**"]
    if summary:
        lines.append(f"- Tá»•ng quan: {summary}")
    if location:
        lines.append(f"- Äá»‹a Ä‘iá»ƒm: {location}")
    if duration:
        lines.append(f"- Thá»i lÆ°á»£ng: {duration}")
    if price:
        lines.append(f"- GiÃ¡: {price}")
    if style:
        lines.append(f"- Phong cÃ¡ch: {style}")
    if transport:
        lines.append(f"- PhÆ°Æ¡ng tiá»‡n: {transport}")
    if accommodation:
        lines.append(f"- LÆ°u trÃº: {accommodation}")
    if meals:
        lines.append(f"- Bá»¯a Äƒn: {meals}")

    if includes:
        lines.append("- Lá»‹ch trÃ¬nh/bao gá»“m:")
        for item in includes[:12]:
            lines.append(f"  â€¢ {item}")

    if notes:
        lines.append(f"- LÆ°u Ã½: {notes}")
    if event_support:
        lines.append(f"- Há»— trá»£ Ä‘oÃ n: {event_support}")

    lines.append("ðŸ“ž Hotline: 0332510486")
    return "\n".join(lines)

def format_tour_location_response(tour):
    """Format location information for a tour"""
    if hasattr(tour, 'location') and tour.location:
        return f"ðŸ“ **Äá»ŠA ÄIá»‚M: {tour.name}** ðŸ“\n\n{tour.location}"
    return None

def format_tour_duration_response(tour):
    """Format duration information for a tour"""
    if hasattr(tour, 'duration') and tour.duration:
        return f"â±ï¸ **THá»œI GIAN: {tour.name}** â±ï¸\n\n{tour.duration}"
    return None

def format_tour_includes_response(tour):
    """Format includes (bao gá»“m) information for a tour"""
    if hasattr(tour, 'includes') and tour.includes:
        includes_list = tour.includes if isinstance(tour.includes, list) else [tour.includes]
        formatted = f"ðŸ“‹ **Dá»ŠCH Vá»¤ BAO Gá»’M - {tour.name}** ðŸ“‹\n\n"
        for item in includes_list:
            formatted += f"â€¢ {item}\n"
        return formatted
    return None

def format_tour_notes_response(tour):
    """Format notes (lÆ°u Ã½) information for a tour"""
    if hasattr(tour, 'notes') and tour.notes:
        return f"ðŸ“Œ **LÆ¯U Ã: {tour.name}** ðŸ“Œ\n\n{tour.notes}"
    return None

def format_tour_style_response(tour):
    """Format style (phong cÃ¡ch) information for a tour"""
    if hasattr(tour, 'style') and tour.style:
        return f"ðŸŽ¯ **PHONG CÃCH TOUR: {tour.name}** ðŸŽ¯\n\n{tour.style}"
    return None

def format_tour_transport_response(tour):
    """Format transport (phÆ°Æ¡ng tiá»‡n) information for a tour"""
    if hasattr(tour, 'transport') and tour.transport:
        return f"ðŸš **PHÆ¯Æ NG TIá»†N: {tour.name}** ðŸš\n\n{tour.transport}"
    return None

def format_tour_accommodation_response(tour):
    """Format accommodation (nÆ¡i á»Ÿ) information for a tour"""
    if hasattr(tour, 'accommodation') and tour.accommodation:
        return f"ðŸ¨ **NÆ I á»ž: {tour.name}** ðŸ¨\n\n{tour.accommodation}"
    return None

def format_tour_meals_response(tour):
    """Format meals (bá»¯a Äƒn) information for a tour"""
    if hasattr(tour, 'meals') and tour.meals:
        return f"ðŸ½ï¸ **Bá»®A Ä‚N: {tour.name}** ðŸ½ï¸\n\n{tour.meals}"
    return None

def format_tour_event_support_response(tour):
    """Format event support (há»— trá»£ sá»± kiá»‡n) information for a tour"""
    if hasattr(tour, 'event_support') and tour.event_support:
        return f"ðŸŽª **Há»– TRá»¢ Sá»° KIá»†N: {tour.name}** ðŸŽª\n\n{tour.event_support}"
    return None

# =========== FLASK APP CONFIG ===========
app = Flask(__name__)
app.json_encoder = EnhancedJSONEncoder  # Use custom JSON encoder
CORS(app, origins=CORS_ORIGINS, supports_credentials=True)

@app.before_request
def ensure_data_loaded():
    """Äáº£m báº£o dá»¯ liá»‡u Ä‘Æ°á»£c táº£i trÆ°á»›c khi xá»­ lÃ½ request"""
    global APP_INITIALIZED

    if not APP_INITIALIZED:
        try:
            logger.info("ðŸ”„ Khá»Ÿi táº¡o dá»¯ liá»‡u trÆ°á»›c request...")

            # Kiá»ƒm tra vÃ  táº¡o thÆ° má»¥c data
            if not os.path.exists("data"):
                os.makedirs("data")

            # Táº£i knowledge base
            load_knowledge()

            # Build index náº¿u cÃ³ dá»¯ liá»‡u
            if HAS_FAISS and len(FLAT_TEXTS) > 0:
                build_index()
                logger.info(f"âœ… ÄÃ£ build FAISS index: {len(FLAT_TEXTS)} passages")

            APP_INITIALIZED = True
            logger.info(f"âœ… HoÃ n thÃ nh khá»Ÿi táº¡o: {len(TOURS_DB)} tours")

        except Exception as e:
            logger.error(f"âŒ Lá»—i khá»Ÿi táº¡o: {e}")
            traceback.print_exc()
            # Váº«n Ä‘Ã¡nh dáº¥u Ä‘Ã£ khá»Ÿi táº¡o Ä‘á»ƒ khÃ´ng retry
            APP_INITIALIZED = True

@app.before_request
def track_pageview_once():
    try:
        if request.method != "GET":
            return
        if not request.accept_mimetypes.accept_html:
            return
        if not request.headers.get("X-RW-EVENT-ID"):
            return

        send_meta_pageview(request)

    except Exception:
        pass

# =========== CHAT ENDPOINT ===========
@app.route("/chat", methods=["POST"])
def chat_endpoint_ultimate():
    """
    Main chat endpoint vá»›i xá»­ lÃ½ AI thÃ´ng minh, context-aware máº¡nh máº½
    Xá»­ lÃ½ má»i loáº¡i cÃ¢u há»i tá»« Ä‘Æ¡n giáº£n Ä‘áº¿n phá»©c táº¡p
    """
    start_time = time.time()

    try:
        # ================== INITIALIZATION ==================
        data = request.get_json() or {}
        user_message = (data.get("message") or "").strip()

        # Khá»Ÿi táº¡o cÃ¡c biáº¿n cáº§n thiáº¿t
        tour_indices = []
        direct_tour_matches = []
        detected_intents = []
        mandatory_filters = FilterSet()  # DÃ¹ng cho filter-based search

        session_id = extract_session_id(data, request.remote_addr)

        if not user_message:
            return jsonify({
                "reply": "ðŸ‘‹ **Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI cá»§a Ruby Wings Travel**\n\n"
                        "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:\n"
                        "â€¢ TÃ¬m hiá»ƒu vá» 32 tour tráº£i nghiá»‡m Ä‘áº·c sáº¯c\n"
                        "â€¢ So sÃ¡nh cÃ¡c tour Ä‘á»ƒ chá»n phÃ¹ há»£p nháº¥t\n"
                        "â€¢ TÆ° váº¥n tour theo nhu cáº§u gia Ä‘Ã¬nh, nhÃ³m, cÃ¡ nhÃ¢n\n"
                        "â€¢ Cung cáº¥p thÃ´ng tin chi tiáº¿t vá» giÃ¡, lá»‹ch trÃ¬nh, Ä‘á»‹a Ä‘iá»ƒm\n\n"
                        "ðŸ“ž **Hotline tÆ° váº¥n 24/7:** 0332510486\n"
                        "ðŸ’¡ **Há»i ngay:** 'Tour nÃ o phÃ¹ há»£p cho gia Ä‘Ã¬nh?', 'Tour Báº¡ch MÃ£ giÃ¡ bao nhiÃªu?'",
                "sources": [],
                "context": {},
                "processing_time": 0
            })

        # ================== CONTEXT MANAGEMENT SYSTEM ==================
        context = get_session_context(session_id)

        # LÆ°u user message vÃ o history
        context.conversation_history.append({
            'role': 'user',
            'message': user_message,
            'timestamp': datetime.utcnow().isoformat()
        })

        # Giá»›i háº¡n history (giá»¯ 10 tin nháº¯n gáº§n nháº¥t)
        if len(context.conversation_history) > 20:
            context.conversation_history = context.conversation_history[-10:]

        # ================== AI-POWERED CONTEXT ANALYSIS ==================
        message_lower = user_message.lower()
        message_norm = normalize_tour_key(user_message)

        # FOLLOW-UP CONTEXT MEMORY (chá»‰ giá»¯ Ä‘á»‹nh nghÄ©a)
        followup_keywords = [
            'giÃ¡ tour', 'giÃ¡', 'chÆ°Æ¡ng trÃ¬nh', 'lá»‹ch trÃ¬nh', 'chi tiáº¿t tour',
            'tour nÃ y', 'tour do', 'giÃ¡ tour nÃ y'
        ]
        is_followup_tour_question = any(k in message_lower for k in followup_keywords)

        # ================== COMPLEXITY SCORING ==================
        complexity_score = 0
        complexity_indicators = {
            'vÃ ': 1, 'cho': 1, 'vá»›i': 1, 'nhÆ°ng': 2, 'tuy nhiÃªn': 2,
            'náº¿u': 2, 'khi': 1, 'Ä‘á»ƒ': 1, 'mÃ ': 1, 'hoáº·c': 1
        }

        for indicator, weight in complexity_indicators.items():
            if indicator in message_lower:
                complexity_score += weight

        # ================== SMART INTENT DETECTION ==================
        intent_categories = {
            'tour_listing': ['cÃ³ nhá»¯ng tour nÃ o','co nhung tour nao','co tour nao','danh sÃ¡ch tour','liá»‡t kÃª tour','tour nÃ o cÃ³','cÃ¡c tour hiá»‡n cÃ³','tá»•ng há»£p tour','toÃ n bá»™ tour','tour Ä‘ang má»Ÿ','tour Ä‘ang cÃ³','cÃ³ tour gÃ¬','hiá»‡n cÃ³ tour gÃ¬','xem danh sÃ¡ch tour','cho xem tour','cÃ¡c chÆ°Æ¡ng trÃ¬nh tour','cÃ¡c hÃ nh trÃ¬nh Ä‘ang cháº¡y','tour ruby wings cÃ³ gÃ¬'],
            'price_inquiry': ['giÃ¡ bao nhiÃªu','gia bao nhieu','bao nhiÃªu tiá»n','bao nhieu tien','chi phÃ­','chi phi','giÃ¡ tour','gia tour','giÃ¡ chÆ°Æ¡ng trÃ¬nh','gia chuong trinh','giÃ¡ hÃ nh trÃ¬nh','gia hanh trinh','giÃ¡ Ä‘i','gia di','má»©c giÃ¡','muc gia','giÃ¡ nhÆ° tháº¿ nÃ o','gia nhu the nao','giÃ¡ khoáº£ng bao nhiÃªu','gia khoang bao nhieu','tá»‘n bao nhiÃªu','ton bao nhieu'],
            'tour_detail': ['chi tiáº¿t tour','chi tiet tour','lá»‹ch trÃ¬nh','lich trinh','chÆ°Æ¡ng trÃ¬nh','chuong trinh','tour cÃ³ gÃ¬','cÃ³ nhá»¯ng gÃ¬','bao gá»“m gÃ¬','bao gom gi','trong tour cÃ³ gÃ¬','ná»™i dung tour','noi dung tour','cÃ¡c hoáº¡t Ä‘á»™ng','hoat dong gi','Ä‘i nhá»¯ng Ä‘Ã¢u','di nhung dau','tham quan nhá»¯ng Ä‘Ã¢u','tham quan gi','tour gá»“m nhá»¯ng gÃ¬'],
            'comparison': ['so sÃ¡nh','so sanh','khÃ¡c nhau','khac nhau','so vá»›i','so voi','so sÃ¡nh giá»¯a','so sanh giua','Ä‘iá»ƒm khÃ¡c nhau','diem khac nhau','khÃ¡c gÃ¬','khac gi','so sÃ¡nh tour','so sanh tour','so sÃ¡nh chÆ°Æ¡ng trÃ¬nh','so sanh chuong trinh'],
            'recommendation': ['phÃ¹ há»£p','phu hop','gá»£i Ã½','goi y','Ä‘á» xuáº¥t','de xuat','tÆ° váº¥n','tu van','nÃªn Ä‘i','nen di','nÃªn chá»n tour nÃ o','nen chon tour nao','tÆ° váº¥n giÃºp','tu van giup','gá»£i Ã½ giÃºp','goi y giup','phÃ¹ há»£p vá»›i tÃ´i','phu hop voi toi','tour nÃ o phÃ¹ há»£p','tour nao phu hop'],
            'booking_info': ['Ä‘áº·t tour','dat tour','Ä‘Äƒng kÃ½','dang ky','booking','giá»¯ chá»—','giu cho','Ä‘áº·t chá»—','dat cho','Ä‘Äƒng kÃ½ tour','dang ky tour','booking tour','giá»¯ suáº¥t','giu suat','Ä‘áº·t lá»‹ch Ä‘i','dat lich di','cÃ¡ch Ä‘áº·t tour','cach dat tour','Ä‘Äƒng kÃ½ nhÆ° tháº¿ nÃ o','dang ky nhu the nao'],
            'policy': ['chÃ­nh sÃ¡ch','chinh sach','giáº£m giÃ¡','giam gia','Æ°u Ä‘Ã£i','uu dai','khuyáº¿n mÃ£i','khuyen mai','chÃ­nh sÃ¡ch tour','chinh sach tour','chÃ­nh sÃ¡ch há»§y','chinh sach huy','chÃ­nh sÃ¡ch hoÃ n','chinh sach hoan','Ä‘iá»u khoáº£n','dieu khoan','Ä‘iá»u kiá»‡n Ã¡p dá»¥ng','dieu kien ap dung','Æ°u Ä‘Ã£i hiá»‡n cÃ³','uu dai hien co','chÆ°Æ¡ng trÃ¬nh khuyáº¿n mÃ£i','chuong trinh khuyen mai'],
            'general_info': ['giá»›i thiá»‡u','gioi thieu','lÃ  gÃ¬','la gi','tháº¿ nÃ o','the nao','ra sao','thÃ´ng tin chung','thong tin chung','nÃ³i vá»','noi ve','tÃ¬m hiá»ƒu','tim hieu','giá»›i thiá»‡u chung','gioi thieu chung','thÃ´ng tin cÆ¡ báº£n','thong tin co ban','cho biáº¿t thÃªm','cho biet them'],
            'location_info': ['á»Ÿ Ä‘Ã¢u','Ä‘á»‹a Ä‘iá»ƒm','Ä‘áº¿n Ä‘Ã¢u','vá»‹ trÃ­','Quáº£ng Trá»‹','Thá»‹ xÃ£ Quáº£ng Trá»‹','ThÃ nh cá»• Quáº£ng Trá»‹','ÄÃ´ng HÃ ','VÄ©nh Linh','Gio Linh','Hiá»n LÆ°Æ¡ng','Báº¿n Háº£i','VÄ© tuyáº¿n 17','HÆ°á»›ng HÃ³a','Khe Sanh','Lao Báº£o','TrÆ°á»ng SÆ¡n','TÃ¢y TrÆ°á»ng SÆ¡n','NghÄ©a trang Liá»‡t sÄ© TrÆ°á»ng SÆ¡n','NghÄ©a trang Liá»‡t sÄ© Quá»‘c gia TrÆ°á»ng SÆ¡n','NhÃ  tÃ¹ Lao Báº£o','SÃ¢n bay TÃ  CÆ¡n','Báº£o tÃ ng Khe Sanh','RÃ o QuÃ¡n','Há»“ RÃ o QuÃ¡n','ÄakrÃ´ng','La Vang','DMZ','Vá»‹nh Má»‘c','Äá»‹a Ä‘áº¡o Vá»‹nh Má»‘c','Cá»­a Viá»‡t','Cáº£ng Cá»­a Viá»‡t','Äáº£o Cá»“n Cá»','Cá»“n Cá»','VÄ©nh Má»‘c','Huáº¿','ThÃ nh phá»‘ Huáº¿','Äáº¡i Ná»™i Huáº¿','ChÃ¹a ThiÃªn Má»¥','ChÃ¹a Tá»« Hiáº¿u','RÃº ChÃ¡','Äáº§m Chuá»“n','PhÃ¡ Tam Giang','Quáº£ng BÃ¬nh','Äá»“ng Há»›i','Phong Nha','Äá»™ng Phong Nha','VÅ©ng ChÃ¹a','Nháº­t Lá»‡','HÃ  Ná»™i','Ninh BÃ¬nh','TrÃ ng An','Tam Cá»‘c','BÃ¡i ÄÃ­nh','Háº¡ Long','BÃ£i ChÃ¡y','Quáº£ng Nam','Há»™i An','Rá»«ng dá»«a Báº£y Máº«u','ÄÃ  Náºµng','NgÅ© HÃ nh SÆ¡n','Sa Pa','Fansipan','LÃ o Cai','PhÃº Thá»','Äá»n HÃ¹ng','TP.HCM','ThÃ nh phá»‘ Há»“ ChÃ­ Minh','BÃ¬nh DÆ°Æ¡ng','Äáº¡i Nam','Cáº§n ThÆ¡','SÃ³c TrÄƒng','CÃ  Mau','Äáº¥t MÅ©i','Äá»“ng ThÃ¡p','Nha Trang','ÄÃ  Láº¡t','BuÃ´n Ma Thuá»™t','Quy NhÆ¡n','PhÃº YÃªn','Tuy HÃ²a','Tam Äáº£o','Má»™c ChÃ¢u','SÆ¡n La','PhÃº Quá»‘c','HÃ²n ThÆ¡m'],
            'time_info': ['khi nÃ o','thá»i gian','bao lÃ¢u','máº¥y ngÃ y','máº¥y Ä‘Ãªm','Ä‘i máº¥y ngÃ y','Ä‘i bao lÃ¢u','thá»i lÆ°á»£ng','ngÃ y nÃ o','bao giá»','máº¥y hÃ´m','thá»i gian Ä‘i','thá»i gian tour','kÃ©o dÃ i bao lÃ¢u'],
            'weather_info': ['thá»i tiáº¿t','thoi tiet','khÃ­ háº­u','khi hau','náº¯ng mÆ°a','nang mua','thá»i tiáº¿t tháº¿ nÃ o','thoi tiet the nao','trá»i cÃ³ mÆ°a khÃ´ng','troi co mua khong','thá»i tiáº¿t cÃ³ tá»‘t khÃ´ng','thoi tiet co tot khong','mÃ¹a nÃ o Ä‘áº¹p','mua nao dep','thá»i tiáº¿t khi Ä‘i','thoi tiet khi di','Ä‘i mÃ¹a nÃ o','di mua nao'],
            'food_info': ['áº©m thá»±c','am thuc','mÃ³n Äƒn','mon an','Ä‘áº·c sáº£n','dac san','Ä‘á»“ Äƒn','do an','Äƒn gÃ¬','an gi','Äƒn uá»‘ng','an uong','áº©m thá»±c Ä‘á»‹a phÆ°Æ¡ng','am thuc dia phuong','Ä‘áº·c sáº£n vÃ¹ng','dac san vung','bá»¯a Äƒn trong tour','bua an trong tour','tour Äƒn gÃ¬','tour an gi'],
            'culture_info': ['vÄƒn hÃ³a','van hoa','lá»‹ch sá»­','lich su','truyá»n thá»‘ng','truyen thong','di tÃ­ch','di tich','giÃ¡ trá»‹ vÄƒn hÃ³a','gia tri van hoa','giÃ¡ trá»‹ lá»‹ch sá»­','gia tri lich su','vÄƒn hÃ³a Ä‘á»‹a phÆ°Æ¡ng','van hoa dia phuong','Ã½ nghÄ©a lá»‹ch sá»­','y nghia lich su','di sáº£n','di san'],
            'wellness_info': ['thiá»n','thien','yoga','chá»¯a lÃ nh','chua lanh','sá»©c khá»e','suc khoe','chÄƒm sÃ³c sá»©c khá»e','cham soc suc khoe','thiá»n Ä‘á»‹nh','thien dinh','khÃ­ cÃ´ng','khi cong','retreat','trá»‹ liá»‡u','tri lieu','phá»¥c há»“i nÄƒng lÆ°á»£ng','phuc hoi nang luong'],
            'group_info': ['nhÃ³m','nhom','Ä‘oÃ n','doan','cÃ´ng ty','cong ty','gia Ä‘Ã¬nh','gia dinh','Ä‘i theo nhÃ³m','di theo nhom','Ä‘i theo Ä‘oÃ n','di theo doan','Ä‘oÃ n Ä‘Ã´ng','doan dong','tour cho nhÃ³m','tour cho doan','tour gia Ä‘Ã¬nh','tour cong ty','Ä‘oÃ n bao nhiÃªu ngÆ°á»i','doan bao nhieu nguoi'],
            'custom_request': ['tÃ¹y chá»‰nh','tuy chinh','riÃªng','tour riÃªng','ca nhan hoa','cÃ¡ nhÃ¢n hÃ³a','theo yÃªu cáº§u','theo yeu cau','thiáº¿t káº¿ riÃªng','thiet ke rieng','lÃ m tour riÃªng','lam tour rieng','tour thiáº¿t káº¿','tour thiet ke','chá»‰nh theo nhu cáº§u','chinh theo nhu cau'],
        }

        detected_intents = []
        for intent, keywords in intent_categories.items():
            for keyword in keywords:
                kw_norm = normalize_tour_key(keyword)
                if keyword in message_lower or (kw_norm and kw_norm in message_norm):
                    detected_intents.append(intent)
                    break

        # ================== TOUR RESOLUTION ENGINE ==================
        # Strategy 1: Direct tour name matching (normalized resolver)
        direct_matches_with_scores = resolve_best_tour_indices(user_message, top_k=5)
        direct_tour_matches = [idx for idx, _ in direct_matches_with_scores[:3]]
        direct_tour_scores = {idx: score for idx, score in direct_matches_with_scores}
        logger.info(f"ðŸ“Œ direct_tour_matches = {direct_tour_matches}")
        logger.info(f"ðŸ“Œ direct_tour_scores = {direct_tour_scores}")

        # Strategy 2: Follow-up context memory (Æ°u tiÃªn cao nháº¥t)
        if is_followup_tour_question:
            last_tour_idx = getattr(context, 'current_tour', None)
            if isinstance(last_tour_idx, int):
                last_tour = TOURS_DB.get(last_tour_idx)
                if last_tour and last_tour.is_tour:
                    # LuÃ´n dÃ¹ng context, bá» qua direct matches
                    tour_indices = [last_tour_idx]
                    logger.info(f"ðŸ§  STRATEGY 2: Using context tour {last_tour_idx} for follow-up")
                else:
                    # context khÃ´ng há»£p lá»‡, dÃ¹ng direct matches
                    if direct_tour_matches:
                        tour_indices = direct_tour_matches[:3]
                        logger.info(f"ðŸŽ¯ STRATEGY 2: Using direct tour matches (context invalid): {tour_indices}")
            else:
                # khÃ´ng cÃ³ context, dÃ¹ng direct matches
                if direct_tour_matches:
                    tour_indices = direct_tour_matches[:3]
                    logger.info(f"ðŸŽ¯ STRATEGY 2: Using direct tour matches (no context): {tour_indices}")
        else:
            # khÃ´ng pháº£i follow-up, dÃ¹ng direct matches
            if direct_tour_matches:
                tour_indices = direct_tour_matches[:3]
                logger.info(f"ðŸŽ¯ STRATEGY 2: Direct tour matches found: {tour_indices}")

        # Cáº­p nháº­t context.current_tour náº¿u cÃ³ tour tháº­t Ä‘Æ°á»£c chá»n
        if tour_indices:
            first_tour = TOURS_DB.get(tour_indices[0])
            if first_tour and first_tour.is_tour:
                context.current_tour = tour_indices[0]
                context.current_tour_updated_at = datetime.utcnow().isoformat()
                context.last_tour_name = first_tour.name
                logger.info(f"ðŸ“ Updated context.current_tour = {tour_indices[0]} ({first_tour.name})")

        logger.info(f"ðŸŽ¯ Final tour indices: {tour_indices}")
        logger.info(f"ðŸŽ¯ Detected intents: {detected_intents}")

        # ================== INTELLIGENT RESPONSE GENERATION ==================
        reply = ""
        sources = []
        response_locked = False

        # ================== PRIORITY PRICE HANDLER ==================
        if not response_locked:
            price_keywords = ['giÃ¡ bao nhiÃªu', 'bao nhiÃªu tiá»n', 'giÃ¡ tour', 'giÃ¡', 'chi phÃ­']
            if any(kw in message_lower for kw in price_keywords):
                target_tour_idx = None
                # Æ¯u tiÃªn context náº¿u lÃ  follow-up
                if is_followup_tour_question:
                    last_tour_idx = getattr(context, 'current_tour', None)
                    if isinstance(last_tour_idx, int):
                        last_tour = TOURS_DB.get(last_tour_idx)
                        if last_tour and last_tour.is_tour:
                            target_tour_idx = last_tour_idx
                            logger.info(f"ðŸ’° PRIORITY PRICE HANDLER: using context tour {last_tour_idx} for follow-up")
                # Náº¿u khÃ´ng cÃ³ context hoáº·c khÃ´ng pháº£i follow-up, dÃ¹ng tour_indices hiá»‡n táº¡i
                if target_tour_idx is None and tour_indices:
                    target_tour_idx = tour_indices[0]
                if target_tour_idx is not None:
                    tour = TOURS_DB.get(target_tour_idx)
                    if tour and tour.price:
                        reply = f"ðŸ’° **GIÃ TOUR: {tour.name}** ðŸ’°\n\n{tour.price}"
                        reply += "\n\nðŸ“ž **Hotline tÆ° váº¥n 24/7:** 0332510486"
                        response_locked = True
                        logger.info(f"ðŸ’° PRIORITY PRICE HANDLER: tráº£ giÃ¡ cho tour index {target_tour_idx}")

        # ================== HANDLE EXPLICIT TOUR NAME MENTION ==================
        if not response_locked and tour_indices:
            first_tour = TOURS_DB.get(tour_indices[0])
            if first_tour and first_tour.is_tour:
                msg_lower = user_message.lower()
                tour_name_lower = first_tour.name.lower()
                is_explicit_tour_name = (
                    tour_name_lower in msg_lower or
                    msg_lower in tour_name_lower or
                    any(part in msg_lower for part in tour_name_lower.split() if len(part) > 3)
                )
                no_specific_intent = not any([
                    'giÃ¡' in msg_lower,
                    'bao nhiÃªu' in msg_lower,
                    'lá»‹ch trÃ¬nh' in msg_lower,
                    'chÆ°Æ¡ng trÃ¬nh' in msg_lower,
                    'á»Ÿ Ä‘Ã¢u' in msg_lower,
                    'Ä‘i Ä‘Ã¢u' in msg_lower,
                    'phÆ°Æ¡ng tiá»‡n' in msg_lower,
                    'Äƒn' in msg_lower,
                    'phong cÃ¡ch' in msg_lower,
                    'lÆ°u Ã½' in msg_lower,
                    'so sÃ¡nh' in msg_lower,
                    'gá»£i Ã½' in msg_lower,
                    'phÃ¹ há»£p' in msg_lower,
                ])
                if is_explicit_tour_name and no_specific_intent:
                    reply = format_tour_program_response(first_tour)
                    if "0332510486" not in reply:
                        reply += "\n\nðŸ“ž **Hotline tÆ° váº¥n 24/7:** 0332510486"
                    response_locked = True
                    context.current_tour = tour_indices[0]
                    context.current_tour_updated_at = datetime.utcnow().isoformat()
                    logger.info(f"ðŸŽ¯ Explicit tour name match: responding with program for '{first_tour.name}' (idx={tour_indices[0]})")

        # ================== FIELD-SPECIFIC RESPONSE (UPGRADE 3) ==================
        if not response_locked and UpgradeFlags.is_enabled("3_ENHANCED_FIELDS") and tour_indices:
            field_name, confidence, _ = EnhancedFieldDetector.detect_field_with_confidence(user_message)
            if field_name and confidence >= 0.6:
                tour = TOURS_DB.get(tour_indices[0])
                if tour:
                    formatter_map = {
                        'price': format_tour_price_response,
                        'location': format_tour_location_response,
                        'duration': format_tour_duration_response,
                        'includes': format_tour_includes_response,
                        'notes': format_tour_notes_response,
                        'style': format_tour_style_response,
                        'transport': format_tour_transport_response,
                        'accommodation': format_tour_accommodation_response,
                        'meals': format_tour_meals_response,
                        'event_support': format_tour_event_support_response,
                        'summary': format_tour_program_response,
                    }
                    if field_name in formatter_map:
                        formatted = formatter_map[field_name](tour)
                        if formatted:
                            reply = formatted
                            if "0332510486" not in reply:
                                reply += "\n\nðŸ“ž **Hotline tÆ° váº¥n 24/7:** 0332510486"
                            response_locked = True
                            logger.info(f"ðŸŽ¯ Field-specific response for '{field_name}' (confidence: {confidence:.2f})")
                        else:
                            tour_name = getattr(tour, 'name', 'tour nÃ y')
                            reply = f"âŒ **Hiá»‡n táº¡i tÃ´i chÆ°a cÃ³ thÃ´ng tin vá» {field_name} cá»§a {tour_name}.**\n\nðŸ“ž Vui lÃ²ng liÃªn há»‡ hotline **0332510486** Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£ chi tiáº¿t."
                            response_locked = True
                            logger.warning(f"âš ï¸ No data for field '{field_name}' of tour index {tour_indices[0]}")

        # ================== CASE 1: LISTING TOURS ==================
        if not response_locked and ('tour_listing' in detected_intents or any(keyword in message_lower for keyword in ['cÃ³ nhá»¯ng tour nÃ o', 'danh sÃ¡ch tour', 'liá»‡t kÃª tour', 'tour nÃ o cÃ³'])):
            # Táº®T Táº M MANDATORY FILTER Äá»‚ TEST
            # use_filters = UpgradeFlags.is_enabled("1_MANDATORY_FILTER") and not mandatory_filters.is_empty()
            use_filters = False  # Táº¯t filter táº¡m thá»i

            if use_filters:
                filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                all_tours = [TOURS_DB[idx] for idx in filtered_indices if idx in TOURS_DB]
                logger.info(f"ðŸŽ¯ Filter-based search: {len(all_tours)} tours")
            else:
                all_tours = list(TOURS_DB.values())
                logger.info(f"ðŸŽ¯ Getting ALL tours: {len(all_tours)} tours")

            if UpgradeFlags.is_enabled("2_DEDUPLICATION") and all_tours:
                seen_keys = set()
                unique_tours = []
                for tour in all_tours:
                    try:
                        key = normalize_tour_key(getattr(tour, "name", ""))
                    except Exception:
                        key = (getattr(tour, "name", "") or "").strip().lower()
                    if key and key not in seen_keys:
                        seen_keys.add(key)
                        unique_tours.append(tour)
                all_tours = unique_tours

            total_tours = len(all_tours)
            logger.info(f"ðŸ“Š Total tours after processing: {total_tours}")

            if total_tours == 0:
                all_tours = list(TOURS_DB.values())[:5]
                total_tours = len(all_tours)
                logger.warning(f"âš ï¸ No tours found, using fallback: {total_tours} tours")

            display_tours = all_tours[:5]

            if display_tours:
                reply = "âœ¨ **DANH SÃCH TOUR RUBY WINGS** âœ¨\n\n"
                for i, tour in enumerate(display_tours, 1):
                    emoji = "âœ¨"
                    if tour.tags:
                        if any('nature' in tag for tag in tour.tags):
                            emoji = "ðŸŒ¿"
                        elif any('history' in tag for tag in tour.tags):
                            emoji = "ðŸ›ï¸"
                        elif any('meditation' in tag for tag in tour.tags):
                            emoji = "ðŸ•‰ï¸"
                        elif any('family' in tag for tag in tour.tags):
                            emoji = "ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦"
                    reply += f"{emoji} **{tour.name}**\n"
                    if tour.duration:
                        reply += f"   â±ï¸ {tour.duration}\n"
                    if tour.location:
                        reply += f"   ðŸ“ {tour.location}\n"
                    if tour.price and i <= 3:
                        price_text = tour.price[:50] + "..." if len(tour.price) > 50 else tour.price
                        reply += f"   ðŸ’° {price_text}\n"
                    reply += "\n"
                if total_tours > 5:
                    reply += f"ðŸ“Š **CÃ²n {total_tours - 5} tour khÃ¡c!**\n\n"
                reply += "ðŸ’¡ **Báº¡n muá»‘n tÃ¬m hiá»ƒu chi tiáº¿t tour nÃ o?**\n"
                reply += "â€¢ Gá»i tÃªn tour cá»¥ thá»ƒ (vÃ­ dá»¥: 'Tour Báº¡ch MÃ£')\n"
                reply += "â€¢ Hoáº·c mÃ´ táº£ nhu cáº§u Ä‘á»ƒ tÃ´i tÆ° váº¥n phÃ¹ há»£p\n\n"
                reply += "ðŸ“ž **Hotline tÆ° váº¥n nhanh:** 0332510486"
            else:
                reply = "âœ¨ **DANH SÃCH TOUR RUBY WINGS** âœ¨\n\n"
                reply += "Hiá»‡n táº¡i Ruby Wings cÃ³ 33 tour Ä‘áº·c sáº¯c phá»¥c vá»¥ nhiá»u nhu cáº§u:\n\n"
                reply += "ðŸŒ¿ **Tour ThiÃªn NhiÃªn:** Báº¡ch MÃ£, TrÆ°á»ng SÆ¡n, Ä‘áº¡i ngÃ n\n"
                reply += "ðŸ›ï¸ **Tour Lá»‹ch Sá»­:** Di sáº£n Huáº¿, chiáº¿n trÆ°á»ng xÆ°a\n"
                reply += "ðŸ•‰ï¸ **Tour Retreat:** Thiá»n, yoga, chá»¯a lÃ nh\n"
                reply += "ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦ **Tour Gia ÄÃ¬nh:** PhÃ¹ há»£p má»i lá»©a tuá»•i\n"
                reply += "ðŸŽ¯ **Tour NhÃ³m:** Teambuilding, cÃ´ng ty, báº¡n bÃ¨\n\n"
                reply += "ðŸ’¡ **Äá»ƒ xem tour cá»¥ thá»ƒ, hÃ£y há»i:**\n"
                reply += "â€¢ 'Tour Báº¡ch MÃ£ cÃ³ gÃ¬?'\n"
                reply += "â€¢ 'Tour gia Ä‘Ã¬nh 2 ngÃ y'\n"
                reply += "â€¢ 'Tour lá»‹ch sá»­ á»Ÿ Huáº¿'\n\n"
                reply += "ðŸ“ž **Hotline tÆ° váº¥n 24/7:** 0332510486"

        # ================== CASE 2: PRICE INQUIRY ==================
        if not response_locked and ('price_inquiry' in detected_intents or any(keyword in message_lower for keyword in ['giÃ¡ bao nhiÃªu', 'bao nhiÃªu tiá»n', 'giÃ¡ tour', 'giÃ¡ tour nÃ y', 'giÃ¡ tout', 'gÃ­a tour'])):
            logger.info("ðŸ’° Processing price inquiry")
            if tour_indices:
                price_responses = []
                for idx in tour_indices[:2]:
                    tour = TOURS_DB.get(idx)
                    if tour and tour.price:
                        price_text = tour.price
                        if 'nghÃ¬n' in price_text.lower():
                            price_text = price_text.replace('nghÃ¬n', 'k').replace('NghÃ¬n', 'k')
                        price_responses.append(f"**{tour.name}:** {price_text}")
                if price_responses:
                    reply = "ðŸ’° **THÃ”NG TIN GIÃ TOUR** ðŸ’°\n\n"
                    reply += "\n".join(price_responses)
                    reply += "\n\nðŸ“ž **GiÃ¡ Æ°u Ä‘Ã£i cho nhÃ³m & Ä‘áº·t sá»›m:** 0332510486"
                    response_locked = True
                else:
                    if client and HAS_OPENAI:
                        try:
                            prompt = f"""Báº¡n lÃ  tÆ° váº¥n viÃªn Ruby Wings. KhÃ¡ch há»i vá» giÃ¡ tour nhÆ°ng chÆ°a chá»‰ Ä‘á»‹nh tour cá»¥ thá»ƒ.

THÃ”NG TIN CHUNG Vá»€ GIÃ TOUR RUBY WINGS:
- Tour 1 ngÃ y: tá»« 500.000Ä‘ - 1.500.000Ä‘
- Tour 2 ngÃ y 1 Ä‘Ãªm: tá»« 1.500.000Ä‘ - 3.000.000Ä‘  
- Tour 3 ngÃ y 2 Ä‘Ãªm: tá»« 2.500.000Ä‘ - 5.000.000Ä‘
- Tour nhÃ³m: cÃ³ chÃ­nh sÃ¡ch giáº£m giÃ¡ theo sá»‘ lÆ°á»£ng
- Tour cao cáº¥p: giÃ¡ theo yÃªu cáº§u

YÃŠU Cáº¦U:
1. Giáº£i thÃ­ch pháº¡m vi giÃ¡ tour cá»§a Ruby Wings
2. Há»i láº¡i khÃ¡ch vá» loáº¡i tour cá»¥ thá»ƒ
3. Äá» nghá»‹ liÃªn há»‡ hotline Ä‘á»ƒ bÃ¡o giÃ¡ chi tiáº¿t

Tráº£ lá»i ngáº¯n gá»n, chuyÃªn nghiá»‡p."""
                            response = client.chat.completions.create(
                                model=CHAT_MODEL,
                                messages=[
                                    {"role": "system", "content": prompt},
                                    {"role": "user", "content": user_message}
                                ],
                                temperature=0.5,
                                max_tokens=250
                            )
                            if response.choices:
                                reply = response.choices[0].message.content or ""
                            else:
                                reply = "GiÃ¡ tour Ruby Wings dao Ä‘á»™ng tá»« 500.000Ä‘ - 5.000.000Ä‘ tÃ¹y loáº¡i tour vÃ  dá»‹ch vá»¥. Báº¡n quan tÃ¢m tour nÃ o cá»¥ thá»ƒ Ä‘á»ƒ tÃ´i bÃ¡o giÃ¡ chi tiáº¿t?"
                        except Exception as e:
                            logger.error(f"OpenAI price inquiry error: {e}")
                            reply = "GiÃ¡ tour tÃ¹y thuá»™c vÃ o loáº¡i tour, thá»i gian vÃ  sá»‘ lÆ°á»£ng ngÆ°á»i. Vui lÃ²ng cho biáº¿t báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i bÃ¡o giÃ¡ cá»¥ thá»ƒ."
                    else:
                        reply = "GiÃ¡ tour Ruby Wings ráº¥t Ä‘a dáº¡ng, tá»« tour 1 ngÃ y giÃ¡ 500.000Ä‘ Ä‘áº¿n tour cao cáº¥p 5.000.000Ä‘. Báº¡n muá»‘n biáº¿t giÃ¡ tour cá»¥ thá»ƒ nÃ o?"
            else:
                reply = "ðŸ’° **Báº¢NG GIÃ THAM KHáº¢O RUBY WINGS** ðŸ’°\n\n"
                reply += "ðŸ·ï¸ **Tour 1 ngÃ y:** 500.000Ä‘ - 1.500.000Ä‘\n"
                reply += "   â€¢ ThiÃªn nhiÃªn, vÄƒn hÃ³a, áº©m thá»±c\n\n"
                reply += "ðŸ·ï¸ **Tour 2 ngÃ y 1 Ä‘Ãªm:** 1.500.000Ä‘ - 3.000.000Ä‘\n"
                reply += "   â€¢ Tráº£i nghiá»‡m sÃ¢u, retreat, lá»‹ch sá»­\n\n"
                reply += "ðŸ·ï¸ **Tour 3+ ngÃ y:** 2.500.000Ä‘ - 5.000.000Ä‘\n"
                reply += "   â€¢ Cao cáº¥p, cÃ¡ nhÃ¢n hÃ³a, nhÃ³m Ä‘áº·c biá»‡t\n\n"
                reply += "ðŸŽ¯ **Æ¯u Ä‘Ã£i Ä‘áº·c biá»‡t:**\n"
                reply += "â€¢ NhÃ³m 10+ ngÆ°á»i: Giáº£m 10-20%\n"
                reply += "â€¢ Äáº·t trÆ°á»›c 30 ngÃ y: Giáº£m 5%\n"
                reply += "â€¢ Cá»±u chiáº¿n binh: Æ¯u Ä‘Ã£i Ä‘áº·c biá»‡t\n\n"
                reply += "ðŸ“ž **LiÃªn há»‡ ngay 0332510486 Ä‘á»ƒ nháº­n bÃ¡o giÃ¡ chi tiáº¿t!**"

        # ================== CASE 3: TOUR COMPARISON ==================
        if not response_locked and 'comparison' in detected_intents:
            logger.info("âš–ï¸ Processing tour comparison request")
            import re
            comparison_tours = []
            tour_patterns = [
                r'tour\s+["\']?(.+?)["\']?\s+vÃ \s+tour\s+["\']?(.+?)["\']?',
                r'tour\s+["\']?(.+?)["\']?\s+vá»›i\s+tour\s+["\']?(.+?)["\']?',
                r'tour\s+["\']?(.+?)["\']?\s+so\s+sÃ¡nh\s+vá»›i\s+tour\s+["\']?(.+?)["\']?',
            ]
            for pattern in tour_patterns:
                matches = re.findall(pattern, message_lower, re.IGNORECASE)
                for match in matches:
                    for tour_name in match:
                        if tour_name.strip():
                            for norm_name, idx in TOUR_NAME_TO_INDEX.items():
                                tour = TOURS_DB.get(idx)
                                if tour and tour.is_tour and tour_name.lower() in norm_name.lower():
                                    comparison_tours.append(idx)
                                    break
            if not comparison_tours and tour_indices:
                comparison_tours = tour_indices[:3]
            if len(comparison_tours) >= 2:
                reply = "ðŸ“Š **SO SÃNH CHI TIáº¾T TOUR** ðŸ“Š\n\n"
                headers = ["TIÃŠU CHÃ"]
                tour_data = []
                for idx in comparison_tours[:3]:
                    tour = TOURS_DB.get(idx)
                    if tour:
                        headers.append(tour.name[:20])
                        tour_data.append(tour)
                comparison_criteria = [
                    ('â±ï¸ Thá»i gian', lambda t: t.duration or 'N/A'),
                    ('ðŸ“ Äá»‹a Ä‘iá»ƒm', lambda t: t.location or 'N/A'),
                    ('ðŸ’° GiÃ¡', lambda t: t.price[:30] + '...' if t.price and len(t.price) > 30 else t.price or 'LiÃªn há»‡'),
                    ('ðŸŽ¯ Loáº¡i hÃ¬nh', lambda t: ', '.join([tag.split(':')[1] for tag in (t.tags or []) if ':' in tag][:2]) or 'Äa dáº¡ng'),
                    ('ðŸ“ Äá»™ phÃ¹ há»£p', lambda t: 'Gia Ä‘Ã¬nh' if any('family' in tag for tag in (t.tags or [])) else 'NhÃ³m/NgÆ°á»i lá»›n'),
                ]
                for criterion_name, get_value in comparison_criteria:
                    row = [criterion_name]
                    for tour in tour_data:
                        value = get_value(tour)
                        row.append(value[:20] if value else 'N/A')
                    row_formatted = " | ".join([cell.ljust(20) for cell in row])
                    reply += f"{row_formatted}\n"
                    reply += "-" * (len(row) * 22) + "\n"
                reply += "\nðŸ’¡ **Gá»¢I Ã Lá»°A CHá»ŒN:**\n"
                if tour_data:
                    prices = []
                    for tour in tour_data:
                        if tour.price:
                            nums = re.findall(r'\d[\d,\.]+', tour.price)
                            if nums:
                                try:
                                    price_num = int(nums[0].replace(',', '').replace('.', ''))
                                    prices.append(price_num)
                                except:
                                    pass
                    if len(prices) >= 2:
                        min_price = min(prices)
                        max_price = max(prices)
                        if max_price > min_price * 1.5:
                            reply += "â€¢ Tiáº¿t kiá»‡m: Chá»n tour giÃ¡ tháº¥p hÆ¡n\n"
                            reply += "â€¢ Tráº£i nghiá»‡m Ä‘áº§y Ä‘á»§: Chá»n tour giÃ¡ cao hÆ¡n\n"
                    durations = [tour.duration.lower() if tour.duration else '' for tour in tour_data]
                    if any('1 ngÃ y' in d for d in durations) and any('2 ngÃ y' in d for d in durations):
                        reply += "â€¢ Ãt thá»i gian: Tour 1 ngÃ y\n"
                        reply += "â€¢ Tráº£i nghiá»‡m sÃ¢u: Tour 2 ngÃ y\n"
                reply += "\nðŸ“ž **TÆ° váº¥n chá»n tour phÃ¹ há»£p:** 0332510486"
            else:
                reply = "Äá»ƒ so sÃ¡nh tour, vui lÃ²ng cho biáº¿t tÃªn 2-3 tour cá»¥ thá»ƒ. VÃ­ dá»¥: 'So sÃ¡nh tour Báº¡ch MÃ£ vÃ  tour TrÆ°á»ng SÆ¡n'"

        # ================== CASE 4: TOUR RECOMMENDATION ==================
        if not response_locked and ('recommendation' in detected_intents or any(keyword in message_lower for keyword in ['phÃ¹ há»£p', 'gá»£i Ã½', 'Ä‘á» xuáº¥t'])):
            logger.info("ðŸŽ¯ Processing recommendation request")
            requirements = {
                'family': any(word in message_lower for word in ['gia Ä‘Ã¬nh', 'tráº» em', 'con nhá»', 'bá»‘ máº¹']),
                'senior': any(word in message_lower for word in ['ngÆ°á»i lá»›n tuá»•i', 'cao tuá»•i', 'Ã´ng bÃ ']),
                'group': any(word in message_lower for word in ['nhÃ³m', 'Ä‘oÃ n', 'cÃ´ng ty', 'báº¡n bÃ¨']),
                'couple': any(word in message_lower for word in ['cáº·p Ä‘Ã´i', 'Ä‘Ã´i lá»©a', 'ngÆ°á»i yÃªu']),
                'solo': any(word in message_lower for word in ['má»™t mÃ¬nh', 'Ä‘i láº»', 'solo']),
                'nature': any(word in message_lower for word in ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi', 'cÃ¢y']),
                'history': any(word in message_lower for word in ['lá»‹ch sá»­', 'di tÃ­ch', 'chiáº¿n tranh']),
                'meditation': any(word in message_lower for word in ['thiá»n', 'tÄ©nh tÃ¢m', 'yoga']),
                'relax': any(word in message_lower for word in ['nghá»‰ ngÆ¡i', 'thÆ° giÃ£n', 'nháº¹ nhÃ ng']),
                'adventure': any(word in message_lower for word in ['phiÃªu lÆ°u', 'máº¡o hiá»ƒm', 'khÃ¡m phÃ¡']),
                'budget': any(word in message_lower for word in ['giÃ¡ ráº»', 'tiáº¿t kiá»‡m', 'kinh táº¿']),
                'premium': any(word in message_lower for word in ['cao cáº¥p', 'sang trá»ng', 'premium']),
            }
            matching_tours = []
            for idx, tour in TOURS_DB.items():
                score = 0
                reasons = []
                tour_tags = [tag.lower() for tag in (tour.tags or [])]
                if requirements['family']:
                    if any('family' in tag for tag in tour_tags):
                        score += 3
                        reasons.append("phÃ¹ há»£p gia Ä‘Ã¬nh")
                    elif 'history' in tour_tags and not requirements['history']:
                        score -= 1
                if requirements['senior']:
                    if any('nature' in tag for tag in tour_tags) or any('meditation' in tag for tag in tour_tags):
                        score += 2
                        reasons.append("nháº¹ nhÃ ng cho ngÆ°á»i lá»›n tuá»•i")
                if requirements['nature']:
                    if any('nature' in tag for tag in tour_tags):
                        score += 2
                        reasons.append("tráº£i nghiá»‡m thiÃªn nhiÃªn")
                if requirements['meditation']:
                    if any('meditation' in tag for tag in tour_tags):
                        score += 3
                        reasons.append("cÃ³ hoáº¡t Ä‘á»™ng thiá»n")
                if requirements['relax']:
                    if any('nature' in tag for tag in tour_tags) or any('meditation' in tag for tag in tour_tags):
                        score += 2
                        reasons.append("táº­p trung nghá»‰ ngÆ¡i")
                if requirements['budget']:
                    if tour.price:
                        nums = re.findall(r'\d[\d,\.]+', tour.price)
                        if nums:
                            try:
                                price_num = int(nums[0].replace(',', '').replace('.', ''))
                                if price_num < 2000000:
                                    score += 2
                                    reasons.append("giÃ¡ há»£p lÃ½")
                            except:
                                pass
                if score > 0:
                    matching_tours.append((idx, score, reasons))
            matching_tours.sort(key=lambda x: x[1], reverse=True)
            if matching_tours:
                reply = "ðŸŽ¯ **Äá»€ XUáº¤T TOUR PHÃ™ Há»¢P** ðŸŽ¯\n\n"
                top_idx, top_score, top_reasons = matching_tours[0]
                top_tour = TOURS_DB.get(top_idx)
                if top_tour:
                    reply += f"ðŸ† **PHÃ™ Há»¢P NHáº¤T ({int(top_score/10*100)}%)**\n"
                    reply += f"**{top_tour.name}**\n"
                    reply += f"âœ… LÃ½ do: {', '.join(top_reasons[:3])}\n"
                    if top_tour.duration:
                        reply += f"â±ï¸ Thá»i gian: {top_tour.duration}\n"
                    if top_tour.location:
                        reply += f"ðŸ“ Äá»‹a Ä‘iá»ƒm: {top_tour.location}\n"
                    if top_tour.price:
                        reply += f"ðŸ’° GiÃ¡: {top_tour.price[:80]}\n"
                    reply += "\n"
                other_tours = matching_tours[1:3]
                if other_tours:
                    reply += "ðŸ“‹ **Lá»°A CHá»ŒN KHÃC:**\n"
                    for idx, score, reasons in other_tours:
                        tour = TOURS_DB.get(idx)
                        if tour:
                            reply += f"â€¢ **{tour.name}** ({int(score/10*100)}%)\n"
                            if tour.duration:
                                reply += f"  â±ï¸ {tour.duration}"
                            if tour.location:
                                reply += f" | ðŸ“ {tour.location[:30]}"
                            reply += "\n"
                reply += "\nðŸ’¡ **Cáº¦N TÆ¯ Váº¤N CHI TIáº¾T?**\n"
                reply += "ðŸ“ž Gá»i ngay 0332510486 Ä‘á»ƒ:\n"
                reply += "â€¢ Nháº­n lá»‹ch trÃ¬nh chi tiáº¿t\n"
                reply += "â€¢ BÃ¡o giÃ¡ chÃ­nh xÃ¡c\n"
                reply += "â€¢ Äáº·t tour Æ°u Ä‘Ã£i\n"
            else:
                if client and HAS_OPENAI:
                    try:
                        prompt = f"""Báº¡n lÃ  tÆ° váº¥n viÃªn Ruby Wings chuyÃªn nghiá»‡p. KhÃ¡ch hÃ ng cáº§n tÆ° váº¥n tour nhÆ°ng chÆ°a tÃ¬m tháº¥y tour phÃ¹ há»£p.

YÃŠU Cáº¦U KHÃCH: {user_message}

THÃ”NG TIN RUBY WINGS:
- ChuyÃªn tour tráº£i nghiá»‡m: lá»‹ch sá»­, thiÃªn nhiÃªn, retreat
- Äa dáº¡ng tour tá»« 1 ngÃ y Ä‘áº¿n 4 ngÃ y
- PhÃ¹ há»£p má»i Ä‘á»‘i tÆ°á»£ng: gia Ä‘Ã¬nh, nhÃ³m, cÃ¡ nhÃ¢n

YÃŠU Cáº¦U:
1. Thá»«a nháº­n chÆ°a tÃ¬m tháº¥y tour phÃ¹ há»£p ngay
2. Äá» nghá»‹ cung cáº¥p thÃªm thÃ´ng tin Ä‘á»ƒ tÆ° váº¥n tá»‘t hÆ¡n
3. Gá»£i Ã½ má»™t sá»‘ loáº¡i tour phá»• biáº¿n
4. Khuyáº¿n khÃ­ch liÃªn há»‡ hotline

Tráº£ lá»i thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p."""
                        response = client.chat.completions.create(
                            model=CHAT_MODEL,
                            messages=[
                                {"role": "system", "content": prompt},
                                {"role": "user", "content": user_message}
                            ],
                            temperature=0.6,
                            max_tokens=300
                        )
                        if response.choices:
                            reply = response.choices[0].message.content or ""
                        else:
                            reply = "Äá»ƒ tÃ´i tÆ° váº¥n tour phÃ¹ há»£p nháº¥t, báº¡n cÃ³ thá»ƒ cho biáº¿t thÃªm:\nâ€¢ Sá»‘ ngÆ°á»i tham gia\nâ€¢ Äá»™ tuá»•i cÃ¡c thÃ nh viÃªn\nâ€¢ Sá»Ÿ thÃ­ch chÃ­nh (thiÃªn nhiÃªn, lá»‹ch sá»­, nghá»‰ dÆ°á»¡ng)\nâ€¢ NgÃ¢n sÃ¡ch dá»± kiáº¿n\nâ€¢ Thá»i gian cÃ³ thá»ƒ Ä‘i"
                    except Exception as e:
                        logger.error(f"OpenAI recommendation error: {e}")
                        reply = "Ruby Wings cÃ³ nhiá»u tour Ä‘a dáº¡ng phÃ¹ há»£p vá»›i nhu cáº§u cá»§a báº¡n. Vui lÃ²ng liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t vÃ  Ä‘á» xuáº¥t tour riÃªng."
                else:
                    reply = "Äá»ƒ tÆ° váº¥n tour phÃ¹ há»£p nháº¥t, vui lÃ²ng cung cáº¥p thÃªm thÃ´ng tin hoáº·c liÃªn há»‡ trá»±c tiáº¿p hotline 0332510486."

        # ================== CASE 5: GENERAL INFORMATION ==================
        if not response_locked and ('general_info' in detected_intents or any(keyword in message_lower for keyword in ['giá»›i thiá»‡u', 'lÃ  gÃ¬', 'tháº¿ nÃ o', 'triáº¿t lÃ½'])):
            logger.info("ðŸ›ï¸ Processing general information request")
            if 'ruby wings' in message_lower or 'cÃ´ng ty' in message_lower:
                reply = "ðŸ›ï¸ **GIá»šI THIá»†U RUBY WINGS TRAVEL** ðŸ›ï¸\n\n"
                reply += "Ruby Wings lÃ  Ä‘Æ¡n vá»‹ tá»• chá»©c tour du lá»‹ch tráº£i nghiá»‡m Ä‘áº·c sáº¯c, chuyÃªn sÃ¢u vá»:\n\n"
                reply += "ðŸŽ¯ **3 TRá»¤ Cá»˜T CHÃNH:**\n"
                reply += "1. **Tour Lá»‹ch Sá»­ - Tri Ã‚n:** HÃ nh trÃ¬nh vá» nguá»“n, káº¿t ná»‘i quÃ¡ khá»©\n"
                reply += "2. **Tour Retreat - Chá»¯a LÃ nh:** Thiá»n, khÃ­ cÃ´ng, tÄ©nh tÃ¢m giá»¯a thiÃªn nhiÃªn\n"
                reply += "3. **Tour Tráº£i Nghiá»‡m - KhÃ¡m PhÃ¡:** VÄƒn hÃ³a, áº©m thá»±c, Ä‘á»i sá»‘ng Ä‘á»‹a phÆ°Æ¡ng\n\n"
                reply += "âœ¨ **TRIáº¾T LÃ HOáº T Äá»˜NG:**\n"
                reply += "â€¢ Chuáº©n má»±c trong dá»‹ch vá»¥\n"
                reply += "â€¢ ChÃ¢n thÃ nh trong káº¿t ná»‘i\n"
                reply += "â€¢ Chiá»u sÃ¢u trong tráº£i nghiá»‡m\n\n"
                reply += "ðŸŒ¿ **GIÃ TRá»Š Cá»T LÃ•I:**\n"
                reply += "â€¢ TÃ´n vinh lá»‹ch sá»­ dÃ¢n tá»™c\n"
                reply += "â€¢ Báº£o tá»“n vÄƒn hÃ³a báº£n Ä‘á»‹a\n"
                reply += "â€¢ Lan tá»a nÄƒng lÆ°á»£ng tÃ­ch cá»±c\n\n"
                reply += "ðŸ“ž **Káº¿t ná»‘i vá»›i chÃºng tÃ´i:** 0332510486"
            elif 'triáº¿t lÃ½' in message_lower or 'chuáº©n má»±c' in message_lower:
                reply = "âœ¨ **TRIáº¾T LÃ 'CHUáº¨N Má»°C - CHÃ‚N THÃ€NH - CÃ“ CHIá»€U SÃ‚U'** âœ¨\n\n"
                reply += "Triáº¿t lÃ½ nÃ y Ä‘Æ°á»£c thá»ƒ hiá»‡n trong má»i tour cá»§a Ruby Wings:\n\n"
                reply += "ðŸ† **CHUáº¨N Má»°C:**\n"
                reply += "â€¢ TiÃªu chuáº©n dá»‹ch vá»¥ cao nháº¥t\n"
                reply += "â€¢ An toÃ n tuyá»‡t Ä‘á»‘i cho khÃ¡ch hÃ ng\n"
                reply += "â€¢ ChuyÃªn nghiá»‡p trong tá»«ng chi tiáº¿t\n\n"
                reply += "â¤ï¸ **CHÃ‚N THÃ€NH:**\n"
                reply += "â€¢ Káº¿t ná»‘i tháº­t vá»›i con ngÆ°á»i, vÄƒn hÃ³a\n"
                reply += "â€¢ Äá»“ng hÃ nh chÃ¢n thÃ nh cÃ¹ng khÃ¡ch hÃ ng\n"
                reply += "â€¢ TÆ° váº¥n trung thá»±c, minh báº¡ch\n\n"
                reply += "ðŸŒŒ **CÃ“ CHIá»€U SÃ‚U:**\n"
                reply += "â€¢ Tráº£i nghiá»‡m cÃ³ Ã½ nghÄ©a, giÃ¡ trá»‹\n"
                reply += "â€¢ KhÃ¡m phÃ¡ báº£n cháº¥t, khÃ´ng chá»‰ bá» ná»•i\n"
                reply += "â€¢ Äá»ng láº¡i bÃ i há»c, cáº£m xÃºc sÃ¢u sáº¯c\n\n"
                reply += "ðŸ“ž **Tráº£i nghiá»‡m triáº¿t lÃ½ nÃ y trong tour:** 0332510486"
            else:
                if client and HAS_OPENAI:
                    try:
                        prompt = f"""Báº¡n lÃ  Ä‘áº¡i diá»‡n Ruby Wings Travel. Tráº£ lá»i cÃ¢u há»i chung vá» cÃ´ng ty.

CÃ‚U Há»ŽI: {user_message}

THÃ”NG TIN CÃ”NG TY:
- TÃªn: Ruby Wings Travel
- ChuyÃªn: Tour tráº£i nghiá»‡m lá»‹ch sá»­, retreat, vÄƒn hÃ³a
- Triáº¿t lÃ½: Chuáº©n má»±c - ChÃ¢n thÃ nh - CÃ³ chiá»u sÃ¢u
- Hotline: 0332510486

YÃŠU Cáº¦U:
1. Tráº£ lá»i Ä‘Ãºng trá»ng tÃ¢m cÃ¢u há»i
2. Giá»›i thiá»‡u ngáº¯n gá»n vá» Ruby Wings náº¿u phÃ¹ há»£p
3. Káº¿t thÃºc báº±ng lá»i má»i tÃ¬m hiá»ƒu tour cá»¥ thá»ƒ
4. Giá»ng vÄƒn chuyÃªn nghiá»‡p, thÃ¢n thiá»‡n

Tráº£ lá»i trong 150-200 tá»«."""
                        response = client.chat.completions.create(
                            model=CHAT_MODEL,
                            messages=[
                                {"role": "system", "content": prompt},
                                {"role": "user", "content": user_message}
                            ],
                            temperature=0.5,
                            max_tokens=300
                        )
                        if response.choices:
                            reply = response.choices[0].message.content or ""
                            if "0332510486" not in reply:
                                reply += "\n\nðŸ“ž **LiÃªn há»‡ tÆ° váº¥n tour:** 0332510486"
                        else:
                            reply = "Ruby Wings lÃ  cÃ´ng ty tá»• chá»©c tour tráº£i nghiá»‡m Ä‘áº·c sáº¯c vá»›i triáº¿t lÃ½ 'Chuáº©n má»±c - ChÃ¢n thÃ nh - CÃ³ chiá»u sÃ¢u'. ChÃºng tÃ´i chuyÃªn vá» cÃ¡c tour lá»‹ch sá»­, retreat thiá»n Ä‘á»‹nh, vÃ  khÃ¡m phÃ¡ vÄƒn hÃ³a."
                    except Exception as e:
                        logger.error(f"OpenAI general info error: {e}")
                        reply = "Ruby Wings Travel chuyÃªn tá»• chá»©c cÃ¡c tour tráº£i nghiá»‡m Ã½ nghÄ©a. Äá»ƒ biáº¿t thÃªm chi tiáº¿t, vui lÃ²ng liÃªn há»‡ hotline 0332510486."
                else:
                    reply = "Ruby Wings Travel - Äá»“ng hÃ nh cÃ¹ng báº¡n trong nhá»¯ng hÃ nh trÃ¬nh Ã½ nghÄ©a. ðŸ“ž Hotline: 0332510486"

        # ================== CASE 6: LOCATION & WEATHER INFO ==================
        if not response_locked and ('location_info' in detected_intents or 'weather_info' in detected_intents):
            logger.info("ðŸŒ¤ï¸ Processing location/weather inquiry")
            locations = ['huáº¿', 'quáº£ng trá»‹', 'báº¡ch mÃ£', 'trÆ°á»ng sÆ¡n', 'Ä‘Ã´ng hÃ ']
            mentioned_location = None
            for loc in locations:
                if loc in message_lower:
                    mentioned_location = loc
                    break
            if mentioned_location:
                if 'weather' in message_lower or 'thá»i tiáº¿t' in message_lower:
                    reply = f"ðŸŒ¤ï¸ **THÃ”NG TIN THá»œI TIáº¾T {mentioned_location.upper()}** ðŸŒ¤ï¸\n\n"
                    if mentioned_location == 'huáº¿':
                        reply += "**ThÃ¡ng 12 táº¡i Huáº¿:**\n"
                        reply += "â€¢ Nhiá»‡t Ä‘á»™: 18-24Â°C (mÃ¡t máº»)\n"
                        reply += "â€¢ Thá»i tiáº¿t: Ãt mÆ°a, nhiá»u náº¯ng nháº¹\n"
                        reply += "â€¢ Äáº·c Ä‘iá»ƒm: Se láº¡nh vá» Ä‘Ãªm vÃ  sÃ¡ng\n"
                        reply += "â€¢ LÆ°u Ã½: Mang theo Ã¡o khoÃ¡c nháº¹\n\n"
                    elif mentioned_location == 'báº¡ch mÃ£':
                        reply += "**Thá»i tiáº¿t Báº¡ch MÃ£:**\n"
                        reply += "â€¢ Nhiá»‡t Ä‘á»™: 15-22Â°C (mÃ¡t láº¡nh)\n"
                        reply += "â€¢ Äáº·c Ä‘iá»ƒm: SÆ°Æ¡ng mÃ¹ buá»•i sÃ¡ng\n"
                        reply += "â€¢ LÆ°u Ã½: Mang giÃ y trekking, Ã¡o áº¥m\n\n"
                    else:
                        reply += f"**Thá»i tiáº¿t {mentioned_location.title()}:**\n"
                        reply += "â€¢ Miá»n Trung: KhÃ­ háº­u nhiá»‡t Ä‘á»›i giÃ³ mÃ¹a\n"
                        reply += "â€¢ MÃ¹a khÃ´: Tá»« thÃ¡ng 1-8 (Ã­t mÆ°a)\n"
                        reply += "â€¢ MÃ¹a mÆ°a: Tá»« thÃ¡ng 9-12 (mÆ°a nhiá»u)\n\n"
                    reply += "ðŸ“… **Thá»i Ä‘iá»ƒm lÃ½ tÆ°á»Ÿng Ä‘á»ƒ Ä‘i tour:**\n"
                    reply += "â€¢ ThÃ¡ng 1-4: Thá»i tiáº¿t Ä‘áº¹p nháº¥t\n"
                    reply += "â€¢ ThÃ¡ng 5-8: Náº¯ng Ä‘áº¹p, phÃ¹ há»£p trekking\n"
                    reply += "â€¢ ThÃ¡ng 9-12: MÆ°a nhiá»u, check ká»¹ dá»± bÃ¡o\n\n"
                    reply += "ðŸ“ž **TÆ° váº¥n tour phÃ¹ há»£p thá»i tiáº¿t:** 0332510486"
                else:
                    reply = f"ðŸ“ **THÃ”NG TIN {mentioned_location.upper()}** ðŸ“\n\n"
                    if mentioned_location == 'huáº¿':
                        reply += "**Huáº¿ - Kinh Ä‘Ã´ cá»• cá»§a Viá»‡t Nam:**\n"
                        reply += "â€¢ Di sáº£n vÄƒn hÃ³a UNESCO\n"
                        reply += "â€¢ Ná»•i tiáº¿ng: Äáº¡i Ná»™i, LÄƒng táº©m, SÃ´ng HÆ°Æ¡ng\n"
                        reply += "â€¢ áº¨m thá»±c: BÃºn bÃ² Huáº¿, bÃ¡nh bÃ¨o, cÆ¡m háº¿n\n"
                        reply += "â€¢ Tour phá»• biáº¿n: Di sáº£n Huáº¿, áº©m thá»±c Huáº¿\n\n"
                    elif mentioned_location == 'báº¡ch mÃ£':
                        reply += "**Báº¡ch MÃ£ - VÆ°á»n quá»‘c gia:**\n"
                        reply += "â€¢ Äá»™ cao: 1.450m so vá»›i má»±c nÆ°á»›c biá»ƒn\n"
                        reply += "â€¢ Há»‡ sinh thÃ¡i: Rá»«ng nguyÃªn sinh Ä‘a dáº¡ng\n"
                        reply += "â€¢ Hoáº¡t Ä‘á»™ng: Trekking, thiá»n, ngáº¯m cáº£nh\n"
                        reply += "â€¢ Tour phá»• biáº¿n: Retreat Báº¡ch MÃ£ 1 ngÃ y\n\n"
                    elif mentioned_location == 'trÆ°á»ng sÆ¡n':
                        reply += "**TrÆ°á»ng SÆ¡n - DÃ£y nÃºi hÃ¹ng vÄ©:**\n"
                        reply += "â€¢ Ã nghÄ©a lá»‹ch sá»­: ÄÆ°á»ng Há»“ ChÃ­ Minh huyá»n thoáº¡i\n"
                        reply += "â€¢ VÄƒn hÃ³a: Cá»™ng Ä‘á»“ng VÃ¢n Kiá»u - Pa KÃ´\n"
                        reply += "â€¢ Hoáº¡t Ä‘á»™ng: TÃ¬m hiá»ƒu lá»‹ch sá»­, vÄƒn hÃ³a\n"
                        reply += "â€¢ Tour phá»• biáº¿n: MÆ°a Äá» vÃ  TrÆ°á»ng SÆ¡n\n\n"
                    reply += "ðŸŽ¯ **TOUR PHÃ™ Há»¢P Táº I ÄÃ‚Y:**\n"
                    location_tours = []
                    for idx, tour in TOURS_DB.items():
                        if tour.location and mentioned_location in tour.location.lower():
                            location_tours.append(tour)
                    if location_tours:
                        for tour in location_tours[:3]:
                            reply += f"â€¢ **{tour.name}**"
                            if tour.duration:
                                reply += f" ({tour.duration})"
                            reply += "\n"
                    else:
                        reply += "â€¢ Tour thiÃªn nhiÃªn Báº¡ch MÃ£\n"
                        reply += "â€¢ Tour lá»‹ch sá»­ TrÆ°á»ng SÆ¡n\n"
                        reply += "â€¢ Tour di sáº£n Huáº¿\n"
                    reply += "\nðŸ“ž **Äáº·t tour khÃ¡m phÃ¡:** 0332510486"
            else:
                reply = "Ruby Wings tá»• chá»©c tour táº¡i nhiá»u Ä‘á»‹a Ä‘iá»ƒm: Huáº¿, Quáº£ng Trá»‹, Báº¡ch MÃ£, TrÆ°á»ng SÆ¡n. Báº¡n quan tÃ¢m tour táº¡i khu vá»±c nÃ o?"

        # ================== CASE 7: FOOD & CULTURE INFO ==================
        if not response_locked and ('food_info' in detected_intents or 'culture_info' in detected_intents):
            logger.info("ðŸœ Processing food/culture inquiry")
            if 'bÃ¡nh bÃ¨o' in message_lower or 'áº©m thá»±c huáº¿' in message_lower:
                reply = "ðŸœ **BÃNH BÃˆO HUáº¾ - Äáº¶C Sáº¢N Ná»”I TIáº¾NG** ðŸœ\n\n"
                reply += "**Äáº·c Ä‘iá»ƒm:**\n"
                reply += "â€¢ LÃ m tá»« bá»™t gáº¡o, háº¥p trong chÃ©n nhá»\n"
                reply += "â€¢ NhÃ¢n: TÃ´m chÃ¡y, thá»‹t xay, má»¡ hÃ nh\n"
                reply += "â€¢ NÆ°á»›c cháº¥m: Máº¯m nÃªm Huáº¿ Ä‘áº·c trÆ°ng\n"
                reply += "â€¢ Ä‚n kÃ¨m: Rau sá»‘ng, á»›t xanh\n\n"
                reply += "ðŸŽ¯ **TRáº¢I NGHIá»†M TRONG TOUR:**\n"
                reply += "â€¢ Tour áº¨m thá»±c Huáº¿: Há»c lÃ m bÃ¡nh bÃ¨o\n"
                reply += "â€¢ Tour VÄƒn hÃ³a: ThÄƒm lÃ ng nghá» truyá»n thá»‘ng\n"
                reply += "â€¢ Tour ÄÃªm Huáº¿: ThÆ°á»Ÿng thá»©c Ä‘áº·c sáº£n\n\n"
                reply += "ðŸ“ž **Äáº·t tour áº©m thá»±c Huáº¿:** 0332510486"
            elif 'vÄƒn hÃ³a' in message_lower or 'lá»‹ch sá»­' in message_lower:
                reply = "ðŸ›ï¸ **VÄ‚N HÃ“A & Lá»ŠCH Sá»¬ MIá»€N TRUNG** ðŸ›ï¸\n\n"
                reply += "**Äiá»ƒm ná»•i báº­t:**\n"
                reply += "â€¢ Di sáº£n Huáº¿: Cá»‘ Ä‘Ã´ triá»u Nguyá»…n\n"
                reply += "â€¢ Chiáº¿n tranh: Äá»‹a Ä‘áº¡o Vá»‹nh Má»‘c, ThÃ nh cá»• Quáº£ng Trá»‹\n"
                reply += "â€¢ VÄƒn hÃ³a báº£n Ä‘á»‹a: DÃ¢n tá»™c VÃ¢n Kiá»u, Pa KÃ´\n"
                reply += "â€¢ Kiáº¿n trÃºc: NhÃ  rÆ°á»ng, Ä‘Ã¬nh lÃ ng\n\n"
                reply += "ðŸŽ¯ **TOUR VÄ‚N HÃ“A Ná»”I Báº¬T:**\n"
                culture_tours = []
                for idx, tour in TOURS_DB.items():
                    if tour.tags and any('history' in tag or 'culture' in tag for tag in tour.tags):
                        culture_tours.append(tour)
                if culture_tours:
                    for tour in culture_tours[:3]:
                        reply += f"â€¢ **{tour.name}**\n"
                        if tour.summary:
                            reply += f"  {tour.summary[:80]}...\n"
                else:
                    reply += "â€¢ MÆ°a Äá» vÃ  TrÆ°á»ng SÆ¡n\n"
                    reply += "â€¢ KÃ½ á»©c - Lá»‹ch Sá»­ vÃ  Äáº¡i NgÃ n\n"
                    reply += "â€¢ Di sáº£n Huáº¿ & Äáº§m Chuá»“n\n\n"
                reply += "\nðŸ“ž **TÆ° váº¥n tour vÄƒn hÃ³a:** 0332510486"
            else:
                reply = "Miá»n Trung Viá»‡t Nam ná»•i tiáº¿ng vá»›i áº©m thá»±c phong phÃº vÃ  vÄƒn hÃ³a Ä‘a dáº¡ng. Ruby Wings cÃ³ nhiá»u tour khÃ¡m phÃ¡ áº©m thá»±c vÃ  vÄƒn hÃ³a Ä‘áº·c sáº¯c."

        # ================== CASE 8: WELLNESS & MEDITATION INFO ==================
        if not response_locked and 'wellness_info' in detected_intents:
            logger.info("ðŸ•‰ï¸ Processing wellness/meditation inquiry")
            if 'thiá»n' in message_lower or 'meditation' in message_lower:
                reply = "ðŸ•‰ï¸ **THIá»€N & Lá»¢I ÃCH Sá»¨C KHá»ŽE** ðŸ•‰ï¸\n\n"
                reply += "**Lá»£i Ã­ch chÃ­nh:**\n"
                reply += "1. **Giáº£m cÄƒng tháº³ng:** Giáº£m cortisol, tÄƒng serotonin\n"
                reply += "2. **Cáº£i thiá»‡n táº­p trung:** TÄƒng kháº£ nÄƒng chÃº Ã½\n"
                reply += "3. **TÄƒng cÆ°á»ng sá»©c khá»e:** Háº¡ huyáº¿t Ã¡p, cáº£i thiá»‡n tim máº¡ch\n"
                reply += "4. **CÃ¢n báº±ng cáº£m xÃºc:** Kiá»ƒm soÃ¡t lo Ã¢u, tráº§m cáº£m\n"
                reply += "5. **NÃ¢ng cao nháº­n thá»©c:** Hiá»ƒu rÃµ báº£n thÃ¢n hÆ¡n\n\n"
                reply += "ðŸŽ¯ **TOUR THIá»€N & RETREAT RUBY WINGS:**\n"
                meditation_tours = []
                for idx, tour in TOURS_DB.items():
                    if tour.tags and any('meditation' in tag or 'retreat' in tag for tag in tour.tags):
                        meditation_tours.append(tour)
                if meditation_tours:
                    for tour in meditation_tours[:3]:
                        reply += f"â€¢ **{tour.name}**\n"
                        if tour.duration:
                            reply += f"  â±ï¸ {tour.duration}"
                        if tour.location:
                            reply += f" | ðŸ“ {tour.location[:30]}"
                        reply += "\n"
                else:
                    reply += "â€¢ Non nÆ°á»›c Báº¡ch MÃ£ - 1 ngÃ y thiá»n\n"
                    reply += "â€¢ Retreat TrÆ°á»ng SÆ¡n - 2 ngÃ y 1 Ä‘Ãªm\n"
                    reply += "â€¢ KhÃ­ cÃ´ng giá»¯a Ä‘áº¡i ngÃ n\n\n"
                reply += "\nðŸ’¡ **PhÃ¹ há»£p cho:** NgÆ°á»i stress, cáº§n cÃ¢n báº±ng, muá»‘n tÄ©nh tÃ¢m\n"
                reply += "ðŸ“ž **Äáº·t retreat thiá»n:** 0332510486"
            else:
                reply = "Ruby Wings chuyÃªn tá»• chá»©c cÃ¡c tour retreat káº¿t há»£p thiá»n, khÃ­ cÃ´ng vÃ  trá»‹ liá»‡u thiÃªn nhiÃªn. LiÃªn há»‡ 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n."

        # ================== CASE 9: GROUP & CUSTOM REQUEST ==================
        if not response_locked and ('group_info' in detected_intents or 'custom_request' in detected_intents):
            logger.info("ðŸ‘¥ Processing group/custom request")
            if 'nhÃ³m' in message_lower or 'Ä‘oÃ n' in message_lower:
                reply = "ðŸ‘¥ **TOUR NHÃ“M & Æ¯U ÄÃƒI Äáº¶C BIá»†T** ðŸ‘¥\n\n"
                reply += "**ChÃ­nh sÃ¡ch Æ°u Ä‘Ã£i nhÃ³m:**\n"
                reply += "â€¢ NhÃ³m 10-15 ngÆ°á»i: Giáº£m 10%\n"
                reply += "â€¢ NhÃ³m 16-20 ngÆ°á»i: Giáº£m 15%\n"
                reply += "â€¢ NhÃ³m 21+ ngÆ°á»i: Giáº£m 20% + quÃ  táº·ng\n"
                reply += "â€¢ Cá»±u chiáº¿n binh: Æ¯u Ä‘Ã£i thÃªm 5%\n\n"
                reply += "ðŸŽ¯ **TOUR PHÃ™ Há»¢P NHÃ“M:**\n"
                reply += "1. **Teambuilding cÃ´ng ty:** Tour káº¿t há»£p hoáº¡t Ä‘á»™ng nhÃ³m\n"
                reply += "2. **Gia Ä‘Ã¬nh Ä‘a tháº¿ há»‡:** Tour nháº¹ nhÃ ng, Ä‘a dáº¡ng hoáº¡t Ä‘á»™ng\n"
                reply += "3. **NhÃ³m báº¡n:** Tour khÃ¡m phÃ¡, phiÃªu lÆ°u\n"
                reply += "4. **NhÃ³m há»c sinh/sinh viÃªn:** Tour giÃ¡o dá»¥c, tráº£i nghiá»‡m\n\n"
                reply += "âœ¨ **Dá»ŠCH Vá»¤ Äáº¶C BIá»†T CHO NHÃ“M:**\n"
                reply += "â€¢ Thiáº¿t káº¿ tour riÃªng theo yÃªu cáº§u\n"
                reply += "â€¢ HÆ°á»›ng dáº«n viÃªn chuyÃªn biá»‡t\n"
                reply += "â€¢ PhÆ°Æ¡ng tiá»‡n riÃªng, linh hoáº¡t lá»‹ch trÃ¬nh\n"
                reply += "â€¢ Há»— trá»£ quay phim, chá»¥p áº£nh\n\n"
                reply += "ðŸ“ž **TÆ° váº¥n tour nhÃ³m:** 0332510486"
            elif 'cÃ¡ nhÃ¢n hÃ³a' in message_lower or 'riÃªng' in message_lower or 'theo yÃªu cáº§u' in message_lower:
                reply = "âœ¨ **TOUR CÃ NHÃ‚N HÃ“A - THEO YÃŠU Cáº¦U** âœ¨\n\n"
                reply += "Ruby Wings chuyÃªn thiáº¿t káº¿ tour riÃªng biá»‡t:\n\n"
                reply += "ðŸŽ¯ **QUY TRÃŒNH THIáº¾T Káº¾ TOUR RIÃŠNG:**\n"
                reply += "1. **Tiáº¿p nháº­n yÃªu cáº§u:** Hiá»ƒu rÃµ nhu cáº§u, sá»Ÿ thÃ­ch\n"
                reply += "2. **Thiáº¿t káº¿ lá»‹ch trÃ¬nh:** PhÃ¹ há»£p thá»i gian, ngÃ¢n sÃ¡ch\n"
                reply += "3. **BÃ¡o giÃ¡ chi tiáº¿t:** Minh báº¡ch, cáº¡nh tranh\n"
                reply += "4. **Chá»‰nh sá»­a & hoÃ n thiá»‡n:** Theo feedback cá»§a báº¡n\n"
                reply += "5. **Triá»ƒn khai tour:** ChuyÃªn nghiá»‡p, táº­n tÃ¢m\n\n"
                reply += "ðŸ† **TOUR RIÃŠNG Ná»”I Báº¬T ÄÃƒ THá»°C HIá»†N:**\n"
                reply += "â€¢ Tour gia Ä‘Ã¬nh 3 tháº¿ há»‡ (tá»« 6-70 tuá»•i)\n"
                reply += "â€¢ Tour teambuilding cÃ´ng ty (50 ngÆ°á»i)\n"
                reply += "â€¢ Tour retreat thiá»n 7 ngÃ y\n"
                reply += "â€¢ Tour nhiáº¿p áº£nh chuyÃªn nghiá»‡p\n\n"
                reply += "ðŸ’¡ **YÃŠU Cáº¦U TOUR RIÃŠNG Cáº¦N CÃ“:**\n"
                reply += "â€¢ Sá»‘ lÆ°á»£ng ngÆ°á»i tham gia\n"
                reply += "â€¢ Thá»i gian dá»± kiáº¿n\n"
                reply += "â€¢ NgÃ¢n sÃ¡ch Æ°á»›c tÃ­nh\n"
                reply += "â€¢ Sá»Ÿ thÃ­ch, yÃªu cáº§u Ä‘áº·c biá»‡t\n\n"
                reply += "ðŸ“ž **LiÃªn há»‡ thiáº¿t káº¿ tour riÃªng:** 0332510486"
            else:
                reply = "Ruby Wings cÃ³ chÃ­nh sÃ¡ch Æ°u Ä‘Ã£i Ä‘áº·c biá»‡t cho nhÃ³m vÃ  dá»‹ch vá»¥ thiáº¿t káº¿ tour theo yÃªu cáº§u. LiÃªn há»‡ hotline Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t."

        # ================== CASE 10: BOOKING & POLICY INFO ==================
        if not response_locked and ('booking_info' in detected_intents or 'policy' in detected_intents):
            logger.info("ðŸ“ Processing booking/policy inquiry")
            if 'Ä‘áº·t tour' in message_lower or 'booking' in message_lower:
                reply = "ðŸ“ **QUY TRÃŒNH Äáº¶T TOUR RUBY WINGS** ðŸ“\n\n"
                reply += "**BÆ°á»›c 1: TÆ° váº¥n & chá»n tour**\n"
                reply += "â€¢ LiÃªn há»‡ hotline 0332510486\n"
                reply += "â€¢ Nháº­n tÆ° váº¥n tour phÃ¹ há»£p\n"
                reply += "â€¢ XÃ¡c nháº­n lá»‹ch trÃ¬nh, giÃ¡ cáº£\n\n"
                reply += "**BÆ°á»›c 2: Äáº·t cá»c & xÃ¡c nháº­n**\n"
                reply += "â€¢ Äáº·t cá»c 30% giÃ¡ trá»‹ tour\n"
                reply += "â€¢ KÃ½ há»£p Ä‘á»“ng dá»‹ch vá»¥\n"
                reply += "â€¢ Nháº­n xÃ¡c nháº­n booking\n\n"
                reply += "**BÆ°á»›c 3: Chuáº©n bá»‹ & thanh toÃ¡n**\n"
                reply += "â€¢ Thanh toÃ¡n 70% cÃ²n láº¡i trÆ°á»›c 7 ngÃ y\n"
                reply += "â€¢ Nháº­n thÃ´ng tin chi tiáº¿t tour\n"
                reply += "â€¢ Chuáº©n bá»‹ hÃ nh lÃ½, giáº¥y tá»\n\n"
                reply += "**BÆ°á»›c 4: Khá»Ÿi hÃ nh & tráº£i nghiá»‡m**\n"
                reply += "â€¢ ÄÃ³n khÃ¡ch táº¡i Ä‘iá»ƒm háº¹n\n"
                reply += "â€¢ Tráº£i nghiá»‡m tour tuyá»‡t vá»i\n"
                reply += "â€¢ Feedback sau tour\n\n"
                reply += "ðŸ“ž **Äáº·t tour ngay:** 0332510486"
            elif 'giáº£m giÃ¡' in message_lower or 'Æ°u Ä‘Ã£i' in message_lower:
                reply = "ðŸŽ **CHÃNH SÃCH Æ¯U ÄÃƒI & KHUYáº¾N MÃƒI** ðŸŽ\n\n"
                reply += "**1. Æ¯u Ä‘Ã£i nhÃ³m:**\n"
                reply += "â€¢ 10-15 ngÆ°á»i: Giáº£m 10%\n"
                reply += "â€¢ 16-20 ngÆ°á»i: Giáº£m 15%\n"
                reply += "â€¢ 21+ ngÆ°á»i: Giáº£m 20%\n\n"
                reply += "**2. Æ¯u Ä‘Ã£i Ä‘áº·t sá»›m:**\n"
                reply += "â€¢ Äáº·t trÆ°á»›c 30 ngÃ y: Giáº£m 5%\n"
                reply += "â€¢ Äáº·t trÆ°á»›c 60 ngÃ y: Giáº£m 8%\n\n"
                reply += "**3. Æ¯u Ä‘Ã£i Ä‘áº·c biá»‡t:**\n"
                reply += "â€¢ Cá»±u chiáº¿n binh: ThÃªm 5%\n"
                reply += "â€¢ Há»c sinh/sinh viÃªn: Giáº£m 10%\n"
                reply += "â€¢ KhÃ¡ch quay láº¡i: Giáº£m 5%\n\n"
                reply += "**4. ChÆ°Æ¡ng trÃ¬nh tÃ­ch Ä‘iá»ƒm:**\n"
                reply += "â€¢ Má»—i tour: TÃ­ch 1 Ä‘iá»ƒm\n"
                reply += "â€¢ 5 Ä‘iá»ƒm: Giáº£m 10% tour tiáº¿p theo\n"
                reply += "â€¢ 10 Ä‘iá»ƒm: Táº·ng 1 tour 1 ngÃ y\n\n"
                reply += "ðŸ“ž **Nháº­n Æ°u Ä‘Ã£i tá»‘t nháº¥t:** 0332510486"
            else:
                reply = "Ruby Wings cÃ³ chÃ­nh sÃ¡ch Æ°u Ä‘Ã£i háº¥p dáº«n vÃ  quy trÃ¬nh Ä‘áº·t tour chuyÃªn nghiá»‡p. LiÃªn há»‡ hotline Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t."

        # ================== SPECIAL CASE: PhÃ¡ Tam Giang / Äáº§m Chuá»“n ==================
        if not response_locked and ('pha tam giang' in message_norm or 'Ä‘áº§m chuá»“n' in message_lower):
            exact_hits_with_scores = resolve_best_tour_indices('Di sáº£n Huáº¿ Äáº§m Chuá»“n HoÃ ng hÃ´n phÃ¡ Tam Giang', top_k=1)
            if exact_hits_with_scores:
                idx, _ = exact_hits_with_scores[0]
                t = TOURS_DB.get(idx)
                if t:
                    reply = format_tour_program_response(t)
                    response_locked = True

        # ================== GENERAL SEARCH / FALLBACK ==================
        if not response_locked:
            logger.info("ðŸ¤– Processing with general search")
            search_results = query_index(user_message, TOP_K)

            if not search_results or len(search_results) < 2:
                logger.warning(f"âš ï¸ FAISS returned {len(search_results) if search_results else 0} results, using fallback")
                fallback_tours = get_fallback_tours(user_message, limit=3)
                if fallback_tours:
                    reply = f"ðŸ” **TÃŒM THáº¤Y {len(fallback_tours)} TOUR PHÃ™ Há»¢P**\n\n"
                    for i, tour in enumerate(fallback_tours, 1):
                        reply += f"{i}. **{tour.name}**\n"
                        if tour.duration:
                            reply += f"   â±ï¸ {tour.duration}\n"
                        if tour.location:
                            reply += f"   ðŸ“ {tour.location}\n"
                        if tour.summary:
                            summary = tour.summary[:100] + "..." if len(tour.summary) > 100 else tour.summary
                            reply += f"   ðŸ“ {summary}\n"
                        reply += "\n"
                    reply += "ðŸ’¡ **Báº¡n muá»‘n biáº¿t thÃªm vá» tour nÃ o?**\n"
                    reply += "ðŸ“ž **TÆ° váº¥n chi tiáº¿t:** 0332510486"
                    for tour in fallback_tours:
                        for idx, db_tour in TOURS_DB.items():
                            if db_tour.name == tour.name:
                                tour_indices.append(idx)
                                break
                else:
                    if client and HAS_OPENAI:
                        try:
                            prompt = f"""Báº¡n lÃ  tÆ° váº¥n viÃªn Ruby Wings Travel. KhÃ¡ch há»i: "{user_message}"

THÃ”NG TIN CÃ”NG TY:
- CÃ³ 33 tour Ä‘a dáº¡ng: thiÃªn nhiÃªn, lá»‹ch sá»­, retreat, gia Ä‘Ã¬nh
- Khu vá»±c: Huáº¿, Quáº£ng Trá»‹, Báº¡ch MÃ£, TrÆ°á»ng SÆ¡n
- GiÃ¡ tá»« 500.000Ä‘ - 5.000.000Ä‘

YÃŠU Cáº¦U:
1. Giá»›i thiá»‡u tá»•ng quan vá» Ruby Wings
2. Gá»£i Ã½ má»™t sá»‘ loáº¡i tour phá»• biáº¿n
3. Má»i liÃªn há»‡ hotline Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t

Tráº£ lá»i thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p."""
                            response = client.chat.completions.create(
                                model=CHAT_MODEL,
                                messages=[
                                    {"role": "system", "content": prompt},
                                    {"role": "user", "content": user_message}
                                ],
                                temperature=0.6,
                                max_tokens=300
                            )
                            if response.choices:
                                reply = response.choices[0].message.content or ""
                            else:
                                reply = "Ruby Wings cÃ³ 33 tour Ä‘a dáº¡ng phá»¥c vá»¥ nhiá»u nhu cáº§u. Báº¡n quan tÃ¢m loáº¡i tour nÃ o: thiÃªn nhiÃªn, lá»‹ch sá»­, retreat hay gia Ä‘Ã¬nh?"
                        except Exception as e:
                            logger.error(f"OpenAI error: {e}")
                            reply = "Ruby Wings Travel - Äá»“ng hÃ nh cÃ¹ng báº¡n trong nhá»¯ng hÃ nh trÃ¬nh Ã½ nghÄ©a. ðŸ“ž Hotline: 0332510486"
                    else:
                        reply = "âœ¨ **RUBY WINGS TRAVEL** âœ¨\n\n"
                        reply += "ChÃºng tÃ´i cÃ³ 33 tour Ä‘áº·c sáº¯c táº¡i miá»n Trung:\n\n"
                        reply += "ðŸŒ¿ **Tour ThiÃªn NhiÃªn:** Báº¡ch MÃ£, TrÆ°á»ng SÆ¡n, rá»«ng nguyÃªn sinh\n"
                        reply += "ðŸ›ï¸ **Tour Lá»‹ch Sá»­:** Di sáº£n Huáº¿, Ä‘á»‹a Ä‘áº¡o Vá»‹nh Má»‘c, ThÃ nh cá»•\n"
                        reply += "ðŸ•‰ï¸ **Tour Retreat:** Thiá»n, yoga, chá»¯a lÃ nh giá»¯a thiÃªn nhiÃªn\n"
                        reply += "ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦ **Tour Gia ÄÃ¬nh:** PhÃ¹ há»£p tá»« tráº» nhá» Ä‘áº¿n ngÆ°á»i lá»›n tuá»•i\n"
                        reply += "ðŸŽ¯ **Tour NhÃ³m:** Teambuilding, cÃ´ng ty, báº¡n bÃ¨\n\n"
                        reply += "ðŸ“ž **LiÃªn há»‡ ngay 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n tour phÃ¹ há»£p!**"
            else:
                if UpgradeFlags.is_enabled("2_DEDUPLICATION") and search_results:
                    search_results = DeduplicationEngine.deduplicate_passages(search_results)
                context_info = {
                    'user_message': user_message,
                    'tour_indices': tour_indices,
                    'detected_intents': detected_intents,
                    'filters': mandatory_filters.to_dict() if mandatory_filters else {}
                }
                prompt = _prepare_llm_prompt(user_message, search_results, context_info)
                if client and HAS_OPENAI:
                    try:
                        messages = [
                            {"role": "system", "content": prompt},
                            {"role": "user", "content": user_message}
                        ]
                        response = client.chat.completions.create(
                            model=CHAT_MODEL,
                            messages=messages,
                            temperature=0.6,
                            max_tokens=500,
                            top_p=0.9,
                            frequency_penalty=0.2,
                            presence_penalty=0.1
                        )
                        if response.choices:
                            reply = response.choices[0].message.content or ""
                        else:
                            reply = _generate_fallback_response(user_message, search_results, tour_indices)
                    except Exception as e:
                        logger.error(f"OpenAI general error: {e}")
                        reply = _generate_fallback_response(user_message, search_results, tour_indices)
                else:
                    reply = _generate_fallback_response(user_message, search_results, tour_indices)
                sources = [m for _, m in search_results]

        # ================== ENHANCE RESPONSE QUALITY ==================
        if "0332510486" not in reply and "hotline" not in reply.lower():
            reply += "\n\nðŸ“ž **Hotline tÆ° váº¥n 24/7:** 0332510486"

        if len(reply) > 2000:
            reply = reply[:2000] + "...\n\nðŸ’¡ Äá»ƒ biáº¿t thÃªm chi tiáº¿t, vui lÃ²ng liÃªn há»‡ hotline 0332510486"

        # ================== UPDATE CONTEXT ==================
        if tour_indices and len(tour_indices) > 0:
            context.current_tour = tour_indices[0]
            context.current_tour_updated_at = datetime.utcnow().isoformat()
            tour = TOURS_DB.get(tour_indices[0])
            if tour:
                context.last_tour_name = tour.name

        context.conversation_history.append({
            'role': 'assistant',
            'message': reply,
            'timestamp': datetime.utcnow().isoformat(),
            'tour_indices': tour_indices
        })

        # ================== FINAL RESPONSE ==================
        processing_time = time.time() - start_time

        chat_response = ChatResponse(
            reply=reply,
            sources=sources,
            context={
                "session_id": session_id,
                "current_tour": getattr(context, 'current_tour', None),
                "last_tour_name": getattr(context, 'last_tour_name', None),
                "user_preferences": getattr(context, 'user_profile', {}),
                "detected_intents": detected_intents,
                "processing_time_ms": int(processing_time * 1000),
                "tours_found": len(tour_indices),
                "complexity_score": complexity_score
            },
            tour_indices=tour_indices,
            processing_time_ms=int(processing_time * 1000),
            from_memory=False
        )

        if UpgradeFlags.get_all_flags().get("ENABLE_CACHING", True):
            context_hash = hashlib.md5(json.dumps({
                'tour_indices': tour_indices,
                'detected_intents': detected_intents,
                'complexity': complexity_score
            }, sort_keys=True).encode()).hexdigest()
            cache_key = CacheSystem.get_cache_key(user_message, context_hash)
            CacheSystem.set(cache_key, chat_response.to_dict())

        logger.info(f"âœ… Processed in {processing_time:.2f}s | "
                   f"Intents: {detected_intents} | "
                   f"Tours: {len(tour_indices)} | "
                   f"Complexity: {complexity_score}")

        return jsonify(chat_response.to_dict())

    except Exception as e:
        logger.error(f"âŒ Chat endpoint error: {e}\n{traceback.format_exc()}")
        processing_time = time.time() - start_time
        error_response = ChatResponse(
            reply="âš¡ **CÃ³ chÃºt trá»¥c tráº·c ká»¹ thuáº­t, nhÆ°ng Ä‘á»™i ngÅ© Ruby Wings váº«n sáºµn sÃ ng há»— trá»£ báº¡n!**\n\n"
                  "ðŸ”§ **CÃ¡ch giáº£i quyáº¿t nhanh:**\n"
                  "1. **Gá»i ngay:** ðŸ“ž 0332510486 (tÆ° váº¥n trá»±c tiáº¿p)\n"
                  "2. **Thá»­ láº¡i:** GÃµ cÃ¢u há»i ngáº¯n gá»n hÆ¡n\n"
                  "3. **Chá»n tour:** 'Tour 1 ngÃ y Huáº¿', 'Tour gia Ä‘Ã¬nh 2 ngÃ y'\n\n"
                  "â° **ChÃºng tÃ´i hoáº¡t Ä‘á»™ng 24/7 Ä‘á»ƒ phá»¥c vá»¥ báº¡n!** ðŸ˜Š",
            sources=[],
            context={
                "error": str(e),
                "processing_time_ms": int(processing_time * 1000)
            },
            tour_indices=[],
            processing_time_ms=int(processing_time * 1000),
            from_memory=False
        )
        return jsonify(error_response.to_dict()), 500

# =========== OTHER ENDPOINTS ===========
@app.route("/")
def home():
    """Home endpoint"""
    return jsonify({
        "status": "ok",
        "version": "4.0",
        "upgrades": UpgradeFlags.get_all_flags(),
        "services": {
            "openai": "available" if client else "unavailable",
            "faiss": "available" if HAS_FAISS else "unavailable",
            "google_sheets": "available" if HAS_GOOGLE_SHEETS else "unavailable",
            "meta_capi": "available" if HAS_META_CAPI else "unavailable",
        },
        "counts": {
            "tours": len(TOURS_DB),
            "passages": len(FLAT_TEXTS),
            "tour_names": len(TOUR_NAME_TO_INDEX),
        }
    })

@app.route("/reindex", methods=["POST"])
def reindex():
    """Rebuild index endpoint"""
    secret = request.headers.get("X-RBW-ADMIN", "")
    if not secret and os.environ.get("RBW_ALLOW_REINDEX", "") != "1":
        return jsonify({"error": "reindex not allowed"}), 403

    load_knowledge()
    build_index(force_rebuild=True)

    return jsonify({
        "ok": True,
        "count": len(FLAT_TEXTS),
        "tours": len(TOURS_DB)
    })

# =========== GOOGLE SHEETS INTEGRATION ===========
_gsheet_client = None
_gsheet_client_lock = threading.Lock()

def get_gspread_client(force_refresh: bool = False):
    """Get Google Sheets client"""
    global _gsheet_client

    if not GOOGLE_SERVICE_ACCOUNT_JSON:
        logger.error("GOOGLE_SERVICE_ACCOUNT_JSON not set")
        return None

    with _gsheet_client_lock:
        if _gsheet_client is not None and not force_refresh:
            return _gsheet_client

        try:
            info = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
            scopes = [
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/drive",
            ]
            creds = Credentials.from_service_account_info(info, scopes=scopes)
            _gsheet_client = gspread.authorize(creds)
            logger.info("âœ… Google Sheets client initialized")
            return _gsheet_client
        except Exception as e:
            logger.error(f"âŒ Google Sheets client failed: {e}")
            return None

# ===============================
# API: SAVE LEAD (Website / Call / Zalo)
# ===============================
@app.route('/api/save-lead', methods=['POST', 'OPTIONS'])
def save_lead():
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200

    try:
        data = request.get_json() or {}

        # =====================================================
        # 1. EXTRACT & VALIDATE (GIá»® NGUYÃŠN LOGIC CÅ¨)
        # =====================================================
        phone = (data.get('phone') or '').strip()
        name = (data.get('name') or '').strip()
        email = (data.get('email') or '').strip()
        tour_interest = (data.get('tour_interest') or '').strip()
        page_url = (data.get('page_url') or '').strip()
        note = (data.get('note') or '').strip()

        # ðŸ”‘ FE â†’ BE event_id (KHÃ”NG tá»± sinh)
        event_id = data.get('event_id')
        # ðŸ”’ HARD DEDUP: CAPI chá»‰ cháº¡y khi cÃ³ event_id tá»« FE
        if not event_id:
            logger.info("â„¹ï¸ Lead without event_id â†’ Pixel only, skip CAPI")
        if not phone and not data.get('event_id'):
            return jsonify({'error': 'Phone number is required'}), 400

        phone_clean = re.sub(r'\D', '', phone)
        if phone_clean and not re.match(r'^0\d{9,10}$', phone_clean):
            return jsonify({'error': 'Invalid phone number format'}), 400

        timestamp = datetime.now().strftime("%d/%m/%Y %H:%M:%S")

        lead_data = {
            'timestamp': timestamp,
            'phone': phone_clean,
            'name': name,
            'email': email,
            'tour_interest': tour_interest,
            'page_url': page_url,
            'note': note,
            'source': 'Website Lead Form'
        }

        # =====================================================
        # 2. SAVE GOOGLE SHEETS (CHá»ˆ GHI KHI CÃ“ LEAD THáº¬T)
        # =====================================================
        if ENABLE_GOOGLE_SHEETS and phone_clean:
            try:
                import gspread
                from google.oauth2.service_account import Credentials

                creds_json = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
                creds = Credentials.from_service_account_info(
                    creds_json,
                    scopes=['https://www.googleapis.com/auth/spreadsheets']
                )

                gc = gspread.authorize(creds)
                sh = gc.open_by_key(GOOGLE_SHEET_ID)
                ws = sh.worksheet(GOOGLE_SHEET_NAME)

                ws.append_row(
                    [
                        timestamp,
                        'Website - Lead Form',
                        'Form Submission',
                        page_url or '',
                        name or '',
                        int(phone_clean) if phone_clean else '',
                        tour_interest or '',
                        note or email or '',
                        'New'
                    ],
                    value_input_option='USER_ENTERED'
                )

                logger.info('âœ… Lead saved to Google Sheets')

            except Exception as e:
                logger.error(f'âŒ Google Sheets error: {e}')

        # =====================================================
        # 3. FALLBACK STORAGE (KHÃ”NG Äá»¤NG)
        # =====================================================
        if ENABLE_FALLBACK_STORAGE:
            try:
                if os.path.exists(FALLBACK_STORAGE_PATH):
                    with open(FALLBACK_STORAGE_PATH, 'r', encoding='utf-8') as f:
                        leads = json.load(f)
                else:
                    leads = []

                leads.append(lead_data)
                leads = leads[-1000:]

                with open(FALLBACK_STORAGE_PATH, 'w', encoding='utf-8') as f:
                    json.dump(leads, f, ensure_ascii=False, indent=2)

            except Exception as e:
                logger.error(f'âŒ Fallback storage error: {e}')

        # =====================================================
        # 4. META PARAM BUILDER (FBP / FBC â€“ FALLBACK DEDUP)
        # =====================================================
        meta = MetaParamService()
        meta.process_request(request)

        fbp = meta.get_fbp()
        fbc = meta.get_fbc()

        # Chuáº©n Meta: event_source_url
        event_source_url = (
            page_url
            or request.headers.get("Referer")
            or request.url
        )

        # =====================================================
        # 5. META CAPI â€“ LEAD (CHUáº¨N META, DEDUP 100%)
        # =====================================================
        if ENABLE_META_CAPI_LEAD and HAS_META_CAPI:

            test_code = os.environ.get("META_TEST_EVENT_CODE", "").strip()
            is_test_mode = bool(test_code)

            # ===== PROD: báº¯t buá»™c cÃ³ event_id Ä‘á»ƒ dedup =====
            if not event_id and not is_test_mode:
                logger.warning(
                    "âš ï¸ Lead submitted without event_id "
                    "(PROD mode â†’ Pixel only, CAPI skipped)"
                )
            else:
                try:
                    # ================= LEAD â€“ META CAPI (CHá»ˆ FORM THáº¬T) =================
                    phone_clean = re.sub(r'\D', '', phone or '')

                    if phone_clean and re.match(r'^0\d{9,10}$', phone_clean) and event_id:
                        send_meta_lead(
                            request=request,
                            event_name="Contact",
                            event_id=event_id,          # ðŸ”’ Báº®T BUá»˜C tá»« FE
                            phone=phone_clean,
                            fbp=fbp,
                            fbc=fbc,
                            event_source_url=event_source_url,
                            content_name=(
                                f"Tour: {tour_interest}"
                                if tour_interest else "Website Lead Form"
                            )
                        )

                        increment_stat("meta_capi_leads")
                        logger.info(
                            f"ðŸ“© Meta CAPI Lead sent | "
                            f"mode=PROD | event_id={event_id}"
                        )
                    else:
                        logger.warning(
                            "âš ï¸ Meta CAPI Lead bá»‹ bá» qua: thiáº¿u event_id hoáº·c chÆ°a pháº£i lead tháº­t"
                        )

                except Exception as e:
                    increment_stat("meta_capi_errors")
                    logger.error(f"âŒ Meta CAPI Lead error: {e}")

        increment_stat("leads")

        # =====================================================
        # 6. RESPONSE
        # =====================================================
        return jsonify({
            'success': True,
            'message': 'Lead Ä‘Ã£ Ä‘Æ°á»£c lÆ°u',
            'data': {
                'phone': phone_clean[:3] + '***' + phone_clean[-2:],
                'timestamp': timestamp
            }
        })

    except Exception as e:
        logger.error(f'âŒ Save lead fatal error: {e}')
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

# =========================================================
# API: CONTACT CLICK (ALIAS â€“ FIX 404, SAFE)
# =========================================================
ALLOWED_ORIGINS = [
    "https://rubywings.vn",
    "https://www.rubywings.vn",
    "http://localhost:3000",  # local dev
]

def cors_origin():
    """
    CORS production-safe:
    - Cho phÃ©p Origin trong whitelist
    - Same-origin / server-side â†’ cho qua
    - Origin láº¡ â†’ váº«n tráº£ vá» Origin Ä‘á»ƒ KHÃ”NG lÃ m cháº¿t há»‡
    - KhÃ´ng dÃ¹ng "*" cho browser-origin (trÃ¡nh lá»—i credentials)
    """
    origin = request.headers.get("Origin")

    # Same-origin / server-side / tool (no Origin header)
    if not origin:
        return "https://www.rubywings.vn"

    # Whitelist chuáº©n
    if origin in ALLOWED_ORIGINS:
        return origin

    # Fallback an toÃ n: KHÃ”NG cháº·n POST, nhÆ°ng KHÃ”NG má»Ÿ wildcard
    return origin

@app.route("/api/track-contact", methods=["POST", "OPTIONS"])
def track_contact():
    logger.warning(f"[CORS AUDIT] Origin={request.headers.get('Origin')}")
    # ===== CORS PREFLIGHT =====
    if request.method == 'OPTIONS':
        response = jsonify({'status': 'ok'})
        response.headers.add("Access-Control-Allow-Origin", cors_origin())
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
        response.headers.add(
            "Access-Control-Allow-Headers",
            "Content-Type, X-RW-EVENT-ID"
        )
        response.headers.add("Access-Control-Max-Age", "86400")
        return response, 200

    try:
        data = request.get_json() or {}
        event_id = data.get('event_id')
        phone = data.get('phone')
        source = data.get('source', 'Contact')

        logger.info(f"ðŸ“ž Track contact: source={source}, event_id={event_id[:8] if event_id else 'None'}")

        # ðŸ”’ 1. CHECK EVENT_ID (báº¯t buá»™c cho CAPI)
        if not event_id:
            logger.warning(f"âš ï¸ Missing event_id â†’ Pixel only ({source})")
            response = jsonify({'success': True, 'message': 'Pixel only (no CAPI)'})
            response.headers.add("Access-Control-Allow-Origin", cors_origin())
            return response

        # ðŸ”’ 2. CHECK META CAPI AVAILABILITY
        if not ENABLE_META_CAPI_LEAD or not HAS_META_CAPI:
            logger.info(f"â„¹ï¸ Meta CAPI disabled: ENABLE_META_CAPI_LEAD={ENABLE_META_CAPI_LEAD}, HAS_META_CAPI={HAS_META_CAPI}")
            response = jsonify({'success': True, 'message': 'CAPI disabled'})
            response.headers.add("Access-Control-Allow-Origin", cors_origin())
            return response

        # ðŸ”’ 3. EXTRACT META PARAMS
        meta = MetaParamService()
        meta.process_request(request)

        # ðŸ”’ 4. SEND META CAPI
        send_meta_lead(
            request=request,
            event_name="Lead",  # Chuáº©n Meta: "Lead" thay vÃ¬ "Contact"
            event_id=event_id,
            phone=phone or "",
            fbp=meta.get_fbp(),
            fbc=meta.get_fbc(),
            content_name=f"Contact: {source}"
        )
        increment_stat('meta_capi_leads')
        logger.info(f"âœ… Meta CAPI Lead sent: {source}")

        response = jsonify({'success': True})
        response.headers.add("Access-Control-Allow-Origin", cors_origin())
        return response

    except Exception as e:
        increment_stat('meta_capi_errors')
        logger.error(f"âŒ Track contact error: {e}", exc_info=True)
        response = jsonify({'error': 'Internal server error'})
        response.headers.add("Access-Control-Allow-Origin", cors_origin())
        return response, 500

@app.route('/api/track-call', methods=['POST', 'OPTIONS'])
def track_call():
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200

    try:
        data = request.get_json() or {}

        event_id = data.get('event_id')
        phone = data.get('phone')
        action = data.get('action', 'Call/Zalo Click')

        # ===== META PARAM BUILDER =====
        meta = MetaParamService()
        meta.process_request(request)

        fbp = meta.get_fbp()
        fbc = meta.get_fbc()

        if ENABLE_META_CAPI_CALL and HAS_META_CAPI:
            send_meta_lead(
                request=request,
                event_name="CallButtonClick",  # KHÃ”NG Ä‘á»•i
                event_id=event_id,             # tá»« FE
                phone=phone,
                fbp=fbp,                       # fallback dedup
                fbc=fbc,                       # fallback dedup
                content_name=action
            )
            increment_stat('meta_capi_calls')
            logger.info("ðŸ“ž CallButtonClick Meta CAPI sent")

        return jsonify({'success': True})

    except Exception as e:
        increment_stat('meta_capi_errors')
        logger.error(f'âŒ Track call error: {e}')
        return jsonify({'error': str(e)}), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    try:
        return jsonify({
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "services": {
                "chatbot": "running",
                "openai": "available" if client else "unavailable",
                "faiss": "available" if INDEX is not None else "unavailable",
                "tours_db": len(TOURS_DB),
                "upgrades": {k: v for k, v in UpgradeFlags.get_all_flags().items()
                           if k.startswith("UPGRADE_")}
            },
            "memory_profile": {
                "ram_profile": RAM_PROFILE,
                "is_low_ram": IS_LOW_RAM,
                "is_high_ram": IS_HIGH_RAM,
                "tour_count": len(TOURS_DB),
                "context_count": len(SESSION_CONTEXTS)
            }
        })
    except Exception as e:
        return jsonify({
            "status": "unhealthy",
            "error": str(e)
        }), 500

# =========== INITIALIZATION ===========
def initialize_app():
    """Initialize the application"""
    logger.info("ðŸš€ Starting Ruby Wings Chatbot v4.0 (Dataclass Rewrite)...")

    # Apply memory optimizations
    optimize_for_memory_profile()

    # Load knowledge base
    load_knowledge()

    # Load or build tours database (SAFE)
    if os.path.exists(FAISS_MAPPING_PATH):
        try:
            with open(FAISS_MAPPING_PATH, 'r', encoding='utf-8') as f:
                loaded = json.load(f)

            # Defensive: chá»‰ cháº¥p nháº­n list[dict]
            if isinstance(loaded, list):
                safe_mapping = [m for m in loaded if isinstance(m, dict)]
                MAPPING[:] = safe_mapping
                FLAT_TEXTS[:] = [m.get('text', '') for m in safe_mapping]
                logger.info(f"ðŸ“ Loaded {len(MAPPING)} mappings from disk (safe)")
            else:
                MAPPING[:] = []
                FLAT_TEXTS[:] = []
                logger.warning(
                    "âš ï¸ FAISS_MAPPING_PATH is not list, skip loading mappings"
                )

        except Exception as e:
            MAPPING[:] = []
            FLAT_TEXTS[:] = []
            logger.error(f"âŒ Failed to load mappings safely: {e}")

    # Build index in background
    def build_index_background():
        time.sleep(2)
        success = build_index(force_rebuild=False)
        if success:
            logger.info("âœ… Index ready")
        else:
            logger.warning("âš ï¸ Index building failed")

    threading.Thread(target=build_index_background, daemon=True).start()

    # Initialize Google Sheets client
    if ENABLE_GOOGLE_SHEETS:
        threading.Thread(target=get_gspread_client, daemon=True).start()

    # Log active upgrades
    active_upgrades = [
        name for name, enabled in UpgradeFlags.get_all_flags().items()
        if enabled and name.startswith("UPGRADE_")
    ]
    logger.info(f"ðŸ”§ Active upgrades: {len(active_upgrades)}")
    for upgrade in active_upgrades:
        logger.info(f"   â€¢ {upgrade}")

    # Log memory profile
    logger.info(
        f"ðŸ§  Memory Profile: {RAM_PROFILE}MB | "
        f"Low RAM: {IS_LOW_RAM} | High RAM: {IS_HIGH_RAM}"
    )
    logger.info(f"ðŸ“Š Tours Database: {len(TOURS_DB)} tours loaded")

    logger.info("âœ… Application initialized successfully with dataclasses")

@app.route("/api/debug", methods=["GET"])
def debug_endpoint():
    """Debug endpoint to check loaded data"""
    debug_info = {
        "status": "healthy" if len(TOURS_DB) > 0 else "no_data",
        "app_initialized": APP_INITIALIZED,
        "counts": {
            "tours_db": len(TOURS_DB),
            "tour_name_to_index": len(TOUR_NAME_TO_INDEX),
            "flat_texts": len(FLAT_TEXTS),
            "knowledge_tours": len(KNOW.get("tours", [])) if KNOW else 0
        },
        "sample_tours": [],
        "file_info": {
            "current_directory": os.getcwd(),
            "data_directory_exists": os.path.exists("data"),
            "files_in_current_dir": os.listdir("."),
        }
    }

    # ThÃªm thÃ´ng tin vá» 3 tour Ä‘áº§u tiÃªn
    for i, (idx, tour) in enumerate(list(TOURS_DB.items())[:3]):
        debug_info["sample_tours"].append({
            "id": idx,
            "name": tour.name,
            "location": tour.location,
            "duration": tour.duration,
            "price": tour.price[:50] if tour.price else ""
        })

    # ThÃªm thÃ´ng tin vá» cÃ¡c file trong thÆ° má»¥c data náº¿u cÃ³
    if os.path.exists("data"):
        debug_info["file_info"]["files_in_data_dir"] = os.listdir("data")
        # Kiá»ƒm tra knowledge.json
        knowledge_paths = [
            "data/knowledge.json",
            "knowledge.json",
            "src/data/knowledge.json"
        ]
        for path in knowledge_paths:
            if os.path.exists(path):
                debug_info["file_info"]["knowledge_json_found"] = path
                # Äá»c kÃ­ch thÆ°á»›c file
                try:
                    size = os.path.getsize(path)
                    debug_info["file_info"]["knowledge_json_size"] = f"{size} bytes"
                except:
                    pass
                break

    # ThÃªm thÃ´ng tin vá» upgrades
    debug_info["upgrades"] = UpgradeFlags.get_all_flags()

    # ThÃªm thÃ´ng tin vá» cÃ¡c services
    debug_info["services"] = {
        "openai": "available" if client else "unavailable",
        "faiss": "available" if HAS_FAISS else "unavailable",
        "google_sheets": "available" if HAS_GOOGLE_SHEETS else "unavailable",
        "meta_capi": "available" if HAS_META_CAPI else "unavailable",
    }

    return jsonify(debug_info)

def get_fallback_tours(query=None, limit=5):
    """Fallback khi FAISS khÃ´ng tráº£ vá» káº¿t quáº£"""
    try:
        all_tours = list(TOURS_DB.values())

        if query:
            # Simple keyword matching
            query_lower = query.lower()
            matched_tours = []

            for tour in all_tours:
                score = 0

                # Check name
                if tour.name and query_lower in tour.name.lower():
                    score += 3

                # Check location
                if tour.location and query_lower in tour.location.lower():
                    score += 2

                # Check tags
                if tour.tags:
                    for tag in tour.tags:
                        if query_lower in tag.lower():
                            score += 1

                if score > 0:
                    matched_tours.append((score, tour))

            # Sort by score
            matched_tours.sort(key=lambda x: x[0], reverse=True)
            return [tour for _, tour in matched_tours[:limit]]

        # Return first N tours if no query
        return all_tours[:limit]

    except Exception as e:
        logger.error(f"Fallback tour error: {e}")
        return list(TOURS_DB.values())[:min(limit, len(TOURS_DB))]

def _prepare_llm_prompt(user_message: str, search_results: List, context: Dict) -> str:
    """Prepare prompt for LLM - THÃ”NG MINH vá»›i context & cÃ¢u há»i chung"""

    message_lower = user_message.lower()

    # PhÃ¢n loáº¡i cÃ¢u há»i
    is_general_question = any(keyword in message_lower for keyword in [
        'cÃ³ bao gá»“m', 'Ä‘Ã£ bao gá»“m', 'bao gá»“m gÃ¬', 'bao gá»“m nhá»¯ng gÃ¬',
        'cÃ³ gÃ¬', 'nhÆ° tháº¿ nÃ o', 'ra sao', 'tháº¿ nÃ o', 'giÃ¡ tour'
    ])

    has_specific_tour = context.get('current_tours') and len(context.get('current_tours', [])) > 0
    tour_count = len(context.get('current_tours', []))

    # PhÃ¡t hiá»‡n cÃ¢u há»i tiáº¿p theo (followup)
    is_followup = (
        context.get('last_action') == 'chat_response' and
        (has_specific_tour or context.get('last_tour_name'))
    )

    # PhÃ¡t hiá»‡n rÃ ng buá»™c Ä‘á»‹a lÃ½
    has_location_constraint = False
    location_constraint = None
    filters = context.get('filters', {})
    if filters:
        if filters.get('location'):
            has_location_constraint = True
            location_constraint = filters.get('location')
        elif filters.get('near_location'):
            has_location_constraint = True
            location_constraint = filters.get('near_location')

    prompt_parts = [
        "Báº¡n lÃ  trá»£ lÃ½ tÆ° váº¥n du lá»‹ch Ruby Wings - CHUYÃŠN NGHIá»†P, THÃ”NG MINH, NHIá»†T TÃŒNH.",
        "",
        "âš ï¸ QUY Táº®C NGHIÃŠM NGáº¶T:",
    ]

    # RULE 1: CÃ¢u há»i CHUNG (khÃ´ng cÃ³ tour cá»¥ thá»ƒ)
    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "",
            "ðŸŽ¯ ÄÃ‚Y LÃ€ CÃ‚U Há»ŽI CHUNG - KHÃ”NG CÃ“ TOUR Cá»¤ THá»‚:",
            "â€¢ TRáº¢ Lá»œI NGáº®N Gá»ŒN (2-4 cÃ¢u) dá»±a trÃªn kiáº¿n thá»©c chung vá» tour du lá»‹ch",
            "â€¢ Sá»¬ Dá»¤NG OPENAI Ä‘á»ƒ tráº£ lá»i tá»± nhiÃªn, khÃ´ng nÃ³i 'khÃ´ng cÃ³ dá»¯ liá»‡u'",
            "â€¢ Káº¾T THÃšC báº±ng cÃ¢u há»i: 'Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t?'",
            "â€¢ KHÃ”NG liá»‡t kÃª tour, KHÃ”NG dump dá»¯ liá»‡u",
            "",
            "VÃ Dá»¤ ÄÃšNG:",
            "Q: 'GiÃ¡ tour bao gá»“m gÃ¬?'",
            "A: 'GiÃ¡ tour Ruby Wings thÆ°á»ng bao gá»“m: xe Ä‘Æ°a Ä‘Ã³n, Äƒn uá»‘ng theo chÆ°Æ¡ng trÃ¬nh, khÃ¡ch sáº¡n, hÆ°á»›ng dáº«n viÃªn vÃ  báº£o hiá»ƒm. TÃ¹y tour cá»¥ thá»ƒ cÃ³ thá»ƒ cÃ³ thÃªm vÃ© tham quan hoáº·c hoáº¡t Ä‘á»™ng Ä‘áº·c biá»‡t. Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t? ðŸ˜Š'",
            "",
            "Q: 'Tour cÃ³ phÃ¹ há»£p gia Ä‘Ã¬nh khÃ´ng?'",
            "A: 'Ruby Wings cÃ³ nhiá»u tour phÃ¹ há»£p gia Ä‘Ã¬nh vá»›i hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng, an toÃ n cho tráº» em vÃ  ngÆ°á»i lá»›n tuá»•i. Gia Ä‘Ã¬nh báº¡n cÃ³ bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch loáº¡i hÃ¬nh nÃ o (thiÃªn nhiÃªn, lá»‹ch sá»­, nghá»‰ dÆ°á»¡ng) Ä‘á»ƒ tÃ´i tÆ° váº¥n tour phÃ¹ há»£p nháº¥t?'",
        ])

    # RULE 2: CÃ¢u há»i TIáº¾P THEO (followup)
    elif is_followup:
        prompt_parts.extend([
            "",
            "ðŸ’­ ÄÃ‚Y LÃ€ CÃ‚U Há»ŽI TIáº¾P THEO - Sá»¬ Dá»¤NG CONTEXT:",
            f"â€¢ ÄÃ£ bÃ n vá» {tour_count} tour: {context.get('last_tour_name', '')}",
            "â€¢ PHáº¢I dá»±a vÃ o context cÅ© - KHÃ”NG reset",
            "â€¢ TRáº¢ Lá»œI TIáº¾P theo ngá»¯ cáº£nh Ä‘Ã£ cÃ³",
            "â€¢ KHÃ”NG liá»‡t kÃª láº¡i toÃ n bá»™ tour",
            "â€¢ Náº¿u há»i vá» giÃ¡/thá»i gian â†’ Chá»‰ nÃ³i vá» tour Ä‘ang bÃ n",
            "â€¢ Náº¿u há»i thÃªm Ä‘iá»u kiá»‡n â†’ Gá»£i Ã½ tour tá»« context hoáº·c há»i láº¡i",
            "",
            "VÃ Dá»¤ ÄÃšNG:",
            "Context: ÄÃ£ nÃ³i vá» 'Tour Báº¡ch MÃ£'",
            "Q: 'Tour nÃ y cÃ³ phÃ¹ há»£p nhÃ³m 10 ngÆ°á»i khÃ´ng?'",
            "A: 'Tour Báº¡ch MÃ£ ráº¥t phÃ¹ há»£p cho nhÃ³m 10 ngÆ°á»i! ChÃºng tÃ´i cÃ³ thá»ƒ tá»• chá»©c riÃªng vá»›i giÃ¡ Æ°u Ä‘Ã£i. NhÃ³m báº¡n thÃ­ch hoáº¡t Ä‘á»™ng nÃ o: trekking, thiá»n tÄ©nh tÃ¢m hay cáº£ hai? TÃ´i sáº½ tÆ° váº¥n lá»‹ch trÃ¬nh chi tiáº¿t.'",
        ])

    # RULE 3: Location constraint
    if has_location_constraint:
        prompt_parts.extend([
            "",
            "ðŸš¨ RÃ€NG BUá»˜C Äá»ŠA LÃ - NGHIÃŠM NGáº¶T:",
            f"â€¢ YÃªu cáº§u tour gáº§n/táº¡i: {location_constraint or 'khu vá»±c cá»¥ thá»ƒ'}",
            "â€¢ CHá»ˆ Ä‘á» xuáº¥t tour trong khu vá»±c nÃ y",
            "â€¢ Náº¾U khÃ´ng cÃ³ tour phÃ¹ há»£p:",
            "  â†’ 'Hiá»‡n Ruby Wings chÆ°a cÃ³ tour táº¡i [Ä‘á»‹a Ä‘iá»ƒm]. Tuy nhiÃªn, chÃºng tÃ´i cÃ³ tour gáº§n nháº¥t táº¡i [X].'",
            "  â†’ Há»i: 'Báº¡n cÃ³ muá»‘n xem tour á»Ÿ khu vá»±c lÃ¢n cáº­n khÃ´ng?'",
        ])

    # RULE 4: Giá»›i háº¡n tour
    prompt_parts.extend([
        "",
        "ðŸ“Š GIá»šI Háº N TOUR (Báº®T BUá»˜C):",
        "â€¢ Tá»‘i Ä‘a 2-3 tour/cÃ¢u tráº£ lá»i",
        "â€¢ Má»–I tour pháº£i cÃ³ LÃ DO rÃµ rÃ ng",
        "â€¢ KHÃ”NG liá»‡t kÃª >3 tour",
        "â€¢ Náº¿u cÃ³ nhiá»u tour phÃ¹ há»£p:",
        "  â†’ Chá»n 2-3 TIÃŠU BIá»‚U nháº¥t",
        "  â†’ TÃ³m táº¯t: 'CÃ²n X tour khÃ¡c...'",
        "  â†’ Há»i: 'Báº¡n muá»‘n xem thÃªm loáº¡i nÃ o?'",
    ])

    # CONTEXT INFO
    prompt_parts.extend([
        "",
        "ðŸ“š THÃ”NG TIN NGá»® Cáº¢NH:",
    ])

    if context.get('user_preferences'):
        prefs = []
        for k, v in context['user_preferences'].items():
            prefs.append(f"{k}: {v}")
        if prefs:
            prompt_parts.append(f"- Sá»Ÿ thÃ­ch: {'; '.join(prefs)}")

    if context.get('current_tours'):
        tours_info = [f"{t['name']}" for t in context['current_tours'][:3]]
        if tours_info:
            prompt_parts.append(f"- Tour Ä‘Ã£ bÃ n: {', '.join(tours_info)}")

    if filters:
        filter_strs = []
        if filters.get('price_max'):
            filter_strs.append(f"giÃ¡ <{filters['price_max']:,}Ä‘")
        if filters.get('location'):
            filter_strs.append(f"Vá»Š TRÃ: {filters['location']}")
        if filter_strs:
            prompt_parts.append(f"- RÃ ng buá»™c: {'; '.join(filter_strs)}")

    # SEARCH RESULTS
    prompt_parts.append("")
    prompt_parts.append("ðŸ“ Dá»® LIá»†U Tá»ª Há»† THá»NG:")

    if search_results:
        for i, (score, passage) in enumerate(search_results[:5], 1):
            text = passage.get('text', '')[:250]
            prompt_parts.append(f"[{i}] {text}")
    else:
        prompt_parts.append("(KhÃ´ng cÃ³ dá»¯ liá»‡u cá»¥ thá»ƒ - sá»­ dá»¥ng kiáº¿n thá»©c chung)")

    # YÃŠU Cáº¦U TRáº¢ Lá»œI
    prompt_parts.append("")
    prompt_parts.append("ðŸ’¬ YÃŠU Cáº¦U TRáº¢ Lá»œI:")

    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "1. Tráº£ lá»i NGáº®N Gá»ŒN (2-4 cÃ¢u) dá»±a OpenAI",
            "2. KHÃ”NG nÃ³i 'khÃ´ng cÃ³ dá»¯ liá»‡u'",
            "3. Káº¿t thÃºc: Há»i láº¡i Ä‘á»ƒ xÃ¡c Ä‘á»‹nh tour",
        ])
    elif is_followup:
        prompt_parts.extend([
            "1. Dá»±a vÃ o CONTEXT (tour Ä‘Ã£ bÃ n)",
            "2. Tráº£ lá»i TIáº¾P, KHÃ”NG reset",
            "3. Tá»‘i Ä‘a nháº¯c 1-2 tour tá»« context",
        ])
    else:
        prompt_parts.extend([
            "1. Chá»n 2-3 tour vá»›i LÃ DO rÃµ",
            "2. KHÃ”NG >3 tour",
            "3. Náº¿u nhiá»u: tÃ³m táº¯t + há»i tiáº¿p",
        ])

    prompt_parts.append("4. LuÃ´n káº¿t thÃºc: CÃ¢u há»i dáº«n dáº¯t hoáº·c 'ðŸ“ž Gá»i 0332510486'")

    return "\n".join(prompt_parts)

def _generate_fallback_response(user_message: str, search_results: List, tour_indices: List[int] = None) -> str:
    """Generate SMART fallback response - DÃ¹ng OpenAI khi cÃ³, context-aware"""
    message_lower = user_message.lower()

    # ===== Sá»¬ Dá»¤NG OPENAI Náº¾U CÃ“ =====
    if client and HAS_OPENAI:
        try:
            # Chuáº©n bá»‹ context
            context_parts = []

            # ThÃ´ng tin tour náº¿u cÃ³
            if tour_indices and TOURS_DB:
                for idx in tour_indices[:2]:
                    tour = TOURS_DB.get(idx)
                    if tour:
                        context_parts.append(f"Tour: {tour.name}")
                        if tour.duration:
                            context_parts.append(f"Thá»i gian: {tour.duration}")
                        if tour.price:
                            context_parts.append(f"GiÃ¡: {tour.price}")
                        if tour.summary:
                            context_parts.append(f"MÃ´ táº£: {tour.summary[:150]}")

            # Dá»¯ liá»‡u search
            if search_results:
                for i, (score, passage) in enumerate(search_results[:3], 1):
                    text = passage.get('text', '')[:200]
                    if text:
                        context_parts.append(f"ThÃ´ng tin {i}: {text}")

            # Táº¡o prompt thÃ´ng minh
            context_str = "\n".join(context_parts) if context_parts else "KhÃ´ng cÃ³ dá»¯ liá»‡u cá»¥ thá»ƒ"

            prompt = f"""Báº¡n lÃ  tÆ° váº¥n viÃªn Ruby Wings chuyÃªn nghiá»‡p.

THÃ”NG TIN CÃ“ Sáº´N:
{context_str}

YÃŠU Cáº¦U TRáº¢ Lá»œI:
1. Náº¿u cÃ³ thÃ´ng tin tour cá»¥ thá»ƒ â†’ TÆ° váº¥n dá»±a trÃªn Ä‘Ã³
2. Náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u â†’ Tráº£ lá»i dá»±a kiáº¿n thá»©c chung vá» tour du lá»‹ch
3. LUÃ”N káº¿t thÃºc báº±ng cÃ¢u há»i dáº«n dáº¯t hoáº·c "Gá»i 0332510486"
4. Ngáº¯n gá»n 2-4 cÃ¢u, nhiá»‡t tÃ¬nh, tá»± nhiÃªn
5. KHÃ”NG nÃ³i "khÃ´ng cÃ³ dá»¯ liá»‡u", "xin lá»—i khÃ´ng tÃ¬m tháº¥y"

CÃ¢u há»i cá»§a khÃ¡ch: {user_message}"""

            response = client.chat.completions.create(
                model=CHAT_MODEL,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.6,
                max_tokens=300
            )

            if response.choices:
                reply = response.choices[0].message.content or ""
                # Äáº£m báº£o cÃ³ hotline
                if "0332510486" not in reply:
                    reply += "\n\nðŸ“ž LiÃªn há»‡ 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t!"
                return reply

        except Exception as e:
            logger.error(f"OpenAI fallback error: {e}")
            # RÆ¡i xuá»‘ng logic template bÃªn dÆ°á»›i

    # ===== FALLBACK KHI KHÃ”NG CÃ“ OPENAI =====

    # CÃ³ tour cá»¥ thá»ƒ â†’ Tráº£ thÃ´ng tin tour
    if tour_indices and TOURS_DB:
        response_parts = []
        for idx in tour_indices[:2]:
            tour = TOURS_DB.get(idx)
            if tour:
                response_parts.append(f"**{tour.name}**")
                if tour.duration:
                    response_parts.append(f"â±ï¸ {tour.duration}")
                if tour.location:
                    response_parts.append(f"ðŸ“ {tour.location}")
                if tour.price:
                    response_parts.append(f"ðŸ’° {tour.price}")
                if tour.summary:
                    response_parts.append(f"ðŸ“ {tour.summary[:150]}...")

        if response_parts:
            return "\n".join(response_parts) + "\n\nðŸ“ž Gá»i 0332510486 Ä‘á»ƒ biáº¿t thÃªm!"

    # CÃ³ search results â†’ TÃ³m táº¯t
    if search_results:
        top_results = search_results[:2]
        response_parts = ["ThÃ´ng tin liÃªn quan:"]

        for i, (score, passage) in enumerate(top_results, 1):
            text = passage.get('text', '')[:150]
            if text:
                response_parts.append(f"\n{i}. {text}...")

        response_parts.append("\n\nðŸ“ž LiÃªn há»‡ 0332510486 Ä‘á»ƒ biáº¿t chi tiáº¿t!")
        return "".join(response_parts)

    # CÃ¢u há»i chung â†’ Template thÃ´ng minh theo keyword
    general_qa = {
        'bao gá»“m': "GiÃ¡ tour Ruby Wings thÆ°á»ng bao gá»“m: xe Ä‘Æ°a Ä‘Ã³n, Äƒn uá»‘ng theo chÆ°Æ¡ng trÃ¬nh, khÃ¡ch sáº¡n, hÆ°á»›ng dáº«n viÃªn vÃ  báº£o hiá»ƒm. TÃ¹y tour cá»¥ thá»ƒ cÃ³ thÃªm hoáº¡t Ä‘á»™ng Ä‘áº·c biá»‡t. Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t? ðŸ˜Š",

        'phÃ¹ há»£p gia Ä‘Ã¬nh': "Ruby Wings cÃ³ nhiá»u tour phÃ¹ há»£p gia Ä‘Ã¬nh vá»›i hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng, an toÃ n cho tráº» em vÃ  ngÆ°á»i lá»›n tuá»•i. Gia Ä‘Ã¬nh báº¡n bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch loáº¡i tour nÃ o (thiÃªn nhiÃªn, lá»‹ch sá»­, nghá»‰ dÆ°á»¡ng)?",

        'phÃ¹ há»£p': "Ruby Wings cÃ³ tour cho má»i Ä‘á»‘i tÆ°á»£ng! Báº¡n Ä‘i nhÃ³m bao nhiÃªu ngÆ°á»i vÃ  cÃ³ sá»Ÿ thÃ­ch gÃ¬ Ä‘áº·c biá»‡t khÃ´ng?",

        'giÃ¡': "GiÃ¡ tour Ruby Wings tá»« 800.000Ä‘ - 3.000.000Ä‘ tÃ¹y loáº¡i. Báº¡n cÃ³ ngÃ¢n sÃ¡ch khoáº£ng bao nhiÃªu vÃ  muá»‘n Ä‘i máº¥y ngÃ y Ä‘á»ƒ tÃ´i tÆ° váº¥n phÃ¹ há»£p?",

        'thá»i gian': "Ruby Wings cÃ³ tour 1 ngÃ y, 2 ngÃ y 1 Ä‘Ãªm, 3 ngÃ y 2 Ä‘Ãªm. Báº¡n cÃ³ khoáº£ng bao nhiÃªu thá»i gian ráº£nh?",

        'Ä‘á»‹a Ä‘iá»ƒm': "Ruby Wings tá»• chá»©c tour táº¡i Huáº¿, Quáº£ng Trá»‹, Báº¡ch MÃ£, TrÆ°á»ng SÆ¡n vÃ  nhiá»u nÆ¡i khÃ¡c. Báº¡n muá»‘n khÃ¡m phÃ¡ khu vá»±c nÃ o?",

        'nhÃ³m': "Tour nhÃ³m cá»§a Ruby Wings ráº¥t phÃ¹ há»£p! NhÃ³m báº¡n bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch hoáº¡t Ä‘á»™ng gÃ¬ (teambuilding, nghá»‰ dÆ°á»¡ng, khÃ¡m phÃ¡)?",

        'retreat': "Ruby Wings chuyÃªn tour retreat káº¿t há»£p thiá»n, khÃ­ cÃ´ng vÃ  thiÃªn nhiÃªn. Báº¡n muá»‘n tour bao nhiÃªu ngÃ y vÃ  má»©c Ä‘á»™ hoáº¡t Ä‘á»™ng nhÆ° nÃ o?",
    }

    # TÃ¬m keyword match
    for keyword, response in general_qa.items():
        if keyword in message_lower:
            return response

    # Default - Dáº«n dáº¯t há»i láº¡i
    return "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n tÃ¬m tour phÃ¹ há»£p! Báº¡n cÃ³ thá»ƒ cho tÃ´i biáº¿t:\n" \
           "â€¢ Muá»‘n Ä‘i Ä‘Ã¢u?\n" \
           "â€¢ Thá»i gian bao lÃ¢u?\n" \
           "â€¢ NgÃ¢n sÃ¡ch khoáº£ng bao nhiÃªu?\n" \
           "â€¢ Äi bao nhiÃªu ngÆ°á»i?\n\n" \
           "Hoáº·c gá»i ngay 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t! ðŸ˜Š"

# Run initialization
initialize_app()

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port, debug=False)