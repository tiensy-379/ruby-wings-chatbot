def safe_validate(reply):
    try:
        if not isinstance(reply, dict):
            return reply
        # Only validate when tour is selected
        if not reply.get("tour_name"):
            return reply
        return AutoValidator.validate_response(reply)
    except Exception as e:
        try:
            reply.setdefault("warnings", []).append(str(e))
        except:
            pass
        return reply


# app.py - Ruby Wings Chatbot v4.0 (Complete Rewrite with Dataclasses)
# =========== IMPORTS ===========
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("ruby-wings")
import os
import sys
import json
import threading
import logging
import re
import unicodedata
import traceback
import hashlib
import time
import random
from functools import lru_cache, wraps
from typing import List, Tuple, Dict, Optional, Any, Set, Union, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import defaultdict, deque
from difflib import SequenceMatcher
from enum import Enum
# Try to import numpy with detailed error handling
try:
    
    import numpy as np
    NUMPY_AVAILABLE = True
    logger.info("‚úÖ NumPy available")
except ImportError as e:
    logger.error(f"‚ùå NumPy import failed: {e}")
    # Create a minimal numpy-like fallback for basic operations
    class NumpyFallback:
        def __init__(self):
            self.float32 = float
            self.int64 = int
            
        def array(self, data, dtype=None):
            # Simple list wrapper
            class SimpleArray:
                def __init__(self, data):
                    self.data = list(data)
                    self.shape = (len(data),) if isinstance(data[0], (int, float)) else (len(data), len(data[0]))
                
                def astype(self, dtype):
                    return self
                
                def reshape(self, shape):
                    return self
                
                def __getitem__(self, idx):
                    return self.data[idx]
                
                def __len__(self):
                    return len(self.data)
            
            return SimpleArray(data)
        
        def empty(self, shape, dtype):
            if len(shape) == 1:
                return [0.0] * shape[0]
            else:
                return [[0.0] * shape[1] for _ in range(shape[0])]
        
        def vstack(self, arrays):
            result = []
            for arr in arrays:
                if hasattr(arr, 'data'):
                    result.extend(arr.data)
                else:
                    result.extend(arr)
            return result
        
        def load(self, path):
            # Mock load function
            class MockNpz:
                def __init__(self):
                    self.files = ['mat']
                
                def __getitem__(self, key):
                    if key == 'mat':
                        # Return empty array
                        return self.array([[0.0]])
                    return None
            
            return MockNpz()
        
        def savez_compressed(self, path, **kwargs):
            # Mock save function
            logger.warning(f"‚ö†Ô∏è NumPy fallback: Mock saving to {path}")
            return None
    
    np = NumpyFallback()
    NUMPY_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Using NumPy fallback - limited functionality")
from flask import Flask, request, jsonify, g
from flask_cors import CORS

# =========== ENTITY IMPORTS ===========
from entities import (
    QuestionType,
    ConversationState,
    PriceLevel,
    DurationType,
    Tour,
    UserProfile,
    SearchResult,
    ConversationContext,
    FilterSet,
    LLMRequest,
    ChatResponse,
    LeadData,
    CacheEntry,
    EnhancedJSONEncoder
)

# =========== CONFIGURATION ===========
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ruby_wings.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("rbw_v4")

# =========== IMPORTS WITH FALLBACKS ===========
HAS_FAISS = False
try:
    import faiss
    HAS_FAISS = True
    logger.info("‚úÖ FAISS available")
except ImportError:
    logger.warning("‚ö†Ô∏è FAISS not available, using numpy fallback")

HAS_OPENAI = False
client = None
try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    logger.warning("‚ö†Ô∏è OpenAI not available, using fallback responses")

# Google Sheets
try:
    import gspread
    from google.oauth2.service_account import Credentials
    from google.auth.exceptions import GoogleAuthError
    from gspread.exceptions import APIError, SpreadsheetNotFound, WorksheetNotFound
    HAS_GOOGLE_SHEETS = True
except ImportError:
    HAS_GOOGLE_SHEETS = False
    logger.warning("‚ö†Ô∏è Google Sheets not available")

# Meta CAPI
try:
    from meta_capi import send_meta_pageview, send_meta_lead, send_meta_call_button
    HAS_META_CAPI = True
    logger.info("‚úÖ Meta CAPI available")
except ImportError:
    HAS_META_CAPI = False
    logger.warning("‚ö†Ô∏è Meta CAPI not available")

# =========== ENVIRONMENT VARIABLES ===========
# Memory Profile
RAM_PROFILE = os.environ.get("RAM_PROFILE", "512").strip()
IS_LOW_RAM = RAM_PROFILE == "512"
IS_HIGH_RAM = RAM_PROFILE == "2048"

# Core API Keys
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "").strip()
OPENAI_BASE_URL = os.environ.get("OPENAI_BASE_URL", "").strip()
GOOGLE_SERVICE_ACCOUNT_JSON = os.environ.get("GOOGLE_SERVICE_ACCOUNT_JSON", "").strip()

# Knowledge & Index
KNOWLEDGE_PATH = os.environ.get("KNOWLEDGE_PATH", "knowledge.json")
FAISS_INDEX_PATH = os.environ.get("FAISS_INDEX_PATH", "faiss_index.bin")
FAISS_MAPPING_PATH = os.environ.get("FAISS_MAPPING_PATH", "faiss_mapping.json")
FALLBACK_VECTORS_PATH = os.environ.get("FALLBACK_VECTORS_PATH", "vectors.npz")

# Models
EMBEDDING_MODEL = os.environ.get("EMBEDDING_MODEL", "text-embedding-3-small")
CHAT_MODEL = os.environ.get("CHAT_MODEL", "gpt-4o-mini")
TOP_K = int(os.environ.get("TOP_K", "10"))

# FAISS
FAISS_ENABLED = os.environ.get("FAISS_ENABLED", "true").lower() in ("1", "true", "yes") and not IS_LOW_RAM

# Google Sheets
GOOGLE_SHEET_ID = os.environ.get("GOOGLE_SHEET_ID", "1SdVbwkuxb8l1meEW--ddyfh4WmUvSXXMOPQ5bCyPkdk")
GOOGLE_SHEET_NAME = os.environ.get("GOOGLE_SHEET_NAME", "RBW_Lead_Raw_Inbox")
ENABLE_GOOGLE_SHEETS = os.environ.get("ENABLE_GOOGLE_SHEETS", "true").lower() in ("1", "true", "yes")

# Storage
ENABLE_FALLBACK_STORAGE = os.environ.get("ENABLE_FALLBACK_STORAGE", "true").lower() in ("1", "true", "yes")
FALLBACK_STORAGE_PATH = os.environ.get("FALLBACK_STORAGE_PATH", "leads_fallback.json")

# Meta CAPI
META_CAPI_TOKEN = os.environ.get("META_CAPI_TOKEN", "").strip()
META_PIXEL_ID = os.environ.get("META_PIXEL_ID", "").strip()
META_CAPI_ENDPOINT = os.environ.get("META_CAPI_ENDPOINT", "https://graph.facebook.com/v17.0/")
ENABLE_META_CAPI_CALL = os.environ.get("ENABLE_META_CAPI_CALL", "true").lower() in ("1", "true", "yes")

# Server
FLASK_ENV = os.environ.get("FLASK_ENV", "production")
DEBUG = os.environ.get("DEBUG", "false").lower() in ("1", "true", "yes")
SECRET_KEY = os.environ.get("SECRET_KEY", "ruby-wings-secret-key-2024")
CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "https://www.rubywings.vn,http://localhost:3000").split(",")
HOST = os.environ.get("HOST", "0.0.0.0")
PORT = int(os.environ.get("PORT", "10000"))

# =========== STATS TRACKING (FIX L·ªñI STATE) ===========
# Th√™m global stats tracking system
STATS_LOCK = threading.Lock()
GLOBAL_STATS = {
    'meta_capi_calls': 0,
    'meta_capi_errors': 0,
    'leads': 0,
    'errors': 0,
    'total_requests': 0
}

def increment_stat(stat_name: str, amount: int = 1):
    """Thread-safe stat increment"""
    with STATS_LOCK:
        if stat_name in GLOBAL_STATS:
            GLOBAL_STATS[stat_name] += amount
        else:
            GLOBAL_STATS[stat_name] = amount

def get_stats() -> dict:
    """Get current stats"""
    with STATS_LOCK:
        return GLOBAL_STATS.copy()

# =========== UPGRADE FEATURE FLAGS ===========
class UpgradeFlags:
    """Control all 10 upgrades with environment variables"""
    
    @staticmethod
    def get_all_flags():
        return {
            # CORE UPGRADES (Essential fixes)
            "UPGRADE_1_MANDATORY_FILTER": os.environ.get("UPGRADE_1_MANDATORY_FILTER", "true").lower() == "true",
            "UPGRADE_2_DEDUPLICATION": os.environ.get("UPGRADE_2_DEDUPLICATION", "true").lower() == "true",
            "UPGRADE_3_ENHANCED_FIELDS": os.environ.get("UPGRADE_3_ENHANCED_FIELDS", "true").lower() == "true",
            "UPGRADE_4_QUESTION_PIPELINE": os.environ.get("UPGRADE_4_QUESTION_PIPELINE", "true").lower() == "true",
            
            # ADVANCED UPGRADES
            "UPGRADE_5_QUERY_SPLITTER": os.environ.get("UPGRADE_5_QUERY_SPLITTER", "true").lower() == "true",
            "UPGRADE_6_FUZZY_MATCHING": os.environ.get("UPGRADE_6_FUZZY_MATCHING", "true").lower() == "true",
            "UPGRADE_7_STATE_MACHINE": os.environ.get("UPGRADE_7_STATE_MACHINE", "true").lower() == "true",
            "UPGRADE_8_SEMANTIC_ANALYSIS": os.environ.get("UPGRADE_8_SEMANTIC_ANALYSIS", "true").lower() == "true",
            "UPGRADE_9_AUTO_VALIDATION": os.environ.get("UPGRADE_9_AUTO_VALIDATION", "true").lower() == "true",
            "UPGRADE_10_TEMPLATE_SYSTEM": os.environ.get("UPGRADE_10_TEMPLATE_SYSTEM", "true").lower() == "true",
            
            # PERFORMANCE OPTIONS
            "ENABLE_CACHING": os.environ.get("ENABLE_CACHING", "true").lower() == "true",
            "CACHE_TTL_SECONDS": int(os.environ.get("CACHE_TTL_SECONDS", "300")),
            "ENABLE_QUERY_LOGGING": os.environ.get("ENABLE_QUERY_LOGGING", "true").lower() == "true",
            
            # MEMORY OPTIMIZATION
            "EMBEDDING_CACHE_SIZE": 100 if IS_LOW_RAM else 1000,
            "TOUR_CACHE_ENABLED": not IS_LOW_RAM,
            "PRELOAD_EMBEDDINGS": not IS_LOW_RAM,
        }
    
    @staticmethod
    def is_enabled(upgrade_name: str) -> bool:
        flags = UpgradeFlags.get_all_flags()
        return flags.get(f"UPGRADE_{upgrade_name}", False)

# =========== FLASK APP CONFIG ===========
app = Flask(__name__)
app.json_encoder = EnhancedJSONEncoder  # Use custom JSON encoder
CORS(app, origins=CORS_ORIGINS, supports_credentials=True)

# =========== GLOBAL STATE (USING DATACLASSES) ===========
# Initialize OpenAI client
# ==== OpenAI client (SDK 1.x safe, Render compatible) ====
from openai import OpenAI
import httpx
import os

def create_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY is not set")

    # Render-safe HTTP client (no proxies param in OpenAI 1.x)
    http_client = httpx.Client(
        timeout=60.0,
        follow_redirects=True
    )

    return OpenAI(
        api_key=api_key,
        http_client=http_client
    )

# Create global OpenAI client
client = create_openai_client()


# Knowledge base state
KNOW: Dict = {}                      # Raw knowledge.json data
FLAT_TEXTS: List[str] = []           # All text passages for indexing
MAPPING: List[Dict] = []             # Mapping from text to original path
INDEX = None                         # FAISS or numpy index
INDEX_LOCK = threading.Lock()        # Thread safety for index operations

# Tour databases (USING Tour DATACLASS)
TOUR_NAME_TO_INDEX: Dict[str, int] = {}      # Normalized tour name ‚Üí index
TOURS_DB: Dict[int, Tour] = {}               # Structured tour database using Tour objects
TOUR_TAGS: Dict[int, List[str]] = {}         # Auto-generated tags for filtering

# Session management (USING ConversationContext DATACLASS)
SESSION_CONTEXTS: Dict[str, ConversationContext] = {}
SESSION_LOCK = threading.Lock()
SESSION_TIMEOUT = 1800  # 30 minutes

# Cache system
_response_cache: Dict[str, CacheEntry] = {}
_cache_lock = threading.Lock()

# Embedding cache (memory optimized)
_embedding_cache: Dict[str, Tuple[List[float], int]] = {}
_embedding_cache_lock = threading.Lock()
MAX_EMBEDDING_CACHE_SIZE = UpgradeFlags.get_all_flags()["EMBEDDING_CACHE_SIZE"]

# =========== MEMORY OPTIMIZATION FUNCTIONS ===========
def optimize_for_memory_profile():
    """Apply memory optimizations based on RAM profile"""
    flags = UpgradeFlags.get_all_flags()
    
    if IS_LOW_RAM:
        logger.info("üß† Low RAM mode (512MB) - optimizing memory usage")
        # Disable heavy preloading
        global FAISS_ENABLED
        FAISS_ENABLED = False
        
        # Reduce cache sizes
        import functools
        functools.lru_cache(maxsize=128)(embed_text)
        
        # Limit tour loading
        global MAX_TOURS_TO_LOAD
        MAX_TOURS_TO_LOAD = 50
        
    elif IS_HIGH_RAM:
        logger.info("üöÄ High RAM mode (2GB) - enabling all features")
        # Enable all features
        FAISS_ENABLED = HAS_FAISS
        MAX_TOURS_TO_LOAD = 1000
        
        # Increase cache sizes
        import functools
        functools.lru_cache(maxsize=flags["EMBEDDING_CACHE_SIZE"])(embed_text)

# =========== UPGRADE 1: MANDATORY FILTER SYSTEM (DATACLASS COMPATIBLE) ===========
class MandatoryFilterSystem:
    """
    UPGRADE 1: Extract and apply mandatory filters BEFORE semantic search
    """
    
    FILTER_PATTERNS = {
        'duration': [
            (r'(?:th·ªùi gian|m·∫•y ng√†y|bao l√¢u|k√©o d√†i)\s*(?:l√†\s*)?(\d+)\s*(?:ng√†y|ƒë√™m)', 'exact_duration'),
            (r'(\d+)\s*ng√†y\s*(?:v√†\s*)?(\d+)?\s*ƒë√™m', 'days_nights'),
            (r'(\d+)\s*ng√†y\s*(?:tr·ªü l√™n|tr·ªü xu·ªëng)', 'duration_range'),
            (r'(?:tour|h√†nh tr√¨nh)\s*(?:kho·∫£ng|t·∫ßm|kho·∫£ng)?\s*(\d+)\s*ng√†y', 'approx_duration'),
        ],
        
        'price': [
            (r'd∆∞·ªõi\s*(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)', 'max_price'),
            (r'tr√™n\s*(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)', 'min_price'),
            (r'kho·∫£ng\s*(\d[\d,\.]*)\s*(?:ƒë·∫øn|-)\s*(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)', 'price_range'),
            (r'gi√°\s*(?:t·ª´\s*)?(\d[\d,\.]*)\s*(?:ƒë·∫øn|-|t·ªõi)\s*(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)', 'price_range'),
            (r'(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)\s*tr·ªü xu·ªëng', 'max_price'),
            (r'(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)\s*tr·ªü l√™n', 'min_price'),
        ],
        
        'location': [
            (r'(?:·ªü|t·∫°i|v·ªÅ|ƒë·∫øn|thƒÉm)\s+([^.,!?\n]+?)(?:\s|$|\.|,|!|\?)', 'location'),
            (r'(?:ƒëi·ªÉm ƒë·∫øn|ƒë·ªãa ƒëi·ªÉm|n∆°i|v√πng)\s+(?:l√†\s*)?([^.,!?\n]+)', 'location'),
            (r'(?:quanh|g·∫ßn|khu v·ª±c)\s+([^.,!?\n]+)', 'near_location'),
        ],
        
        'date_time': [
            (r'(?:th√°ng|v√†o)\s*(\d{1,2})', 'month'),
            (r'(?:cu·ªëi tu·∫ßn|weekend)', 'weekend'),
            (r'(?:d·ªãp|l·ªÖ|t·∫øt)\s+([^.,!?\n]+)', 'holiday'),
        ],
        
        'group_type': [
            (r'(?:gia ƒë√¨nh|family)', 'family'),
            (r'(?:c·∫∑p ƒë√¥i|couple|ƒë√¥i l·ª©a)', 'couple'),
            (r'(?:nh√≥m b·∫°n|b·∫°n b√®|friends)', 'friends'),
            (r'(?:c√¥ng ty|doanh nghi·ªáp|team building)', 'corporate'),
            (r'(?:m·ªôt m√¨nh|ƒëi l·∫ª|solo)', 'solo'),
        ],
    }
    
    @staticmethod
    def extract_filters(message: str) -> FilterSet:
        """
        Extract ALL mandatory filters from user message
        """
        filters = FilterSet()
        
        if not message:
            return filters
        
        message_lower = message.lower()
        
        # 1. DURATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['duration']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'exact_duration':
                    try:
                        days = int(match.group(1))
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'days_nights':
                    try:
                        days = int(match.group(1))
                        nights = int(match.group(2)) if match.group(2) else days
                        # Store in appropriate fields
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass
        
        # 2. PRICE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['price']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                try:
                    if filter_type == 'max_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_max = amount
                            logger.info(f"üí∞ Extracted MAX price filter: {amount} VND")
                    
                    elif filter_type == 'min_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_min = amount
                            logger.info(f"üí∞ Extracted MIN price filter: {amount} VND")
                    
                    elif filter_type == 'price_range':
                        min_amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(3))
                        max_amount = MandatoryFilterSystem._parse_price(match.group(2), match.group(3))
                        if min_amount and max_amount:
                            filters.price_min = min_amount
                            filters.price_max = max_amount
                            logger.info(f"üí∞ Extracted PRICE RANGE: {min_amount} - {max_amount} VND")
                
                except (ValueError, IndexError, AttributeError):
                    continue
        
        # 3. LOCATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['location']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                location = match.group(1).strip()
                if location and len(location) > 1:
                    if filter_type == 'location':
                        filters.location = location
                    elif filter_type == 'near_location':
                        filters.near_location = location
        
        # 4. DATE/TIME FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['date_time']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'month':
                    try:
                        filters.month = int(match.group(1))
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'weekend':
                    filters.weekend = True
                elif filter_type == 'holiday':
                    filters.holiday = match.group(1).strip()
        
        # 5. GROUP TYPE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['group_type']:
            if re.search(pattern, message_lower):
                filters.group_type = filter_type
        
        # 6. SPECIAL KEYWORDS
        special_keywords = {
            'r·∫ª': ('price_max', 1500000),
            'gi√° r·∫ª': ('price_max', 1500000),
            'ti·∫øt ki·ªám': ('price_max', 1500000),
            'cao c·∫•p': ('price_min', 3000000),
            'sang tr·ªçng': ('price_min', 3000000),
            'premium': ('price_min', 3000000),
            'ng·∫Øn ng√†y': ('duration_max', 2),
            'd√†i ng√†y': ('duration_min', 3),
        }
        
        for keyword, (filter_key, value) in special_keywords.items():
            if keyword in message_lower:
                if filter_key == 'price_max':
                    filters.price_max = value
                elif filter_key == 'price_min':
                    filters.price_min = value
                elif filter_key == 'duration_max':
                    filters.duration_max = value
                elif filter_key == 'duration_min':
                    filters.duration_min = value
        
        logger.info(f"üéØ Extracted filters: {filters}")
        return filters
    
    @staticmethod
    def _parse_price(amount_str: str, unit: str) -> Optional[int]:
        """Parse price string like '1.5 tri·ªáu' to integer VND"""
        if not amount_str:
            return None
        
        try:
            amount_str = amount_str.replace(',', '').replace('.', '')
            if not amount_str.isdigit():
                return None
            
            amount = int(amount_str)
            
            if unit in ['tri·ªáu', 'tr']:
                return amount * 1000000
            elif unit == 'k':
                return amount * 1000
            elif unit == 'ngh√¨n':
                return amount * 1000
            else:
                return amount if amount > 1000 else amount * 1000
        
        except (ValueError, AttributeError):
            return None
    
    @staticmethod
    def apply_filters(tours_db: Dict[int, Tour], filters: FilterSet) -> List[int]:
        """
        Apply mandatory filters to tour database
        Returns list of tour indices that pass ALL filters
        Enhanced version with better error handling and group_type support
        """
        if filters.is_empty() or not tours_db:
            logger.info(f"üîç No filters or empty DB, returning all {len(tours_db)} tours")
            return list(tours_db.keys())
        
        passing_tours = []
        total_tours = len(tours_db)
        
        try:
            logger.info(f"üéØ Applying filters: {filters}")
            
            # Validate group_type if present
            if hasattr(filters, 'group_type') and filters.group_type:
                valid_group_types = ['family', 'friends', 'corporate', 'solo', 'couple', 'senior', 'group']
                if filters.group_type not in valid_group_types:
                    logger.warning(f"‚ö†Ô∏è Invalid group_type: {filters.group_type}, using default filtering")
                    # Continue without group_type filter but log warning
            
            for tour_idx, tour in tours_db.items():
                passes_all = True
                
                # PRICE FILTERING - ENHANCED
                if passes_all and (filters.price_max is not None or filters.price_min is not None):
                    tour_price_text = tour.price or ""
                    if not tour_price_text or tour_price_text.lower() == 'li√™n h·ªá':
                        # If tour doesn't have price, check if we require price filter
                        if filters.price_max is not None or filters.price_min is not None:
                            # If price is required but not available, fail this tour
                            passes_all = False
                    else:
                        tour_prices = MandatoryFilterSystem._extract_tour_prices(tour_price_text)
                        if not tour_prices:
                            # Can't extract price, be conservative - pass if no strict requirement
                            if filters.price_max is not None and filters.price_min is not None:
                                passes_all = False
                        else:
                            min_tour_price = min(tour_prices)
                            max_tour_price = max(tour_prices)
                            
                            # Apply price range filter
                            if filters.price_max is not None and min_tour_price > filters.price_max:
                                passes_all = False
                            if filters.price_min is not None and max_tour_price < filters.price_min:
                                passes_all = False
                
                # DURATION FILTERING - ENHANCED
                if passes_all and (filters.duration_min is not None or filters.duration_max is not None):
                    duration_text = (tour.duration or "").lower()
                    tour_duration = MandatoryFilterSystem._extract_duration_days(duration_text)
                    
                    if tour_duration is not None:
                        if filters.duration_min is not None and tour_duration < filters.duration_min:
                            passes_all = False
                        if filters.duration_max is not None and tour_duration > filters.duration_max:
                            passes_all = False
                    else:
                        # If duration cannot be extracted, be conservative
                        if filters.duration_min is not None and filters.duration_max is not None:
                            passes_all = False
                
                # LOCATION FILTERING - ENHANCED
                if passes_all and (filters.location is not None or filters.near_location is not None):
                    tour_location = (tour.location or "").lower()
                    if filters.location is not None:
                        filter_location = filters.location.lower()
                        # Enhanced location matching
                        if filter_location and filter_location not in tour_location:
                            # Try partial matching for common location names
                            location_keywords = {
                                'hu·∫ø': ['hu·∫ø', 'hue'],
                                'qu·∫£ng tr·ªã': ['qu·∫£ng tr·ªã', 'quang tri'],
                                'b·∫°ch m√£': ['b·∫°ch m√£', 'bach ma'],
                                'tr∆∞·ªùng s∆°n': ['tr∆∞·ªùng s∆°n', 'truong son'],
                                'ƒë√¥ng h√†': ['ƒë√¥ng h√†', 'dong ha']
                            }
                            
                            # Check if filter_location matches any keyword
                            matches = False
                            for keyword, variants in location_keywords.items():
                                if filter_location in variants:
                                    # Check if any variant is in tour_location
                                    for variant in variants:
                                        if variant in tour_location:
                                            matches = True
                                            break
                                if matches:
                                    break
                            
                            if not matches:
                                passes_all = False
                    
                    if filters.near_location is not None and passes_all:
                        near_location = filters.near_location.lower()
                        if near_location and near_location not in tour_location:
                            passes_all = False
                
                # GROUP TYPE FILTERING - ADDED SUPPORT
                if passes_all and hasattr(filters, 'group_type') and filters.group_type:
                    group_type = filters.group_type.lower()
                    tour_summary = (tour.summary or "").lower()
                    tour_tags = [tag.lower() for tag in (tour.tags or [])]
                    
                    # Enhanced group type matching
                    group_type_matched = False
                    
                    # Define keywords for each group type
                    group_keywords = {
                        'family': ['gia ƒë√¨nh', 'tr·∫ª em', 'con nh·ªè', 'b·ªë m·∫π', 'ƒëa th·∫ø h·ªá'],
                        'friends': ['nh√≥m b·∫°n', 'b·∫°n b√®', 'b·∫°n tr·∫ª', 'thanh ni√™n', 'sinh vi√™n'],
                        'corporate': ['c√¥ng ty', 'team building', 'doanh nghi·ªáp', 'nh√¢n vi√™n', 'ƒë·ªìng nghi·ªáp'],
                        'solo': ['m·ªôt m√¨nh', 'ƒëi l·∫ª', 'solo', 'c√° nh√¢n'],
                        'couple': ['c·∫∑p ƒë√¥i', 'ƒë√¥i l·ª©a', 'ng∆∞·ªùi y√™u', 't√¨nh nh√¢n'],
                        'senior': ['ng∆∞·ªùi l·ªõn tu·ªïi', 'cao tu·ªïi', 'c·ª±u chi·∫øn binh', 'veteran'],
                        'group': ['nh√≥m', 'ƒëo√†n', 't·∫≠p th·ªÉ']
                    }
                    
                    if group_type in group_keywords:
                        keywords = group_keywords[group_type]
                        
                        # Check in tour tags
                        for tag in tour_tags:
                            if any(keyword in tag for keyword in keywords):
                                group_type_matched = True
                                break
                        
                        # Check in tour summary
                        if not group_type_matched:
                            if any(keyword in tour_summary for keyword in keywords):
                                group_type_matched = True
                        
                        # Special handling for senior/veteran
                        if group_type == 'senior':
                            # Also check for historical/meaningful tours
                            if any(word in tour_summary for word in ['l·ªãch s·ª≠', 'tri √¢n', 'k√Ω ·ª©c', 'chi·∫øn tranh']):
                                group_type_matched = True
                        
                        if not group_type_matched:
                            passes_all = False
                    else:
                        logger.warning(f"‚ö†Ô∏è Unknown group_type: {group_type}, skipping group filter")
                
                # MONTH FILTERING - ADDED SUPPORT
                if passes_all and hasattr(filters, 'month') and filters.month:
                    try:
                        month = int(filters.month)
                        # Simple season-based filtering
                        tour_summary = (tour.summary or "").lower()
                        
                        # Tours suitable for specific months
                        # This is simplified - in reality would need more complex logic
                        if month in [1, 2, 3]:  # Dry season, good for most tours
                            # No filtering, most tours are suitable
                            pass
                        elif month in [9, 10, 11, 12]:  # Rainy season
                            # Avoid tours with lots of outdoor activities
                            if any(word in tour_summary for word in ['trekking', 'leo n√∫i', 'ƒëi b·ªô ƒë∆∞·ªùng d√†i']):
                                passes_all = False
                    except (ValueError, TypeError):
                        # Invalid month format, ignore filter
                        pass
                
                # WEEKEND/HOLIDAY FILTERING - ADDED SUPPORT
                if passes_all:
                    tour_duration = MandatoryFilterSystem._extract_duration_days((tour.duration or "").lower())
                    
                    if hasattr(filters, 'weekend') and filters.weekend and tour_duration:
                        # Weekend tours should be 1-2 days
                        if tour_duration > 2:
                            passes_all = False
                    
                    if hasattr(filters, 'holiday') and filters.holiday and tour_duration:
                        # Holiday tours might be longer
                        # No specific filtering for now
                        pass
                
                if passes_all:
                    passing_tours.append(tour_idx)
            
            logger.info(f"‚úÖ Filtering complete: {len(passing_tours)}/{total_tours} tours pass")
            
            # If filtering results in too few tours, provide fallback
            if len(passing_tours) < 3 and total_tours > 10:
                logger.info(f"‚ö†Ô∏è Only {len(passing_tours)} tours passed filters, applying lenient filtering")
                
                # Apply lenient filtering: tours must pass at least 50% of non-empty filters
                if not filters.is_empty():
                    lenient_passing_tours = []
                    
                    # Count non-empty filters
                    non_empty_filters = 0
                    if filters.price_max is not None or filters.price_min is not None:
                        non_empty_filters += 1
                    if filters.duration_min is not None or filters.duration_max is not None:
                        non_empty_filters += 1
                    if filters.location is not None or filters.near_location is not None:
                        non_empty_filters += 1
                    if hasattr(filters, 'group_type') and filters.group_type:
                        non_empty_filters += 1
                    
                    if non_empty_filters > 0:
                        for tour_idx, tour in tours_db.items():
                            passed_filters = 0
                            
                            # Check price
                            if not (filters.price_max is not None or filters.price_min is not None):
                                passed_filters += 1
                            else:
                                tour_price_text = tour.price or ""
                                if tour_price_text and tour_price_text.lower() != 'li√™n h·ªá':
                                    tour_prices = MandatoryFilterSystem._extract_tour_prices(tour_price_text)
                                    if tour_prices:
                                        min_tour_price = min(tour_prices)
                                        max_tour_price = max(tour_prices)
                                        
                                        price_passed = True
                                        if filters.price_max is not None and min_tour_price > filters.price_max:
                                            price_passed = False
                                        if filters.price_min is not None and max_tour_price < filters.price_min:
                                            price_passed = False
                                        
                                        if price_passed:
                                            passed_filters += 1
                            
                            # Check duration
                            if not (filters.duration_min is not None or filters.duration_max is not None):
                                passed_filters += 1
                            else:
                                duration_text = (tour.duration or "").lower()
                                tour_duration = MandatoryFilterSystem._extract_duration_days(duration_text)
                                
                                if tour_duration is not None:
                                    duration_passed = True
                                    if filters.duration_min is not None and tour_duration < filters.duration_min:
                                        duration_passed = False
                                    if filters.duration_max is not None and tour_duration > filters.duration_max:
                                        duration_passed = False
                                    
                                    if duration_passed:
                                        passed_filters += 1
                            
                            # Check location
                            if not (filters.location is not None or filters.near_location is not None):
                                passed_filters += 1
                            else:
                                tour_location = (tour.location or "").lower()
                                location_passed = True
                                
                                if filters.location is not None:
                                    filter_location = filters.location.lower()
                                    if filter_location not in tour_location:
                                        location_passed = False
                                
                                if filters.near_location is not None and location_passed:
                                    near_location = filters.near_location.lower()
                                    if near_location not in tour_location:
                                        location_passed = False
                                
                                if location_passed:
                                    passed_filters += 1
                            
                            # Check group type
                            if not (hasattr(filters, 'group_type') and filters.group_type):
                                passed_filters += 1
                            else:
                                # Simplified group type check for lenient filtering
                                group_type = filters.group_type.lower()
                                tour_summary = (tour.summary or "").lower()
                                tour_tags = [tag.lower() for tag in (tour.tags or [])]
                                
                                group_passed = False
                                if group_type == 'family':
                                    if any(word in tour_summary for word in ['gia ƒë√¨nh', 'tr·∫ª em', 'con nh·ªè']):
                                        group_passed = True
                                elif group_type == 'friends':
                                    if any(word in tour_summary for word in ['nh√≥m b·∫°n', 'b·∫°n b√®']):
                                        group_passed = True
                                elif group_type == 'senior':
                                    if any(word in tour_summary for word in ['l·ªãch s·ª≠', 'tri √¢n', 'nh·∫π nh√†ng']):
                                        group_passed = True
                                else:
                                    # For other group types, be lenient
                                    group_passed = True
                                
                                if group_passed:
                                    passed_filters += 1
                            
                            # Pass if at least 50% of filters passed
                            if passed_filters >= non_empty_filters * 0.5:
                                lenient_passing_tours.append(tour_idx)
                        
                        # Use lenient results if better
                        if len(lenient_passing_tours) > len(passing_tours):
                            logger.info(f"üîÑ Using lenient filtering: {len(lenient_passing_tours)} tours")
                            passing_tours = lenient_passing_tours
            
        except Exception as e:
            logger.error(f"‚ùå Error in apply_filters: {e}\n{traceback.format_exc()}")
            # Fallback: return all tours
            passing_tours = list(tours_db.keys())
        
        return passing_tours
        
    @staticmethod
    def _extract_tour_prices(price_text: str) -> List[int]:
        """Extract price numbers from tour price text"""
        prices = []
        
        number_patterns = [
            r'(\d[\d,\.]+)\s*(?:tri·ªáu|tr)',
            r'(\d[\d,\.]+)\s*(?:k|ngh√¨n)',
            r'(\d[\d,\.]+)\s*(?:ƒë·ªìng|vnƒë|vnd)',
            r'(\d[\d,\.]+)\s*-\s*(\d[\d,\.]+)',
        ]
        
        for pattern in number_patterns:
            matches = re.finditer(pattern, price_text, re.IGNORECASE)
            for match in matches:
                try:
                    for i in range(1, 3):
                        if match.group(i):
                            num_str = match.group(i).replace(',', '').replace('.', '')
                            if num_str.isdigit():
                                num = int(num_str)
                                
                                if 'tri·ªáu' in match.group(0).lower() or 'tr' in match.group(0).lower():
                                    num = num * 1000000
                                elif 'k' in match.group(0).lower() or 'ngh√¨n' in match.group(0).lower():
                                    num = num * 1000
                                
                                prices.append(num)
                except (ValueError, AttributeError):
                    continue
        
        if not prices:
            raw_numbers = re.findall(r'\d[\d,\.]+', price_text)
            for num_str in raw_numbers[:2]:
                try:
                    num_str = num_str.replace(',', '').replace('.', '')
                    if num_str.isdigit():
                        num = int(num_str)
                        if 100 <= num <= 10000:
                            num = num * 1000
                        prices.append(num)
                except ValueError:
                    continue
        
        return prices
    
    @staticmethod
    def _extract_duration_days(duration_text: str) -> Optional[int]:
        """Extract duration in days from text"""
        if not duration_text:
            return None
        
        patterns = [
            r'(\d+)\s*ng√†y',
            r'(\d+)\s*ng√†y\s*\d*\s*ƒë√™m',
            r'(\d+)\s*ƒë√™m',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, duration_text)
            if match:
                try:
                    return int(match.group(1))
                except (ValueError, IndexError):
                    continue
        
        return None

# =========== UPGRADE 2: DEDUPLICATION ENGINE (DATACLASS COMPATIBLE) ===========
class DeduplicationEngine:
    """
    UPGRADE 2: Remove duplicate and highly similar results
    """
    
    SIMILARITY_THRESHOLD = 0.85
    MIN_TEXT_LENGTH = 20
    
    @staticmethod
    def calculate_similarity(text1: str, text2: str) -> float:
        """Calculate text similarity using multiple methods"""
        if not text1 or not text2:
            return 0.0
        
        text1_norm = DeduplicationEngine._normalize_text(text1)
        text2_norm = DeduplicationEngine._normalize_text(text2)
        
        if len(text1_norm) < DeduplicationEngine.MIN_TEXT_LENGTH or len(text2_norm) < DeduplicationEngine.MIN_TEXT_LENGTH:
            return 0.0
        
        seq_ratio = SequenceMatcher(None, text1_norm, text2_norm).ratio()
        
        words1 = set(text1_norm.split())
        words2 = set(text2_norm.split())
        
        if not words1 or not words2:
            jaccard = 0.0
        else:
            intersection = words1.intersection(words2)
            union = words1.union(words2)
            jaccard = len(intersection) / len(union)
        
        prefix_len = min(50, min(len(text1_norm), len(text2_norm)))
        prefix1 = text1_norm[:prefix_len]
        prefix2 = text2_norm[:prefix_len]
        prefix_sim = SequenceMatcher(None, prefix1, prefix2).ratio()
        
        similarity = (seq_ratio * 0.5) + (jaccard * 0.3) + (prefix_sim * 0.2)
        
        return similarity
    
    @staticmethod
    def _normalize_text(text: str) -> str:
        """Normalize text for comparison"""
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        stopwords = {'v√†', 'c·ªßa', 'cho', 'v·ªõi', 't·∫°i', '·ªü', 'n√†y', 'ƒë√≥', 'kia', 'v·ªÅ', 'trong'}
        words = [word for word in text.split() if word not in stopwords]
        
        return ' '.join(words)
    
    @staticmethod
    def deduplicate_passages(passages: List[Tuple[float, Dict]], 
                            similarity_threshold: float = None) -> List[Tuple[float, Dict]]:
        """
        Remove duplicate passages from results
        """
        if len(passages) <= 1:
            return passages
        
        threshold = similarity_threshold or DeduplicationEngine.SIMILARITY_THRESHOLD
        unique_passages = []
        seen_passages = []
        
        sorted_passages = sorted(passages, key=lambda x: x[0], reverse=True)
        
        for score, passage in sorted_passages:
            text = passage.get('text', '').strip()
            path = passage.get('path', '')
            
            if not text or len(text) < DeduplicationEngine.MIN_TEXT_LENGTH:
                unique_passages.append((score, passage))
                continue
            
            is_duplicate = False
            for seen_text, seen_path in seen_passages:
                tour_match1 = re.search(r'tours\[(\d+)\]', path)
                tour_match2 = re.search(r'tours\[(\d+)\]', seen_path)
                
                if tour_match1 and tour_match2:
                    if tour_match1.group(1) == tour_match2.group(1):
                        field1 = path.split('.')[-1] if '.' in path else ''
                        field2 = seen_path.split('.')[-1] if '.' in seen_path else ''
                        if field1 == field2:
                            is_duplicate = True
                            break
                
                similarity = DeduplicationEngine.calculate_similarity(text, seen_text)
                if similarity > threshold:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_passages.append((score, passage))
                seen_passages.append((text, path))
        
        logger.info(f"üîÑ Deduplication: {len(passages)} ‚Üí {len(unique_passages)} passages")
        return unique_passages
    
    @staticmethod
    def merge_similar_tours(tour_indices: List[int], tours_db: Dict[int, Tour]) -> List[int]:
        """Merge tours that are essentially the same"""
        if len(tour_indices) <= 1:
            return tour_indices
        
        tour_groups = []
        processed = set()
        
        for i, idx1 in enumerate(tour_indices):
            if idx1 in processed:
                continue
            
            group = [idx1]
            tour1 = tours_db.get(idx1)
            name1 = (tour1.name if tour1 else "").strip()
            
            if not name1:
                processed.add(idx1)
                tour_groups.append(group)
                continue
            
            for j, idx2 in enumerate(tour_indices[i+1:], i+1):
                if idx2 in processed:
                    continue
                
                tour2 = tours_db.get(idx2)
                name2 = (tour2.name if tour2 else "").strip()
                
                if not name2:
                    continue
                
                similarity = DeduplicationEngine.calculate_similarity(name1, name2)
                if similarity > 0.9:
                    group.append(idx2)
                    processed.add(idx2)
            
            processed.add(idx1)
            tour_groups.append(group)
        
        best_tours = []
        for group in tour_groups:
            if not group:
                continue
            
            if len(group) == 1:
                best_tours.append(group[0])
                continue
            
            best_score = -1
            best_idx = group[0]
            
            for idx in group:
                tour = tours_db.get(idx)
                if not tour:
                    continue
                
                score = 0
                
                if tour.name:
                    score += 2
                if tour.duration:
                    score += 2
                if tour.location:
                    score += 2
                if tour.price:
                    score += 3
                if tour.includes:
                    score += 2
                if tour.summary:
                    score += 1
                
                for field in [tour.includes, tour.summary, tour.notes]:
                    if isinstance(field, str) and len(field) > 50:
                        score += 1
                    elif isinstance(field, list) and field:
                        score += len(field)
                
                if score > best_score:
                    best_score = score
                    best_idx = idx
            
            best_tours.append(best_idx)
        
        logger.info(f"üîÑ Tour merging: {len(tour_indices)} ‚Üí {len(best_tours)} unique tours")
        return best_tours

# =========== UPGRADE 3: ENHANCED FIELD DETECTION (DATACLASS COMPATIBLE) ===========
class EnhancedFieldDetector:
    """
    UPGRADE 3: Better detection of what user is asking for
    """
    
    FIELD_DETECTION_RULES = [
        # TOUR LIST
        {
            "field": "tour_name",
            "patterns": [
                (r'li·ªát k√™.*tour|danh s√°ch.*tour|c√°c tour|c√≥ nh·ªØng tour n√†o', 1.0),
                (r'tour n√†o.*c√≥|tour n√†o.*hi·ªán|tour n√†o.*ƒëang', 0.9),
                (r'k·ªÉ t√™n.*tour|n√™u t√™n.*tour|t√™n c√°c tour', 0.9),
                (r'c√≥ m·∫•y.*tour|bao nhi√™u.*tour|s·ªë l∆∞·ª£ng.*tour', 0.8),
                (r'list tour|show tour|all tour|every tour', 0.8),
            ],
            "keywords": [
                ("li·ªát k√™", 0.9), ("danh s√°ch", 0.9), ("c√°c", 0.7),
                ("t·∫•t c·∫£", 0.8), ("m·ªçi", 0.7), ("m·∫•y", 0.6),
                ("bao nhi√™u", 0.7), ("s·ªë l∆∞·ª£ng", 0.7),
            ]
        },
        
        # PRICE
        {
            "field": "price",
            "patterns": [
                (r'gi√°.*bao nhi√™u|bao nhi√™u ti·ªÅn|chi ph√≠.*bao nhi√™u', 1.0),
                (r'gi√° tour|gi√° c·∫£|gi√° th√†nh|chi ph√≠ tour', 0.9),
                (r'tour.*gi√°.*bao nhi√™u|tour.*bao nhi√™u ti·ªÅn', 0.95),
                (r'ph·∫£i tr·∫£.*bao nhi√™u|t·ªën.*bao nhi√™u|m·∫•t.*bao nhi√™u', 0.8),
                (r'ƒë√≥ng.*bao nhi√™u|thanh to√°n.*bao nhi√™u', 0.8),
            ],
            "keywords": [
                ("gi√°", 0.8), ("ti·ªÅn", 0.7), ("chi ph√≠", 0.8),
                ("ƒë√≥ng", 0.6), ("tr·∫£", 0.6), ("t·ªën", 0.6),
                ("ph√≠", 0.7), ("kinh ph√≠", 0.7), ("t·ªïng chi", 0.7),
            ]
        },
        
        # DURATION
        {
            "field": "duration",
            "patterns": [
                (r'th·ªùi gian.*bao l√¢u|m·∫•y ng√†y.*ƒëi|bao l√¢u.*tour', 1.0),
                (r'tour.*bao nhi√™u ng√†y|m·∫•y ng√†y.*tour', 0.9),
                (r'ƒëi trong.*bao l√¢u|k√©o d√†i.*bao l√¢u', 0.9),
                (r'th·ªùi l∆∞·ª£ng.*bao nhi√™u|th·ªùi gian.*d√†i bao l√¢u', 0.8),
            ],
            "keywords": [
                ("bao l√¢u", 0.9), ("m·∫•y ng√†y", 0.9), ("th·ªùi gian", 0.8),
                ("k√©o d√†i", 0.7), ("th·ªùi l∆∞·ª£ng", 0.8), ("ng√†y", 0.6),
                ("ƒë√™m", 0.6), ("th·ªùi h·∫°n", 0.7),
            ]
        },
        
        # LOCATION
        {
            "field": "location",
            "patterns": [
                (r'·ªü ƒë√¢u|ƒëi ƒë√¢u|ƒë·∫øn ƒë√¢u|t·ªõi ƒë√¢u|thƒÉm quan ƒë√¢u', 1.0),
                (r'ƒë·ªãa ƒëi·ªÉm.*n√†o|n∆°i n√†o|v√πng n√†o|khu v·ª±c n√†o', 0.9),
                (r'tour.*·ªü.*ƒë√¢u|h√†nh tr√¨nh.*ƒëi.*ƒë√¢u', 0.9),
                (r'kh√°m ph√°.*ƒë√¢u|thƒÉm.*ƒë√¢u|gh√©.*ƒë√¢u', 0.8),
            ],
            "keywords": [
                ("·ªü ƒë√¢u", 1.0), ("ƒëi ƒë√¢u", 1.0), ("ƒë·∫øn ƒë√¢u", 0.9),
                ("t·ªõi ƒë√¢u", 0.9), ("ƒë·ªãa ƒëi·ªÉm", 0.8), ("n∆°i", 0.7),
                ("v√πng", 0.7), ("khu v·ª±c", 0.7),
            ]
        },
        
        # SUMMARY
        {
            "field": "summary",
            "patterns": [
                (r'c√≥ g√¨ hay|c√≥ g√¨ ƒë·∫∑c bi·ªát|c√≥ g√¨ th√∫ v·ªã', 0.9),
                (r'tour n√†y th·∫ø n√†o|h√†nh tr√¨nh ra sao|chuy·∫øn ƒëi nh∆∞ n√†o', 0.8),
                (r'gi·ªõi thi·ªáu.*tour|m√¥ t·∫£.*tour|n√≥i v·ªÅ.*tour', 0.8),
                (r'tour.*c√≥ g√¨|ƒëi.*ƒë∆∞·ª£c g√¨|tr·∫£i nghi·ªám.*g√¨', 0.7),
                (r'ƒëi·ªÉm nh·∫•n.*tour|n·ªïi b·∫≠t.*g√¨|ƒë·∫∑c s·∫Øc.*g√¨', 0.7),
            ],
            "keywords": [
                ("c√≥ g√¨", 0.7), ("th·∫ø n√†o", 0.6), ("ra sao", 0.6),
                ("gi·ªõi thi·ªáu", 0.7), ("m√¥ t·∫£", 0.7), ("n√≥i v·ªÅ", 0.6),
                ("ƒëi·ªÉm nh·∫•n", 0.7), ("n·ªïi b·∫≠t", 0.7), ("ƒë·∫∑c s·∫Øc", 0.7),
            ]
        },
        
        # INCLUDES
        {
            "field": "includes",
            "patterns": [
                (r'l·ªãch tr√¨nh.*chi ti·∫øt|ch∆∞∆°ng tr√¨nh.*chi ti·∫øt', 0.9),
                (r'l√†m g√¨.*tour|ho·∫°t ƒë·ªông.*g√¨|sinh ho·∫°t.*g√¨', 0.8),
                (r'tour.*g·ªìm.*g√¨|bao g·ªìm.*g√¨|g·ªìm nh·ªØng g√¨', 0.8),
                (r'ƒëi ƒë√¢u.*l√†m g√¨|thƒÉm quan.*g√¨|kh√°m ph√°.*g√¨', 0.7),
            ],
            "keywords": [
                ("l·ªãch tr√¨nh", 0.8), ("ch∆∞∆°ng tr√¨nh", 0.8), ("l√†m g√¨", 0.7),
                ("ho·∫°t ƒë·ªông", 0.7), ("sinh ho·∫°t", 0.6), ("g·ªìm", 0.6),
                ("bao g·ªìm", 0.7), ("g·ªìm nh·ªØng", 0.7),
            ]
        },
    ]
    
    @staticmethod
    def detect_field_with_confidence(message: str) -> Tuple[Optional[str], float, Dict[str, float]]:
        """
        Detect which field user is asking about with confidence scores
        """
        if not message:
            return None, 0.0, {}
        
        message_lower = message.lower()
        scores = {}
        
        for rule in EnhancedFieldDetector.FIELD_DETECTION_RULES:
            field = rule["field"]
            field_score = 0.0
            
            for pattern, weight in rule["patterns"]:
                if re.search(pattern, message_lower):
                    field_score = max(field_score, weight)
            
            for keyword, weight in rule["keywords"]:
                if keyword in message_lower:
                    position = message_lower.find(keyword)
                    position_factor = 1.0 - (position / max(len(message_lower), 1))
                    adjusted_weight = weight * (0.7 + 0.3 * position_factor)
                    field_score = max(field_score, adjusted_weight)
            
            if field_score > 0:
                field_score = min(field_score * 1.1, 1.0)
            
            scores[field] = field_score
        
        best_field = None
        best_score = 0.0
        
        for field, score in scores.items():
            if score > best_score:
                best_score = score
                best_field = field
        
        if (best_score < 0.3 and 
            ("c√≥ g√¨" in message_lower or "th·∫ø n√†o" in message_lower) and
            "tour" in message_lower):
            best_field = "summary"
            best_score = 0.6
        
        logger.info(f"üîç Field detection: '{message}' ‚Üí {best_field} (confidence: {best_score:.2f})")
        return best_field, best_score, scores

# =========== UPGRADE 4: QUESTION PIPELINE (DATACLASS COMPATIBLE) ===========
class QuestionPipeline:
    """
    UPGRADE 4: Process different types of questions differently
    """
    
    @staticmethod
    def classify_question(message: str) -> Tuple[QuestionType, float, Dict]:
        """
        Classify question type with confidence and metadata
        """
        message_lower = message.lower()
        type_scores = defaultdict(float)
        metadata = {}
        
        # LISTING detection - CH·ªà khi y√™u c·∫ßu r√µ r√†ng li·ªát k√™ DANH S√ÅCH
        listing_patterns = [
            (r'li·ªát k√™.*t·∫•t c·∫£.*tour|danh s√°ch.*t·∫•t c·∫£.*tour|t·∫•t c·∫£.*tour', 0.95),
            (r'li·ªát k√™.*tour|danh s√°ch.*tour|list.*tour', 0.9),
            (r'k·ªÉ t√™n.*tour|n√™u t√™n.*tour', 0.9),
            (r'c√≥ nh·ªØng.*tour n√†o|c√≥ m·∫•y.*tour|m·∫•y.*tour', 0.7),
            (r'b√™n b·∫°n.*c√≥.*tour|hi·ªán c√≥.*tour', 0.75),
        ]
        
        for pattern, weight in listing_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.LISTING] = max(
                    type_scores[QuestionType.LISTING], weight
                )
        
        # COMPARISON detection
        comparison_patterns = [
            (r'so s√°nh.*v√†|ƒë·ªëi chi·∫øu.*v√†', 0.95),
            (r'kh√°c nhau.*n√†o|gi·ªëng nhau.*n√†o', 0.9),
            (r'n√™n ch·ªçn.*n√†o|t·ªët h∆°n.*n√†o|h∆°n k√©m.*n√†o', 0.85),
            (r'tour.*v√†.*tour', 0.8),
            (r's√°nh.*v·ªõi|ƒë·ªëi chi·∫øu.*v·ªõi', 0.8),
        ]
        
        for pattern, weight in comparison_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.COMPARISON] = max(
                    type_scores[QuestionType.COMPARISON], weight
                )
                metadata['comparison_type'] = 'direct'
        
        # RECOMMENDATION detection
        recommendation_patterns = [
            (r'ph√π h·ª£p.*v·ªõi|n√™n ƒëi.*n√†o|g·ª£i √Ω.*tour', 0.95),
            (r'tour n√†o.*ph√π h·ª£p|ph√π h·ª£p.*tour n√†o', 0.95),
            (r'tour.*t·ªët.*nh·∫•t|h√†nh tr√¨nh.*hay nh·∫•t|tour.*l√Ω t∆∞·ªüng', 0.9),
            (r'ƒë·ªÅ xu·∫•t.*tour|t∆∞ v·∫•n.*tour|ch·ªçn.*tour n√†o', 0.9),
            (r'tour n√†o.*cho.*gia ƒë√¨nh|tour.*gia ƒë√¨nh|gia ƒë√¨nh.*tour', 0.9),
            (r'tour n√†o.*cho|d√†nh cho.*tour|tour.*d√†nh cho', 0.85),
            (r'n√™n.*tour n√†o|n√™n ch·ªçn.*tour|tour.*n√™n', 0.85),
            (r'tour.*nh·∫π nh√†ng|tour.*d·ªÖ|tour.*ph√π h·ª£p.*ng∆∞·ªùi', 0.85),
            (r'tour.*tr·∫ª em|tour.*con n√≠t|tour.*b√©', 0.85),
            (r'tour.*ng∆∞·ªùi l·ªõn tu·ªïi|tour.*cao tu·ªïi|tour.*ngh·ªâ d∆∞·ª°ng', 0.85),
            (r'chi ph√≠.*v·ª´a ph·∫£i|gi√°.*ph√π h·ª£p|gi√°.*h·ª£p l√Ω', 0.8),
            (r'cho.*t√¥i|d√†nh cho.*t√¥i|h·ª£p v·ªõi.*t√¥i', 0.75),
            (r'n·∫øu.*th√¨.*n√™n.*tour|n√™n ch·ªçn.*tour', 0.8),
        ]
        
        for pattern, weight in recommendation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.RECOMMENDATION] = max(
                    type_scores[QuestionType.RECOMMENDATION], weight
                )
        
        # GREETING detection
        greeting_words = ['xin ch√†o', 'ch√†o', 'hello', 'hi', 'helo', 'chao']
        greeting_score = 0.0
        for word in greeting_words:
            if word in message_lower:
                if message_lower.startswith(word) or f" {word} " in message_lower or message_lower.endswith(f" {word}"):
                    greeting_score += 0.3
        
        other_intent_score = max([score for qtype, score in type_scores.items() 
                                 if qtype != QuestionType.GREETING], default=0.0)
        
        if greeting_score > 0.8 and other_intent_score < 0.3:
            type_scores[QuestionType.GREETING] = min(greeting_score, 1.0)
        
        # FAREWELL detection
        farewell_words = ['t·∫°m bi·ªát', 'c·∫£m ∆°n', 'thanks', 'thank you', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            type_scores[QuestionType.FAREWELL] = 0.95
        
        # CALCULATION detection
        calculation_patterns = [
            (r't√≠nh to√°n|t√≠nh.*bao nhi√™u|t·ªïng.*bao nhi√™u', 0.9),
            (r'c·ªông.*l·∫°i|nh√¢n.*l√™n|chia.*ra', 0.8),
            (r'bao nhi√™u.*ng∆∞·ªùi|m·∫•y.*ng∆∞·ªùi|s·ªë l∆∞·ª£ng.*ng∆∞·ªùi', 0.7),
        ]
        
        for pattern, weight in calculation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.CALCULATION] = max(
                    type_scores[QuestionType.CALCULATION], weight
                )
        
        # COMPLEX question detection
        complex_indicators = [
            ('v√†', 0.3), ('r·ªìi', 0.4), ('sau ƒë√≥', 0.5),
            ('ti·∫øp theo', 0.5), ('ngo√†i ra', 0.4), ('th√™m n·ªØa', 0.4),
        ]
        
        complex_score = 0.0
        for indicator, weight in complex_indicators:
            if indicator in message_lower:
                complex_score += weight
        
        if complex_score > 0.8:
            type_scores[QuestionType.COMPLEX] = min(complex_score / 2, 1.0)
            metadata['complex_parts'] = QuestionPipeline._split_complex_question(message)
        
        # DEFAULT: INFORMATION request
        if not type_scores:
            type_scores[QuestionType.INFORMATION] = 0.6
        else:
            info_keywords = ['l√† g√¨', 'bao nhi√™u', '·ªü ƒë√¢u', 'khi n√†o', 'th·∫ø n√†o', 'ai', 't·∫°i sao']
            if any(keyword in message_lower for keyword in info_keywords):
                type_scores[QuestionType.INFORMATION] = max(
                    type_scores.get(QuestionType.INFORMATION, 0),
                    0.5
                )
        
        # Determine best type
        best_type = QuestionType.INFORMATION
        best_score = 0.0
        
        for qtype, score in type_scores.items():
            if score > best_score:
                best_score = score
                best_type = qtype
        
        if best_score < 0.5:
            best_type = QuestionType.INFORMATION
            best_score = 0.5
        
        logger.info(f"üéØ Question classification: '{message}' ‚Üí {best_type.value} (score: {best_score:.2f})")
        return best_type, best_score, metadata
    
    @staticmethod
    def _split_complex_question(message: str) -> List[str]:
        """Split complex multi-part question into simpler parts"""
        split_patterns = [
            r'\s+v√†\s+',
            r'\s+r·ªìi\s+',
            r'\s+sau ƒë√≥\s+',
            r'\s+ti·∫øp theo\s+',
            r'\s+ngo√†i ra\s+',
            r'\s+th√™m n·ªØa\s+',
            r'\s+ƒë·ªìng th·ªùi\s+',
            r'\s+cu·ªëi c√πng\s+',
        ]
        
        parts = [message]
        
        for pattern in split_patterns:
            new_parts = []
            for part in parts:
                split_result = re.split(pattern, part, flags=re.IGNORECASE)
                new_parts.extend([p.strip() for p in split_result if p.strip()])
            parts = new_parts
        
        return parts
    
    @staticmethod
    def process_comparison_question(tour_indices: List[int], tours_db: Dict[int, Tour], 
                                  aspect: str = "", context: Dict = None) -> str:
        """
        Process comparison question between tours
        """
        if len(tour_indices) < 2:
            return "C·∫ßn √≠t nh·∫•t 2 tour ƒë·ªÉ so s√°nh."
        
        tours_to_compare = []
        for idx in tour_indices[:3]:
            tour = tours_db.get(idx)
            if tour:
                tours_to_compare.append((idx, tour))
        
        if len(tours_to_compare) < 2:
            return "Kh√¥ng t√¨m th·∫•y ƒë·ªß th√¥ng tin tour ƒë·ªÉ so s√°nh."
        
        if not aspect:
            aspect = 'price'
        
        result_lines = []
        
        headers = ["TI√äU CH√ç"]
        for idx, tour in tours_to_compare:
            tour_name = tour.name or f'Tour #{idx}'
            headers.append(tour_name[:25])
        
        result_lines.append(" | ".join(headers))
        result_lines.append("-" * (len(headers) * 30))
        
        comparison_fields = [
            ('duration', '‚è±Ô∏è Th·ªùi gian'),
            ('location', 'üìç ƒê·ªãa ƒëi·ªÉm'),
            ('price', 'üí∞ Gi√° tour'),
            ('accommodation', 'üè® Ch·ªó ·ªü'),
            ('meals', 'üçΩÔ∏è ƒÇn u·ªëng'),
            ('transport', 'üöó Di chuy·ªÉn'),
            ('summary', 'üìù M√¥ t·∫£'),
        ]
        
        for field, display_name in comparison_fields:
            if aspect and field != aspect and aspect not in ['all', 't·∫•t c·∫£']:
                continue
            
            row = [display_name]
            all_values = []
            
            for idx, tour in tours_to_compare:
                value = getattr(tour, field, 'N/A')
                if isinstance(value, list):
                    value = ', '.join(value[:2])
                row.append(str(value)[:30])
                all_values.append(str(value).lower())
            
            if len(set(all_values)) > 1 or aspect == field:
                result_lines.append(" | ".join(row))
        
        result_lines.append("\n" + "="*50)
        result_lines.append("**ƒê√ÅNH GI√Å & G·ª¢I √ù:**")
        
        durations = [tour.duration for _, tour in tours_to_compare]
        if any('1 ng√†y' in d for d in durations) and any('2 ng√†y' in d for d in durations):
            result_lines.append("‚Ä¢ N·∫øu b·∫°n c√≥ √≠t th·ªùi gian: Ch·ªçn tour 1 ng√†y")
            result_lines.append("‚Ä¢ N·∫øu mu·ªën tr·∫£i nghi·ªám s√¢u: Ch·ªçn tour 2 ng√†y")
        
        prices = []
        for _, tour in tours_to_compare:
            price_text = tour.price or ''
            price_nums = re.findall(r'\d[\d,\.]+', price_text)
            if price_nums:
                try:
                    price = int(price_nums[0].replace(',', '').replace('.', ''))
                    prices.append(price)
                except:
                    pass
        
        if len(prices) >= 2:
            min_price_idx = prices.index(min(prices))
            max_price_idx = prices.index(max(prices))
            
            if prices[max_price_idx] > prices[min_price_idx] * 1.5:
                result_lines.append(f"‚Ä¢ Ti·∫øt ki·ªám chi ph√≠: {headers[min_price_idx + 1]}")
                result_lines.append(f"‚Ä¢ Tr·∫£i nghi·ªám cao c·∫•p: {headers[max_price_idx + 1]}")
        
        result_lines.append("\nüí° *Li√™n h·ªá hotline 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt*")
        
        return "\n".join(result_lines)

# =========== UPGRADE 5: COMPLEX QUERY SPLITTER (DATACLASS COMPATIBLE) ===========
class ComplexQueryProcessor:
    """
    UPGRADE 5: Handle complex multi-condition queries
    """
    
    @staticmethod
    def split_query(query: str) -> List[Dict[str, Any]]:
        """
        Split complex query into sub-queries with priorities
        """
        sub_queries = []
        
        complexity_score = ComplexQueryProcessor._calculate_complexity(query)
        if complexity_score < 1.5:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': {},
                'focus': 'general'
            }]
        
        conditions = ComplexQueryProcessor._extract_conditions(query)
        
        if len(conditions) <= 1:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': conditions[0] if conditions else {},
                'focus': 'general'
            }]
        
        sub_queries.append({
            'query': query,
            'priority': 1.0,
            'filters': ComplexQueryProcessor._merge_conditions(conditions),
            'focus': 'specific'
        })
        
        location_conds = [c for c in conditions if 'location' in c]
        other_conds = [c for c in conditions if 'location' not in c]
        
        if location_conds and other_conds:
            for other_cond in other_conds[:2]:
                merged = ComplexQueryProcessor._merge_conditions(location_conds + [other_cond])
                sub_queries.append({
                    'query': f"{query} (focus on location + {list(other_cond.keys())[0]})",
                    'priority': 0.8,
                    'filters': merged,
                    'focus': list(other_cond.keys())[0]
                })
        
        important_conds = ['price', 'duration', 'location']
        for cond_type in important_conds:
            conds_of_type = [c for c in conditions if cond_type in c]
            if conds_of_type:
                sub_queries.append({
                    'query': f"{query} (focus on {cond_type})",
                    'priority': 0.6,
                    'filters': conds_of_type[0],
                    'focus': cond_type
                })
        
        sub_queries.sort(key=lambda x: x['priority'], reverse=True)
        
        logger.info(f"üîÄ Split query into {len(sub_queries)} sub-queries")
        return sub_queries[:3]
    
    @staticmethod
    def _calculate_complexity(query: str) -> float:
        """Calculate how complex a query is"""
        complexity = 0.0
        
        aspects = {
            'price': ['gi√°', 'ti·ªÅn', 'chi ph√≠', 'ƒë·∫Øt', 'r·∫ª'],
            'duration': ['ng√†y', 'ƒë√™m', 'bao l√¢u', 'th·ªùi gian'],
            'location': ['·ªü', 't·∫°i', 'ƒë·∫øn', 'v·ªÅ', 'ƒë·ªãa ƒëi·ªÉm'],
            'quality': ['t·ªët', 'hay', 'ƒë·∫πp', 'h·∫•p d·∫´n', 'th√∫ v·ªã'],
            'type': ['thi·ªÅn', 'kh√≠ c√¥ng', 'retreat', 'ch·ªØa l√†nh'],
        }
        
        query_lower = query.lower()
        
        distinct_aspects = 0
        for aspect, keywords in aspects.items():
            if any(keyword in query_lower for keyword in keywords):
                distinct_aspects += 1
        
        complexity += distinct_aspects * 0.5
        complexity += min(len(query.split()) / 10, 1.0)
        
        conjunctions = ['v√†', 'v·ªõi', 'c√≥', 'cho', 'm√†', 'nh∆∞ng']
        for conj in conjunctions:
            if conj in query_lower:
                complexity += 0.3
        
        return complexity
    
    @staticmethod
    def _extract_conditions(query: str) -> List[Dict[str, Any]]:
        """Extract individual conditions from query"""
        conditions = []
        
        filters = MandatoryFilterSystem.extract_filters(query)
        
        if filters.price_min is not None or filters.price_max is not None:
            price_cond = {'price': {}}
            if filters.price_min is not None:
                price_cond['price']['min'] = filters.price_min
            if filters.price_max is not None:
                price_cond['price']['max'] = filters.price_max
            conditions.append(price_cond)
        
        if filters.duration_min is not None or filters.duration_max is not None:
            duration_cond = {'duration': {}}
            if filters.duration_min is not None:
                duration_cond['duration']['min'] = filters.duration_min
            if filters.duration_max is not None:
                duration_cond['duration']['max'] = filters.duration_max
            conditions.append(duration_cond)
        
        if filters.location:
            conditions.append({'location': filters.location})
        if filters.near_location:
            conditions.append({'near_location': filters.near_location})
        
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['r·∫ª', 'gi√° r·∫ª', 'ti·∫øt ki·ªám']):
            conditions.append({'price_quality': 'budget'})
        if any(word in query_lower for word in ['cao c·∫•p', 'sang', 'premium']):
            conditions.append({'price_quality': 'premium'})
        
        if 'thi·ªÅn' in query_lower:
            conditions.append({'activity_type': 'meditation'})
        if 'kh√≠ c√¥ng' in query_lower:
            conditions.append({'activity_type': 'qigong'})
        if 'retreat' in query_lower:
            conditions.append({'activity_type': 'retreat'})
        if 'ch·ªØa l√†nh' in query_lower:
            conditions.append({'activity_type': 'healing'})
        
        tour_name_patterns = [
            r'tour\s+([^v√†\s,]+)\s+v√†\s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+v·ªõi\s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+.*tour\s+([^\s,]+)',
        ]
        
        for pattern in tour_name_patterns:
            matches = re.finditer(pattern, query_lower)
            for match in matches:
                for i in range(1, 3):
                    if match.group(i):
                        tour_name = match.group(i).strip()
                        normalized_name = FuzzyMatcher.normalize_vietnamese(tour_name)
                        for name, idx in TOUR_NAME_TO_INDEX.items():
                            if normalized_name in name or name in normalized_name:
                                conditions.append({'specific_tour': idx})
                                logger.info(f"üîç Extracted tour name from complex query: {tour_name} ‚Üí index {idx}")
        
        return conditions
    
    @staticmethod
    def _merge_conditions(conditions: List[Dict]) -> Dict[str, Any]:
        """Merge multiple conditions into one filter dict"""
        merged = {}
        
        for condition in conditions:
            for key, value in condition.items():
                if key in merged:
                    if isinstance(merged[key], dict) and isinstance(value, dict):
                        merged[key].update(value)
                    elif isinstance(merged[key], list) and isinstance(value, list):
                        merged[key].extend(value)
                    else:
                        if isinstance(value, dict) or (isinstance(value, str) and len(value) > len(str(merged[key]))):
                            merged[key] = value
                else:
                    merged[key] = value
        
        return merged

# =========== UPGRADE 6: FUZZY MATCHING (DATACLASS COMPATIBLE) ===========
class FuzzyMatcher:
    """
    UPGRADE 6: Handle misspellings and variations in tour names
    """
    
    SIMILARITY_THRESHOLD = 0.75
    
    @staticmethod
    def normalize_vietnamese(text: str) -> str:
        """
        Normalize Vietnamese text for fuzzy matching
        """
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        
        replacements = {
            'ƒë': 'd',
            'kh√¥ng': 'ko',
            'khong': 'ko',
            'r·ªìi': 'roi',
            'v·ªõi': 'voi',
            'ƒë∆∞·ª£c': 'duoc',
            'm·ªôt': 'mot',
            'hai': '2',
            'ba': '3',
            'b·ªën': '4',
            'nƒÉm': '5',
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    @staticmethod
    def find_similar_tours(query: str, tour_names: Dict[str, int]) -> List[Tuple[int, float]]:
        """
        Find tours with names similar to query - Enhanced version
        Returns list of (tour_idx, similarity_score) sorted by similarity
        """
        if not query or not tour_names:
            logger.info(f"üîç Fuzzy matching: Empty query or tour_names, returning empty list")
            return []
        
        query_lower = query.lower().strip()
        query_norm = FuzzyMatcher.normalize_vietnamese(query_lower)
        
        if not query_norm:
            logger.info(f"üîç Fuzzy matching: Cannot normalize query '{query}'")
            return []
        
        logger.info(f"üîç Fuzzy matching: Query '{query}' -> Normalized: '{query_norm}'")
        
        matches = []
        query_words = set(query_norm.split())
        
        # Define common stop words to ignore
        stop_words = {'tour', 'ch∆∞∆°ng', 'tr√¨nh', 'c·ªßa', 'cho', 'v·ªõi', 'v√†', 't·∫°i', '·ªü', 't·ª´'}
        query_filtered_words = [word for word in query_norm.split() if word not in stop_words]
        
        # Enhanced keyword extraction
        query_keywords = set(query_filtered_words)
        
        # Check for specific tour patterns
        known_tour_patterns = {
            'b·∫°ch m√£': ['b·∫°ch m√£', 'bach ma'],
            'tr∆∞·ªùng s∆°n': ['tr∆∞·ªùng s∆°n', 'truong son', 't√¢y tr∆∞·ªùng s∆°n'],
            'm∆∞a ƒë·ªè': ['m∆∞a ƒë·ªè', 'mua do'],
            'ng·ªçn l·ª≠a': ['ng·ªçn l·ª≠a', 'ngon lua'],
            'k√Ω ·ª©c': ['k√Ω ·ª©c', 'ky uc'],
            'l·ªãch s·ª≠': ['l·ªãch s·ª≠', 'lich su'],
            'ƒë·∫°i ng√†n': ['ƒë·∫°i ng√†n', 'dai ngan'],
            'non n∆∞·ªõc': ['non n∆∞·ªõc', 'non nuoc'],
            'h√†nh tr√¨nh': ['h√†nh tr√¨nh', 'hanh trinh'],
            'kh√°t v·ªçng': ['kh√°t v·ªçng', 'khat vong'],
            'tƒ©nh l·∫∑ng': ['tƒ©nh l·∫∑ng', 'tinh lang'],
            'retreat': ['retreat', 'tƒ©nh t√¢m', 'tinh tam'],
            'thi·ªÅn': ['thi·ªÅn', 'thien'],
            'hu·∫ø': ['hu·∫ø', 'hue'],
            'qu·∫£ng tr·ªã': ['qu·∫£ng tr·ªã', 'quang tri']
        }
        
        # Extract potential tour name from query
        extracted_tour_names = []
        for pattern, variants in known_tour_patterns.items():
            for variant in variants:
                if variant in query_lower:
                    extracted_tour_names.append(pattern)
                    break
        
        logger.info(f"üîç Extracted tour patterns: {extracted_tour_names}")
        
        for tour_name, tour_idx in tour_names.items():
            tour_name_lower = tour_name.lower().strip()
            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name_lower)
            
            if not tour_norm:
                continue
            
            # Calculate multiple similarity scores
            scores = []
            
            # 1. Direct string similarity
            direct_similarity = SequenceMatcher(None, query_norm, tour_norm).ratio()
            scores.append(('direct', direct_similarity))
            
            # 2. Check if query contains tour name or vice versa (partial match)
            if query_norm in tour_norm:
                scores.append(('query_in_tour', min(direct_similarity + 0.3, 1.0)))
            if tour_norm in query_norm:
                scores.append(('tour_in_query', min(direct_similarity + 0.3, 1.0)))
            
            # 3. Word overlap similarity
            tour_words = set(tour_norm.split())
            tour_filtered_words = [word for word in tour_norm.split() if word not in stop_words]
            
            common_words = query_words.intersection(tour_words)
            if common_words:
                word_overlap = len(common_words) / max(len(query_words), len(tour_words))
                scores.append(('word_overlap', word_overlap))
            
            # 4. Enhanced keyword matching
            if query_keywords:
                keyword_matches = sum(1 for keyword in query_keywords if any(keyword in word for word in tour_filtered_words))
                if keyword_matches > 0:
                    keyword_score = keyword_matches / len(query_keywords)
                    scores.append(('keyword', keyword_score))
            
            # 5. Pattern matching for known tour names
            pattern_score = 0
            for pattern in extracted_tour_names:
                if pattern in tour_norm:
                    pattern_score += 0.5
            if pattern_score > 0:
                scores.append(('pattern', min(pattern_score, 1.0)))
            
            # 6. Abbreviation/alias matching
            # Check if tour has common abbreviations
            tour_abbreviations = {
                'b·∫°ch m√£': 'bm',
                'tr∆∞·ªùng s∆°n': 'ts',
                'm∆∞a ƒë·ªè': 'md',
                'hu·∫ø': 'h',
                'qu·∫£ng tr·ªã': 'qt'
            }
            
            for full, abbrev in tour_abbreviations.items():
                if full in tour_norm and abbrev in query_norm:
                    scores.append(('abbreviation', 0.7))
                    break
            
            # 7. Number matching (for tour durations like 1 ng√†y, 2 ng√†y)
            import re
            query_numbers = set(re.findall(r'\d+', query_norm))
            tour_numbers = set(re.findall(r'\d+', tour_norm))
            if query_numbers and tour_numbers:
                number_match = len(query_numbers.intersection(tour_numbers)) / len(query_numbers)
                if number_match > 0:
                    scores.append(('number', number_match))
            
            # Calculate final similarity (weighted average)
            weights = {
                'direct': 0.3,
                'query_in_tour': 0.25,
                'tour_in_query': 0.25,
                'word_overlap': 0.15,
                'keyword': 0.15,
                'pattern': 0.1,
                'abbreviation': 0.05,
                'number': 0.05
            }
            
            weighted_scores = []
            for score_type, score_value in scores:
                if score_type in weights:
                    weighted_scores.append(score_value * weights[score_type])
            
            final_similarity = sum(weighted_scores) if weighted_scores else direct_similarity
            
            # Apply bonuses for specific cases
            bonuses = 0
            
            # Bonus for exact word match
            exact_word_match = any(word == tour_word for word in query_filtered_words for tour_word in tour_filtered_words)
            if exact_word_match:
                bonuses += 0.1
            
            # Bonus for matching at beginning of tour name
            if query_filtered_words and any(tour_norm.startswith(word) for word in query_filtered_words):
                bonuses += 0.15
            
            # Bonus for historical/relevant keywords
            historical_keywords = ['l·ªãch s·ª≠', 'chi·∫øn tranh', 'di t√≠ch', 'tri √¢n', 'c·ª±u chi·∫øn binh']
            if any(keyword in query_norm for keyword in historical_keywords) and \
            any(keyword in tour_norm for keyword in historical_keywords):
                bonuses += 0.2
            
            # Bonus for wellness/retreat keywords
            wellness_keywords = ['thi·ªÅn', 'yoga', 'retreat', 'tƒ©nh t√¢m', 'kh√≠ c√¥ng', 'ch·ªØa l√†nh']
            if any(keyword in query_norm for keyword in wellness_keywords) and \
            any(keyword in tour_norm for keyword in wellness_keywords):
                bonuses += 0.2
            
            final_similarity = min(final_similarity + bonuses, 1.0)
            
            # Adjust threshold based on query complexity
            dynamic_threshold = 0.5  # Base threshold
            
            # Lower threshold for complex queries (more words)
            if len(query_filtered_words) >= 3:
                dynamic_threshold = 0.4
            
            # Higher threshold for very short queries
            if len(query_filtered_words) == 1:
                dynamic_threshold = 0.6
            
            # Special case for known tour patterns
            if extracted_tour_names and any(pattern in tour_norm for pattern in extracted_tour_names):
                dynamic_threshold = 0.3
            
            if final_similarity >= dynamic_threshold:
                matches.append((tour_idx, final_similarity))
                logger.debug(f"  ‚úì Match: '{tour_name}' (idx: {tour_idx}) - Score: {final_similarity:.2f}")
        
        # Sort by similarity score (descending)
        matches.sort(key=lambda x: x[1], reverse=True)
        
        # Limit results but ensure we get relevant matches
        max_results = 10
        if matches:
            # Ensure we include all high-confidence matches (>0.7)
            high_confidence = [m for m in matches if m[1] > 0.7]
            if high_confidence:
                matches = high_confidence + [m for m in matches if m[1] <= 0.7][:max_results - len(high_confidence)]
            else:
                matches = matches[:max_results]
        
        logger.info(f"‚úÖ Fuzzy matching: '{query}' ‚Üí {len(matches)} matches (threshold: dynamic)")
        
        # Log top matches for debugging
        if matches:
            for i, (idx, score) in enumerate(matches[:5]):
                tour_name = next((name for name, tid in tour_names.items() if tid == idx), "Unknown")
                logger.debug(f"  Top {i+1}: {tour_name} (idx: {idx}) - Score: {score:.2f}")
        
        return matches


    # Th√™m ph∆∞∆°ng th·ª©c helper cho normalization n√¢ng cao n·∫øu c·∫ßn
    @staticmethod
    def enhanced_normalize_vietnamese(text: str) -> str:
        """
        Enhanced Vietnamese text normalization
        """
        if not text:
            return ""
        
        # Basic normalization (gi·ªØ nguy√™n t·ª´ h√†m g·ªëc)
        normalized = text.lower().strip()
        
        # Remove extra spaces
        normalized = ' '.join(normalized.split())
        
        # Common replacements for tour names
        replacements = {
            '‚Äì': ' ',
            '-': ' ',
            '‚Äì': ' ',
            '(': ' ',
            ')': ' ',
            ',': ' ',
            '.': ' ',
            '!': ' ',
            '?': ' ',
            '"': ' ',
            "'": ' ',
            ';': ' ',
            ':': ' ',
        }
        
        for old, new in replacements.items():
            normalized = normalized.replace(old, new)
        
        # Remove multiple spaces again
        normalized = ' '.join(normalized.split())
        
        return normalizeds
        
    @staticmethod
    def find_tour_by_partial_name(partial_name: str, tours_db: Dict[int, Tour]) -> List[int]:
        """
        Find tours by partial name match
        """
        if not partial_name or not tours_db:
            return []
        
        partial_norm = FuzzyMatcher.normalize_vietnamese(partial_name)
        matches = []
        
        for tour_idx, tour in tours_db.items():
            tour_name = tour.name or ""
            if not tour_name:
                continue
            
            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name)
            
            if partial_norm in tour_norm:
                match_ratio = len(partial_norm) / len(tour_norm) if tour_norm else 0
                matches.append((tour_idx, match_ratio))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        return [idx for idx, _ in matches[:3]]

# =========== UPGRADE 7: STATE MACHINE (DATACLASS COMPATIBLE) ===========
class ConversationStateMachine:
    """
    UPGRADE 7: Track conversation state for better context
    """
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.state = ConversationState.INITIAL
        self.context = ConversationContext(session_id=session_id)
        self.transitions = []
        self.created_at = datetime.utcnow()
        self.last_updated = datetime.utcnow()
    
    def update(self, user_message: str, bot_response: str, tour_indices: List[int] = None):
        """Update state based on new interaction"""
        self.last_updated = datetime.utcnow()
        self.context.update(user_message, bot_response, tour_indices)
        
        new_state = self._determine_state(user_message, bot_response)
        
        self.transitions.append({
            'timestamp': datetime.utcnow().isoformat(),
            'from': self.state.value,
            'to': new_state.value,
            'message': user_message[:100]
        })
        
        self.state = new_state
        
        logger.info(f"üîÑ State update: {self.state.value} for session {self.session_id}")
    
    def _determine_state(self, user_message: str, bot_response: str) -> ConversationState:
        """Determine new state based on current interaction"""
        message_lower = user_message.lower()
        
        farewell_words = ['t·∫°m bi·ªát', 'c·∫£m ∆°n', 'thanks', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            return ConversationState.FAREWELL
        
        tour_ref_patterns = [
            r'tour n√†y', r'tour ƒë√≥', r'tour ƒëang n√≥i', r'c√°i tour',
            r'n√≥', r'c√°i ƒë√≥', r'c√°i n√†y', r'ƒë·∫•y'
        ]
        
        if any(re.search(pattern, message_lower) for pattern in tour_ref_patterns):
            if self.context.current_tours:
                return ConversationState.TOUR_SELECTED
            elif self.context.last_successful_tours:
                self.context.current_tours = self.context.last_successful_tours
                return ConversationState.TOUR_SELECTED
        
        if 'so s√°nh' in message_lower or 's√°nh' in message_lower:
            return ConversationState.COMPARING
        
        if any(word in message_lower for word in ['ph√π h·ª£p', 'g·ª£i √Ω', 'ƒë·ªÅ xu·∫•t', 't∆∞ v·∫•n', 'n√™n ch·ªçn']):
            return ConversationState.RECOMMENDATION
        
        if any(word in message_lower for word in ['ƒë·∫∑t', 'booking', 'ƒëƒÉng k√Ω', 'gi·ªØ ch·ªó']):
            return ConversationState.BOOKING
        
        if self.context.current_tours:
            return ConversationState.ASKING_DETAILS
        
        return ConversationState.INITIAL
    
    def get_context_hint(self) -> str:
        """Get hint about current context for LLM prompt"""
        hints = []
        
        if self.state == ConversationState.TOUR_SELECTED and self.context.current_tours:
            tour_indices = self.context.current_tours
            if len(tour_indices) == 1:
                hints.append(f"User is asking about tour index {tour_indices[0]}")
            else:
                hints.append(f"User is asking about tours {tour_indices}")
        
        if self.context.user_preferences:
            prefs = []
            for key, value in self.context.user_preferences.items():
                prefs.append(f"{key}: {value}")
            if prefs:
                hints.append(f"User preferences: {', '.join(prefs)}")
        
        return "; ".join(hints) if hints else "No specific context"
    
    def extract_reference(self, message: str) -> List[int]:
        """Extract tour reference from message using conversation context"""
        message_lower = message.lower()
        
        if self.context.current_tours:
            for tour_idx in self.context.current_tours:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"üîÑ State machine: Using current tour {tour_idx}")
                        return self.context.current_tours
        
        ref_patterns = [
            (r'tour n√†y', 1.0),
            (r'tour ƒë√≥', 0.9),
            (r'tour ƒëang n√≥i', 0.9),
            (r'c√°i tour', 0.8),
            (r'n√≥', 0.7),
            (r'ƒë·∫•y', 0.7),
            (r'c√°i ƒë√≥', 0.7),
        ]
        
        for pattern, confidence in ref_patterns:
            if re.search(pattern, message_lower):
                if self.context.current_tours:
                    logger.info(f"üîÑ State machine: Resolved reference to {self.context.current_tours}")
                    return self.context.current_tours
                elif self.context.last_successful_tours:
                    logger.info(f"üîÑ State machine: Using last successful tours {self.context.last_successful_tours}")
                    return self.context.last_successful_tours
        
        if self.context.mentioned_tours:
            recent_tours = list(self.context.mentioned_tours)
            for tour_idx in recent_tours[-3:]:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"üîÑ State machine: Matched to recently mentioned tour {tour_idx}")
                        return [tour_idx]
        
        return []

# =========== UPGRADE 8: DEEP SEMANTIC ANALYSIS (DATACLASS COMPATIBLE) ===========
class SemanticAnalyzer:
    """
    UPGRADE 8: Deep understanding of user intent beyond keywords
    """
    
    USER_PROFILE_PATTERNS = {
        'age_group': [
            (r'ng∆∞·ªùi gi√†|ng∆∞·ªùi l·ªõn tu·ªïi|cao tu·ªïi', 'senior'),
            (r'thanh ni√™n|tr·∫ª|sinh vi√™n|h·ªçc sinh', 'young'),
            (r'trung ni√™n|trung tu·ªïi', 'middle_aged'),
            (r'gia ƒë√¨nh.*tr·∫ª em|tr·∫ª nh·ªè|con n√≠t', 'family_with_kids'),
        ],
        
        'group_type': [
            (r'm·ªôt m√¨nh|ƒëi l·∫ª|solo', 'solo'),
            (r'c·∫∑p ƒë√¥i|ƒë√¥i l·ª©a|ng∆∞·ªùi y√™u', 'couple'),
            (r'gia ƒë√¨nh|b·ªë m·∫π con', 'family'),
            (r'b·∫°n b√®|nh√≥m b·∫°n|h·ªôi b·∫°n', 'friends'),
            (r'c√¥ng ty|doanh nghi·ªáp|ƒë·ªìng nghi·ªáp', 'corporate'),
        ],
        
        'interest_type': [
            (r'thi√™n nhi√™n|r·ª´ng|c√¢y|c·∫£nh quan', 'nature'),
            (r'l·ªãch s·ª≠|di t√≠ch|chi·∫øn tranh|tri √¢n', 'history'),
            (r'vƒÉn h√≥a|c·ªông ƒë·ªìng|d√¢n t·ªôc|truy·ªÅn th·ªëng', 'culture'),
            (r'thi·ªÅn|t√¢m linh|tƒ©nh t√¢m|yoga', 'spiritual'),
            (r'kh√≠ c√¥ng|s·ª©c kh·ªèe|ch·ªØa l√†nh|wellness', 'wellness'),
            (r'·∫©m th·ª±c|ƒë·ªì ƒÉn|m√≥n ngon|ƒë·∫∑c s·∫£n', 'food'),
            (r'phi√™u l∆∞u|m·∫°o hi·ªÉm|kh√°m ph√°|tr·∫£i nghi·ªám', 'adventure'),
        ],
        
        'budget_level': [
            (r'kinh t·∫ø|ti·∫øt ki·ªám|r·∫ª|gi√° th·∫•p', 'budget'),
            (r'trung b√¨nh|v·ª´a ph·∫£i|ph·∫£i chƒÉng', 'midrange'),
            (r'cao c·∫•p|sang tr·ªçng|premium|ƒë·∫Øt', 'premium'),
        ],
        
        'physical_level': [
            (r'nh·∫π nh√†ng|d·ªÖ d√†ng|kh√¥ng m·ªát', 'easy'),
            (r'v·ª´a ph·∫£i|trung b√¨nh|b√¨nh th∆∞·ªùng', 'moderate'),
            (r'th·ª≠ th√°ch|kh√≥|m·ªát|leo n√∫i', 'challenging'),
        ],
    }
    
    @staticmethod
    def analyze_user_profile(message: str, current_context: ConversationContext = None) -> UserProfile:
        """
        Analyze message to build user profile
        """
        if current_context and hasattr(current_context, 'user_profile') and current_context.user_profile:
            profile = current_context.user_profile
        else:
            profile = UserProfile()
        
        message_lower = message.lower()
        
        for category, patterns in SemanticAnalyzer.USER_PROFILE_PATTERNS.items():
            for pattern, value in patterns:
                if re.search(pattern, message_lower):
                    if category == 'interests':
                        if value not in profile.interests:
                            profile.interests.append(value)
                            profile.confidence_scores[f'interest_{value}'] = 0.8
                    else:
                        setattr(profile, category, value)
                        profile.confidence_scores[category] = 0.8
        
        SemanticAnalyzer._infer_attributes(profile, message_lower)
        profile.overall_confidence = SemanticAnalyzer._calculate_confidence(profile)
        
        logger.info(f"üë§ User profile analysis: {profile}")
        return profile
    
    @staticmethod
    def _infer_attributes(profile: UserProfile, message_lower: str):
        """Infer additional attributes from context"""
        if not profile.age_group:
            if profile.group_type and 'family_with_kids' in profile.group_type:
                profile.age_group = 'middle_aged'
                profile.confidence_scores['age_group'] = 0.6
            elif 'senior' in message_lower or 'gi√†' in message_lower:
                profile.age_group = 'senior'
                profile.confidence_scores['age_group'] = 0.7
        
        if not profile.physical_level:
            if 'adventure' in profile.interests:
                profile.physical_level = 'challenging'
                profile.confidence_scores['physical_level'] = 0.6
            elif 'spiritual' in profile.interests or 'wellness' in profile.interests:
                profile.physical_level = 'easy'
                profile.confidence_scores['physical_level'] = 0.6
        
        if not profile.budget_level:
            budget_keywords = {
                'budget': ['r·∫ª', 'ti·∫øt ki·ªám', '√≠t ti·ªÅn', 'kinh t·∫ø'],
                'premium': ['cao c·∫•p', 'sang', 'ƒë·∫Øt', 'premium']
            }
            
            for level, keywords in budget_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    profile.budget_level = level
                    profile.confidence_scores['budget_level'] = 0.7
                    break
    
    @staticmethod
    def _calculate_confidence(profile: UserProfile) -> float:
        """Calculate overall confidence in user profile"""
        if not profile.confidence_scores:
            return 0.0
        
        total = 0.0
        count = 0
        
        for key, score in profile.confidence_scores.items():
            total += score
            count += 1
        
        return total / max(count, 1)
    
    @staticmethod
    def match_tours_to_profile(profile: UserProfile, tours_db: Dict[int, Tour], 
                              max_results: int = 5) -> List[Tuple[int, float, List[str]]]:
        """
        Match tours to user profile with explanation
        """
        matches = []
        
        for tour_idx, tour in tours_db.items():
            score = 0.0
            reasons = []
            
            tour_tags = tour.tags or []
            
            if profile.age_group:
                if profile.age_group == 'senior':
                    if any('easy' in tag for tag in tour_tags):
                        score += 0.3
                        reasons.append("ph√π h·ª£p ng∆∞·ªùi l·ªõn tu·ªïi")
                    if any('nature' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("thi√™n nhi√™n nh·∫π nh√†ng")
            
            if profile.interests:
                for interest in profile.interests:
                    tour_summary = (tour.summary or "").lower()
                    if (interest in tour_summary or 
                        any(interest in tag for tag in tour_tags)):
                        score += 0.4
                        reasons.append(f"c√≥ y·∫øu t·ªë {interest}")
            
            if profile.budget_level:
                tour_price = tour.price or ""
                price_nums = re.findall(r'\d[\d,\.]+', tour_price)
                
                if price_nums:
                    try:
                        first_price = int(price_nums[0].replace(',', '').replace('.', ''))
                        
                        if profile.budget_level == 'budget' and first_price < 2000000:
                            score += 0.3
                            reasons.append("gi√° h·ª£p l√Ω")
                        elif profile.budget_level == 'premium' and first_price > 2500000:
                            score += 0.3
                            reasons.append("cao c·∫•p")
                        elif profile.budget_level == 'midrange' and 1500000 <= first_price <= 3000000:
                            score += 0.3
                            reasons.append("gi√° v·ª´a ph·∫£i")
                    except:
                        pass
            
            if profile.physical_level:
                if profile.physical_level == 'easy':
                    if any('easy' in tag or 'meditation' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("ho·∫°t ƒë·ªông nh·∫π nh√†ng")
            
            if score > 0:
                matches.append((tour_idx, score, reasons))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        return matches[:max_results]

# =========== UPGRADE 9: AUTO-VALIDATION SYSTEM (DATACLASS COMPATIBLE) ===========
class AutoValidator:
    """
    UPGRADE 9: Validate and correct information before returning
    """
    
    VALIDATION_RULES = {
        'duration': {
            'patterns': [
                r'(\d+)\s*ng√†y\s*(\d+)\s*ƒë√™m',
                r'(\d+)\s*ng√†y',
                r'(\d+)\s*ƒë√™m',
            ],
            'constraints': {
                'max_days': 7,
                'max_nights': 7,
                'valid_day_night_combos': [(1,0), (1,1), (2,1), (2,2), (3,2), (3,3)],
                'common_durations': ['1 ng√†y', '2 ng√†y 1 ƒë√™m', '3 ng√†y 2 ƒë√™m']
            }
        },
        
        'price': {
            'patterns': [
                r'(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)',
                r'(\d[\d,\.]*)\s*-\s*(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)?',
                r'(\d[\d,\.]*)\s*(ƒë·ªìng|vnƒë|vnd)',
            ],
            'constraints': {
                'min_tour_price': 500000,
                'max_tour_price': 10000000,
                'common_ranges': [
                    (800000, 1500000),
                    (1500000, 2500000),
                    (2500000, 4000000),
                ]
            }
        },
        
        'location': {
            'patterns': [
                r'·ªü\s+([^.,!?]+)',
                r't·∫°i\s+([^.,!?]+)',
                r'ƒë·∫øn\s+([^.,!?]+)',
            ],
            'constraints': {
                'valid_locations': ['Hu·∫ø', 'Qu·∫£ng Tr·ªã', 'B·∫°ch M√£', 'Tr∆∞·ªùng S∆°n', 'ƒê√¥ng H√†', 'Khe Sanh'],
                'max_length': 100
            }
        },
    }
    
    @staticmethod
    def validate_response(response: str) -> str:
        """
        Validate and correct response content
        """
        if not response:
            return response
        
        validated = response
        
        validated = AutoValidator._validate_duration(validated)
        validated = AutoValidator._validate_price(validated)
        validated = AutoValidator._validate_locations(validated)
        validated = AutoValidator._check_unrealistic_info(validated)
        
        if validated != response:
            validated = AutoValidator._add_validation_note(validated)
        
        return validated
    
    @staticmethod
    def _validate_duration(text: str) -> str:
        """Validate and correct duration information"""
        for pattern in AutoValidator.VALIDATION_RULES['duration']['patterns']:
            matches = list(re.finditer(pattern, text))
            for match in matches:
                try:
                    if match.lastindex == 2:
                        days = int(match.group(1))
                        nights = int(match.group(2))
                        
                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']
                        
                        valid_combos = constraints['valid_day_night_combos']
                        is_valid_combo = any(d == d2 and n == n2 for d2, n2 in valid_combos)
                        
                        if days > constraints['max_days'] or nights > constraints['max_nights']:
                            replacement = random.choice(constraints['common_durations'])
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"‚ö†Ô∏è Corrected unrealistic duration: {days} ng√†y {nights} ƒë√™m ‚Üí {replacement}")
                        
                        elif not is_valid_combo:
                            valid_days = min(days, constraints['max_days'])
                            valid_nights = min(nights, constraints['max_nights'])
                            if abs(valid_days - valid_nights) > 1:
                                valid_nights = valid_days
                            
                            replacement = f"{valid_days} ng√†y {valid_nights} ƒë√™m"
                            text = text.replace(match.group(0), replacement)
                            logger.info(f"üîÑ Fixed duration combo: {replacement}")
                    
                    elif match.lastindex == 1:
                        num = int(match.group(1))
                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']
                        
                        if num > constraints['max_days']:
                            replacement = f"{constraints['max_days']} ng√†y"
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"‚ö†Ô∏è Capped long duration: {num} ‚Üí {constraints['max_days']}")
                
                except (ValueError, IndexError):
                    continue
        
        return text
    
    @staticmethod
    def _validate_price(text: str) -> str:
        """Validate and correct price information"""
        for pattern in AutoValidator.VALIDATION_RULES['price']['patterns']:
            matches = list(re.finditer(pattern, text, re.IGNORECASE))
            for match in matches:
                try:
                    amount_str = match.group(1).replace(',', '').replace('.', '')
                    if not amount_str.isdigit():
                        continue
                    
                    amount = int(amount_str)
                    
                    unit = match.group(2).lower() if match.lastindex >= 2 else ''
                    
                    if unit in ['tri·ªáu', 'tr']:
                        amount = amount * 1000000
                    elif unit in ['k', 'ngh√¨n']:
                        amount = amount * 1000
                    
                    constraints = AutoValidator.VALIDATION_RULES['price']['constraints']
                    
                    if amount < constraints['min_tour_price']:
                        replacement = "gi√° h·ª£p l√Ω"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"‚ö†Ô∏è Corrected too-low price: {amount} ‚Üí {replacement}")
                    
                    elif amount > constraints['max_tour_price']:
                        replacement = "gi√° cao c·∫•p"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"‚ö†Ô∏è Corrected too-high price: {amount} ‚Üí {replacement}")
                
                except (ValueError, IndexError, AttributeError):
                    continue
        
        return text
    
    @staticmethod
    def _validate_locations(text: str) -> str:
        """Validate location names"""
        wrong_locations = {
            'h√† n·ªôi': 'Hu·∫ø',
            'h·ªì ch√≠ minh': 'Qu·∫£ng Tr·ªã',
            'ƒë√† n·∫µng': 'B·∫°ch M√£',
            'nha trang': 'Tr∆∞·ªùng S∆°n',
        }
        
        for wrong, correct in wrong_locations.items():
            if wrong in text.lower():
                text = text.replace(wrong, correct)
                text = text.replace(wrong.capitalize(), correct)
                logger.info(f"üîÑ Corrected location: {wrong} ‚Üí {correct}")
        
        return text
    
    @staticmethod
    def _check_unrealistic_info(text: str) -> str:
        """Check for other unrealistic information"""
        unrealistic_patterns = [
            (r'\d+\s*gi·ªù\s*bay', "th·ªùi gian di chuy·ªÉn"),
            (r'\d+\s*sao', "ch·∫•t l∆∞·ª£ng d·ªãch v·ª•"),
            (r'\d+\s*t·∫ßng', "ch·ªó ·ªü"),
            (r'\d+\s*m\s*cao', "ƒë·ªãa h√¨nh"),
        ]
        
        for pattern, replacement in unrealistic_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
                logger.info(f"üîÑ Replaced unrealistic info with: {replacement}")
        
        return text
    
    @staticmethod
    def _add_validation_note(text: str) -> str:
        """Add note about information validation"""
        note = "\n\n*Th√¥ng tin ƒë∆∞·ª£c cung c·∫•p d·ª±a tr√™n d·ªØ li·ªáu hi·ªán c√≥. " \
               "Vui l√≤ng li√™n h·ªá hotline 0332510486 ƒë·ªÉ x√°c nh·∫≠n chi ti·∫øt ch√≠nh x√°c nh·∫•t.*"
        
        if note not in text:
            text += note
        
        return text

# =========== UPGRADE 10: TEMPLATE SYSTEM (DATACLASS COMPATIBLE) ===========
class TemplateSystem:
    """
    UPGRADE 10: Beautiful, structured responses for different question types
    """
    
    TEMPLATES = {
        'tour_list': {
            'header': "‚ú® **DANH S√ÅCH TOUR RUBY WINGS** ‚ú®\n\n",
            'item': "**{index}. {tour_name}** {emoji}\n"
                   "   üìÖ {duration}\n"
                   "   üìç {location}\n"
                   "   üí∞ {price}\n"
                   "   {summary}\n",
            'footer': "\nüìû **Li√™n h·ªá ƒë·∫∑t tour:** 0332510486\n"
                     "üìç **Ruby Wings Travel** - H√†nh tr√¨nh tr·∫£i nghi·ªám ƒë·∫∑c s·∫Øc\n"
                     "üí° *H·ªèi chi ti·∫øt v·ªÅ b·∫•t k·ª≥ tour n√†o b·∫±ng c√°ch nh·∫≠p t√™n tour*",
            'emoji_map': {
                '1 ng√†y': 'üåÖ',
                '2 ng√†y': 'üåÑ',
                '3 ng√†y': 'üèîÔ∏è',
                'default': '‚ú®'
            }
        },
        
        'tour_detail': {
            'header': "üéØ **{tour_name}**\n\n",
            'sections': {
                'overview': "üìã **TH√îNG TIN CH√çNH:**\n"
                          "   ‚è±Ô∏è Th·ªùi gian: {duration}\n"
                          "   üìç ƒê·ªãa ƒëi·ªÉm: {location}\n"
                          "   üí∞ Gi√° tour: {price}\n\n",
                'description': "üìñ **M√î T·∫¢ TOUR:**\n{summary}\n\n",
                'includes': "üé™ **L·ªäCH TR√åNH & D·ªäCH V·ª§:**\n{includes}\n\n",
                'accommodation': "üè® **CH·ªñ ·ªû:**\n{accommodation}\n\n",
                'meals': "üçΩÔ∏è **ƒÇN U·ªêNG:**\n{meals}\n\n",
                'transport': "üöó **DI CHUY·ªÇN:**\n{transport}\n\n",
                'notes': "üìù **GHI CH√ö:**\n{notes}\n\n",
            },
            'footer': "üìû **ƒê·∫∂T TOUR & T∆Ø V·∫æN:** 0332510486\n"
                     "‚≠ê *Tour ph√π h·ª£p cho: {suitable_for}*",
            'default_values': {
                'duration': 'ƒêang c·∫≠p nh·∫≠t',
                'location': 'ƒêang c·∫≠p nh·∫≠t',
                'price': 'Li√™n h·ªá ƒë·ªÉ bi·∫øt gi√°',
                'summary': 'H√†nh tr√¨nh tr·∫£i nghi·ªám ƒë·∫∑c s·∫Øc c·ªßa Ruby Wings',
                'includes': 'Chi ti·∫øt l·ªãch tr√¨nh li√™n h·ªá t∆∞ v·∫•n',
                'accommodation': 'ƒêang c·∫≠p nh·∫≠t',
                'meals': 'ƒêang c·∫≠p nh·∫≠t',
                'transport': 'ƒêang c·∫≠p nh·∫≠t',
                'notes': 'Vui l√≤ng li√™n h·ªá ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt',
                'suitable_for': 'm·ªçi ƒë·ªëi t∆∞·ª£ng',
            }
        },
        
        'comparison': {
            'header': "üìä **SO S√ÅNH TOUR**\n\n",
            'table_header': "| Ti√™u ch√≠ | {tour1} | {tour2} |\n|----------|----------|----------|\n",
            'table_row': "| {criterion} | {value1} | {value2} |\n",
            'recommendation': "\nüí° **G·ª¢I √ù L·ª∞A CH·ªåN:**\n{recommendations}\n",
            'footer': "\nüìû **T∆∞ v·∫•n chi ti·∫øt:** 0332510486\n"
                     "ü§î *C·∫ßn so s√°nh th√™m ti√™u ch√≠ n√†o?*",
        },
        
        'recommendation': {
            'header': "üéØ **ƒê·ªÄ XU·∫§T TOUR PH√ô H·ª¢P**\n\n",
            'top_recommendation': "üèÜ **PH√ô H·ª¢P NH·∫§T ({score}%)**\n"
                                "**{tour_name}**\n"
                                "   ‚úÖ {reasons}\n"
                                "   üìÖ {duration} | üìç {location} | üí∞ {price}\n\n",
            'other_recommendations': "üìã **L·ª∞A CH·ªåN KH√ÅC:**\n",
            'other_item': "   ‚Ä¢ **{tour_name}** ({score}%)\n"
                         "     üìÖ {duration} | üìç {location}\n",
            'criteria': "\nüîç **TI√äU CH√ç ƒê·ªÄ XU·∫§T:**\n{criteria}\n",
            'footer': "\nüìû **Li√™n h·ªá t∆∞ v·∫•n c√° nh√¢n h√≥a:** 0332510486\n"
                     "üí¨ *Cho t√¥i bi·∫øt th√™m s·ªü th√≠ch c·ªßa b·∫°n ƒë·ªÉ ƒë·ªÅ xu·∫•t ch√≠nh x√°c h∆°n*",
        },
        
        'information': {
            'header': "‚ÑπÔ∏è **TH√îNG TIN:**\n\n",
            'content': "{content}\n",
            'sources': "\nüìö *Ngu·ªìn th√¥ng tin t·ª´ d·ªØ li·ªáu Ruby Wings*",
            'footer': "\nüìû **Hotline h·ªó tr·ª£:** 0332510486",
        },
        
        'greeting': {
            'template': "üëã **Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI c·ªßa Ruby Wings**\n\n"
                       "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\n"
                       "‚Ä¢ T√¨m hi·ªÉu v·ªÅ c√°c tour tr·∫£i nghi·ªám\n"
                       "‚Ä¢ So s√°nh c√°c h√†nh tr√¨nh\n"
                       "‚Ä¢ ƒê·ªÅ xu·∫•t tour ph√π h·ª£p v·ªõi b·∫°n\n"
                       "‚Ä¢ Cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ tour\n\n"
                       "üí° **V√≠ d·ª• b·∫°n c√≥ th·ªÉ h·ªèi:**\n"
                       "- 'C√≥ nh·ªØng tour n√†o?'\n"
                       "- 'Tour B·∫°ch M√£ gi√° bao nhi√™u?'\n"
                       "- 'Tour n√†o ph√π h·ª£p cho gia ƒë√¨nh?'\n\n"
                       "H√£y cho t√¥i bi·∫øt b·∫°n c·∫ßn g√¨ nh√©! üòä",
        },
        
        'farewell': {
            'template': "üôè **C·∫£m ∆°n b·∫°n ƒë√£ tr√≤ chuy·ªán c√πng Ruby Wings!**\n\n"
                       "Ch√∫c b·∫°n m·ªôt ng√†y tr√†n ƒë·∫ßy nƒÉng l∆∞·ª£ng v√† b√¨nh an.\n"
                       "Hy v·ªçng s·ªõm ƒë∆∞·ª£c ƒë·ªìng h√†nh c√πng b·∫°n trong h√†nh tr√¨nh tr·∫£i nghi·ªám s·∫Øp t·ªõi!\n\n"
                       "üìû **Li√™n h·ªá ƒë·∫∑t tour:** 0332510486\n"
                       "üåê **Website:** rubywings.vn\n\n"
                       "H·∫πn g·∫∑p l·∫°i! ‚ú®",
        },
    }
    
    @staticmethod
    def render(template_name: str, **kwargs) -> str:
        """Render template with provided variables"""
        template_data = TemplateSystem.TEMPLATES.get(template_name)
        if not template_data:
            return kwargs.get('content', '')
        
        if template_name in ['greeting', 'farewell']:
            return template_data['template']
        
        response_parts = []
        
        if 'header' in template_data:
            header = template_data['header']
            for key, value in kwargs.items():
                header = header.replace(f'{{{key}}}', str(value))
            response_parts.append(header)
        
        if template_name == 'tour_list':
            response_parts.append(TemplateSystem._render_tour_list(template_data, kwargs))
        
        elif template_name == 'tour_detail':
            response_parts.append(TemplateSystem._render_tour_detail(template_data, kwargs))
        
        elif template_name == 'comparison':
            response_parts.append(TemplateSystem._render_comparison(template_data, kwargs))
        
        elif template_name == 'recommendation':
            response_parts.append(TemplateSystem._render_recommendation(template_data, kwargs))
        
        elif template_name == 'information':
            response_parts.append(TemplateSystem._render_information(template_data, kwargs))
        
        if 'footer' in template_data:
            footer = template_data['footer']
            for key, value in kwargs.items():
                footer = footer.replace(f'{{{key}}}', str(value))
            response_parts.append(footer)
        
        return '\n'.join(response_parts)
    
    @staticmethod
    def _render_tour_list(template_data: Dict, kwargs: Dict) -> str:
        """Render tour list template"""
        tours = kwargs.get('tours', [])
        if not tours:
            return "Hi·ªán ch∆∞a c√≥ th√¥ng tin tour."
        
        items = []
        for i, tour in enumerate(tours[:10], 1):
            duration = tour.duration or ''
            emoji = template_data['emoji_map'].get('default')
            for dur_pattern, dur_emoji in template_data['emoji_map'].items():
                if dur_pattern in duration.lower():
                    emoji = dur_emoji
                    break
            
            item_template = template_data['item']
            item = item_template.format(
                index=i,
                tour_name=tour.name or f'Tour #{i}',
                emoji=emoji or '‚ú®',
                duration=duration or 'ƒêang c·∫≠p nh·∫≠t',
                location=tour.location or 'ƒêang c·∫≠p nh·∫≠t',
                price=tour.price or 'Li√™n h·ªá ƒë·ªÉ bi·∫øt gi√°',
                summary=(tour.summary or 'Tour tr·∫£i nghi·ªám ƒë·∫∑c s·∫Øc')[:100] + '...'
            )
            items.append(item)
        
        return '\n'.join(items)
    
    @staticmethod
    def _render_tour_detail(template_data: Dict, kwargs: Dict) -> str:
        """Render tour detail template"""
        sections = []
        
        for section_name, section_template in template_data['sections'].items():
            value = kwargs.get(section_name, template_data['default_values'].get(section_name, ''))
            
            if value and value != template_data['default_values'].get(section_name):
                if isinstance(value, list):
                    if section_name == 'includes':
                        value = '\n'.join([f'   ‚Ä¢ {item}' for item in value[:5]])
                    else:
                        value = ', '.join(value[:3])
                
                section = section_template.format(**{section_name: value})
                sections.append(section)
        
        return '\n'.join(sections)
    
    @staticmethod
    def _render_comparison(template_data: Dict, kwargs: Dict) -> str:
        """Render comparison template"""
        comparison_table = []
        
        tour1_name = kwargs.get('tour1_name', 'Tour 1')[:20]
        tour2_name = kwargs.get('tour2_name', 'Tour 2')[:20]
        table_header = template_data['table_header'].format(tour1=tour1_name, tour2=tour2_name)
        comparison_table.append(table_header)
        
        criteria = kwargs.get('criteria', [])
        for criterion in criteria[:8]:
            row = template_data['table_row'].format(
                criterion=criterion.get('name', ''),
                value1=criterion.get('value1', 'N/A')[:20],
                value2=criterion.get('value2', 'N/A')[:20]
            )
            comparison_table.append(row)
        
        return '\n'.join(comparison_table)
    
    @staticmethod
    def _render_recommendation(template_data: Dict, kwargs: Dict) -> str:
        """Render recommendation template"""
        recommendation_text = []
        
        top_tour = kwargs.get('top_tour')
        if top_tour:
            top_text = template_data['top_recommendation'].format(
                score=int(top_tour.get('score', 0) * 100),
                tour_name=top_tour.get('name', ''),
                reasons=', '.join(top_tour.get('reasons', ['ph√π h·ª£p'])[:3]),
                duration=top_tour.get('duration', ''),
                location=top_tour.get('location', ''),
                price=top_tour.get('price', 'Li√™n h·ªá ƒë·ªÉ bi·∫øt gi√°')
            )
            recommendation_text.append(top_text)
        
        other_tours = kwargs.get('other_tours', [])
        if other_tours:
            recommendation_text.append(template_data['other_recommendations'])
            
            for tour in other_tours[:2]:
                other_item = template_data['other_item'].format(
                    tour_name=tour.get('name', ''),
                    score=int(tour.get('score', 0) * 100),
                    duration=tour.get('duration', ''),
                    location=tour.get('location', '')
                )
                recommendation_text.append(other_item)
        
        return '\n'.join(recommendation_text)
    
    @staticmethod
    def _render_information(template_data: Dict, kwargs: Dict) -> str:
        """Render information template"""
        content = kwargs.get('content', '')
        if not content:
            return ""
        
        info_text = template_data['content'].format(content=content)
        
        if kwargs.get('has_sources'):
            info_text += template_data['sources']
        
        return info_text

# =========== TOUR DATABASE BUILDER (USING Tour DATACLASS) ===========
def load_knowledge(path: str = KNOWLEDGE_PATH):
    """Load knowledge base from JSON file"""
    global KNOW, FLAT_TEXTS, MAPPING
    
    try:
        with open(path, "r", encoding="utf-8") as f:
            KNOW = json.load(f)
        logger.info(f"‚úÖ Loaded knowledge from {path}")
    except Exception as e:
        logger.error(f"‚ùå Could not open {path}: {e}")
        KNOW = {}
    
    FLAT_TEXTS = []
    MAPPING = []
    
    def scan(obj, prefix="root"):
        if isinstance(obj, dict):
            for k, v in obj.items():
                scan(v, f"{prefix}.{k}")
        elif isinstance(obj, list):
            for i, v in enumerate(obj):
                scan(v, f"{prefix}[{i}]")
        elif isinstance(obj, str):
            t = obj.strip()
            if t:
                FLAT_TEXTS.append(t)
                MAPPING.append({"path": prefix, "text": t})
        else:
            try:
                s = str(obj).strip()
                if s:
                    FLAT_TEXTS.append(s)
                    MAPPING.append({"path": prefix, "text": s})
            except Exception:
                pass
    
    scan(KNOW)
    logger.info(f"üìä Knowledge scanned: {len(FLAT_TEXTS)} passages")

def index_tour_names():
    """Build tour name to index mapping"""
    global TOUR_NAME_TO_INDEX
    TOUR_NAME_TO_INDEX = {}
    
    for m in MAPPING:
        path = m.get("path", "")
        if path.endswith(".tour_name"):
            txt = m.get("text", "") or ""
            norm = normalize_text_simple(txt)
            if not norm:
                continue
            
            match = re.search(r"\[(\d+)\]", path)
            if match:
                idx = int(match.group(1))
                prev = TOUR_NAME_TO_INDEX.get(norm)
                if prev is None:
                    TOUR_NAME_TO_INDEX[norm] = idx
                else:
                    existing_txt = MAPPING[next(
                        i for i, m2 in enumerate(MAPPING) 
                        if re.search(rf"\[{prev}\]", m2.get('path','')) and ".tour_name" in m2.get('path','')
                    )].get("text","")
                    if len(txt) > len(existing_txt):
                        TOUR_NAME_TO_INDEX[norm] = idx
    
    logger.info(f"üìù Indexed {len(TOUR_NAME_TO_INDEX)} tour names")

def build_tours_db():
    """Build structured tour database from MAPPING using Tour dataclass"""
    global TOURS_DB, TOUR_TAGS
    
    TOURS_DB.clear()
    TOUR_TAGS.clear()
    
    # First pass: collect all fields for each tour
    for m in MAPPING:
        path = m.get("path", "")
        text = m.get("text", "")
        
        if not path or not text:
            continue
        
        tour_match = re.search(r'tours\[(\d+)\]', path)
        if not tour_match:
            continue
        
        tour_idx = int(tour_match.group(1))
        
        field_match = re.search(r'tours\[\d+\]\.(\w+)(?:\[\d+\])?', path)
        if not field_match:
            continue
        
        field_name = field_match.group(1)
        
        # Initialize tour entry
        if tour_idx not in TOURS_DB:
            TOURS_DB[tour_idx] = Tour(index=tour_idx)
        
        # Update field in Tour object
        tour_obj = TOURS_DB[tour_idx]
        if field_name == 'tour_name':
            tour_obj.name = text
        elif field_name == 'duration':
            tour_obj.duration = text
        elif field_name == 'location':
            tour_obj.location = text
        elif field_name == 'price':
            tour_obj.price = text
        elif field_name == 'summary':
            tour_obj.summary = text
        elif field_name == 'includes':
            if isinstance(tour_obj.includes, list):
                tour_obj.includes.append(text)
            else:
                tour_obj.includes = [text]
        elif field_name == 'accommodation':
            tour_obj.accommodation = text
        elif field_name == 'meals':
            tour_obj.meals = text
        elif field_name == 'transport':
            tour_obj.transport = text
        elif field_name == 'notes':
            tour_obj.notes = text
        elif field_name == 'style':
            tour_obj.style = text
    
    # Second pass: generate tags and metadata
    for tour_idx, tour_obj in TOURS_DB.items():
        tags = []
        
        # Location tags
        if tour_obj.location:
            locations = [loc.strip() for loc in tour_obj.location.split(",") if loc.strip()]
            tags.extend([f"location:{loc}" for loc in locations[:2]])
        
        # Duration tags
        if tour_obj.duration:
            duration_lower = tour_obj.duration.lower()
            if "1 ng√†y" in duration_lower:
                tags.append("duration:1day")
            elif "2 ng√†y" in duration_lower:
                tags.append("duration:2day")
            elif "3 ng√†y" in duration_lower:
                tags.append("duration:3day")
            else:
                day_match = re.search(r'(\d+)\s*ng√†y', duration_lower)
                if day_match:
                    days = int(day_match.group(1))
                    tags.append(f"duration:{days}day")
        
        # Price tags
        if tour_obj.price:
            price_nums = re.findall(r'[\d,\.]+', tour_obj.price)
            if price_nums:
                try:
                    clean_nums = []
                    for p in price_nums[:2]:
                        p_clean = p.replace(',', '').replace('.', '')
                        if p_clean.isdigit():
                            clean_nums.append(int(p_clean))
                    
                    if clean_nums:
                        avg_price = sum(clean_nums) / len(clean_nums)
                        if avg_price < 1000000:
                            tags.append("price:budget")
                        elif avg_price < 2000000:
                            tags.append("price:midrange")
                        else:
                            tags.append("price:premium")
                except:
                    pass
        
        # Style/theme tags
        text_to_check = (tour_obj.style + " " + (tour_obj.summary or '')).lower()
        
        theme_keywords = {
            'meditation': ['thi·ªÅn', 'ch√°nh ni·ªám', 't√¢m linh'],
            'history': ['l·ªãch s·ª≠', 'di t√≠ch', 'chi·∫øn tranh', 'tri √¢n'],
            'nature': ['thi√™n nhi√™n', 'r·ª´ng', 'n√∫i', 'c√¢y'],
            'culture': ['vƒÉn h√≥a', 'c·ªông ƒë·ªìng', 'd√¢n t·ªôc'],
            'wellness': ['kh√≠ c√¥ng', 's·ª©c kh·ªèe', 'ch·ªØa l√†nh'],
            'adventure': ['phi√™u l∆∞u', 'm·∫°o hi·ªÉm', 'kh√°m ph√°'],
        }
        
        for theme, keywords in theme_keywords.items():
            if any(keyword in text_to_check for keyword in keywords):
                tags.append(f"theme:{theme}")
        
        # Destination tags from tour name
        if tour_obj.name:
            name_lower = tour_obj.name.lower()
            if "b·∫°ch m√£" in name_lower:
                tags.append("destination:bachma")
            if "tr∆∞·ªùng s∆°n" in name_lower:
                tags.append("destination:truongson")
            if "qu·∫£ng tr·ªã" in name_lower:
                tags.append("destination:quangtri")
            if "hu·∫ø" in name_lower:
                tags.append("destination:hue")
        
        # Update Tour object tags
        tour_obj.tags = list(set(tags))
        TOUR_TAGS[tour_idx] = tour_obj.tags
        
        # Calculate completeness score
        completeness = 0
        important_fields = ['name', 'duration', 'location', 'price', 'summary']
        for field in important_fields:
            if getattr(tour_obj, field, None):
                completeness += 1
        
        tour_obj.completeness_score = completeness / len(important_fields)
    
    logger.info(f"‚úÖ Built tours database: {len(TOURS_DB)} tours with tags")

def get_passages_by_field(field_name: str, limit: int = 50, 
                         tour_indices: Optional[List[int]] = None) -> List[Tuple[float, Dict]]:
    """
    Get passages for a specific field
    """
    exact_matches = []
    global_matches = []
    
    for m in MAPPING:
        path = m.get("path", "")
        if path.endswith(f".{field_name}") or f".{field_name}" in path:
            is_exact_match = False
            if tour_indices:
                for ti in tour_indices:
                    if f"[{ti}]" in path:
                        is_exact_match = True
                        break
            
            if is_exact_match:
                exact_matches.append((2.0, m))
            elif not tour_indices:
                global_matches.append((1.0, m))
    
    all_results = exact_matches + global_matches
    all_results.sort(key=lambda x: x[0], reverse=True)
    return all_results[:limit]

# =========== CACHE SYSTEM (DATACLASS COMPATIBLE) ===========
class CacheSystem:
    """Simple caching system for responses"""
    
    @staticmethod
    def get_cache_key(query: str, context_hash: str = "") -> str:
        """Generate cache key"""
        key_parts = [query]
        if context_hash:
            key_parts.append(context_hash)
        return hashlib.md5("|".join(key_parts).encode()).hexdigest()
    
    @staticmethod
    def get(key: str, ttl_seconds: int = 300):
        """Get item from cache"""
        with _cache_lock:
            if key in _response_cache:
                cache_entry = _response_cache[key]
                if not cache_entry.is_expired():
                    logger.info(f"üíæ Cache hit for key: {key[:20]}...")
                    return cache_entry.value
                else:
                    del _response_cache[key]
            return None
    
    @staticmethod
    def set(key: str, value: Any, expiry: int = None):
        """
        Set item in cache with enhanced features
        - Supports custom expiry (TTL in seconds)
        - Intelligent cache eviction
        - Thread-safe with lock
        """
        with _cache_lock:
            try:
                # Get TTL from parameter or config
                ttl_seconds = expiry or UpgradeFlags.get_all_flags().get("CACHE_TTL_SECONDS", 300)
                
                # Create cache entry
                cache_entry = CacheEntry(
                    key=key,
                    value=value,
                    created_at=datetime.utcnow(),
                    ttl_seconds=ttl_seconds,
                    access_count=0,  # Track how many times accessed
                    last_accessed=datetime.utcnow()
                )
                
                # Store in cache
                _response_cache[key] = cache_entry
                
                # Intelligent cache cleaning
                CacheSystem._clean_cache()
                
                logger.debug(f"üíæ Cached response for key: {key[:50]}... (TTL: {ttl_seconds}s)")
                
            except Exception as e:
                logger.error(f"‚ùå Cache set error: {e}")
                # Don't crash if cache fails


    @staticmethod
    def _clean_cache():
        """
        Intelligent cache cleaning with multiple strategies
        """
        try:
            now = datetime.utcnow()
            cache_size = len(_response_cache)
            
            # Strategy 1: Remove expired entries
            expired_keys = []
            for key, entry in _response_cache.items():
                # Check if entry has expired
                if hasattr(entry, 'is_expired'):
                    if entry.is_expired(now):
                        expired_keys.append(key)
                else:
                    # Fallback: manual expiration check
                    age = (now - entry.created_at).total_seconds()
                    if age > (entry.ttl_seconds if hasattr(entry, 'ttl_seconds') else 300):
                        expired_keys.append(key)
            
            # Remove expired entries
            for key in expired_keys:
                del _response_cache[key]
            
            if expired_keys:
                logger.debug(f"üßπ Removed {len(expired_keys)} expired cache entries")
            
            # Strategy 2: If still over limit, remove least recently used
            current_size = len(_response_cache)
            if current_size > 1000:
                logger.warning(f"‚ö†Ô∏è Cache size ({current_size}) exceeds limit, performing LRU cleanup")
                
                # Sort by last accessed time (oldest first)
                lru_items = sorted(_response_cache.items(), 
                                key=lambda x: x[1].last_accessed if hasattr(x[1], 'last_accessed') 
                                else x[1].created_at)
                
                # Remove oldest 20% or at least 200 items
                remove_count = max(200, int(current_size * 0.2))
                remove_keys = [k for k, _ in lru_items[:remove_count]]
                
                for key in remove_keys:
                    if key in _response_cache:
                        del _response_cache[key]
                
                logger.info(f"üßπ LRU cleanup removed {len(remove_keys)} items")
            
            # Strategy 3: Clean up very old entries regardless of size
            if _response_cache:
                very_old_threshold = 86400  # 24 hours in seconds
                very_old_keys = []
                
                for key, entry in _response_cache.items():
                    age = (now - entry.created_at).total_seconds()
                    if age > very_old_threshold:
                        very_old_keys.append(key)
                
                if very_old_keys:
                    for key in very_old_keys:
                        del _response_cache[key]
                    logger.debug(f"üßπ Removed {len(very_old_keys)} very old cache entries")
            
            # Final size check
            final_size = len(_response_cache)
            if final_size > 0:
                logger.debug(f"üìä Cache stats: {final_size} items, " 
                            f"approx. {final_size * 0.5:.1f}KB memory")
                
        except Exception as e:
            logger.error(f"‚ùå Cache cleanup error: {e}")


    @staticmethod
    def get(key: str, update_access: bool = True) -> Optional[Any]:
        """
        Get item from cache with enhanced features
        - Updates access count and timestamp
        - Auto-removes expired items
        """
        with _cache_lock:
            try:
                if key not in _response_cache:
                    return None
                
                entry = _response_cache[key]
                now = datetime.utcnow()
                
                # Check expiration
                if hasattr(entry, 'is_expired'):
                    if entry.is_expired(now):
                        del _response_cache[key]
                        logger.debug(f"üóëÔ∏è  Auto-removed expired cache: {key[:50]}...")
                        return None
                else:
                    # Manual expiration check
                    age = (now - entry.created_at).total_seconds()
                    ttl = entry.ttl_seconds if hasattr(entry, 'ttl_seconds') else 300
                    if age > ttl:
                        del _response_cache[key]
                        return None
                
                # Update access metadata if requested
                if update_access:
                    if hasattr(entry, 'access_count'):
                        entry.access_count += 1
                    if hasattr(entry, 'last_accessed'):
                        entry.last_accessed = now
                
                logger.debug(f"üíæ Cache hit for key: {key[:50]}...")
                return entry.value
                
            except Exception as e:
                logger.error(f"‚ùå Cache get error: {e}")
                return None


    @staticmethod
    def delete(key: str) -> bool:
        """Delete specific cache entry"""
        with _cache_lock:
            try:
                if key in _response_cache:
                    del _response_cache[key]
                    logger.debug(f"üóëÔ∏è  Deleted cache: {key[:50]}...")
                    return True
                return False
            except Exception as e:
                logger.error(f"‚ùå Cache delete error: {e}")
                return False


    @staticmethod
    def clear() -> int:
        """Clear all cache, return number of items cleared"""
        with _cache_lock:
            try:
                count = len(_response_cache)
                _response_cache.clear()
                logger.info(f"üßπ Cleared all cache ({count} items)")
                return count
            except Exception as e:
                logger.error(f"‚ùå Cache clear error: {e}")
                return 0


    @staticmethod
    def stats() -> Dict[str, Any]:
        """Get cache statistics"""
        with _cache_lock:
            try:
                now = datetime.utcnow()
                total_size = len(_response_cache)
                
                # Calculate age distribution
                age_distribution = {
                    "under_1min": 0,
                    "1min_10min": 0,
                    "10min_1hour": 0,
                    "1hour_24hour": 0,
                    "over_24hour": 0
                }
                
                # Calculate expiration status
                expired_count = 0
                will_expire_soon = 0  # Within 60 seconds
                
                for entry in _response_cache.values():
                    # Age distribution
                    age = (now - entry.created_at).total_seconds()
                    if age < 60:
                        age_distribution["under_1min"] += 1
                    elif age < 600:
                        age_distribution["1min_10min"] += 1
                    elif age < 3600:
                        age_distribution["10min_1hour"] += 1
                    elif age < 86400:
                        age_distribution["1hour_24hour"] += 1
                    else:
                        age_distribution["over_24hour"] += 1
                    
                    # Expiration check
                    ttl = entry.ttl_seconds if hasattr(entry, 'ttl_seconds') else 300
                    remaining = ttl - age
                    if remaining <= 0:
                        expired_count += 1
                    elif remaining < 60:
                        will_expire_soon += 1
                
                return {
                    "total_items": total_size,
                    "age_distribution": age_distribution,
                    "expired_items": expired_count,
                    "expiring_soon": will_expire_soon,
                    "memory_estimate_kb": total_size * 0.5  # Rough estimate
                }
                
            except Exception as e:
                logger.error(f"‚ùå Cache stats error: {e}")
                return {"error": str(e)}


    @staticmethod
    def get_cache_key(user_message: str, context_hash: str = None) -> str:
        """
        Generate cache key with enhanced hashing
        """
        try:
            # Normalize the user message
            normalized = user_message.lower().strip()
            
            # Remove extra whitespace
            normalized = ' '.join(normalized.split())
            
            # Create base key
            base_content = normalized
            
            # Add context hash if provided
            if context_hash:
                base_content += f"|{context_hash}"
            
            # Create hash (shorter for efficiency)
            import hashlib
            cache_key = hashlib.md5(base_content.encode('utf-8')).hexdigest()[:16]
            
            # Add prefix for identification
            cache_key = f"chat_{cache_key}"
            
            return cache_key
            
        except Exception as e:
            logger.error(f"‚ùå Cache key generation error: {e}")
            # Fallback: use simple hash
            import hashlib
            return f"chat_fallback_{hashlib.md5(user_message.encode()).hexdigest()[:8]}"


    # C·∫≠p nh·∫≠t class CacheEntry ƒë·ªÉ h·ªó tr·ª£ c√°c t√≠nh nƒÉng m·ªõi
    @dataclass
    class CacheEntry:
        """
        Enhanced cache entry with metadata for intelligent cache management
        """
        key: str
        value: Any
        created_at: datetime
        ttl_seconds: int = 300
        access_count: int = 0
        last_accessed: datetime = None
        
        def __post_init__(self):
            """Initialize last_accessed if not provided"""
            if self.last_accessed is None:
                self.last_accessed = self.created_at
        
        def is_expired(self, current_time: datetime = None) -> bool:
            """Check if cache entry has expired"""
            if current_time is None:
                current_time = datetime.utcnow()
            
            age = (current_time - self.created_at).total_seconds()
            return age > self.ttl_seconds
        
        def age_seconds(self) -> float:
            """Get age of cache entry in seconds"""
            return (datetime.utcnow() - self.created_at).total_seconds()
        
        def ttl_remaining(self) -> float:
            """Get remaining TTL in seconds"""
            age = self.age_seconds()
            remaining = self.ttl_seconds - age
            return max(0, remaining)

# =========== EMBEDDING FUNCTIONS (MEMORY OPTIMIZED) ===========
@lru_cache(maxsize=128 if IS_LOW_RAM else 1000)
def embed_text(text: str) -> Tuple[List[float], int]:
    """Embed text using OpenAI or fallback (with memory optimization)"""
    if not text:
        return [], 0
    
    text = text[:2000]
    
    if client:
        try:
            response = client.embeddings.create(
                model=EMBEDDING_MODEL,
                input=text
            )
            if response.data:
                embedding = response.data[0].embedding
                return embedding, len(embedding)
        except Exception as e:
            logger.error(f"OpenAI embedding error: {e}")
    
    # Fallback: deterministic hash-based embedding
    h = hash(text) % (10 ** 12)
    dim = 1536
    embedding = [(float((h >> (i % 32)) & 0xFF) + (i % 7)) / 255.0 
                 for i in range(dim)]
    
    return embedding, dim

def query_index(
    query: str,
    top_k: int = 5,
    min_score: float = 0.78
):
    """
    Semantic search d√πng FAISS ‚Äì CH·∫∂N B·ªäA TUY·ªÜT ƒê·ªêI
    Tr·∫£ v·ªÅ [] n·∫øu KH√îNG c√≥ d·ªØ li·ªáu ƒë·ªß tin c·∫≠y
    """

    # ========== SAFETY CHECK ==========
    if not query or not query.strip():
        return []

    if not INDEX or not MAPPING: 
        logger.error("‚ùå FAISS index ho·∫∑c mapping ch∆∞a ƒë∆∞·ª£c load")
        return []

    # ========== EMBEDDING QUERY ==========
    try:
        embedding = embedding_client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=query
        ).data[0].embedding
    except Exception as e:
        logger.error(f"‚ùå Embedding error: {e}")
        return []

    import numpy as np

    query_vector = np.array([embedding], dtype="float32")

    # ========== FAISS SEARCH ==========
    try:
        distances, indices = FAISS_INDEX.search(query_vector, top_k)
    except Exception as e:
        logger.error(f"‚ùå FAISS search error: {e}")
        return []

    results = []

    for score, idx in zip(distances[0], indices[0]):
        if idx == -1:
            continue

        # FAISS cosine similarity (index ƒë√£ normalize)
        similarity = float(score)

        # üö® NG∆Ø·ª†NG CH·∫∂N B·ªäA
        if similarity < min_score:
            continue

        mapping = FAISS_MAPPING.get(str(idx))
        if not mapping:
            continue

        text = mapping.get("text", "").strip()
        if not text:
            continue

        results.append((similarity, text))

    # ========== SORT & RETURN ==========
    results.sort(key=lambda x: x[0], reverse=True)

    if not results:
        logger.info(
            f"‚ö†Ô∏è No semantic match above threshold "
            f"(min_score={min_score}) for query: {query}"
        )

    return results


class NumpyIndex:
    """Simple numpy-based index with safe numpy handling"""

    def __init__(self, mat=None):
        if NUMPY_AVAILABLE:
            if mat is None:
                self.mat = np.empty((0, 0), dtype="float32")
            else:
                # Force numpy float32 2D
                self.mat = np.asarray(mat, dtype="float32")
                if self.mat.ndim == 1:
                    self.mat = self.mat.reshape(1, -1)
        else:
            self.mat = mat if mat is not None else []

        # SAFE dimension detection (no numpy truth check)
        if NUMPY_AVAILABLE:
            if self.mat.shape[0] > 0 and self.mat.ndim == 2:
                self.dim = int(self.mat.shape[1])
            else:
                self.dim = 0
            self.size = int(self.mat.shape[0])
        else:
            self.size = len(self.mat)
            self.dim = len(self.mat[0]) if self.size > 0 else 0

    def is_empty(self):
        if NUMPY_AVAILABLE:
            return self.mat.shape[0] == 0
        return len(self.mat) == 0

    def search(self, query_vec, k=5):
        if self.is_empty():
            return [], []

        if NUMPY_AVAILABLE:
            q = np.asarray(query_vec, dtype="float32").reshape(1, -1)
            sims = np.dot(self.mat, q.T).reshape(-1)
            topk = np.argsort(-sims)[:k]
            return sims[topk].tolist(), topk.tolist()
        else:
            return [], []

    
    def search(self, qvec, k):
        if not self.mat or (NUMPY_AVAILABLE and self.mat.shape[0] == 0) or (not NUMPY_AVAILABLE and len(self.mat) == 0):
            # Return empty results
            return np.array([[]]), np.array([[]], dtype=np.int64)
        
        q = np.array(qvec).flatten()
        
        if NUMPY_AVAILABLE:
            # Use numpy if available
            q = q / (np.linalg.norm(q) + 1e-12)
            m = self.mat / (np.linalg.norm(self.mat, axis=1, keepdims=True) + 1e-12)
            sims = np.dot(q, m.T)
            idx = np.argsort(-sims)[:k]
            scores = sims[idx]
        else:
            # Fallback calculation
            q_norm = q / (sum(x*x for x in q)**0.5 + 1e-12)
            scores = []
            for i, row in enumerate(self.mat):
                row_norm = row / (sum(x*x for x in row)**0.5 + 1e-12)
                sim = sum(q_norm[j] * row_norm[j] for j in range(min(len(q_norm), len(row_norm))))
                scores.append((sim, i))
            
            scores.sort(key=lambda x: x[0], reverse=True)
            top_k = scores[:k]
            if top_k:
                scores_arr = np.array([s[0] for s in top_k])
                idx_arr = np.array([s[1] for s in top_k])
            else:
                scores_arr = np.array([])
                idx_arr = np.array([], dtype=np.int64)
            
            return scores_arr.reshape(1, -1), idx_arr.reshape(1, -1)
        
        return scores.reshape(1, -1), idx.reshape(1, -1)
    
    def save(self, path):
        if NUMPY_AVAILABLE:
            np.savez_compressed(path, mat=self.mat)
        else:
            logger.warning(f"‚ö†Ô∏è Cannot save index without NumPy: {path}")
    
    @classmethod
    def load(cls, path):
        if NUMPY_AVAILABLE:
            try:
                arr = np.load(path)
                return cls(arr['mat'])
            except Exception as e:
                logger.error(f"Failed to load numpy index: {e}")
                return cls()
        else:
            logger.warning(f"‚ö†Ô∏è Cannot load index without NumPy: {path}")
            return cls()

def build_index(force_rebuild: bool = False) -> bool:
    """Build or load FAISS/numpy index"""
    global INDEX, EMBEDDING_MODEL
    
    with INDEX_LOCK:
        # Try to load existing index
        if not force_rebuild:
            if FAISS_ENABLED and HAS_FAISS and os.path.exists(FAISS_INDEX_PATH):
                try:
                    INDEX = faiss.read_index(FAISS_INDEX_PATH)
                    logger.info(f"‚úÖ Loaded FAISS index from {FAISS_INDEX_PATH}")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load FAISS index: {e}")
            
            # Try numpy fallback
            if os.path.exists(FALLBACK_VECTORS_PATH):
                try:
                    arr = np.load(FALLBACK_VECTORS_PATH)
                    INDEX = NumpyIndex(arr['mat'])
                    logger.info("‚úÖ Loaded numpy index")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load numpy index: {e}")
        
        # Build new index
        if not FLAT_TEXTS:
            logger.warning("No texts to index")
            return False
        
        logger.info(f"üî® Building index for {len(FLAT_TEXTS)} passages...")
        
        # Generate embeddings
        vectors = []
        dims = None
        
        for text in FLAT_TEXTS:
            emb, d = embed_text(text)
            if emb:
                if dims is None:
                    dims = len(emb)
                vectors.append(np.array(emb, dtype="float32"))
        
        if not vectors:
            logger.error("No embeddings generated")
            return False
        
        # Create index
        mat = np.vstack(vectors)
        mat = mat / (np.linalg.norm(mat, axis=1, keepdims=True) + 1e-12)
        
        if FAISS_ENABLED and HAS_FAISS:
            INDEX = faiss.IndexFlatIP(dims)
            INDEX.add(mat)
            try:
                faiss.write_index(INDEX, FAISS_INDEX_PATH)
                logger.info(f"‚úÖ Saved FAISS index to {FAISS_INDEX_PATH}")
            except Exception as e:
                logger.error(f"Failed to save FAISS index: {e}")
        else:
            INDEX = NumpyIndex(mat)
            try:
                INDEX.save(FALLBACK_VECTORS_PATH)
                logger.info(f"‚úÖ Saved numpy index to {FALLBACK_VECTORS_PATH}")
            except Exception as e:
                logger.error(f"Failed to save numpy index: {e}")
        
        logger.info(f"‚úÖ Index built: {len(vectors)} vectors, {dims} dimensions")
        return True

# =========== HELPER FUNCTIONS ===========
def normalize_text_simple(s: str) -> str:
    """Basic text normalization"""
    if not s:
        return ""
    s = s.lower()
    s = unicodedata.normalize("NFD", s)
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
    s = re.sub(r"[^\w\s]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def get_session_context(session_id: str) -> ConversationContext:
    """Get or create context for session using ConversationContext dataclass with auto-repair"""

    ctx = SESSION_CONTEXTS.get(session_id)

    if ctx is None:
        ctx = ConversationContext(session_id=session_id)
        SESSION_CONTEXTS[session_id] = ctx
        return ctx

    # ===== AUTO REPAIR FOR OLD CONTEXT OBJECTS =====
    if not hasattr(ctx, "last_tour_indices"):
        ctx.last_tour_indices = []

    if not hasattr(ctx, "current_tours"):
        ctx.current_tours = []

    if not hasattr(ctx, "mentioned_tours"):
        ctx.mentioned_tours = set()

    if not hasattr(ctx, "last_successful_tours"):
        ctx.last_successful_tours = []

    if not hasattr(ctx, "conversation_history"):
        ctx.conversation_history = []

    if not hasattr(ctx, "user_preferences"):
        ctx.user_preferences = {}

    return ctx

def save_session_context(session_id: str, context: ConversationContext):
    """L∆∞u context cho session"""
    with SESSION_LOCK:
        SESSION_CONTEXTS[session_id] = context
        # D·ªçn d·∫πp session c≈© (gi·ªØ t·ªëi ƒëa 100 session)
        if len(SESSION_CONTEXTS) > 100:
            # X√≥a c√°c session c≈© nh·∫•t
            sorted_sessions = sorted(
                SESSION_CONTEXTS.items(),
                key=lambda x: getattr(x[1], 'last_updated', datetime.utcnow())
            )
            for key, _ in sorted_sessions[:20]:
                if key in SESSION_CONTEXTS:
                    del SESSION_CONTEXTS[key]
def extract_session_id(request_data: Dict, remote_addr: str) -> str:
    """Extract or create session ID"""
    session_id = request_data.get("session_id")
    if not session_id:
        ip = remote_addr or "0.0.0.0"
        current_hour = datetime.utcnow().strftime("%Y%m%d%H")
        unique_str = f"{ip}_{current_hour}"
        session_id = hashlib.md5(unique_str.encode()).hexdigest()[:12]
    return f"session_{session_id}"

def _prepare_llm_prompt(user_message: str, search_results: List, context: Dict) -> str:
    """Prepare prompt for LLM - TH√îNG MINH v·ªõi context & c√¢u h·ªèi chung"""
    
    message_lower = user_message.lower()
    
    # Ph√¢n lo·∫°i c√¢u h·ªèi
    is_general_question = any(keyword in message_lower for keyword in [
        'c√≥ bao g·ªìm', 'ƒë√£ bao g·ªìm', 'bao g·ªìm g√¨', 'bao g·ªìm nh·ªØng g√¨',
        'c√≥ g√¨', 'nh∆∞ th·∫ø n√†o', 'ra sao', 'th·∫ø n√†o', 'gi√° tour'
    ])
    
    has_specific_tour = context.get('current_tours') and len(context.get('current_tours', [])) > 0
    tour_count = len(context.get('current_tours', []))
    
    # Ph√°t hi·ªán c√¢u h·ªèi ti·∫øp theo (followup)
    is_followup = (
        context.get('last_action') == 'chat_response' and 
        (has_specific_tour or context.get('last_tour_name'))
    )
    
    # Ph√°t hi·ªán r√†ng bu·ªôc ƒë·ªãa l√Ω
    has_location_constraint = False
    location_constraint = None
    filters = context.get('filters', {})
    if filters:
        if filters.get('location'):
            has_location_constraint = True
            location_constraint = filters.get('location')
        elif filters.get('near_location'):
            has_location_constraint = True
            location_constraint = filters.get('near_location')
    
    prompt_parts = [
        "B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n du l·ªãch Ruby Wings - CHUY√äN NGHI·ªÜP, TH√îNG MINH, NHI·ªÜT T√åNH.",
        "",
        "‚ö†Ô∏è QUY T·∫ÆC NGHI√äM NG·∫∂T:",
    ]
    
    # RULE 1: C√¢u h·ªèi CHUNG (kh√¥ng c√≥ tour c·ª• th·ªÉ)
    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "",
            "üéØ ƒê√ÇY L√Ä C√ÇU H·ªéI CHUNG - KH√îNG C√ì TOUR C·ª§ TH·ªÇ:",
            "‚Ä¢ TR·∫¢ L·ªúI NG·∫ÆN G·ªåN (2-4 c√¢u) d·ª±a tr√™n ki·∫øn th·ª©c chung v·ªÅ tour du l·ªãch",
            "‚Ä¢ S·ª¨ D·ª§NG OPENAI ƒë·ªÉ tr·∫£ l·ªùi t·ª± nhi√™n, kh√¥ng n√≥i 'kh√¥ng c√≥ d·ªØ li·ªáu'",
            "‚Ä¢ K·∫æT TH√öC b·∫±ng c√¢u h·ªèi: 'B·∫°n quan t√¢m tour n√†o ƒë·ªÉ t√¥i t∆∞ v·∫•n chi ti·∫øt?'",
            "‚Ä¢ KH√îNG li·ªát k√™ tour, KH√îNG dump d·ªØ li·ªáu",
            "",
            "V√ç D·ª§ ƒê√öNG:",
            "Q: 'Gi√° tour bao g·ªìm g√¨?'",
            "A: 'Gi√° tour Ruby Wings th∆∞·ªùng bao g·ªìm: xe ƒë∆∞a ƒë√≥n, ƒÉn u·ªëng theo ch∆∞∆°ng tr√¨nh, kh√°ch s·∫°n, h∆∞·ªõng d·∫´n vi√™n v√† b·∫£o hi·ªÉm. T√πy tour c·ª• th·ªÉ c√≥ th·ªÉ c√≥ th√™m v√© tham quan ho·∫∑c ho·∫°t ƒë·ªông ƒë·∫∑c bi·ªát. B·∫°n quan t√¢m tour n√†o ƒë·ªÉ t√¥i t∆∞ v·∫•n chi ti·∫øt? üòä'",
            "",
            "Q: 'Tour c√≥ ph√π h·ª£p gia ƒë√¨nh kh√¥ng?'",
            "A: 'Ruby Wings c√≥ nhi·ªÅu tour ph√π h·ª£p gia ƒë√¨nh v·ªõi ho·∫°t ƒë·ªông nh·∫π nh√†ng, an to√†n cho tr·∫ª em v√† ng∆∞·ªùi l·ªõn tu·ªïi. Gia ƒë√¨nh b·∫°n c√≥ bao nhi√™u ng∆∞·ªùi v√† th√≠ch lo·∫°i h√¨nh n√†o (thi√™n nhi√™n, l·ªãch s·ª≠, ngh·ªâ d∆∞·ª°ng) ƒë·ªÉ t√¥i t∆∞ v·∫•n tour ph√π h·ª£p nh·∫•t?'",
        ])
    
    # RULE 2: C√¢u h·ªèi TI·∫æP THEO (followup)
    elif is_followup:
        prompt_parts.extend([
            "",
            "üí≠ ƒê√ÇY L√Ä C√ÇU H·ªéI TI·∫æP THEO - S·ª¨ D·ª§NG CONTEXT:",
            f"‚Ä¢ ƒê√£ b√†n v·ªÅ {tour_count} tour: {context.get('last_tour_name', '')}",
            "‚Ä¢ PH·∫¢I d·ª±a v√†o context c≈© - KH√îNG reset",
            "‚Ä¢ TR·∫¢ L·ªúI TI·∫æP theo ng·ªØ c·∫£nh ƒë√£ c√≥",
            "‚Ä¢ KH√îNG li·ªát k√™ l·∫°i to√†n b·ªô tour",
            "‚Ä¢ N·∫øu h·ªèi v·ªÅ gi√°/th·ªùi gian ‚Üí Ch·ªâ n√≥i v·ªÅ tour ƒëang b√†n",
            "‚Ä¢ N·∫øu h·ªèi th√™m ƒëi·ªÅu ki·ªán ‚Üí G·ª£i √Ω tour t·ª´ context ho·∫∑c h·ªèi l·∫°i",
            "",
            "V√ç D·ª§ ƒê√öNG:",
            "Context: ƒê√£ n√≥i v·ªÅ 'Tour B·∫°ch M√£'",
            "Q: 'Tour n√†y c√≥ ph√π h·ª£p nh√≥m 10 ng∆∞·ªùi kh√¥ng?'",
            "A: 'Tour B·∫°ch M√£ r·∫•t ph√π h·ª£p cho nh√≥m 10 ng∆∞·ªùi! Ch√∫ng t√¥i c√≥ th·ªÉ t·ªï ch·ª©c ri√™ng v·ªõi gi√° ∆∞u ƒë√£i. Nh√≥m b·∫°n th√≠ch ho·∫°t ƒë·ªông n√†o: trekking, thi·ªÅn tƒ©nh t√¢m hay c·∫£ hai? T√¥i s·∫Ω t∆∞ v·∫•n l·ªãch tr√¨nh chi ti·∫øt.'",
        ])
    
    # RULE 3: Location constraint
    if has_location_constraint:
        prompt_parts.extend([
            "",
            "üö® R√ÄNG BU·ªòC ƒê·ªäA L√ù - NGHI√äM NG·∫∂T:",
            f"‚Ä¢ Y√™u c·∫ßu tour g·∫ßn/t·∫°i: {location_constraint or 'khu v·ª±c c·ª• th·ªÉ'}",
            "‚Ä¢ CH·ªà ƒë·ªÅ xu·∫•t tour trong khu v·ª±c n√†y",
            "‚Ä¢ N·∫æU kh√¥ng c√≥ tour ph√π h·ª£p:",
            "  ‚Üí 'Hi·ªán Ruby Wings ch∆∞a c√≥ tour t·∫°i [ƒë·ªãa ƒëi·ªÉm]. Tuy nhi√™n, ch√∫ng t√¥i c√≥ tour g·∫ßn nh·∫•t t·∫°i [X].'",
            "  ‚Üí H·ªèi: 'B·∫°n c√≥ mu·ªën xem tour ·ªü khu v·ª±c l√¢n c·∫≠n kh√¥ng?'",
        ])
    
    # RULE 4: Gi·ªõi h·∫°n tour
    prompt_parts.extend([
        "",
        "üìä GI·ªöI H·∫†N TOUR (B·∫ÆT BU·ªòC):",
        "‚Ä¢ T·ªëi ƒëa 2-3 tour/c√¢u tr·∫£ l·ªùi",
        "‚Ä¢ M·ªñI tour ph·∫£i c√≥ L√ù DO r√µ r√†ng",
        "‚Ä¢ KH√îNG li·ªát k√™ >3 tour",
        "‚Ä¢ N·∫øu c√≥ nhi·ªÅu tour ph√π h·ª£p:",
        "  ‚Üí Ch·ªçn 2-3 TI√äU BI·ªÇU nh·∫•t",
        "  ‚Üí T√≥m t·∫Øt: 'C√≤n X tour kh√°c...'",
        "  ‚Üí H·ªèi: 'B·∫°n mu·ªën xem th√™m lo·∫°i n√†o?'",
    ])
    
    # CONTEXT INFO
    prompt_parts.extend([
        "",
        "üìö TH√îNG TIN NG·ªÆ C·∫¢NH:",
    ])
    
    if context.get('user_preferences'):
        prefs = []
        for k, v in context['user_preferences'].items():
            prefs.append(f"{k}: {v}")
        if prefs:
            prompt_parts.append(f"- S·ªü th√≠ch: {'; '.join(prefs)}")
    
    if context.get('current_tours'):
        tours_info = [f"{t['name']}" for t in context['current_tours'][:3]]
        if tours_info:
            prompt_parts.append(f"- Tour ƒë√£ b√†n: {', '.join(tours_info)}")
    
    if filters:
        filter_strs = []
        if filters.get('price_max'):
            filter_strs.append(f"gi√° <{filters['price_max']:,}ƒë")
        if filters.get('location'):
            filter_strs.append(f"V·ªä TR√ç: {filters['location']}")
        if filter_strs:
            prompt_parts.append(f"- R√†ng bu·ªôc: {'; '.join(filter_strs)}")
    
    # SEARCH RESULTS
    prompt_parts.append("")
    prompt_parts.append("üìù D·ªÆ LI·ªÜU T·ª™ H·ªÜ TH·ªêNG:")
    
    if search_results:
        for i, (score, passage) in enumerate(search_results[:5], 1):
            text = passage.get('text', '')[:250]
            prompt_parts.append(f"[{i}] {text}")
    else:
        prompt_parts.append("(Kh√¥ng c√≥ d·ªØ li·ªáu c·ª• th·ªÉ - s·ª≠ d·ª•ng ki·∫øn th·ª©c chung)")
    
    # Y√äU C·∫¶U TR·∫¢ L·ªúI
    prompt_parts.append("")
    prompt_parts.append("üí¨ Y√äU C·∫¶U TR·∫¢ L·ªúI:")
    
    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "1. Tr·∫£ l·ªùi NG·∫ÆN G·ªåN (2-4 c√¢u) d·ª±a OpenAI",
            "2. KH√îNG n√≥i 'kh√¥ng c√≥ d·ªØ li·ªáu'",
            "3. K·∫øt th√∫c: H·ªèi l·∫°i ƒë·ªÉ x√°c ƒë·ªãnh tour",
        ])
    elif is_followup:
        prompt_parts.extend([
            "1. D·ª±a v√†o CONTEXT (tour ƒë√£ b√†n)",
            "2. Tr·∫£ l·ªùi TI·∫æP, KH√îNG reset",
            "3. T·ªëi ƒëa nh·∫Øc 1-2 tour t·ª´ context",
        ])
    else:
        prompt_parts.extend([
            "1. Ch·ªçn 2-3 tour v·ªõi L√ù DO r√µ",
            "2. KH√îNG >3 tour",
            "3. N·∫øu nhi·ªÅu: t√≥m t·∫Øt + h·ªèi ti·∫øp",
        ])
    
    prompt_parts.append("4. Lu√¥n k·∫øt th√∫c: C√¢u h·ªèi d·∫´n d·∫Øt ho·∫∑c 'üìû G·ªçi 0332510486'")
    
    return "\n".join(prompt_parts)

def _generate_fallback_response(user_message: str, search_results: List, tour_indices: List[int] = None) -> str:
    """Generate SMART fallback response - D√πng OpenAI khi c√≥, context-aware"""
    message_lower = user_message.lower()
    
    # ===== S·ª¨ D·ª§NG OPENAI N·∫æU C√ì =====
    if client and HAS_OPENAI:
        try:
            # Chu·∫©n b·ªã context
            context_parts = []
            
            # Th√¥ng tin tour n·∫øu c√≥
            if tour_indices and TOURS_DB:
                for idx in tour_indices[:2]:
                    tour = TOURS_DB.get(idx)
                    if tour:
                        context_parts.append(f"Tour: {tour.name}")
                        if tour.duration:
                            context_parts.append(f"Th·ªùi gian: {tour.duration}")
                        if tour.price:
                            context_parts.append(f"Gi√°: {tour.price}")
                        if tour.summary:
                            context_parts.append(f"M√¥ t·∫£: {tour.summary[:150]}")
            
            # D·ªØ li·ªáu search
            if search_results:
                for i, (score, passage) in enumerate(search_results[:3], 1):
                    text = passage.get('text', '')[:200]
                    if text:
                        context_parts.append(f"Th√¥ng tin {i}: {text}")
            
            # T·∫°o prompt th√¥ng minh
            context_str = "\n".join(context_parts) if context_parts else "Kh√¥ng c√≥ d·ªØ li·ªáu c·ª• th·ªÉ"
            
            prompt = f"""B·∫°n l√† t∆∞ v·∫•n vi√™n Ruby Wings chuy√™n nghi·ªáp.

TH√îNG TIN C√ì S·∫¥N:
{context_str}

Y√äU C·∫¶U TR·∫¢ L·ªúI:
1. N·∫øu c√≥ th√¥ng tin tour c·ª• th·ªÉ ‚Üí T∆∞ v·∫•n d·ª±a tr√™n ƒë√≥
2. N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu ‚Üí Tr·∫£ l·ªùi d·ª±a ki·∫øn th·ª©c chung v·ªÅ tour du l·ªãch
3. LU√îN k·∫øt th√∫c b·∫±ng c√¢u h·ªèi d·∫´n d·∫Øt ho·∫∑c "G·ªçi 0332510486"
4. Ng·∫Øn g·ªçn 2-4 c√¢u, nhi·ªát t√¨nh, t·ª± nhi√™n
5. KH√îNG n√≥i "kh√¥ng c√≥ d·ªØ li·ªáu", "xin l·ªói kh√¥ng t√¨m th·∫•y"

C√¢u h·ªèi c·ªßa kh√°ch: {user_message}"""

            response = client.chat.completions.create(
                model=CHAT_MODEL,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.6,
                max_tokens=300
            )
            
            if response.choices:
                reply = response.choices[0].message.content or ""
                # ƒê·∫£m b·∫£o c√≥ hotline
                if "0332510486" not in reply:
                    reply += "\n\nüìû Li√™n h·ªá 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt!"
                return reply
        
        except Exception as e:
            logger.error(f"OpenAI fallback error: {e}")
            # R∆°i xu·ªëng logic template b√™n d∆∞·ªõi
    
    # ===== FALLBACK KHI KH√îNG C√ì OPENAI =====
    
    # C√≥ tour c·ª• th·ªÉ ‚Üí Tr·∫£ th√¥ng tin tour
    if tour_indices and TOURS_DB:
        response_parts = []
        for idx in tour_indices[:2]:
            tour = TOURS_DB.get(idx)
            if tour:
                response_parts.append(f"**{tour.name}**")
                if tour.duration:
                    response_parts.append(f"‚è±Ô∏è {tour.duration}")
                if tour.location:
                    response_parts.append(f"üìç {tour.location}")
                if tour.price:
                    response_parts.append(f"üí∞ {tour.price}")
                if tour.summary:
                    response_parts.append(f"üìù {tour.summary[:150]}...")
        
        if response_parts:
            return "\n".join(response_parts) + "\n\nüìû G·ªçi 0332510486 ƒë·ªÉ bi·∫øt th√™m!"
    
    # C√≥ search results ‚Üí T√≥m t·∫Øt
    if search_results:
        top_results = search_results[:2]
        response_parts = ["Th√¥ng tin li√™n quan:"]
        
        for i, (score, passage) in enumerate(top_results, 1):
            text = passage.get('text', '')[:150]
            if text:
                response_parts.append(f"\n{i}. {text}...")
        
        response_parts.append("\n\nüìû Li√™n h·ªá 0332510486 ƒë·ªÉ bi·∫øt chi ti·∫øt!")
        return "".join(response_parts)
    
    # C√¢u h·ªèi chung ‚Üí Template th√¥ng minh theo keyword
    general_qa = {
        'bao g·ªìm': "Gi√° tour Ruby Wings th∆∞·ªùng bao g·ªìm: xe ƒë∆∞a ƒë√≥n, ƒÉn u·ªëng theo ch∆∞∆°ng tr√¨nh, kh√°ch s·∫°n, h∆∞·ªõng d·∫´n vi√™n v√† b·∫£o hi·ªÉm. T√πy tour c·ª• th·ªÉ c√≥ th√™m ho·∫°t ƒë·ªông ƒë·∫∑c bi·ªát. B·∫°n quan t√¢m tour n√†o ƒë·ªÉ t√¥i t∆∞ v·∫•n chi ti·∫øt? üòä",
        
        'ph√π h·ª£p gia ƒë√¨nh': "Ruby Wings c√≥ nhi·ªÅu tour ph√π h·ª£p gia ƒë√¨nh v·ªõi ho·∫°t ƒë·ªông nh·∫π nh√†ng, an to√†n cho tr·∫ª em v√† ng∆∞·ªùi l·ªõn tu·ªïi. Gia ƒë√¨nh b·∫°n bao nhi√™u ng∆∞·ªùi v√† th√≠ch lo·∫°i tour n√†o (thi√™n nhi√™n, l·ªãch s·ª≠, ngh·ªâ d∆∞·ª°ng)?",
        
        'ph√π h·ª£p': "Ruby Wings c√≥ tour cho m·ªçi ƒë·ªëi t∆∞·ª£ng! B·∫°n ƒëi nh√≥m bao nhi√™u ng∆∞·ªùi v√† c√≥ s·ªü th√≠ch g√¨ ƒë·∫∑c bi·ªát kh√¥ng?",
        
        'gi√°': "Gi√° tour Ruby Wings t·ª´ 800.000ƒë - 3.000.000ƒë t√πy lo·∫°i. B·∫°n c√≥ ng√¢n s√°ch kho·∫£ng bao nhi√™u v√† mu·ªën ƒëi m·∫•y ng√†y ƒë·ªÉ t√¥i t∆∞ v·∫•n ph√π h·ª£p?",
        
        'th·ªùi gian': "Ruby Wings c√≥ tour 1 ng√†y, 2 ng√†y 1 ƒë√™m, 3 ng√†y 2 ƒë√™m. B·∫°n c√≥ kho·∫£ng bao nhi√™u th·ªùi gian r·∫£nh?",
        
        'ƒë·ªãa ƒëi·ªÉm': "Ruby Wings t·ªï ch·ª©c tour t·∫°i Hu·∫ø, Qu·∫£ng Tr·ªã, B·∫°ch M√£, Tr∆∞·ªùng S∆°n v√† nhi·ªÅu n∆°i kh√°c. B·∫°n mu·ªën kh√°m ph√° khu v·ª±c n√†o?",
        
        'nh√≥m': "Tour nh√≥m c·ªßa Ruby Wings r·∫•t ph√π h·ª£p! Nh√≥m b·∫°n bao nhi√™u ng∆∞·ªùi v√† th√≠ch ho·∫°t ƒë·ªông g√¨ (teambuilding, ngh·ªâ d∆∞·ª°ng, kh√°m ph√°)?",
        
        'retreat': "Ruby Wings chuy√™n tour retreat k·∫øt h·ª£p thi·ªÅn, kh√≠ c√¥ng v√† thi√™n nhi√™n. B·∫°n mu·ªën tour bao nhi√™u ng√†y v√† m·ª©c ƒë·ªô ho·∫°t ƒë·ªông nh∆∞ n√†o?",
    }
    
    # T√¨m keyword match
    for keyword, response in general_qa.items():
        if keyword in message_lower:
            return response
    
    # Default - D·∫´n d·∫Øt h·ªèi l·∫°i
    return "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n t√¨m tour ph√π h·ª£p! B·∫°n c√≥ th·ªÉ cho t√¥i bi·∫øt:\n" \
           "‚Ä¢ Mu·ªën ƒëi ƒë√¢u?\n" \
           "‚Ä¢ Th·ªùi gian bao l√¢u?\n" \
           "‚Ä¢ Ng√¢n s√°ch kho·∫£ng bao nhi√™u?\n" \
           "‚Ä¢ ƒêi bao nhi√™u ng∆∞·ªùi?\n\n" \
           "Ho·∫∑c g·ªçi ngay 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt! üòä"


# =========== MAIN CHAT ENDPOINT - ƒê·ªàNH CAO TH√îNG MINH V4.1 ===========
@app.route("/chat", methods=["POST"])
def chat_endpoint_ultimate():
    """
    Main chat endpoint v·ªõi x·ª≠ l√Ω AI th√¥ng minh, context-aware m·∫°nh m·∫Ω
    X·ª≠ l√Ω m·ªçi lo·∫°i c√¢u h·ªèi t·ª´ ƒë∆°n gi·∫£n ƒë·∫øn ph·ª©c t·∫°p - Version 4.1 (Enhanced)
    """
    start_time = time.time()
    
    try:
        # ================== INITIALIZATION ==================
        data = request.get_json() or {}
        user_message = (data.get("message") or "").strip()
        session_id = extract_session_id(data, request.remote_addr)
        
        if not user_message:
            return jsonify({
                "reply": "üëã **Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI c·ªßa Ruby Wings Travel**\n\n"
                        "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\n"
                        "‚Ä¢ T√¨m hi·ªÉu v·ªÅ 32 tour tr·∫£i nghi·ªám ƒë·∫∑c s·∫Øc\n"
                        "‚Ä¢ So s√°nh c√°c tour ƒë·ªÉ ch·ªçn ph√π h·ª£p nh·∫•t\n"
                        "‚Ä¢ T∆∞ v·∫•n tour theo nhu c·∫ßu gia ƒë√¨nh, nh√≥m, c√° nh√¢n\n"
                        "‚Ä¢ Cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ gi√°, l·ªãch tr√¨nh, ƒë·ªãa ƒëi·ªÉm\n\n"
                        "üìû **Hotline t∆∞ v·∫•n 24/7:** 0332510486\n"
                        "üí° **H·ªèi ngay:** 'Tour n√†o ph√π h·ª£p cho gia ƒë√¨nh?', 'Tour B·∫°ch M√£ gi√° bao nhi√™u?'",
                "sources": [],
                "context": {},
                "processing_time": 0
            })
        
        # ================== CONTEXT MANAGEMENT SYSTEM ==================
        context = get_session_context(session_id)
        
        # Kh·ªüi t·∫°o context n·∫øu ch∆∞a c√≥
        if not hasattr(context, 'conversation_history'):
            context.conversation_history = []
        if not hasattr(context, 'current_tour'):
            context.current_tour = None
        if not hasattr(context, 'user_profile'):
            context.user_profile = {}
        
        # L∆∞u user message v√†o history
        context.conversation_history.append({
            'role': 'user',
            'message': user_message,
            'timestamp': datetime.utcnow().isoformat()
        })
        
        # Gi·ªõi h·∫°n history (gi·ªØ 20 tin nh·∫Øn g·∫ßn nh·∫•t)
        if len(context.conversation_history) > 40:
            context.conversation_history = context.conversation_history[-20:]
        
        # ================== ADVANCED CONTEXT ANALYSIS ==================
        message_lower = user_message.lower()
        
        # Ph√¢n t√≠ch c·∫•p ƒë·ªô ph·ª©c t·∫°p n√¢ng cao
        complexity_score = 0
        complexity_indicators = {
            'v√†': 1, 'cho': 1, 'v·ªõi': 1, 'nh∆∞ng': 2, 'tuy nhi√™n': 2,
            'n·∫øu': 2, 'khi': 1, 'ƒë·ªÉ': 1, 'm√†': 1, 'ho·∫∑c': 1, 'so s√°nh': 3,
            'ph√¢n bi·ªát': 3, 'kh√°c nhau': 3, 't∆∞∆°ng t·ª±': 2, 'gi·ªØa': 2
        }
        
        for indicator, weight in complexity_indicators.items():
            if indicator in message_lower:
                complexity_score += weight
        
        # Ph√¢n t√≠ch ƒë·ªô d√†i c√¢u h·ªèi
        word_count = len(user_message.split())
        if word_count > 15:
            complexity_score += 2
        elif word_count > 25:
            complexity_score += 3
        
        # ================== ENHANCED INTENT DETECTION ==================
        intent_categories = {
            'tour_listing': ['c√≥ nh·ªØng tour n√†o', 'danh s√°ch tour', 'li·ªát k√™ tour', 'tour n√†o c√≥', 'tour g√¨'],
            'price_inquiry': ['gi√° bao nhi√™u', 'bao nhi√™u ti·ªÅn', 'chi ph√≠', 'gi√° tour', 'b·∫£ng gi√°', 'bao nhi√™u'],
            'tour_detail': ['chi ti·∫øt tour', 'l·ªãch tr√¨nh', 'c√≥ g√¨', 'bao g·ªìm g√¨', 'th√¥ng tin', 'm√¥ t·∫£'],
            'comparison': ['so s√°nh', 'kh√°c nhau', 'n√™n ch·ªçn', 't·ªët h∆°n', 'h∆°n k√©m', 'ph√¢n bi·ªát'],
            'recommendation': ['ph√π h·ª£p', 'g·ª£i √Ω', 'ƒë·ªÅ xu·∫•t', 't∆∞ v·∫•n', 'n√™n ƒëi', 'ch·ªçn n√†o', 't√¨m tour'],
            'booking_info': ['ƒë·∫∑t tour', 'ƒëƒÉng k√Ω', 'booking', 'gi·ªØ ch·ªó', 'thanh to√°n', 'ƒë·∫∑t ch·ªó'],
            'policy': ['ch√≠nh s√°ch', 'gi·∫£m gi√°', '∆∞u ƒë√£i', 'khuy·∫øn m√£i', 'gi·∫£m', 'promotion'],
            'general_info': ['gi·ªõi thi·ªáu', 'l√† g√¨', 'th·∫ø n√†o', 'ra sao', 's·ª© m·ªánh', 'gi√° tr·ªã', 'tri·∫øt l√Ω'],
            'location_info': ['·ªü ƒë√¢u', 'ƒë·ªãa ƒëi·ªÉm', 'ƒë·∫øn ƒë√¢u', 'v·ªã tr√≠', 't·∫°i ƒë√¢u', 'ch·ªó n√†o'],
            'time_info': ['khi n√†o', 'th·ªùi gian', 'bao l√¢u', 'm·∫•y ng√†y', 'bao gi·ªù', 'th·ªùi ƒëi·ªÉm'],
            'weather_info': ['th·ªùi ti·∫øt', 'kh√≠ h·∫≠u', 'n·∫Øng m∆∞a', 'm√πa n√†o', 'nhi·ªát ƒë·ªô'],
            'food_info': ['·∫©m th·ª±c', 'm√≥n ƒÉn', 'ƒë·∫∑c s·∫£n', 'ƒë·ªì ƒÉn', 'b√°nh b√®o', 'm·∫Øm n√™m'],
            'culture_info': ['vƒÉn h√≥a', 'l·ªãch s·ª≠', 'truy·ªÅn th·ªëng', 'di t√≠ch', 'di s·∫£n', 'vƒÉn minh'],
            'wellness_info': ['thi·ªÅn', 'yoga', 'ch·ªØa l√†nh', 's·ª©c kh·ªèe', 'retreat', 'tƒ©nh t√¢m', 'kh√≠ c√¥ng'],
            'group_info': ['nh√≥m', 'ƒëo√†n', 'c√¥ng ty', 'gia ƒë√¨nh', 'b·∫°n b√®', 't·∫≠p th·ªÉ', 'c·ª±u chi·∫øn binh'],
            'custom_request': ['t√πy ch·ªânh', 'ri√™ng', 'c√° nh√¢n h√≥a', 'theo y√™u c·∫ßu', 'ri√™ng bi·ªát'],
            'sustainability': ['b·ªÅn v·ªØng', 'm√¥i tr∆∞·ªùng', 'xanh', 'c·ªông ƒë·ªìng', 'ph√°t tri·ªÉn b·ªÅn v·ªØng'],
            'experience': ['tr·∫£i nghi·ªám', 'c·∫£m gi√°c', 'c·∫£m nh·∫≠n', 'th·ª±c t·∫ø', 'tr·ª±c ti·∫øp']
        }
        
        detected_intents = []
        for intent, keywords in intent_categories.items():
            for keyword in keywords:
                if keyword in message_lower:
                    if intent not in detected_intents:
                        detected_intents.append(intent)
                    break
        
        # ∆Øu ti√™n intent ch√≠nh
        primary_intent = None
        if detected_intents:
            # ∆Øu ti√™n c√°c intent c·ª• th·ªÉ h∆°n
            priority_order = ['comparison', 'recommendation', 'tour_detail', 'price_inquiry', 
                            'tour_listing', 'general_info', 'wellness_info', 'culture_info']
            for intent in priority_order:
                if intent in detected_intents:
                    primary_intent = intent
                    break
            if not primary_intent:
                primary_intent = detected_intents[0]
        
        # ================== ENHANCED TOUR RESOLUTION ENGINE ==================
        tour_indices = []
        tour_names_mentioned = []
        
        # Strategy 1: Enhanced direct tour name matching
        direct_tour_matches = []
        import re
        
        # T√¨m t√™n tour trong c√¢u h·ªèi v·ªõi pattern matching
        tour_name_patterns = [
            r'["\'](.+?)["\']',  # T√™n trong d·∫•u nh√°y
            r'tour\s+(.+?)\s+(?:c√≥|gi√°|·ªü|cho|t·∫°i)',
            r'tour\s+["\']?(.+?)["\']?'
        ]
        
        for pattern in tour_name_patterns:
            matches = re.findall(pattern, user_message, re.IGNORECASE)
            for match in matches:
                if match and len(match.strip()) > 3:
                    tour_names_mentioned.append(match.strip())
        
        # Lo·∫°i b·ªè c√°c t·ª´ chung chung
        filter_words = ['n√†o', 'g√¨', 'ƒë√≥', '·∫•y', 'n√†y', 'kia', 'cho', 'v·ªõi', 'c·ªßa']
        tour_names_mentioned = [name for name in tour_names_mentioned 
                              if not any(word in name.lower() for word in filter_words)]
        
        logger.info(f"üîç Tour names mentioned in query: {tour_names_mentioned}")
        
        # T√¨m tour index cho t·ª´ng t√™n ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p
        for tour_name in tour_names_mentioned:
            for norm_name, idx in TOUR_NAME_TO_INDEX.items():
                similarity_score = 0
                
                # Ki·ªÉm tra t·ª´ kh√≥a ch√≠nh
                name_words = set(norm_name.lower().split())
                query_words = set(tour_name.lower().split())
                common_words = name_words.intersection(query_words)
                
                if len(common_words) >= 2:
                    similarity_score = len(common_words) / max(len(name_words), len(query_words))
                
                # Ki·ªÉm tra contain
                if tour_name.lower() in norm_name.lower() or norm_name.lower() in tour_name.lower():
                    similarity_score = max(similarity_score, 0.8)
                
                if similarity_score >= 0.5 and idx not in direct_tour_matches:
                    direct_tour_matches.append(idx)
                    logger.info(f"üéØ Found tour '{norm_name}' (idx: {idx}) for query '{tour_name}'")
        
        if direct_tour_matches:
            tour_indices = direct_tour_matches[:5]  # TƒÉng l√™n 5 tour
            logger.info(f"üéØ Direct tour matches found: {tour_indices}")
        
        # Strategy 2: Enhanced fuzzy matching
        if not tour_indices and UpgradeFlags.is_enabled("6_FUZZY_MATCHING"):
            fuzzy_matches = FuzzyMatcher.find_similar_tours(user_message, TOUR_NAME_TO_INDEX)
            if fuzzy_matches:
                tour_indices = [idx for idx, score in fuzzy_matches[:3] if score > 0.6]  # Gi·∫£m ng∆∞·ª°ng
                if tour_indices:
                    logger.info(f"üîç Fuzzy matches found: {tour_indices}")
        
        # Strategy 3: Semantic content matching
        if not tour_indices and UpgradeFlags.is_enabled("8_SEMANTIC_ANALYSIS"):
            # T√¨m tour d·ª±a tr√™n n·ªôi dung semantic
            semantic_matches = []
            for idx, tour in TOURS_DB.items():
                # T·∫°o text blob ƒë·ªÉ ph√¢n t√≠ch
                text_blob = f"{tour.name or ''} {tour.summary or ''} {tour.style or ''} {tour.location or ''}".lower()
                
                # Ph√¢n t√≠ch t·ª´ kh√≥a trong c√¢u h·ªèi
                query_words = [word for word in message_lower.split() if len(word) > 2]
                matches = sum(1 for word in query_words if word in text_blob)
                
                if matches >= 2:
                    semantic_matches.append((idx, matches))
            
            if semantic_matches:
                semantic_matches.sort(key=lambda x: x[1], reverse=True)
                tour_indices = [idx for idx, score in semantic_matches[:3]]
                logger.info(f"üß† Semantic matches found: {tour_indices}")
        
        # Strategy 4: Filter-based search
        mandatory_filters = FilterSet()
        filter_applied = False
        
        if UpgradeFlags.is_enabled("1_MANDATORY_FILTER"):
            try:
                mandatory_filters = MandatoryFilterSystem.extract_filters(user_message)
                
                if not mandatory_filters.is_empty():
                    logger.info(f"üéØ Filters extracted: {mandatory_filters}")
                    
                    # Ki·ªÉm tra l·ªói trong filter
                    if hasattr(mandatory_filters, 'group_type') and mandatory_filters.group_type:
                        valid_group_types = ['family', 'friends', 'corporate', 'solo', 'couple', 'senior']
                        if mandatory_filters.group_type not in valid_group_types:
                            logger.warning(f"‚ö†Ô∏è Invalid group type: {mandatory_filters.group_type}")
                    
                    filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                    
                    if filtered_indices:
                        filter_applied = True
                        if tour_indices:
                            # K·∫øt h·ª£p k·∫øt qu·∫£: l·∫•y giao c·ªßa c√°c k·∫øt qu·∫£
                            combined = list(set(tour_indices) & set(filtered_indices))
                            if combined:
                                tour_indices = combined[:5]
                            else:
                                # N·∫øu kh√¥ng c√≥ giao, ∆∞u ti√™n filter-based
                                tour_indices = filtered_indices[:5]
                            logger.info(f"üéØ Combined filter-based search: {len(tour_indices)} tours")
                        else:
                            tour_indices = filtered_indices[:8]  # TƒÉng l√™n 8 tour
                            logger.info(f"üéØ Filter-based search only: {len(tour_indices)} tours")
            except Exception as e:
                logger.error(f"‚ùå Filter system error: {e}")
                # Continue without filters
        
        # ================== INTELLIGENT RESPONSE GENERATION ==================
        reply = ""
        sources = []
        
        # üîπ CASE 0: CONTEXT-AWARE FOLLOW-UP (N√¢ng c·∫•p m·ªõi)
        if len(context.conversation_history) > 1:
            last_user_msg = None
            last_bot_msg = None
            
            # T√¨m tin nh·∫Øn g·∫ßn nh·∫•t
            for msg in reversed(context.conversation_history[:-1]):
                if msg['role'] == 'user':
                    last_user_msg = msg['message']
                elif msg['role'] == 'assistant' and not last_bot_msg:
                    last_bot_msg = msg['message']
                
                if last_user_msg and last_bot_msg:
                    break
            
            # X·ª≠ l√Ω follow-up questions
            if last_bot_msg and ('tour n√†o' in message_lower or 'g·ª£i √Ω' in message_lower):
                # Ki·ªÉm tra n·∫øu ƒë√¢y l√† c√¢u h·ªèi follow-up v·ªÅ tour
                follow_up_tours = getattr(context, 'last_recommended_tours', [])
                if follow_up_tours and len(tour_indices) == 0:
                    tour_indices = follow_up_tours[:3]
                    logger.info(f"üîÑ Using context tour recommendations: {tour_indices}")
        
        # üîπ CASE 1: LISTING TOURS
        if 'tour_listing' in detected_intents or any(keyword in message_lower for keyword in ['c√≥ nh·ªØng tour n√†o', 'danh s√°ch tour', 'li·ªát k√™ tour']):
            logger.info("üìã Processing tour listing request")
            
            all_tours = list(TOURS_DB.values())
            
            # Apply deduplication
            if UpgradeFlags.is_enabled("2_DEDUPLICATION") and all_tours:
                seen_names = set()
                unique_tours = []
                for tour in all_tours:
                    name = tour.name
                    if name and name not in seen_names:
                        seen_names.add(name)
                        unique_tours.append(tour)
                all_tours = unique_tours
            
            # Apply additional filters
            if filter_applied and not mandatory_filters.is_empty():
                filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                all_tours = [TOURS_DB[idx] for idx in filtered_indices if idx in TOURS_DB]
            
            total_tours = len(all_tours)
            
            if total_tours > 0:
                # Ph√¢n lo·∫°i tour theo category
                categorized_tours = {
                    'history': [],
                    'retreat': [],
                    'nature': [],
                    'culture': [],
                    'family': []
                }
                
                for tour in all_tours:
                    tags_lower = [tag.lower() for tag in (tour.tags or [])]
                    
                    if any('history' in tag for tag in tags_lower):
                        categorized_tours['history'].append(tour)
                    elif any('meditation' in tag or 'retreat' in tag for tag in tags_lower):
                        categorized_tours['retreat'].append(tour)
                    elif any('nature' in tag for tag in tags_lower):
                        categorized_tours['nature'].append(tour)
                    elif any('culture' in tag or 'food' in tag for tag in tags_lower):
                        categorized_tours['culture'].append(tour)
                    elif any('family' in tag for tag in tags_lower):
                        categorized_tours['family'].append(tour)
                    else:
                        categorized_tours['nature'].append(tour)  # M·∫∑c ƒë·ªãnh
                
                # Format response c√≥ c·∫•u tr√∫c
                reply = "‚ú® **DANH S√ÅCH TOUR RUBY WINGS** ‚ú®\n\n"
                reply += f"üìä **T·ªïng c·ªông:** {total_tours} tour ƒë·∫∑c s·∫Øc\n\n"
                
                # Hi·ªÉn th·ªã theo t·ª´ng lo·∫°i
                categories_display = [
                    ('üèõÔ∏è L·ªäCH S·ª¨ - TRI √ÇN', 'history', 'history'),
                    ('üïâÔ∏è RETREAT - CH·ªÆA L√ÄNH', 'retreat', 'meditation'),
                    ('üåø THI√äN NHI√äN - KH√ÅM PH√Å', 'nature', 'nature'),
                    ('üçú VƒÇN H√ìA - ·∫®M TH·ª∞C', 'culture', 'culture'),
                    ('üë®‚Äçüë©‚Äçüëß‚Äçüë¶ GIA ƒê√åNH - NH√ìM', 'family', 'family')
                ]
                
                tours_displayed = 0
                for cat_name, cat_key, emoji_key in categories_display:
                    cat_tours = categorized_tours[cat_key]
                    if cat_tours:
                        reply += f"**{cat_name}** ({len(cat_tours)} tour)\n"
                        
                        for i, tour in enumerate(cat_tours[:3], 1):
                            # Ch·ªçn emoji ph√π h·ª£p
                            emoji = "‚ú®"
                            if cat_key == 'history': emoji = "üèõÔ∏è"
                            elif cat_key == 'retreat': emoji = "üïâÔ∏è"
                            elif cat_key == 'nature': emoji = "üåø"
                            elif cat_key == 'culture': emoji = "üçú"
                            elif cat_key == 'family': emoji = "üë®‚Äçüë©‚Äçüëß‚Äçüë¶"
                            
                            reply += f"{emoji} **{tour.name}**\n"
                            if tour.duration:
                                reply += f"   ‚è±Ô∏è {tour.duration}\n"
                            if tour.location:
                                location_short = tour.location[:40] + "..." if len(tour.location) > 40 else tour.location
                                reply += f"   üìç {location_short}\n"
                            if i == 1 and tour.price:  # Hi·ªán gi√° tour ƒë·∫ßu m·ªói lo·∫°i
                                price_short = tour.price[:60] + "..." if len(tour.price) > 60 else tour.price
                                reply += f"   üí∞ {price_short}\n"
                            reply += "\n"
                            tours_displayed += 1
                        
                        if len(cat_tours) > 3:
                            reply += f"   üìå ...v√† {len(cat_tours) - 3} tour kh√°c\n\n"
                        else:
                            reply += "\n"
                
                if tours_displayed < total_tours:
                    reply += f"üìå **C√≤n {total_tours - tours_displayed} tour kh√°c trong h·ªá th·ªëng!**\n\n"
                
                reply += "üí° **H∆Ø·ªöNG D·∫™N T√åM TOUR:**\n"
                reply += "‚Ä¢ G·ªçi t√™n tour c·ª• th·ªÉ (v√≠ d·ª•: 'Tour B·∫°ch M√£')\n"
                reply += "‚Ä¢ M√¥ t·∫£ nhu c·∫ßu: 'tour gia ƒë√¨nh 2 ng√†y', 'retreat thi·ªÅn'\n"
                reply += "‚Ä¢ So s√°nh tour: 'so s√°nh tour A v√† tour B'\n\n"
                reply += "üìû **Hotline t∆∞ v·∫•n nhanh:** 0332510486"
                
                # L∆∞u context ƒë·ªÉ follow-up
                context.last_listed_tours = [idx for idx, tour in enumerate(all_tours[:10])]
            else:
                reply = "Hi·ªán ch∆∞a c√≥ tour n√†o ph√π h·ª£p v·ªõi y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng th·ª≠ v·ªõi ti√™u ch√≠ kh√°c ho·∫∑c li√™n h·ªá hotline 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n tour ri√™ng."
        
        # üîπ CASE 2: PRICE INQUIRY - N√ÇNG C·∫§P
        elif 'price_inquiry' in detected_intents or any(keyword in message_lower for keyword in ['gi√° bao nhi√™u', 'bao nhi√™u ti·ªÅn', 'chi ph√≠', 'b·∫£ng gi√°']):
            logger.info("üí∞ Processing enhanced price inquiry")
            
            if tour_indices:
                # C√≥ tour c·ª• th·ªÉ
                price_responses = []
                detailed_info = []
                
                for idx in tour_indices[:3]:  # Hi·ªán 3 tour
                    tour = TOURS_DB.get(idx)
                    if tour:
                        # Format price information
                        price_info = {
                            'name': tour.name,
                            'price': tour.price or 'Li√™n h·ªá ƒë·ªÉ bi·∫øt gi√°',
                            'duration': tour.duration or 'Kh√¥ng x√°c ƒë·ªãnh',
                            'location': tour.location or 'Kh√¥ng x√°c ƒë·ªãnh'
                        }
                        
                        # Ph√¢n t√≠ch gi√° n·∫øu c√≥
                        price_text = price_info['price']
                        if price_text and price_text != 'Li√™n h·ªá ƒë·ªÉ bi·∫øt gi√°':
                            # T√¨m c√°c m·ª©c gi√°
                            price_numbers = re.findall(r'\d[\d,\.]+', price_text)
                            if price_numbers:
                                try:
                                    # Chuy·ªÉn ƒë·ªïi sang s·ªë
                                    clean_nums = []
                                    for num in price_numbers:
                                        clean_num = num.replace(',', '').replace('.', '')
                                        if clean_num.isdigit():
                                            clean_nums.append(int(clean_num))
                                    
                                    if clean_nums:
                                        min_price = min(clean_nums)
                                        max_price = max(clean_nums) if len(clean_nums) > 1 else min_price
                                        
                                        if min_price < 1000000:
                                            price_range = f"{min_price:,}ƒë"
                                        elif min_price == max_price:
                                            price_range = f"{min_price:,}ƒë"
                                        else:
                                            price_range = f"{min_price:,}ƒë - {max_price:,}ƒë"
                                        
                                        price_info['formatted'] = price_range
                                except:
                                    price_info['formatted'] = price_text
                        
                        detailed_info.append(price_info)
                
                if detailed_info:
                    reply = "üí∞ **TH√îNG TIN GI√Å TOUR CHI TI·∫æT** üí∞\n\n"
                    
                    for info in detailed_info:
                        reply += f"**{info['name']}**\n"
                        reply += f"‚è±Ô∏è Th·ªùi gian: {info['duration']}\n"
                        reply += f"üìç ƒê·ªãa ƒëi·ªÉm: {info.get('location_short', info['location'][:50])}\n"
                        
                        if 'formatted' in info:
                            reply += f"üí∞ **Gi√°:** {info['formatted']}\n"
                        else:
                            reply += f"üí∞ **Gi√°:** {info['price']}\n"
                        
                        # Th√™m ph√¢n lo·∫°i gi√°
                        if 'formatted' in info and 'ƒë' in info['formatted']:
                            price_num = int(info['formatted'].split('ƒë')[0].replace(',', '').replace('.', '').strip())
                            if price_num < 1000000:
                                reply += "   üè∑Ô∏è Ph√¢n lo·∫°i: Ti·∫øt ki·ªám\n"
                            elif price_num < 2500000:
                                reply += "   üè∑Ô∏è Ph√¢n lo·∫°i: Ti√™u chu·∫©n\n"
                            else:
                                reply += "   üè∑Ô∏è Ph√¢n lo·∫°i: Cao c·∫•p\n"
                        
                        reply += "\n"
                    
                    reply += "üéØ **∆ØU ƒê√ÉI ƒê·∫∂C BI·ªÜT:**\n"
                    reply += "‚Ä¢ Nh√≥m 5-9 ng∆∞·ªùi: Gi·∫£m 5%\n"
                    reply += "‚Ä¢ Nh√≥m 10-15 ng∆∞·ªùi: Gi·∫£m 10%\n"
                    reply += "‚Ä¢ Nh√≥m 16+ ng∆∞·ªùi: Gi·∫£m 15%\n"
                    reply += "‚Ä¢ ƒê·∫∑t tr∆∞·ªõc 30 ng√†y: Gi·∫£m th√™m 5%\n"
                    reply += "‚Ä¢ C·ª±u chi·∫øn binh: ∆Øu ƒë√£i ƒë·∫∑c bi·ªát\n\n"
                    reply += "üìû **Li√™n h·ªá ngay ƒë·ªÉ nh·∫≠n b√°o gi√° t·ªët nh·∫•t:** 0332510486"
                else:
                    reply = "Hi·ªán ch∆∞a c√≥ th√¥ng tin gi√° cho c√°c tour n√†y. Vui l√≤ng li√™n h·ªá hotline 0332510486 ƒë·ªÉ ƒë∆∞·ª£c b√°o gi√° chi ti·∫øt."
            else:
                # Kh√¥ng c√≥ tour c·ª• th·ªÉ - Hi·ªÉn th·ªã b·∫£ng gi√° t·ªïng qu√°t
                reply = "üí∞ **B·∫¢NG GI√Å THAM KH·∫¢O RUBY WINGS** üí∞\n\n"
                
                # T·∫°o b·∫£ng gi√° theo lo·∫°i tour
                price_categories = [
                    ("üåø TOUR 1 NG√ÄY (Thi√™n nhi√™n, VƒÉn h√≥a)", "500.000ƒë - 1.500.000ƒë", 
                     "B·∫°ch M√£, Hu·∫ø city tour, ·∫®m th·ª±c Hu·∫ø"),
                    ("üèõÔ∏è TOUR 2 NG√ÄY 1 ƒê√äM (L·ªãch s·ª≠, Retreat)", "1.500.000ƒë - 3.000.000ƒë", 
                     "Tr∆∞·ªùng S∆°n, Di t√≠ch l·ªãch s·ª≠, Thi·ªÅn ƒë·ªãnh"),
                    ("üïâÔ∏è TOUR 3+ NG√ÄY (Cao c·∫•p, C√° nh√¢n h√≥a)", "2.500.000ƒë - 5.000.000ƒë", 
                     "Tour ri√™ng, Nh√≥m ƒë·∫∑c bi·ªát, Retreat s√¢u"),
                    ("üë• TOUR TEAMBUILDING (C√¥ng ty, Nh√≥m l·ªõn)", "Li√™n h·ªá t∆∞ v·∫•n", 
                     "Thi·∫øt k·∫ø ri√™ng, Ho·∫°t ƒë·ªông nh√≥m, G·∫Øn k·∫øt")
                ]
                
                for cat_name, price_range, description in price_categories:
                    reply += f"**{cat_name}**\n"
                    reply += f"üí∞ {price_range}\n"
                    reply += f"üìù {description}\n\n"
                
                reply += "üìä **Y·∫æU T·ªê ·∫¢NH H∆Ø·ªûNG ƒê·∫æN GI√Å:**\n"
                reply += "‚Ä¢ S·ªë l∆∞·ª£ng ng∆∞·ªùi tham gia\n"
                reply += "‚Ä¢ Th·ªùi ƒëi·ªÉm ƒë·∫∑t tour\n"
                reply += "‚Ä¢ D·ªãch v·ª• b·ªï sung (ƒÉn u·ªëng, ph∆∞∆°ng ti·ªán)\n"
                reply += "‚Ä¢ ƒê·ªô d√†i v√† ƒë·ªô ph·ª©c t·∫°p c·ªßa h√†nh tr√¨nh\n\n"
                
                reply += "üéÅ **CAM K·∫æT GI√Å T·ªêT:**\n"
                reply += "‚Ä¢ Kh√¥ng ph√°t sinh chi ph√≠ ·∫©n\n"
                reply += "‚Ä¢ B√°o gi√° minh b·∫°ch, r√µ r√†ng\n"
                reply += "‚Ä¢ Ho√†n ti·ªÅn n·∫øu kh√¥ng h√†i l√≤ng\n\n"
                
                reply += "üìû **Li√™n h·ªá t∆∞ v·∫•n gi√° ch√≠nh x√°c:** 0332510486"
        
        # üîπ CASE 3: ENHANCED TOUR COMPARISON
        elif 'comparison' in detected_intents or any(keyword in message_lower for keyword in ['so s√°nh', 'kh√°c nhau', 'n√™n ch·ªçn', 't·ªët h∆°n']):
            logger.info("‚öñÔ∏è Processing enhanced tour comparison request")
            
            # Enhanced tour extraction
            comparison_tours = []
            extracted_tour_names = []
            
            # Pattern matching n√¢ng cao
            comparison_patterns = [
                r'(?:tour|ch∆∞∆°ng tr√¨nh)\s+["\']?(.+?)["\']?\s+(?:v√†|v·ªõi|so s√°nh v·ªõi)\s+(?:tour|ch∆∞∆°ng tr√¨nh)\s+["\']?(.+?)["\']',
                r'["\'](.+?)["\']\s+(?:v√†|v·ªõi)\s+["\'](.+?)["\']',
                r'(?:gi·ªØa\s+)?(.+?)\s+(?:v√†|v·ªõi)\s+(.+)',
                r'so s√°nh\s+(.+?)\s+(?:v√†|v·ªõi)\s+(.+)'
            ]
            
            for pattern in comparison_patterns:
                matches = re.findall(pattern, user_message, re.IGNORECASE)
                if matches:
                    for match in matches:
                        for tour_name in match:
                            if tour_name and len(tour_name.strip()) > 3:
                                clean_name = tour_name.strip().lower()
                                # Lo·∫°i b·ªè t·ª´ chung
                                if not any(word in clean_name for word in ['tour', 'ch∆∞∆°ng tr√¨nh', 'gi·ªØa']):
                                    extracted_tour_names.append(clean_name)
            
            logger.info(f"üîç Extracted tour names for comparison: {extracted_tour_names}")
            
            # T√¨m tour index cho t·ª´ng t√™n
            for tour_query in extracted_tour_names:
                best_match = None
                best_score = 0
                
                for norm_name, idx in TOUR_NAME_TO_INDEX.items():
                    # T√≠nh ƒëi·ªÉm similarity
                    score = 0
                    
                    # Check exact match
                    if tour_query == norm_name.lower():
                        score = 1.0
                    # Check contains
                    elif tour_query in norm_name.lower() or norm_name.lower() in tour_query:
                        score = 0.8
                    # Check word overlap
                    else:
                        query_words = set(tour_query.split())
                        name_words = set(norm_name.lower().split())
                        common = query_words.intersection(name_words)
                        if common:
                            score = len(common) / max(len(query_words), len(name_words))
                    
                    if score > best_score and score > 0.4:
                        best_score = score
                        best_match = idx
                
                if best_match and best_match not in comparison_tours:
                    comparison_tours.append(best_match)
            
            # Fallback: s·ª≠ d·ª•ng tour_indices n·∫øu kh√¥ng extract ƒë∆∞·ª£c
            if not comparison_tours and tour_indices:
                comparison_tours = tour_indices[:3]
            
            # N·∫øu v·∫´n kh√¥ng c√≥, t√¨m tour c√≥ t·ª´ kh√≥a trong t√™n
            if not comparison_tours:
                # T√¨m tour c√≥ t·ª´ kh√≥a "Tr∆∞·ªùng S∆°n", "B·∫°ch M√£", "Hu·∫ø"
                keywords = ['tr∆∞·ªùng s∆°n', 'b·∫°ch m√£', 'hu·∫ø', 'l·ªãch s·ª≠', 'thi·ªÅn']
                for keyword in keywords:
                    if keyword in message_lower:
                        for norm_name, idx in TOUR_NAME_TO_INDEX.items():
                            if keyword in norm_name.lower() and idx not in comparison_tours:
                                comparison_tours.append(idx)
                                if len(comparison_tours) >= 2:
                                    break
                    if len(comparison_tours) >= 2:
                        break
            
            logger.info(f"üéØ Tours to compare: {comparison_tours}")
            
            if len(comparison_tours) >= 2:
                # Thu th·∫≠p th√¥ng tin tour
                tour_data = []
                for idx in comparison_tours[:3]:  # T·ªëi ƒëa 3 tour
                    tour = TOURS_DB.get(idx)
                    if tour:
                        tour_data.append(tour)
                
                if len(tour_data) >= 2:
                    # T·∫°o b·∫£ng so s√°nh chi ti·∫øt
                    reply = "üìä **SO S√ÅNH TOUR CHI TI·∫æT** üìä\n\n"
                    
                    # T·∫°o header
                    headers = ["**TI√äU CH√ç**"]
                    for tour in tour_data:
                        # R√∫t g·ªçn t√™n tour n·∫øu qu√° d√†i
                        name = tour.name
                        if len(name) > 25:
                            name = name[:22] + "..."
                        headers.append(f"**{name}**")
                    
                    # ƒê·ªô r·ªông c·ªôt
                    col_width = 25
                    
                    # C√°c ti√™u ch√≠ so s√°nh n√¢ng cao
                    comparison_criteria = [
                        ('‚è±Ô∏è **Th·ªùi gian**', lambda t: t.duration or 'Ch∆∞a c√≥ th√¥ng tin'),
                        ('üìç **ƒê·ªãa ƒëi·ªÉm**', lambda t: (t.location[:30] + '...' if t.location and len(t.location) > 30 else t.location) or 'Ch∆∞a c√≥ th√¥ng tin'),
                        ('üí∞ **Gi√°**', lambda t: t.price[:40] + '...' if t.price and len(t.price) > 40 else t.price or 'Li√™n h·ªá'),
                        ('üéØ **Lo·∫°i h√¨nh**', lambda t: self._get_tour_category(t) if hasattr(self, '_get_tour_category') else self._extract_tour_type(t)),
                        ('üìù **ƒê·ªô ph√π h·ª£p**', lambda t: self._get_suitability(t)),
                        ('‚≠ê **ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t**', lambda t: self._get_key_features(t)),
                        ('üåø **Ho·∫°t ƒë·ªông ch√≠nh**', lambda t: self._get_main_activities(t))
                    ]
                    
                    # Th√™m h√†m helper n·∫øu ch∆∞a c√≥
                    def _extract_tour_type(tour):
                        tags = [tag.lower() for tag in (tour.tags or [])]
                        if any('history' in tag for tag in tags):
                            return "L·ªãch s·ª≠"
                        elif any('meditation' in tag for tag in tags):
                            return "Retreat/Thi·ªÅn"
                        elif any('nature' in tag for tag in tags):
                            return "Thi√™n nhi√™n"
                        elif any('family' in tag for tag in tags):
                            return "Gia ƒë√¨nh"
                        else:
                            return "Tr·∫£i nghi·ªám"
                    
                    def _get_suitability(tour):
                        tags = [tag.lower() for tag in (tour.tags or [])]
                        if any('family' in tag for tag in tags):
                            return "Gia ƒë√¨nh, Nh√≥m nh·ªè"
                        elif any('corporate' in tag for tag in tags):
                            return "C√¥ng ty, Team building"
                        elif any('solo' in tag for tag in tags):
                            return "C√° nh√¢n, C·∫∑p ƒë√¥i"
                        elif any('senior' in tag for tag in tags):
                            return "Ng∆∞·ªùi l·ªõn tu·ªïi"
                        else:
                            return "M·ªçi ƒë·ªëi t∆∞·ª£ng"
                    
                    def _get_key_features(tour):
                        features = []
                        summary = (tour.summary or '').lower()
                        
                        if 'thi·ªÅn' in summary or 'kh√≠ c√¥ng' in summary:
                            features.append("Thi·ªÅn/Kh√≠ c√¥ng")
                        if 'l·ªãch s·ª≠' in summary or 'chi·∫øn tranh' in summary:
                            features.append("Di t√≠ch l·ªãch s·ª≠")
                        if 'thi√™n nhi√™n' in summary or 'r·ª´ng' in summary:
                            features.append("Tr·∫£i nghi·ªám thi√™n nhi√™n")
                        if '·∫©m th·ª±c' in summary or 'm√≥n ƒÉn' in summary:
                            features.append("·∫®m th·ª±c ƒë·∫∑c s·∫£n")
                        
                        return ', '.join(features[:3]) if features else "Tr·∫£i nghi·ªám ƒëa d·∫°ng"
                    
                    def _get_main_activities(tour):
                        activities = []
                        summary = (tour.summary or '').lower()
                        
                        if 'trekking' in summary or 'ƒëi b·ªô' in summary:
                            activities.append("Trekking")
                        if 'thƒÉm quan' in summary or 'thƒÉm' in summary:
                            activities.append("Tham quan")
                        if 'thi·ªÅn' in summary:
                            activities.append("Thi·ªÅn ƒë·ªãnh")
                        if 'ƒÉn u·ªëng' in summary or '·∫©m th·ª±c' in summary:
                            activities.append("·∫®m th·ª±c")
                        
                        return ', '.join(activities[:3]) if activities else "Kh√°m ph√°"
                    
                    # G√°n c√°c h√†m v√†o ƒë·ªëi t∆∞·ª£ng c·ª•c b·ªô
                    import types
                    self_obj = types.SimpleNamespace()
                    self_obj._extract_tour_type = _extract_tour_type
                    self_obj._get_suitability = _get_suitability
                    self_obj._get_key_features = _get_key_features
                    self_obj._get_main_activities = _get_main_activities
                    
                    # T·∫°o b·∫£ng so s√°nh
                    for criterion_name, get_value_func in comparison_criteria:
                        row = [criterion_name]
                        for tour in tour_data:
                            value = get_value_func(tour)
                            # Gi·ªõi h·∫°n ƒë·ªô d√†i gi√° tr·ªã
                            if value and len(str(value)) > col_width - 5:
                                value = str(value)[:col_width - 8] + "..."
                            row.append(value or "N/A")
                        
                        # Format row v·ªõi ƒë·ªãnh d·∫°ng ƒë·∫πp
                        row_formatted = ""
                        for i, cell in enumerate(row):
                            if i == 0:
                                row_formatted += f"{cell.ljust(col_width)} | "
                            else:
                                row_formatted += f"{str(cell).ljust(col_width)} | "
                        
                        reply += row_formatted.rstrip(" | ") + "\n"
                        reply += "-" * (len(tour_data) + 1) * (col_width + 3) + "\n"
                    
                    # Ph√¢n t√≠ch v√† ƒë∆∞a ra khuy·∫øn ngh·ªã
                    reply += "\nüí° **PH√ÇN T√çCH & KHUY·∫æN NGH·ªä:**\n"
                    
                    # Ph√¢n t√≠ch theo ti√™u ch√≠
                    if len(tour_data) == 2:
                        tour1, tour2 = tour_data[0], tour_data[1]
                        
                        # So s√°nh gi√°
                        price1 = self._extract_price_value(tour1.price) if hasattr(tour1, 'price') else None
                        price2 = self._extract_price_value(tour2.price) if hasattr(tour2, 'price') else None
                        
                        if price1 and price2:
                            if price1 < price2 * 0.7:
                                reply += "‚Ä¢ **V·ªÅ gi√°:** Tour 1 c√≥ gi√° t·ªët h∆°n ƒë√°ng k·ªÉ\n"
                            elif price2 < price1 * 0.7:
                                reply += "‚Ä¢ **V·ªÅ gi√°:** Tour 2 c√≥ gi√° t·ªët h∆°n ƒë√°ng k·ªÉ\n"
                            else:
                                reply += "‚Ä¢ **V·ªÅ gi√°:** Hai tour c√≥ m·ª©c gi√° t∆∞∆°ng ƒë∆∞∆°ng\n"
                        
                        # So s√°nh th·ªùi gian
                        duration1 = tour1.duration or ""
                        duration2 = tour2.duration or ""
                        
                        if '1 ng√†y' in duration1.lower() and '2 ng√†y' in duration2.lower():
                            reply += "‚Ä¢ **V·ªÅ th·ªùi gian:** Tour 1 ng·∫Øn h∆°n, ph√π h·ª£p b·∫≠n r·ªôn\n"
                            reply += "‚Ä¢ **V·ªÅ th·ªùi gian:** Tour 2 cho tr·∫£i nghi·ªám s√¢u h∆°n\n"
                        
                        # So s√°nh lo·∫°i h√¨nh
                        type1 = _extract_tour_type(tour1)
                        type2 = _extract_tour_type(tour2)
                        
                        if type1 != type2:
                            reply += f"‚Ä¢ **V·ªÅ tr·ªçng t√¢m:** Tour 1 t·∫≠p trung {type1}\n"
                            reply += f"‚Ä¢ **V·ªÅ tr·ªçng t√¢m:** Tour 2 t·∫≠p trung {type2}\n"
                    
                    # Khuy·∫øn ngh·ªã chung
                    reply += "\nüéØ **H∆Ø·ªöNG D·∫™N CH·ªåN TOUR:**\n"
                    
                    # D·ª±a tr√™n c√¢u h·ªèi c·ªßa user
                    if 'gia ƒë√¨nh' in message_lower or 'ng∆∞·ªùi l·ªõn tu·ªïi' in message_lower:
                        reply += "‚Ä¢ ∆Øu ti√™n tour c√≥ ho·∫°t ƒë·ªông nh·∫π nh√†ng\n"
                        reply += "‚Ä¢ Ch·ªçn tour c√≥ d·ªãch v·ª• h·ªó tr·ª£ t·ªët\n"
                        reply += "‚Ä¢ Xem x√©t tour c√≥ √Ω nghƒ©a l·ªãch s·ª≠, vƒÉn h√≥a\n"
                    elif 'b·∫°n tr·∫ª' in message_lower or 'nh√≥m b·∫°n' in message_lower:
                        reply += "‚Ä¢ ∆Øu ti√™n tour c√≥ ho·∫°t ƒë·ªông team building\n"
                        reply += "‚Ä¢ Ch·ªçn tour c√≥ nhi·ªÅu tr·∫£i nghi·ªám m·ªõi l·∫°\n"
                        reply += "‚Ä¢ Xem x√©t tour c√≥ chi ph√≠ h·ª£p l√Ω cho nh√≥m\n"
                    elif 'thi·ªÅn' in message_lower or 'tƒ©nh t√¢m' in message_lower:
                        reply += "‚Ä¢ ∆Øu ti√™n tour c√≥ ho·∫°t ƒë·ªông thi·ªÅn, kh√≠ c√¥ng\n"
                        reply += "‚Ä¢ Ch·ªçn tour t·∫°i kh√¥ng gian y√™n tƒ©nh\n"
                        reply += "‚Ä¢ Xem x√©t tour c√≥ h∆∞·ªõng d·∫´n vi√™n chuy√™n m√¥n\n"
                    else:
                        reply += "‚Ä¢ X√°c ƒë·ªãnh r√µ m·ª•c ƒë√≠ch chuy·∫øn ƒëi\n"
                        reply += "‚Ä¢ C√¢n nh·∫Øc ng√¢n s√°ch v√† th·ªùi gian\n"
                        reply += "‚Ä¢ Xem x√©t s·ªü th√≠ch v√† nhu c·∫ßu nh√≥m\n"
                    
                    reply += "\nüìû **C·∫ßn t∆∞ v·∫•n th√™m? G·ªçi ngay:** 0332510486"
                else:
                    reply = "Kh√¥ng t√¨m th·∫•y ƒë·ªß th√¥ng tin tour ƒë·ªÉ so s√°nh. Vui l√≤ng cung c·∫•p t√™n tour c·ª• th·ªÉ ho·∫∑c li√™n h·ªá hotline 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n."
            else:
                reply = "ƒê·ªÉ so s√°nh tour, vui l√≤ng cho bi·∫øt t√™n 2-3 tour c·ª• th·ªÉ. V√≠ d·ª•:\n"
                reply += "‚Ä¢ 'So s√°nh tour B·∫°ch M√£ v√† tour Tr∆∞·ªùng S∆°n'\n"
                reply += "‚Ä¢ 'Tour n√†o t·ªët h∆°n gi·ªØa M∆∞a ƒê·ªè v√† Ng·ªçn L·ª≠a Tr∆∞·ªùng S∆°n?'\n"
                reply += "‚Ä¢ 'Ph√¢n bi·ªát tour l·ªãch s·ª≠ v√† tour thi√™n nhi√™n'\n\n"
                reply += "üìû **T∆∞ v·∫•n ch·ªçn tour:** 0332510486"
        
        # üîπ CASE 4: ENHANCED RECOMMENDATION SYSTEM
        elif 'recommendation' in detected_intents or any(keyword in message_lower for keyword in ['ph√π h·ª£p', 'g·ª£i √Ω', 'ƒë·ªÅ xu·∫•t', 't∆∞ v·∫•n', 'n√™n ƒëi']):
            logger.info("üéØ Processing enhanced recommendation request")
            
            # Advanced user profile extraction
            user_profile = {
                'group_type': None,
                'age_group': None,
                'interests': [],
                'budget_range': None,
                'time_constraint': None,
                'preferred_location': None,
                'special_requirements': []
            }
            
            # Extract group type
            group_keywords = {
                'family': ['gia ƒë√¨nh', 'con nh·ªè', 'tr·∫ª em', 'b·ªë m·∫π', '√¥ng b√†', 'ƒëa th·∫ø h·ªá'],
                'senior': ['ng∆∞·ªùi l·ªõn tu·ªïi', 'cao tu·ªïi', 'c·ª±u chi·∫øn binh', 'veteran', '√¥ng b√†'],
                'friends': ['nh√≥m b·∫°n', 'b·∫°n b√®', 'sinh vi√™n', 'b·∫°n tr·∫ª', 'thanh ni√™n'],
                'corporate': ['c√¥ng ty', 'team building', 'doanh nghi·ªáp', 'nh√¢n vi√™n', 'ƒë·ªìng nghi·ªáp'],
                'couple': ['c·∫∑p ƒë√¥i', 'ƒë√¥i l·ª©a', 'ng∆∞·ªùi y√™u', 't√¨nh nh√¢n'],
                'solo': ['m·ªôt m√¨nh', 'ƒëi l·∫ª', 'solo', 'c√° nh√¢n']
            }
            
            for group_type, keywords in group_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    user_profile['group_type'] = group_type
                    break
            
            # Extract interests
            interest_keywords = {
                'history': ['l·ªãch s·ª≠', 'di t√≠ch', 'chi·∫øn tranh', 'tri √¢n', 'k√Ω ·ª©c', 'c·ªï'],
                'nature': ['thi√™n nhi√™n', 'r·ª´ng', 'n√∫i', 'c√¢y', 'su·ªëi', 'kh√¥ng kh√≠ trong l√†nh'],
                'meditation': ['thi·ªÅn', 'yoga', 'tƒ©nh t√¢m', 'ch·ªØa l√†nh', 'retreat', 'kh√≠ c√¥ng'],
                'culture': ['vƒÉn h√≥a', 'truy·ªÅn th·ªëng', '·∫©m th·ª±c', 'ƒë·∫∑c s·∫£n', 'phong t·ª•c'],
                'adventure': ['phi√™u l∆∞u', 'm·∫°o hi·ªÉm', 'kh√°m ph√°', 'tr·∫£i nghi·ªám m·ªõi'],
                'relaxation': ['ngh·ªâ ng∆°i', 'th∆∞ gi√£n', 'nh·∫π nh√†ng', 'kh√¥ng v·ªôi', 'ch·∫≠m r√£i'],
                'photography': ['ch·ª•p ·∫£nh', 'nhi·∫øp ·∫£nh', 's·ªëng ·∫£o', 'check-in', 'ƒë·∫πp']
            }
            
            for interest, keywords in interest_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    if interest not in user_profile['interests']:
                        user_profile['interests'].append(interest)
            
            # Extract budget
            budget_patterns = [
                r'gi√° r·∫ª|ti·∫øt ki·ªám|kinh t·∫ø|d∆∞·ªõi\s+(\d+)',
                r't·∫ßm trung|trung b√¨nh|v·ª´a ph·∫£i|kho·∫£ng\s+(\d+)',
                r'cao c·∫•p|sang tr·ªçng|premium|tr√™n\s+(\d+)'
            ]
            
            for i, pattern in enumerate(budget_patterns):
                if re.search(pattern, message_lower):
                    if i == 0:
                        user_profile['budget_range'] = 'low'
                    elif i == 1:
                        user_profile['budget_range'] = 'medium'
                    else:
                        user_profile['budget_range'] = 'high'
                    break
            
            # Extract time constraint
            if '1 ng√†y' in message_lower or 'ng·∫Øn ng√†y' in message_lower:
                user_profile['time_constraint'] = '1day'
            elif '2 ng√†y' in message_lower or 'cu·ªëi tu·∫ßn' in message_lower:
                user_profile['time_constraint'] = '2days'
            elif '3 ng√†y' in message_lower or 'd√†i ng√†y' in message_lower:
                user_profile['time_constraint'] = '3+days'
            
            # Extract location preference
            locations = ['hu·∫ø', 'qu·∫£ng tr·ªã', 'b·∫°ch m√£', 'tr∆∞·ªùng s∆°n', 'ƒë√¥ng h√†', 'mi·ªÅn trung']
            for loc in locations:
                if loc in message_lower:
                    user_profile['preferred_location'] = loc
                    break
            
            # Special requirements
            special_keywords = {
                'accessible': ['d·ªÖ ƒëi', 'tho·∫£i m√°i', 'nh·∫π nh√†ng', '√≠t di chuy·ªÉn'],
                'educational': ['h·ªçc h·ªèi', 'gi√°o d·ª•c', 't√¨m hi·ªÉu', 'ki·∫øn th·ª©c'],
                'luxury': ['ti·ªán nghi', 'ƒë·∫ßy ƒë·ªß', 'cao c·∫•p', 'sang'],
                'eco': ['xanh', 'b·ªÅn v·ªØng', 'm√¥i tr∆∞·ªùng', 'thi√™n nhi√™n']
            }
            
            for req, keywords in special_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    user_profile['special_requirements'].append(req)
            
            logger.info(f"üéØ User profile extracted: {user_profile}")
            
            # SCORING SYSTEM N√ÇNG C·∫§P
            matching_tours = []
            
            for idx, tour in TOURS_DB.items():
                score = 0
                reasons = []
                match_details = {}
                
                # 1. Group type matching (30%)
                if user_profile['group_type']:
                    tour_tags = [tag.lower() for tag in (tour.tags or [])]
                    
                    if user_profile['group_type'] == 'family':
                        if any('family' in tag for tag in tour_tags):
                            score += 30
                            reasons.append("ph√π h·ª£p gia ƒë√¨nh")
                            match_details['group'] = 'excellent'
                        elif not any('adventure' in tag or 'extreme' in tag for tag in tour_tags):
                            score += 15
                            reasons.append("c√≥ th·ªÉ ph√π h·ª£p gia ƒë√¨nh")
                            match_details['group'] = 'good'
                    
                    elif user_profile['group_type'] == 'senior':
                        if any('senior' in tag or 'accessible' in tag for tag in tour_tags):
                            score += 30
                            reasons.append("thi·∫øt k·∫ø cho ng∆∞·ªùi l·ªõn tu·ªïi")
                            match_details['group'] = 'excellent'
                        elif any('nature' in tag or 'meditation' in tag for tag in tour_tags):
                            score += 20
                            reasons.append("nh·∫π nh√†ng, ph√π h·ª£p l·ªõn tu·ªïi")
                            match_details['group'] = 'good'
                    
                    elif user_profile['group_type'] == 'friends':
                        if any('friends' in tag or 'group' in tag for tag in tour_tags):
                            score += 30
                            reasons.append("ph√π h·ª£p nh√≥m b·∫°n")
                            match_details['group'] = 'excellent'
                        elif any('adventure' in tag or 'experience' in tag for tag in tour_tags):
                            score += 20
                            reasons.append("nhi·ªÅu ho·∫°t ƒë·ªông nh√≥m")
                            match_details['group'] = 'good'
                
                # 2. Interest matching (40%)
                if user_profile['interests']:
                    tour_summary = (tour.summary or '').lower()
                    tour_tags = [tag.lower() for tag in (tour.tags or [])]
                    
                    for interest in user_profile['interests']:
                        if interest == 'history':
                            if any('history' in tag for tag in tour_tags) or 'l·ªãch s·ª≠' in tour_summary:
                                score += 40
                                reasons.append("tr·ªçng t√¢m l·ªãch s·ª≠")
                                match_details['interest'] = 'history'
                                break
                        
                        elif interest == 'nature':
                            if any('nature' in tag for tag in tour_tags) or 'thi√™n nhi√™n' in tour_summary:
                                score += 40
                                reasons.append("tr·∫£i nghi·ªám thi√™n nhi√™n")
                                match_details['interest'] = 'nature'
                                break
                        
                        elif interest == 'meditation':
                            if any('meditation' in tag for tag in tour_tags) or 'thi·ªÅn' in tour_summary:
                                score += 40
                                reasons.append("c√≥ ho·∫°t ƒë·ªông thi·ªÅn/retreat")
                                match_details['interest'] = 'meditation'
                                break
                        
                        elif interest == 'culture':
                            if any('culture' in tag for tag in tour_tags) or 'vƒÉn h√≥a' in tour_summary:
                                score += 40
                                reasons.append("kh√°m ph√° vƒÉn h√≥a")
                                match_details['interest'] = 'culture'
                                break
                
                # 3. Budget matching (15%)
                if user_profile['budget_range'] and tour.price:
                    price_value = self._extract_price_value(tour.price)
                    
                    if price_value:
                        if user_profile['budget_range'] == 'low' and price_value < 1500000:
                            score += 15
                            reasons.append("gi√° h·ª£p l√Ω")
                            match_details['budget'] = 'good'
                        elif user_profile['budget_range'] == 'medium' and 1500000 <= price_value <= 3000000:
                            score += 15
                            reasons.append("gi√° t·∫ßm trung")
                            match_details['budget'] = 'good'
                        elif user_profile['budget_range'] == 'high' and price_value > 3000000:
                            score += 15
                            reasons.append("d·ªãch v·ª• cao c·∫•p")
                            match_details['budget'] = 'good'
                
                # 4. Time constraint matching (10%)
                if user_profile['time_constraint'] and tour.duration:
                    duration_lower = tour.duration.lower()
                    
                    if user_profile['time_constraint'] == '1day' and '1 ng√†y' in duration_lower:
                        score += 10
                        reasons.append("ƒë√∫ng 1 ng√†y")
                        match_details['time'] = 'perfect'
                    elif user_profile['time_constraint'] == '2days' and '2 ng√†y' in duration_lower:
                        score += 10
                        reasons.append("ƒë√∫ng 2 ng√†y")
                        match_details['time'] = 'perfect'
                    elif user_profile['time_constraint'] == '3+days' and ('3 ng√†y' in duration_lower or '4 ng√†y' in duration_lower):
                        score += 10
                        reasons.append("ƒëa ng√†y nh∆∞ y√™u c·∫ßu")
                        match_details['time'] = 'perfect'
                
                # 5. Location preference (5%)
                if user_profile['preferred_location'] and tour.location:
                    if user_profile['preferred_location'] in tour.location.lower():
                        score += 5
                        reasons.append(f"t·∫°i {user_profile['preferred_location']}")
                        match_details['location'] = 'exact'
                
                # 6. Special requirements bonus
                if user_profile['special_requirements']:
                    tour_summary = (tour.summary or '').lower()
                    
                    if 'accessible' in user_profile['special_requirements']:
                        if 'd·ªÖ d√†ng' in tour_summary or 'tho·∫£i m√°i' in tour_summary:
                            score += 5
                            reasons.append("d·ªÖ ti·∫øp c·∫≠n")
                    
                    if 'educational' in user_profile['special_requirements']:
                        if 'h·ªçc h·ªèi' in tour_summary or 't√¨m hi·ªÉu' in tour_summary:
                            score += 5
                            reasons.append("gi√°o d·ª•c, h·ªçc h·ªèi")
                    
                    if 'eco' in user_profile['special_requirements']:
                        if any('nature' in tag or 'eco' in tag for tag in (tour.tags or [])):
                            score += 5
                            reasons.append("th√¢n thi·ªán m√¥i tr∆∞·ªùng")
                
                if score > 0:
                    matching_tours.append((idx, score, reasons, match_details))
            
            # S·∫Øp x·∫øp theo ƒëi·ªÉm
            matching_tours.sort(key=lambda x: x[1], reverse=True)
            
            # ================== FALLBACK STRATEGIES ==================
            # Strategy 1: Content-based fallback
            if not matching_tours:
                logger.info("üîÑ Trying content-based fallback")
                content_matches = []
                
                for idx, tour in TOURS_DB.items():
                    content_score = 0
                    content_reasons = []
                    
                    # Ki·ªÉm tra t·ª´ kh√≥a trong summary
                    summary = (tour.summary or '').lower()
                    query_words = [word for word in message_lower.split() if len(word) > 3]
                    
                    for word in query_words:
                        if word in summary:
                            content_score += 10
                            content_reasons.append(f"c√≥ t·ª´ kh√≥a '{word}'")
                    
                    if content_score > 0:
                        content_matches.append((idx, content_score, content_reasons, {}))
                
                if content_matches:
                    content_matches.sort(key=lambda x: x[1], reverse=True)
                    matching_tours = content_matches[:5]
                    logger.info(f"üîç Content-based matches found: {len(matching_tours)} tours")
            
            # Strategy 2: Popular tours fallback
            if not matching_tours:
                logger.info("üîÑ Trying popular tours fallback")
                # Ch·ªçn c√°c tour ph·ªï bi·∫øn d·ª±a tr√™n tags v√† duration
                popular_tours = []
                for idx, tour in TOURS_DB.items():
                    popularity_score = 0
                    
                    # Tour 1-2 ng√†y ph·ªï bi·∫øn h∆°n
                    if tour.duration and ('1 ng√†y' in tour.duration.lower() or '2 ng√†y' in tour.duration.lower()):
                        popularity_score += 20
                    
                    # Tour c√≥ price r√µ r√†ng
                    if tour.price and 'li√™n h·ªá' not in tour.price.lower():
                        popularity_score += 10
                    
                    # Tour c√≥ summary d√†i (nhi·ªÅu th√¥ng tin)
                    if tour.summary and len(tour.summary) > 100:
                        popularity_score += 10
                    
                    if popularity_score > 0:
                        popular_tours.append((idx, popularity_score, ["tour ph·ªï bi·∫øn"], {}))
                
                if popular_tours:
                    popular_tours.sort(key=lambda x: x[1], reverse=True)
                    matching_tours = popular_tours[:3]
                    logger.info(f"üîç Popular tours fallback: {len(matching_tours)} tours")
            
            # Strategy 3: Last resort - random 2 tours
            if not matching_tours and TOURS_DB:
                logger.info("üîÑ Last resort: selecting 2 random tours")
                import random
                all_indices = list(TOURS_DB.keys())
                if len(all_indices) >= 2:
                    random_indices = random.sample(all_indices, min(2, len(all_indices)))
                    matching_tours = [(idx, 10, ["tour ti√™u bi·ªÉu"], {}) for idx in random_indices]
            
            # ================== GENERATE RECOMMENDATION RESPONSE ==================
            if matching_tours:
                # L∆∞u recommendations v√†o context
                context.last_recommended_tours = [idx for idx, _, _, _ in matching_tours]
                
                # Ph√¢n lo·∫°i recommendations
                excellent_matches = [t for t in matching_tours if t[1] >= 60]
                good_matches = [t for t in matching_tours if 30 <= t[1] < 60]
                other_matches = [t for t in matching_tours if t[1] < 30]
                
                reply = "üéØ **ƒê·ªÄ XU·∫§T TOUR TH√îNG MINH** üéØ\n\n"
                
                # Hi·ªÉn th·ªã th√¥ng tin user profile
                if any([user_profile['group_type'], user_profile['interests'], user_profile['budget_range']]):
                    reply += "üìã **D·ª∞A TR√äN Y√äU C·∫¶U C·ª¶A B·∫†N:**\n"
                    
                    if user_profile['group_type']:
                        group_names = {
                            'family': 'Gia ƒë√¨nh',
                            'senior': 'Ng∆∞·ªùi l·ªõn tu·ªïi/C·ª±u chi·∫øn binh',
                            'friends': 'Nh√≥m b·∫°n',
                            'corporate': 'C√¥ng ty/Team building',
                            'couple': 'C·∫∑p ƒë√¥i',
                            'solo': 'ƒêi m·ªôt m√¨nh'
                        }
                        reply += f"‚Ä¢ **ƒê·ªëi t∆∞·ª£ng:** {group_names.get(user_profile['group_type'], user_profile['group_type'])}\n"
                    
                    if user_profile['interests']:
                        interest_names = {
                            'history': 'L·ªãch s·ª≠',
                            'nature': 'Thi√™n nhi√™n',
                            'meditation': 'Thi·ªÅn/Retreat',
                            'culture': 'VƒÉn h√≥a/·∫®m th·ª±c',
                            'adventure': 'Phi√™u l∆∞u',
                            'relaxation': 'Th∆∞ gi√£n',
                            'photography': 'Ch·ª•p ·∫£nh'
                        }
                        interests_str = ', '.join([interest_names.get(i, i) for i in user_profile['interests'][:3]])
                        reply += f"‚Ä¢ **S·ªü th√≠ch:** {interests_str}\n"
                    
                    if user_profile['budget_range']:
                        budget_names = {
                            'low': 'Ti·∫øt ki·ªám (d∆∞·ªõi 1.5 tri·ªáu)',
                            'medium': 'T·∫ßm trung (1.5-3 tri·ªáu)',
                            'high': 'Cao c·∫•p (tr√™n 3 tri·ªáu)'
                        }
                        reply += f"‚Ä¢ **Ng√¢n s√°ch:** {budget_names.get(user_profile['budget_range'], 'Kh√¥ng x√°c ƒë·ªãnh')}\n"
                    
                    reply += "\n"
                
                # Top recommendations (xu·∫•t s·∫Øc)
                if excellent_matches:
                    reply += "üèÜ **PH√ô H·ª¢P NH·∫§T V·ªöI B·∫†N**\n\n"
                    
                    for idx, score, reasons, details in excellent_matches[:2]:
                        tour = TOURS_DB.get(idx)
                        if tour:
                            # T√≠nh ph·∫ßn trƒÉm ph√π h·ª£p
                            match_percent = min(100, int(score))
                            
                            reply += f"**{tour.name}** ({match_percent}% ph√π h·ª£p)\n"
                            reply += f"‚úÖ **L√Ω do ƒë·ªÅ xu·∫•t:** {', '.join(reasons[:3])}\n"
                            
                            if tour.duration:
                                reply += f"‚è±Ô∏è **Th·ªùi gian:** {tour.duration}\n"
                            if tour.location:
                                location_short = tour.location[:50] + "..." if len(tour.location) > 50 else tour.location
                                reply += f"üìç **ƒê·ªãa ƒëi·ªÉm:** {location_short}\n"
                            if tour.price:
                                price_short = tour.price[:80] + "..." if len(tour.price) > 80 else tour.price
                                reply += f"üí∞ **Gi√°:** {price_short}\n"
                            
                            # Th√™m ƒëi·ªÉm n·ªïi b·∫≠t t·ª´ summary
                            if tour.summary:
                                # L·∫•y c√¢u ƒë·∫ßu ti√™n c·ªßa summary
                                first_sentence = tour.summary.split('.')[0]
                                if len(first_sentence) > 100:
                                    first_sentence = first_sentence[:100] + "..."
                                if first_sentence:
                                    reply += f"‚ú® **ƒêi·ªÉm n·ªïi b·∫≠t:** {first_sentence}\n"
                            
                            reply += "\n"
                
                # Good recommendations
                if good_matches and (not excellent_matches or len(excellent_matches) < 2):
                    reply += "ü•à **L·ª∞A CH·ªåN T·ªêT KH√ÅC**\n\n"
                    
                    display_count = min(2, len(good_matches))
                    for idx, score, reasons, details in good_matches[:display_count]:
                        tour = TOURS_DB.get(idx)
                        if tour:
                            match_percent = min(100, int(score))
                            reply += f"‚Ä¢ **{tour.name}** ({match_percent}%)\n"
                            
                            if tour.duration:
                                reply += f"  ‚è±Ô∏è {tour.duration}"
                            if tour.location:
                                loc_short = tour.location[:30] + "..." if len(tour.location) > 30 else tour.location
                                reply += f" | üìç {loc_short}"
                            reply += "\n"
                
                # Other recommendations (n·∫øu c·∫ßn)
                if other_matches and (not excellent_matches and not good_matches):
                    reply += "üìã **C√ÅC L·ª∞A CH·ªåN KH√ÅC**\n\n"
                    
                    for idx, score, reasons, details in other_matches[:2]:
                        tour = TOURS_DB.get(idx)
                        if tour:
                            reply += f"‚Ä¢ **{tour.name}**\n"
                            if tour.duration:
                                reply += f"  ‚è±Ô∏è {tour.duration}\n"
                
                # Personalized advice
                reply += "\nüí° **L·ªúI KHUY√äN C√Å NH√ÇN H√ìA:**\n"
                
                if user_profile['group_type'] == 'senior' or 'c·ª±u chi·∫øn binh' in message_lower:
                    reply += "‚Ä¢ **V·ªõi c·ª±u chi·∫øn binh:** Ch·ªçn tour c√≥ l·ªãch tr√¨nh nh·∫π nh√†ng, √Ω nghƒ©a tri √¢n\n"
                    reply += "‚Ä¢ **L∆∞u √Ω:** Th√¥ng b√°o tr∆∞·ªõc v·ªÅ nhu c·∫ßu ƒë·∫∑c bi·ªát (n·∫øu c√≥)\n"
                    reply += "‚Ä¢ **∆Øu ƒë√£i:** C·ª±u chi·∫øn binh ƒë∆∞·ª£c gi·∫£m 5-10% gi√° tour\n\n"
                    
                    # ƒê·∫∑c bi·ªát t√¨m tour cho c·ª±u chi·∫øn binh
                    veteran_tours = []
                    for idx, tour in TOURS_DB.items():
                        if tour.summary and any(word in tour.summary.lower() for word in ['l·ªãch s·ª≠', 'tri √¢n', 'chi·∫øn tranh', 'k√Ω ·ª©c']):
                            veteran_tours.append(idx)
                    
                    if veteran_tours and veteran_tours[0] not in [t[0] for t in matching_tours]:
                        vet_tour = TOURS_DB.get(veteran_tours[0])
                        if vet_tour:
                            reply += f"üéñÔ∏è **G·ª¢I √ù ƒê·∫∂C BI·ªÜT:** {vet_tour.name}\n"
                            reply += f"   ‚è±Ô∏è {vet_tour.duration or 'N/A'} | üìç {vet_tour.location[:40] if vet_tour.location else 'N/A'}\n\n"
                
                elif user_profile['group_type'] == 'family':
                    reply += "‚Ä¢ **V·ªõi gia ƒë√¨nh:** ∆Øu ti√™n tour c√≥ ho·∫°t ƒë·ªông ƒëa d·∫°ng cho m·ªçi l·ª©a tu·ªïi\n"
                    reply += "‚Ä¢ **L∆∞u √Ω:** Ki·ªÉm tra ƒë·ªô tu·ªïi ph√π h·ª£p v√† ƒëi·ªÅu ki·ªán s·ª©c kh·ªèe\n"
                    reply += "‚Ä¢ **∆Øu ƒë√£i:** Tr·∫ª em ƒë∆∞·ª£c gi·∫£m 30-50% t√πy ƒë·ªô tu·ªïi\n\n"
                
                elif 'retreat' in message_lower or 'thi·ªÅn' in message_lower:
                    reply += "‚Ä¢ **V·ªõi retreat:** Ch·ªçn kh√¥ng gian y√™n tƒ©nh, h∆∞·ªõng d·∫´n vi√™n chuy√™n m√¥n\n"
                    reply += "‚Ä¢ **L∆∞u √Ω:** Mang theo trang ph·ª•c tho·∫£i m√°i, t√¢m th·∫ø c·ªüi m·ªü\n"
                    reply += "‚Ä¢ **Hi·ªáu qu·∫£:** N√™n tham gia √≠t nh·∫•t 2 ng√†y ƒë·ªÉ c√≥ tr·∫£i nghi·ªám s√¢u\n\n"
                
                else:
                    reply += "‚Ä¢ X√°c ƒë·ªãnh r√µ m·ª•c ƒë√≠ch chuy·∫øn ƒëi (ngh·ªâ d∆∞·ª°ng, kh√°m ph√°, h·ªçc h·ªèi)\n"
                    reply += "‚Ä¢ C√¢n nh·∫Øc th·ªùi gian v√† ng√¢n s√°ch th·ª±c t·∫ø\n"
                    reply += "‚Ä¢ ƒê·ªçc k·ªπ th√¥ng tin tour v√† chu·∫©n b·ªã tinh th·∫ßn ph√π h·ª£p\n\n"
                
                reply += "üìû **C·∫¶N T∆Ø V·∫§N CHI TI·∫æT?**\n"
                reply += "G·ªçi ngay **0332510486** ƒë·ªÉ:\n"
                reply += "‚Ä¢ Nh·∫≠n l·ªãch tr√¨nh chi ti·∫øt v√† b√°o gi√° ch√≠nh x√°c\n"
                reply += "‚Ä¢ ƒê∆∞·ª£c t∆∞ v·∫•n tour ri√™ng theo nhu c·∫ßu c·ª• th·ªÉ\n"
                reply += "‚Ä¢ ƒê·∫∑t tour v·ªõi ∆∞u ƒë√£i t·ªët nh·∫•t\n"
                
                # L∆∞u user profile v√†o context
                context.user_profile.update(user_profile)
            
            else:
                # No tours found - use intelligent response
                if client and HAS_OPENAI:
                    try:
                        prompt = f"""B·∫°n l√† t∆∞ v·∫•n vi√™n Ruby Wings chuy√™n nghi·ªáp. Kh√°ch h√†ng h·ªèi: "{user_message}"

D·ªÆ LI·ªÜU RUBY WINGS:
- Chuy√™n tour tr·∫£i nghi·ªám: l·ªãch s·ª≠, thi√™n nhi√™n, retreat
- 32 tour ƒëa d·∫°ng t·ª´ 1-4 ng√†y
- Ph√π h·ª£p m·ªçi ƒë·ªëi t∆∞·ª£ng: gia ƒë√¨nh, nh√≥m, c√° nh√¢n
- ƒê·ªãa b√†n: Hu·∫ø, Qu·∫£ng Tr·ªã, B·∫°ch M√£, Tr∆∞·ªùng S∆°n
- Hotline: 0332510486

Y√äU C·∫¶U:
1. Th·ª´a nh·∫≠n ch∆∞a t√¨m th·∫•y tour ph√π h·ª£p ngay l·∫≠p t·ª©c
2. H·ªèi th√™m 2-3 c√¢u h·ªèi ƒë·ªÉ hi·ªÉu r√µ nhu c·∫ßu kh√°ch
3. G·ª£i √Ω 3 lo·∫°i tour ph·ªï bi·∫øn c·ªßa Ruby Wings
4. Khuy·∫øn kh√≠ch li√™n h·ªá hotline ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt

Tr·∫£ l·ªùi t·ª± nhi√™n, th√¢n thi·ªán, chuy√™n nghi·ªáp."""

                        response = client.chat.completions.create(
                            model=CHAT_MODEL,
                            messages=[
                                {"role": "system", "content": prompt},
                                {"role": "user", "content": user_message}
                            ],
                            temperature=0.7,
                            max_tokens=350
                        )
                        
                        if response.choices:
                            reply = response.choices[0].message.content or ""
                        else:
                            reply = "ƒê·ªÉ t√¥i t∆∞ v·∫•n tour ph√π h·ª£p nh·∫•t, b·∫°n c√≥ th·ªÉ cho bi·∫øt th√™m:\n‚Ä¢ S·ªë ng∆∞·ªùi v√† ƒë·ªô tu·ªïi tham gia\n‚Ä¢ S·ªü th√≠ch ch√≠nh (thi√™n nhi√™n, l·ªãch s·ª≠, ngh·ªâ d∆∞·ª°ng)\n‚Ä¢ Ng√¢n s√°ch d·ª± ki·∫øn v√† th·ªùi gian c√≥ th·ªÉ ƒëi\n\nüìû Ho·∫∑c g·ªçi ngay 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n nhanh!"
                    
                    except Exception as e:
                        logger.error(f"OpenAI recommendation error: {e}")
                        reply = "Ruby Wings c√≥ nhi·ªÅu tour ƒëa d·∫°ng ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa b·∫°n. Vui l√≤ng li√™n h·ªá hotline 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt v√† ƒë·ªÅ xu·∫•t tour ri√™ng."
                else:
                    reply = "ƒê·ªÉ t∆∞ v·∫•n tour ph√π h·ª£p nh·∫•t, vui l√≤ng cung c·∫•p th√™m th√¥ng tin ho·∫∑c li√™n h·ªá tr·ª±c ti·∫øp hotline 0332510486."
        
        # üîπ CASE 5: GENERAL INFORMATION - N√ÇNG C·∫§P
        elif 'general_info' in detected_intents or any(keyword in message_lower for keyword in ['gi·ªõi thi·ªáu', 'l√† g√¨', 'th·∫ø n√†o', 's·ª© m·ªánh', 'gi√° tr·ªã', 'tri·∫øt l√Ω']):
            logger.info("üèõÔ∏è Processing enhanced general information request")
            
            # X√°c ƒë·ªãnh lo·∫°i th√¥ng tin c·ª• th·ªÉ
            if any(word in message_lower for word in ['s·ª© m·ªánh', 'mission', 'm·ª•c ƒë√≠ch']):
                reply = "üåü **S·ª® M·ªÜNH RUBY WINGS** üåü\n\n"
                reply += "Ruby Wings ra ƒë·ªùi v·ªõi s·ª© m·ªánh:\n\n"
                reply += "üéØ **1. K·∫æT N·ªêI QU√Å KH·ª® - HI·ªÜN T·∫†I:**\n"
                reply += "‚Ä¢ T·∫°o c·∫ßu n·ªëi gi·ªØa l·ªãch s·ª≠ h√†o h√πng v√† th·∫ø h·ªá h√¥m nay\n"
                reply += "‚Ä¢ Gi√∫p kh√°ch h√†ng hi·ªÉu v√† tr√¢n tr·ªçng gi√° tr·ªã l·ªãch s·ª≠\n"
                reply += "‚Ä¢ B·∫£o t·ªìn v√† ph√°t huy di s·∫£n vƒÉn h√≥a d√¢n t·ªôc\n\n"
                reply += "üéØ **2. CH·ªÆA L√ÄNH V√Ä C√ÇN B·∫∞NG:**\n"
                reply += "‚Ä¢ Mang ƒë·∫øn kh√¥ng gian retreat gi·ªØa thi√™n nhi√™n\n"
                reply += "‚Ä¢ Gi√∫p kh√°ch h√†ng t√¨m l·∫°i s·ª± b√¨nh an n·ªôi t√¢m\n"
                reply += "‚Ä¢ C√¢n b·∫±ng cu·ªôc s·ªëng qua thi·ªÅn v√† kh√≠ c√¥ng\n\n"
                reply += "üéØ **3. LAN T·ªéA GI√Å TR·ªä T√çCH C·ª∞C:**\n"
                reply += "‚Ä¢ T·∫°o tr·∫£i nghi·ªám du l·ªãch c√≥ √Ω nghƒ©a v√† chi·ªÅu s√¢u\n"
                reply += "‚Ä¢ ƒê√≥ng g√≥p cho c·ªông ƒë·ªìng v√† ph√°t tri·ªÉn b·ªÅn v·ªØng\n"
                reply += "‚Ä¢ Truy·ªÅn c·∫£m h·ª©ng s·ªëng t√≠ch c·ª±c, c√≥ m·ª•c ƒë√≠ch\n\n"
                reply += "üìû **ƒê·ªìng h√†nh c√πng s·ª© m·ªánh c·ªßa ch√∫ng t√¥i:** 0332510486"
            
            elif any(word in message_lower for word in ['gi√° tr·ªã c·ªët l√µi', 'core value', 'gi√° tr·ªã']):
                reply = "üíé **3 GI√Å TR·ªä C·ªêT L√ïI RUBY WINGS** üíé\n\n"
                reply += "**1. üèõÔ∏è T√îN VINH L·ªäCH S·ª¨ D√ÇN T·ªòC**\n"
                reply += "‚Ä¢ T·ªï ch·ª©c c√°c h√†nh tr√¨nh v·ªÅ ngu·ªìn c√≥ chi·ªÅu s√¢u\n"
                reply += "‚Ä¢ K·∫øt n·ªëi th·∫ø h·ªá tr·∫ª v·ªõi qu√° kh·ª© h√†o h√πng\n"
                reply += "‚Ä¢ B·∫£o t·ªìn v√† ph√°t huy gi√° tr·ªã di s·∫£n\n"
                reply += "‚Ä¢ T·∫°o kh√¥ng gian tri √¢n v√† t∆∞·ªüng nh·ªõ\n\n"
                reply += "**2. üåø B·∫¢O T·ªíN VƒÇN H√ìA B·∫¢N ƒê·ªäA**\n"
                reply += "‚Ä¢ ƒê∆∞a kh√°ch ƒë·∫øn v·ªõi vƒÉn h√≥a ƒë·ªãa ph∆∞∆°ng ch√¢n th·ª±c\n"
                reply += "‚Ä¢ H·ªó tr·ª£ c·ªông ƒë·ªìng v√† kinh t·∫ø ƒë·ªãa ph∆∞∆°ng\n"
                reply += "‚Ä¢ Gi·ªõi thi·ªáu ·∫©m th·ª±c, ngh·ªÅ truy·ªÅn th·ªëng ƒë·∫∑c s·∫Øc\n"
                reply += "‚Ä¢ T·∫°o t∆∞∆°ng t√°c c√≥ √Ω nghƒ©a v·ªõi ng∆∞·ªùi d√¢n\n\n"
                reply += "**3. ‚ú® LAN T·ªéA NƒÇNG L∆Ø·ª¢NG T√çCH C·ª∞C**\n"
                reply += "‚Ä¢ Thi·∫øt k·∫ø tour gi√∫p kh√°ch t√°i t·∫°o nƒÉng l∆∞·ª£ng\n"
                reply += "‚Ä¢ T·∫°o m√¥i tr∆∞·ªùng ƒë·ªÉ kh√°m ph√° b·∫£n th√¢n\n"
                reply += "‚Ä¢ Truy·ªÅn c·∫£m h·ª©ng s·ªëng ch·∫≠m, s·ªëng s√¢u\n"
                reply += "‚Ä¢ K·∫øt n·ªëi con ng∆∞·ªùi v·ªõi thi√™n nhi√™n v√† n·ªôi t√¢m\n\n"
                reply += "üìû **Tr·∫£i nghi·ªám gi√° tr·ªã c·ªët l√µi trong t·ª´ng h√†nh tr√¨nh:** 0332510486"
            
            elif 'tri·∫øt l√Ω' in message_lower or 'chu·∫©n m·ª±c' in message_lower:
                reply = self._get_philosophy_response()
            
            elif 'ruby wings' in message_lower or 'c√¥ng ty' in message_lower:
                reply = self._get_company_introduction()
            
            else:
                # D√πng AI cho c√°c c√¢u h·ªèi chung kh√°c
                if client and HAS_OPENAI:
                    try:
                        prompt = f"""B·∫°n l√† ƒë·∫°i di·ªán Ruby Wings Travel. Tr·∫£ l·ªùi c√¢u h·ªèi: "{user_message}"

TH√îNG TIN C√îNG TY:
- T√™n: Ruby Wings Travel
- Chuy√™n: Tour tr·∫£i nghi·ªám l·ªãch s·ª≠, retreat, vƒÉn h√≥a
- Tri·∫øt l√Ω: Chu·∫©n m·ª±c - Ch√¢n th√†nh - C√≥ chi·ªÅu s√¢u
- S·ª© m·ªánh: K·∫øt n·ªëi qu√° kh·ª©, ch·ªØa l√†nh hi·ªán t·∫°i, lan t·ªèa t∆∞∆°ng lai
- Gi√° tr·ªã: T√¥n vinh l·ªãch s·ª≠, b·∫£o t·ªìn vƒÉn h√≥a, lan t·ªèa nƒÉng l∆∞·ª£ng t√≠ch c·ª±c
- Hotline: 0332510486

Y√äU C·∫¶U:
1. Tr·∫£ l·ªùi ƒë√∫ng tr·ªçng t√¢m c√¢u h·ªèi
2. K·∫øt h·ª£p th√¥ng tin v·ªÅ Ruby Wings m·ªôt c√°ch t·ª± nhi√™n
3. Gi·ªçng vƒÉn chuy√™n nghi·ªáp, th√¢n thi·ªán
4. K·∫øt th√∫c b·∫±ng l·ªùi m·ªùi t√¨m hi·ªÉu tour c·ª• th·ªÉ

Tr·∫£ l·ªùi trong 200-250 t·ª´."""

                        response = client.chat.completions.create(
                            model=CHAT_MODEL,
                            messages=[
                                {"role": "system", "content": prompt},
                                {"role": "user", "content": user_message}
                            ],
                            temperature=0.6,
                            max_tokens=400
                        )
                        
                        if response.choices:
                            reply = response.choices[0].message.content or ""
                            if "0332510486" not in reply:
                                reply += "\n\nüìû **Li√™n h·ªá t∆∞ v·∫•n tour:** 0332510486"
                        else:
                            reply = "Ruby Wings l√† c√¥ng ty t·ªï ch·ª©c tour tr·∫£i nghi·ªám ƒë·∫∑c s·∫Øc v·ªõi tri·∫øt l√Ω 'Chu·∫©n m·ª±c - Ch√¢n th√†nh - C√≥ chi·ªÅu s√¢u'. Ch√∫ng t√¥i chuy√™n v·ªÅ c√°c tour l·ªãch s·ª≠, retreat thi·ªÅn ƒë·ªãnh, v√† kh√°m ph√° vƒÉn h√≥a."
                    
                    except Exception as e:
                        logger.error(f"OpenAI general info error: {e}")
                        reply = "Ruby Wings Travel chuy√™n t·ªï ch·ª©c c√°c tour tr·∫£i nghi·ªám √Ω nghƒ©a. ƒê·ªÉ bi·∫øt th√™m chi ti·∫øt, vui l√≤ng li√™n h·ªá hotline 0332510486."
                else:
                    reply = "Ruby Wings Travel - ƒê·ªìng h√†nh c√πng b·∫°n trong nh·ªØng h√†nh tr√¨nh √Ω nghƒ©a. üìû Hotline: 0332510486"
        
        # üîπ CASE 6: WELLNESS & MEDITATION INFO - N√ÇNG C·∫§P
        elif 'wellness_info' in detected_intents or any(keyword in message_lower for keyword in ['thi·ªÅn', 'yoga', 'ch·ªØa l√†nh', 'retreat', 'tƒ©nh t√¢m', 'kh√≠ c√¥ng']):
            logger.info("üïâÔ∏è Processing enhanced wellness/meditation inquiry")
            
            # T√¨m tour c√≥ ho·∫°t ƒë·ªông thi·ªÅn/retreat
            meditation_tours = []
            for idx, tour in TOURS_DB.items():
                tour_text = f"{tour.name or ''} {tour.summary or ''} {tour.style or ''}".lower()
                if any(keyword in tour_text for keyword in ['thi·ªÅn', 'yoga', 'retreat', 'tƒ©nh t√¢m', 'kh√≠ c√¥ng', 'ch·ªØa l√†nh']):
                    meditation_tours.append(idx)
            
            if meditation_tours:
                # L·∫•y th√¥ng tin chi ti·∫øt
                detailed_tours = []
                for idx in meditation_tours[:5]:  # Gi·ªõi h·∫°n 5 tour
                    tour = TOURS_DB.get(idx)
                    if tour:
                        # Ph√¢n lo·∫°i m·ª©c ƒë·ªô t·∫≠p trung v√†o thi·ªÅn
                        meditation_level = "c√≥ ho·∫°t ƒë·ªông"
                        tour_text = f"{tour.summary or ''}".lower()
                        
                        if 'thi·ªÅn ƒë·ªãnh' in tour_text or 'retreat' in tour_text:
                            meditation_level = "tr·ªçng t√¢m"
                        elif 'kh√≠ c√¥ng' in tour_text or 'yoga' in tour_text:
                            meditation_level = "k·∫øt h·ª£p"
                        
                        detailed_tours.append({
                            'tour': tour,
                            'level': meditation_level,
                            'duration': tour.duration or 'N/A',
                            'location': tour.location or 'N/A'
                        })
                
                if detailed_tours:
                    reply = "üïâÔ∏è **TOUR THI·ªÄN & RETREAT RUBY WINGS** üïâÔ∏è\n\n"
                    
                    # Ph√¢n lo·∫°i theo m·ª©c ƒë·ªô
                    focus_tours = [t for t in detailed_tours if t['level'] == 'tr·ªçng t√¢m']
                    combined_tours = [t for t in detailed_tours if t['level'] == 'k·∫øt h·ª£p']
                    activity_tours = [t for t in detailed_tours if t['level'] == 'c√≥ ho·∫°t ƒë·ªông']
                    
                    if focus_tours:
                        reply += "üéØ **TOUR RETREAT CHUY√äN S√ÇU**\n"
                        reply += "(T·∫≠p trung v√†o thi·ªÅn, kh√≠ c√¥ng, ch·ªØa l√†nh)\n\n"
                        
                        for tour_info in focus_tours[:2]:
                            tour = tour_info['tour']
                            reply += f"‚Ä¢ **{tour.name}**\n"
                            reply += f"  ‚è±Ô∏è {tour_info['duration']} | üìç {tour_info['location'][:40] if len(tour_info['location']) > 40 else tour_info['location']}\n"
                            
                            # Tr√≠ch d·∫´n ƒëi·ªÉm ƒë·∫∑c bi·ªát
                            if tour.summary:
                                # T√¨m c√¢u c√≥ t·ª´ kh√≥a thi·ªÅn
                                sentences = tour.summary.split('.')
                                meditation_sentences = [s.strip() for s in sentences if any(word in s.lower() for word in ['thi·ªÅn', 'yoga', 'kh√≠ c√¥ng', 'tƒ©nh t√¢m'])]
                                if meditation_sentences:
                                    highlight = meditation_sentences[0][:100] + "..." if len(meditation_sentences[0]) > 100 else meditation_sentences[0]
                                    reply += f"  ‚ú® {highlight}\n"
                            
                            reply += "\n"
                    
                    if combined_tours:
                        reply += "üßò **TOUR K·∫æT H·ª¢P THI·ªÄN**\n"
                        reply += "(C√≥ ho·∫°t ƒë·ªông thi·ªÅn/yoga trong l·ªãch tr√¨nh)\n\n"
                        
                        for tour_info in combined_tours[:2]:
                            tour = tour_info['tour']
                            reply += f"‚Ä¢ **{tour.name}**\n"
                            reply += f"  ‚è±Ô∏è {tour_info['duration']} | üìç {tour_info['location'][:35]}\n"
                            reply += "\n"
                    
                    if activity_tours and not (focus_tours or combined_tours):
                        reply += "üåø **TOUR C√ì HO·∫†T ƒê·ªòNG THI·ªÄN**\n\n"
                        for tour_info in activity_tours[:3]:
                            tour = tour_info['tour']
                            reply += f"‚Ä¢ **{tour.name}**\n"
                            reply += f"  ‚è±Ô∏è {tour_info['duration']} | üìç {tour_info['location'][:30]}\n"
                    
                    # Th√¥ng tin v·ªÅ l·ª£i √≠ch
                    reply += "\nüí´ **L·ª¢I √çCH THI·ªÄN & RETREAT:**\n"
                    reply += "1. **Gi·∫£m stress:** H·∫° cortisol, tƒÉng serotonin\n"
                    reply += "2. **C·∫£i thi·ªán s·ª©c kh·ªèe:** H·∫° huy·∫øt √°p, tƒÉng mi·ªÖn d·ªãch\n"
                    reply += "3. **TƒÉng t·∫≠p trung:** C·∫£i thi·ªán kh·∫£ nƒÉng ch√∫ √Ω\n"
                    reply += "4. **C√¢n b·∫±ng c·∫£m x√∫c:** Ki·ªÉm so√°t lo √¢u, tr·∫ßm c·∫£m\n"
                    reply += "5. **K·∫øt n·ªëi n·ªôi t√¢m:** Hi·ªÉu r√µ b·∫£n th√¢n h∆°n\n\n"
                    
                    reply += "üë• **ƒê·ªêI T∆Ø·ª¢NG PH√ô H·ª¢P:**\n"
                    reply += "‚Ä¢ Ng∆∞·ªùi l√†m vi·ªác cƒÉng th·∫≥ng, stress\n"
                    reply += "‚Ä¢ Mu·ªën t√¨m l·∫°i s·ª± b√¨nh an n·ªôi t√¢m\n"
                    reply += "‚Ä¢ C·∫ßn kh√¥ng gian ƒë·ªÉ suy ng·∫´m v√† ph√°t tri·ªÉn\n"
                    reply += "‚Ä¢ Mu·ªën c·∫£i thi·ªán s·ª©c kh·ªèe tinh th·∫ßn v√† th·ªÉ ch·∫•t\n\n"
                    
                    reply += "üìû **ƒê·∫∑t tour retreat thi·ªÅn:** 0332510486"
                else:
                    reply = "Ruby Wings chuy√™n t·ªï ch·ª©c c√°c tour retreat k·∫øt h·ª£p thi·ªÅn, kh√≠ c√¥ng v√† tr·ªã li·ªáu thi√™n nhi√™n. Li√™n h·ªá 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n."
            else:
                reply = "Ruby Wings c√≥ nhi·ªÅu tour k·∫øt h·ª£p ho·∫°t ƒë·ªông thi·ªÅn v√† retreat. Li√™n h·ªá 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n tour ph√π h·ª£p."
        
        # üîπ CASE 7: LOCATION & WEATHER INFO - N√ÇNG C·∫§P
        elif 'location_info' in detected_intents or 'weather_info' in detected_intents:
            logger.info("üå§Ô∏è Processing enhanced location/weather inquiry")
            
            # X√°c ƒë·ªãnh ƒë·ªãa ƒëi·ªÉm ƒë∆∞·ª£c h·ªèi
            locations = ['hu·∫ø', 'qu·∫£ng tr·ªã', 'b·∫°ch m√£', 'tr∆∞·ªùng s∆°n', 'ƒë√¥ng h√†', 'mi·ªÅn trung']
            mentioned_location = None
            
            for loc in locations:
                if loc in message_lower:
                    mentioned_location = loc
                    break
            
            if mentioned_location:
                # T√¨m tour t·∫°i ƒë·ªãa ƒëi·ªÉm n√†y
                location_tours = []
                for idx, tour in TOURS_DB.items():
                    if tour.location and mentioned_location in tour.location.lower():
                        location_tours.append(tour)
                
                if 'weather' in message_lower or 'th·ªùi ti·∫øt' in message_lower:
                    reply = self._get_weather_info(mentioned_location, location_tours)
                else:
                    reply = self._get_location_info(mentioned_location, location_tours)
            else:
                reply = "Ruby Wings t·ªï ch·ª©c tour t·∫°i nhi·ªÅu ƒë·ªãa ƒëi·ªÉm: Hu·∫ø, Qu·∫£ng Tr·ªã, B·∫°ch M√£, Tr∆∞·ªùng S∆°n, ƒê√¥ng H√†. B·∫°n quan t√¢m tour t·∫°i khu v·ª±c n√†o?"
        
        # üîπ CASE 8: FOOD & CULTURE INFO - N√ÇNG C·∫§P
        elif 'food_info' in detected_intents or 'culture_info' in detected_intents:
            reply = self._get_food_culture_response(message_lower, tour_indices)
        
        # üîπ CASE 9: SUSTAINABILITY INFO
        elif 'sustainability' in detected_intents or any(word in message_lower for word in ['b·ªÅn v·ªØng', 'm√¥i tr∆∞·ªùng', 'xanh', 'c·ªông ƒë·ªìng']):
            reply = self._get_sustainability_response()
        
        # üîπ CASE 10: EXPERIENCE INFO
        elif 'experience' in detected_intents or any(word in message_lower for word in ['tr·∫£i nghi·ªám', 'c·∫£m gi√°c', 'c·∫£m nh·∫≠n']):
            reply = self._get_experience_response(message_lower, tour_indices)
        
        # üîπ CASE 11: GROUP & CUSTOM REQUEST - N√ÇNG C·∫§P
        elif 'group_info' in detected_intents or 'custom_request' in detected_intents:
            reply = self._get_group_custom_response(message_lower)
        
        # üîπ CASE 12: BOOKING & POLICY INFO - N√ÇNG C·∫§P
        elif 'booking_info' in detected_intents or 'policy' in detected_intents:
            reply = self._get_booking_policy_response(message_lower)
        
        # üîπ CASE 13: OUT OF SCOPE QUESTIONS (x·ª≠ l√Ω b·∫±ng AI n√¢ng cao)
        else:
            logger.info("ü§ñ Processing complex/out-of-scope question with enhanced AI")
            
            # Ki·ªÉm tra m·ª©c ƒë·ªô ph·ª©c t·∫°p
            is_complex = complexity_score >= 5 or len(user_message.split()) > 20
            
            if is_complex and client and HAS_OPENAI:
                try:
                    # Chu·∫©n b·ªã context t·ª´ database
                    db_context = ""
                    if tour_indices:
                        tour_info = []
                        for idx in tour_indices[:3]:
                            tour = TOURS_DB.get(idx)
                            if tour:
                                tour_info.append(f"- {tour.name}: {tour.summary[:150] if tour.summary else 'Kh√¥ng c√≥ m√¥ t·∫£'}")
                        if tour_info:
                            db_context = "TH√îNG TIN TOUR LI√äN QUAN:\n" + "\n".join(tour_info)
                    
                    prompt = f"""B·∫°n l√† t∆∞ v·∫•n vi√™n Ruby Wings Travel chuy√™n nghi·ªáp, th√¥ng minh.

C√ÇU H·ªéI KH√ÅCH: {user_message}

{db_context}

TH√îNG TIN RUBY WINGS:
- Chuy√™n tour tr·∫£i nghi·ªám: l·ªãch s·ª≠, thi√™n nhi√™n, retreat
- Tri·∫øt l√Ω: Chu·∫©n m·ª±c - Ch√¢n th√†nh - C√≥ chi·ªÅu s√¢u
- 32 tour ƒëa d·∫°ng t·ª´ 1-4 ng√†y
- Hotline: 0332510486

Y√äU C·∫¶U:
1. Ph√¢n t√≠ch c√¢u h·ªèi v√† tr·∫£ l·ªùi ch√≠nh x√°c, th√¥ng minh
2. K·∫øt h·ª£p th√¥ng tin v·ªÅ Ruby Wings m·ªôt c√°ch t·ª± nhi√™n
3. N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, ƒë·ªÅ xu·∫•t c√°c tour ph√π h·ª£p
4. K·∫øt th√∫c b·∫±ng l·ªùi m·ªùi li√™n h·ªá hotline
5. Gi·ªçng vƒÉn: chuy√™n nghi·ªáp, th√¢n thi·ªán, nhi·ªát t√¨nh

Tr·∫£ l·ªùi trong 250-300 t·ª´."""

                    response = client.chat.completions.create(
                        model=CHAT_MODEL,
                        messages=[
                            {"role": "system", "content": prompt},
                            {"role": "user", "content": user_message}
                        ],
                        temperature=0.7,
                        max_tokens=500
                    )
                    
                    if response.choices:
                        reply = response.choices[0].message.content or ""
                    else:
                        reply = _generate_fallback_response(user_message, [], tour_indices)
                
                except Exception as e:
                    logger.error(f"OpenAI complex question error: {e}")
                    reply = _generate_fallback_response(user_message, [], tour_indices)
            else:
                # Default: Semantic search + AI
                search_results = query_index(user_message, TOP_K)
                
                if UpgradeFlags.is_enabled("2_DEDUPLICATION") and search_results:
                    search_results = DeduplicationEngine.deduplicate_passages(search_results)
                
                # Chu·∫©n b·ªã context cho AI
                context_info = {
                    'user_message': user_message,
                    'tour_indices': tour_indices,
                    'detected_intents': detected_intents,
                    'primary_intent': primary_intent,
                    'filters': mandatory_filters.to_dict() if mandatory_filters else {},
                    'complexity_score': complexity_score
                }
                
                # T·∫°o prompt th√¥ng minh
                prompt = _prepare_enhanced_llm_prompt(user_message, search_results, context_info, TOURS_DB)
                
                # G·ªçi AI
                if client and HAS_OPENAI:
                    try:
                        messages = [
                            {"role": "system", "content": prompt},
                            {"role": "user", "content": user_message}
                        ]
                        
                        response = client.chat.completions.create(
                            model=CHAT_MODEL,
                            messages=messages,
                            temperature=0.6,
                            max_tokens=600,
                            top_p=0.9,
                            frequency_penalty=0.2,
                            presence_penalty=0.1
                        )
                        
                        if response.choices:
                            reply = response.choices[0].message.content or ""
                        else:
                            reply = _generate_enhanced_fallback_response(user_message, search_results, tour_indices, TOURS_DB)
                    
                    except Exception as e:
                        logger.error(f"OpenAI general error: {e}")
                        reply = _generate_enhanced_fallback_response(user_message, search_results, tour_indices, TOURS_DB)
                else:
                    reply = _generate_enhanced_fallback_response(user_message, search_results, tour_indices, TOURS_DB)
                
                sources = [m for _, m in search_results]
        
        # ================== ENHANCE RESPONSE QUALITY ==================
        # ƒê·∫£m b·∫£o m·ªçi response ƒë·ªÅu c√≥ hotline
        if "0332510486" not in reply and "hotline" not in reply.lower() and "li√™n h·ªá" not in reply.lower():
            reply += "\n\nüìû **Hotline t∆∞ v·∫•n 24/7:** 0332510486"
        
        # Th√™m signature n·∫øu response d√†i
        if len(reply) > 300:
            if not reply.endswith("0332510486") and not reply.endswith("Hotline"):
                reply += "\n\n---\n**Ruby Wings Travel** - H√†nh tr√¨nh √Ω nghƒ©a, tr·∫£i nghi·ªám s√¢u s·∫Øc"
        
        # Gi·ªõi h·∫°n ƒë·ªô d√†i response
        if len(reply) > 2500:
            reply = reply[:2500] + "...\n\nüí° **ƒê·ªÉ bi·∫øt th√™m chi ti·∫øt, vui l√≤ng li√™n h·ªá hotline 0332510486**"
        
        # ================== UPDATE CONTEXT ==================
        # C·∫≠p nh·∫≠t tour context
        if tour_indices and len(tour_indices) > 0:
            context.current_tour = tour_indices[0]
            tour = TOURS_DB.get(tour_indices[0])
            if tour:
                context.last_tour_name = tour.name
        
        # C·∫≠p nh·∫≠t conversation history v·ªõi metadata
        context.conversation_history.append({
            'role': 'assistant',
            'message': reply,
            'timestamp': datetime.utcnow().isoformat(),
            'tour_indices': tour_indices,
            'detected_intents': detected_intents,
            'primary_intent': primary_intent,
            'complexity_score': complexity_score
        })
        
        # L∆∞u session context
        save_session_context(session_id, context)
        
        # ================== FINAL RESPONSE ==================
        processing_time = time.time() - start_time
        
        chat_response = ChatResponse(
            reply=reply,
            sources=sources,
            context={
                "session_id": session_id,
                "current_tour": getattr(context, 'current_tour', None),
                "last_tour_name": getattr(context, 'last_tour_name', None),
                "user_preferences": getattr(context, 'user_profile', {}),
                "detected_intents": detected_intents,
                "primary_intent": primary_intent,
                "processing_time_ms": int(processing_time * 1000),
                "tours_found": len(tour_indices),
                "complexity_score": complexity_score,
                "filter_applied": filter_applied
            },
            tour_indices=tour_indices,
            processing_time_ms=int(processing_time * 1000),
            from_memory=False
        )
        
        # Cache response v·ªõi key n√¢ng cao
        if UpgradeFlags.get_all_flags().get("ENABLE_CACHING", True):
            context_hash = hashlib.md5(json.dumps({
                'tour_indices': tour_indices,
                'detected_intents': detected_intents,
                'primary_intent': primary_intent,
                'complexity': complexity_score,
                'filters': mandatory_filters.to_dict() if mandatory_filters else {}
            }, sort_keys=True).encode()).hexdigest()
            
            cache_key = CacheSystem.get_cache_key(user_message, context_hash)
            CacheSystem.set(cache_key, chat_response.to_dict(), expiry=300)  # 5 ph√∫t
        
        logger.info(f"‚úÖ Processed in {processing_time:.2f}s | "
                   f"Primary Intent: {primary_intent} | "
                   f"Tours: {len(tour_indices)} | "
                   f"Complexity: {complexity_score} | "
                   f"Filters: {filter_applied}")
        
        return jsonify(chat_response.to_dict())
    
    except Exception as e:
        logger.error(f"‚ùå Chat endpoint error: {e}\n{traceback.format_exc()}")
        
        processing_time = time.time() - start_time
        
        # Enhanced error response
        error_response = ChatResponse(
            reply="‚ö° **C√≥ ch√∫t tr·ª•c tr·∫∑c k·ªπ thu·∫≠t!**\n\n"
                  "ƒê·ªôi ng≈© Ruby Wings v·∫´n s·∫µn s√†ng h·ªó tr·ª£ b·∫°n qua c√°c k√™nh sau:\n\n"
                  "üîß **GI·∫¢I PH√ÅP NHANH:**\n"
                  "1. **G·ªçi tr·ª±c ti·∫øp:** üìû 0332510486 (t∆∞ v·∫•n ngay)\n"
                  "2. **H·ªèi ƒë∆°n gi·∫£n h∆°n:** 'Tour 1 ng√†y Hu·∫ø', 'Tour gia ƒë√¨nh 2 ng√†y'\n"
                  "3. **Ch·ªçn t·ª´ danh s√°ch:**\n"
                  "   ‚Ä¢ Tour thi√™n nhi√™n B·∫°ch M√£\n"
                  "   ‚Ä¢ Tour l·ªãch s·ª≠ Tr∆∞·ªùng S∆°n\n"
                  "   ‚Ä¢ Tour retreat thi·ªÅn\n\n"
                  "‚è∞ **Ch√∫ng t√¥i ho·∫°t ƒë·ªông 24/7 ƒë·ªÉ ph·ª•c v·ª• b·∫°n t·ªët nh·∫•t!** üòä",
            sources=[],
            context={
                "error": str(e),
                "processing_time_ms": int(processing_time * 1000),
                "error_type": type(e).__name__
            },
            tour_indices=[],
            processing_time_ms=int(processing_time * 1000),
            from_memory=False
        )
        
        return jsonify(error_response.to_dict()), 500


# ================== HELPER FUNCTIONS ==================

def _extract_price_value(price_text):
    """Tr√≠ch xu·∫•t gi√° tr·ªã s·ªë t·ª´ text gi√°"""
    if not price_text:
        return None
    
    import re
    
    # T√¨m t·∫•t c·∫£ c√°c s·ªë trong text
    numbers = re.findall(r'\d[\d,\.]+', price_text)
    if not numbers:
        return None
    
    try:
        # L·∫•y s·ªë ƒë·∫ßu ti√™n v√† chuy·ªÉn ƒë·ªïi
        num_str = numbers[0].replace(',', '').replace('.', '')
        if num_str.isdigit():
            return int(num_str)
    except:
        pass
    
    return None


def _get_philosophy_response():
    """Tr·∫£ l·ªùi v·ªÅ tri·∫øt l√Ω Ruby Wings"""
    return """‚ú® **TRI·∫æT L√ù 'CHU·∫®N M·ª∞C - CH√ÇN TH√ÄNH - C√ì CHI·ªÄU S√ÇU'** ‚ú®

Tri·∫øt l√Ω n√†y th·∫•m nhu·∫ßn trong m·ªçi ho·∫°t ƒë·ªông c·ªßa Ruby Wings:

üèÜ **CHU·∫®N M·ª∞C - S·ª∞ HO√ÄN H·∫¢O TRONG T·ª™NG CHI TI·∫æT:**
‚Ä¢ Ti√™u chu·∫©n d·ªãch v·ª• cao nh·∫•t, an to√†n tuy·ªát ƒë·ªëi
‚Ä¢ Chuy√™n nghi·ªáp t·ª´ kh√¢u thi·∫øt k·∫ø ƒë·∫øn tri·ªÉn khai tour
‚Ä¢ Cam k·∫øt ch·∫•t l∆∞·ª£ng kh√¥ng th·ªèa hi·ªáp

‚ù§Ô∏è **CH√ÇN TH√ÄNH - K·∫æT N·ªêI T·ª™ TR√ÅI TIM:**
‚Ä¢ T∆∞∆°ng t√°c ch√¢n th·∫≠t v·ªõi kh√°ch h√†ng v√† c·ªông ƒë·ªìng
‚Ä¢ T∆∞ v·∫•n trung th·ª±c, minh b·∫°ch m·ªçi th√¥ng tin
‚Ä¢ ƒê·ªìng h√†nh c√πng kh√°ch h√†ng nh∆∞ ng∆∞·ªùi th√¢n

üåå **C√ì CHI·ªÄU S√ÇU - GI√Å TR·ªä B·ªÄN V·ªÆNG:**
‚Ä¢ Thi·∫øt k·∫ø tour c√≥ √Ω nghƒ©a, ƒë·ªÉ l·∫°i b√†i h·ªçc s√¢u s·∫Øc
‚Ä¢ Kh√°m ph√° b·∫£n ch·∫•t ch·ª© kh√¥ng ch·ªâ b·ªÅ n·ªïi
‚Ä¢ T·∫°o tr·∫£i nghi·ªám ch·∫°m ƒë·∫øn c·∫£m x√∫c v√† nh·∫≠n th·ª©c

üìû **Tr·∫£i nghi·ªám tri·∫øt l√Ω n√†y trong t·ª´ng h√†nh tr√¨nh:** 0332510486"""


def _get_company_introduction():
    """Tr·∫£ l·ªùi gi·ªõi thi·ªáu c√¥ng ty"""
    return """üèõÔ∏è **GI·ªöI THI·ªÜU RUBY WINGS TRAVEL** üèõÔ∏è

Ruby Wings l√† ƒë∆°n v·ªã t·ªï ch·ª©c tour du l·ªãch tr·∫£i nghi·ªám ƒë·∫∑c s·∫Øc, chuy√™n s√¢u v·ªÅ:

üéØ **3 TR·ª§ C·ªòT CH√çNH:**

1. **TOUR L·ªäCH S·ª¨ - TRI √ÇN**
   ‚Ä¢ H√†nh tr√¨nh v·ªÅ ngu·ªìn, k·∫øt n·ªëi qu√° kh·ª©
   ‚Ä¢ Tham quan di t√≠ch, t√¨m hi·ªÉu l·ªãch s·ª≠
   ‚Ä¢ Ho·∫°t ƒë·ªông tri √¢n, t∆∞·ªüng nh·ªõ

2. **TOUR RETREAT - CH·ªÆA L√ÄNH**
   ‚Ä¢ Thi·ªÅn, kh√≠ c√¥ng, yoga gi·ªØa thi√™n nhi√™n
   ‚Ä¢ Tƒ©nh t√¢m, t√°i t·∫°o nƒÉng l∆∞·ª£ng
   ‚Ä¢ K·∫øt n·ªëi v·ªõi b·∫£n th√¢n v√† v≈© tr·ª•

3. **TOUR TR·∫¢I NGHI·ªÜM - KH√ÅM PH√Å**
   ‚Ä¢ VƒÉn h√≥a, ·∫©m th·ª±c, ƒë·ªùi s·ªëng ƒë·ªãa ph∆∞∆°ng
   ‚Ä¢ Ho·∫°t ƒë·ªông t∆∞∆°ng t√°c v·ªõi c·ªông ƒë·ªìng
   ‚Ä¢ Kh√°m ph√° thi√™n nhi√™n h√πng vƒ©

‚ú® **T·∫¶M NH√åN:**
Tr·ªü th√†nh ƒë∆°n v·ªã d·∫´n ƒë·∫ßu v·ªÅ tour tr·∫£i nghi·ªám c√≥ chi·ªÅu s√¢u t·∫°i Vi·ªát Nam

üåü **S·ª® M·ªÜNH:**
Mang ƒë·∫øn h√†nh tr√¨nh √Ω nghƒ©a, k·∫øt n·ªëi con ng∆∞·ªùi v·ªõi l·ªãch s·ª≠, thi√™n nhi√™n v√† ch√≠nh m√¨nh

üìû **K·∫øt n·ªëi v·ªõi ch√∫ng t√¥i:** 0332510486"""


def _get_weather_info(location, location_tours):
    """Tr·∫£ l·ªùi th√¥ng tin th·ªùi ti·∫øt"""
    reply = f"üå§Ô∏è **TH√îNG TIN TH·ªúI TI·∫æT {location.upper()}** üå§Ô∏è\n\n"
    
    if location == 'hu·∫ø':
        reply += "**HU·∫æ - TH·ªúI TI·∫æT ƒê·∫∂C TR∆ØNG:**\n"
        reply += "‚Ä¢ **Nhi·ªát ƒë·ªô:** 18-35¬∞C (m√°t v·ªÅ ƒë√™m, ·∫•m v·ªÅ ng√†y)\n"
        reply += "‚Ä¢ **M√πa kh√¥:** Th√°ng 1-8 (√≠t m∆∞a, n·∫Øng ƒë·∫πp)\n"
        reply += "‚Ä¢ **M√πa m∆∞a:** Th√°ng 9-12 (m∆∞a nhi·ªÅu, l·ª•t c·ª•c b·ªô)\n"
        reply += "‚Ä¢ **ƒê·ªô ·∫©m:** 70-85% (cao v√†o m√πa m∆∞a)\n\n"
        
        reply += "üìÖ **TH√ÅNG L√ù T∆Ø·ªûNG ƒêI TOUR:**\n"
        reply += "‚Ä¢ **Th√°ng 1-3:** M√°t m·∫ª, √≠t m∆∞a, hoa mai n·ªü\n"
        reply += "‚Ä¢ **Th√°ng 4-6:** N·∫Øng ƒë·∫πp, ph√π h·ª£p tham quan\n"
        reply += "‚Ä¢ **Th√°ng 7-8:** N√≥ng nh∆∞ng √≠t m∆∞a, gi√° tour t·ªët\n"
        reply += "‚Ä¢ **Th√°ng 9-12:** M∆∞a nhi·ªÅu, check d·ª± b√°o k·ªπ\n\n"
        
    elif location == 'b·∫°ch m√£':
        reply += "**B·∫†CH M√É - KH√ç H·∫¨U √îN ƒê·ªöI:**\n"
        reply += "‚Ä¢ **Nhi·ªát ƒë·ªô:** 15-25¬∞C (m√°t l·∫°nh quanh nƒÉm)\n"
        reply += "‚Ä¢ **ƒê·∫∑c ƒëi·ªÉm:** S∆∞∆°ng m√π bu·ªïi s√°ng, se l·∫°nh ƒë√™m\n"
        reply += "‚Ä¢ **M√πa ƒë·∫πp:** Th√°ng 2-5 (hoa phong lan n·ªü r·ªô)\n"
        reply += "‚Ä¢ **M√πa m∆∞a:** Th√°ng 9-12 (ƒë∆∞·ªùng tr∆°n, c·∫©n th·∫≠n)\n\n"
        
        reply += "üéí **CHU·∫®N B·ªä KHI ƒêI B·∫†CH M√É:**\n"
        reply += "‚Ä¢ √Åo ·∫•m, √°o m∆∞a nh·∫π\n"
        reply += "‚Ä¢ Gi√†y trekking ch·ªëng tr∆∞·ª£t\n"
        reply += "‚Ä¢ Thu·ªëc ch·ªëng c√¥n tr√πng\n"
        reply += "‚Ä¢ ƒê√®n pin (n·∫øu ·ªü l·∫°i qua ƒë√™m)\n\n"
        
    elif location == 'tr∆∞·ªùng s∆°n':
        reply += "**TR∆Ø·ªúNG S∆†N - KH√ç H·∫¨U ƒê·∫∂C BI·ªÜT:**\n"
        reply += "‚Ä¢ **Nhi·ªát ƒë·ªô:** 18-30¬∞C (ch√™nh l·ªách ng√†y ƒë√™m l·ªõn)\n"
        reply += "‚Ä¢ **M√πa kh√¥:** Th√°ng 1-4 (ƒë·∫πp nh·∫•t ƒë·ªÉ tham quan)\n"
        reply += "‚Ä¢ **M√πa m∆∞a:** Th√°ng 5-12 (m∆∞a r·ª´ng, ·∫©m ∆∞·ªõt)\n"
        reply += "‚Ä¢ **ƒê·∫∑c ƒëi·ªÉm:** Nhi·ªÅu s∆∞∆°ng m√π, th·ªùi ti·∫øt thay ƒë·ªïi nhanh\n\n"
        
    else:
        reply += f"**{location.upper()} - KH√ç H·∫¨U MI·ªÄN TRUNG:**\n"
        reply += "‚Ä¢ **ƒê·∫∑c tr∆∞ng:** Nhi·ªát ƒë·ªõi gi√≥ m√πa\n"
        reply += "‚Ä¢ **M√πa kh√¥:** Th√°ng 1-8 (n·∫Øng n√≥ng, √≠t m∆∞a)\n"
        reply += "‚Ä¢ **M√πa m∆∞a:** Th√°ng 9-12 (m∆∞a b√£o, l≈© l·ª•t)\n"
        reply += "‚Ä¢ **L·ªùi khuy√™n:** Check d·ª± b√°o 3-5 ng√†y tr∆∞·ªõc khi ƒëi\n\n"
    
    if location_tours:
        reply += "üéØ **TOUR PH√ô H·ª¢P THEO TH·ªúI TI·∫æT:**\n"
        for tour in location_tours[:3]:
            reply += f"‚Ä¢ **{tour.name}**"
            if tour.duration:
                reply += f" ({tour.duration})"
            reply += "\n"
    
    reply += "\nüìû **T∆∞ v·∫•n tour ph√π h·ª£p th·ªùi ti·∫øt:** 0332510486"
    return reply


def _get_location_info(location, location_tours):
    """Tr·∫£ l·ªùi th√¥ng tin ƒë·ªãa ƒëi·ªÉm"""
    reply = f"üìç **TH√îNG TIN {location.upper()}** üìç\n\n"
    
    if location == 'hu·∫ø':
        reply += "**HU·∫æ - KINH ƒê√î C·ªî VI·ªÜT NAM**\n\n"
        reply += "üèõÔ∏è **DI S·∫¢N UNESCO:**\n"
        reply += "‚Ä¢ ƒê·∫°i N·ªôi, LƒÉng t·∫©m c√°c vua Nguy·ªÖn\n"
        reply += "‚Ä¢ Nh√£ nh·∫°c cung ƒë√¨nh Hu·∫ø\n"
        reply += "‚Ä¢ H·ªá th·ªëng ƒë√¨nh, ch√πa, mi·∫øu c·ªï\n\n"
        
        reply += "üçú **·∫®M TH·ª∞C ƒê·∫∂C S·∫ÆC:**\n"
        reply += "‚Ä¢ B√∫n b√≤ Hu·∫ø, c∆°m h·∫øn, b√°nh b√®o\n"
        reply += "‚Ä¢ Ch√® Hu·∫ø, m·ª©t cung ƒë√¨nh\n"
        reply += "‚Ä¢ R∆∞·ª£u ng√¥ l√†ng Chu·ªìn\n\n"
        
        reply += "üåø **THI√äN NHI√äN:**\n"
        reply += "‚Ä¢ S√¥ng H∆∞∆°ng, N√∫i Ng·ª± th∆° m·ªông\n"
        reply += "‚Ä¢ Bi·ªÉn LƒÉng C√¥, C·∫£nh D∆∞∆°ng\n"
        reply += "‚Ä¢ V∆∞·ªùn qu·ªëc gia B·∫°ch M√£\n\n"
        
    elif location == 'b·∫°ch m√£':
        reply += "**B·∫†CH M√É - V∆Ø·ªúN QU·ªêC GIA**\n\n"
        reply += "üèûÔ∏è **THI√äN NHI√äN H√ôNG Vƒ®:**\n"
        reply += "‚Ä¢ ƒê·ªô cao: 1.450m so v·ªõi m·ª±c n∆∞·ªõc bi·ªÉn\n"
        reply += "‚Ä¢ H·ªá sinh th√°i: R·ª´ng nguy√™n sinh ƒëa d·∫°ng\n"
        reply += "‚Ä¢ ƒê·ªông th·ª±c v·∫≠t: Nhi·ªÅu lo√†i qu√Ω hi·∫øm\n\n"
        
        reply += "üö∂ **HO·∫†T ƒê·ªòNG:**\n"
        reply += "‚Ä¢ Trekking kh√°m ph√° r·ª´ng\n"
        reply += "‚Ä¢ Ng·∫Øm th√°c, su·ªëi, c·∫£nh quan\n"
        reply += "‚Ä¢ Thi·ªÅn, yoga gi·ªØa thi√™n nhi√™n\n"
        reply += "‚Ä¢ Quan s√°t ƒë·ªông v·∫≠t hoang d√£\n\n"
        
        reply += "üå°Ô∏è **KH√ç H·∫¨U:**\n"
        reply += "‚Ä¢ M√°t m·∫ª quanh nƒÉm (15-25¬∞C)\n"
        reply += "‚Ä¢ S∆∞∆°ng m√π bu·ªïi s√°ng t·∫°o c·∫£m gi√°c huy·ªÅn ·∫£o\n"
        reply += "‚Ä¢ L√Ω t∆∞·ªüng ƒë·ªÉ tr√°nh n√≥ng\n\n"
        
    elif location == 'tr∆∞·ªùng s∆°n':
        reply += "**TR∆Ø·ªúNG S∆†N - D√ÉY N√öI HUY·ªÄN THO·∫†I**\n\n"
        reply += "üéñÔ∏è **L·ªäCH S·ª¨ H√ÄO H√ôNG:**\n"
        reply += "‚Ä¢ ƒê∆∞·ªùng H·ªì Ch√≠ Minh huy·ªÅn tho·∫°i\n"
        reply += "‚Ä¢ ƒê·ªãa ƒë·∫°o V·ªãnh M·ªëc, Th√†nh c·ªï Qu·∫£ng Tr·ªã\n"
        reply += "‚Ä¢ C·∫ßu Hi·ªÅn L∆∞∆°ng, s√¥ng B·∫øn H·∫£i\n\n"
        
        reply += "üë• **VƒÇN H√ìA B·∫¢N ƒê·ªäA:**\n"
        reply += "‚Ä¢ C·ªông ƒë·ªìng V√¢n Ki·ªÅu, Pa K√¥\n"
        reply += "‚Ä¢ Ki·∫øn tr√∫c nh√† s√†n truy·ªÅn th·ªëng\n"
        reply += "‚Ä¢ L·ªÖ h·ªôi, √¢m nh·∫°c d√¢n t·ªôc\n\n"
        
        reply += "üåÑ **C·∫¢NH QUAN:**\n"
        reply += "‚Ä¢ N√∫i r·ª´ng tr√πng ƒëi·ªáp\n"
        reply += "‚Ä¢ Th√°c, su·ªëi, hang ƒë·ªông\n"
        reply += "‚Ä¢ Kh√¥ng kh√≠ trong l√†nh, y√™n tƒ©nh\n\n"
    
    if location_tours:
        reply += "üéØ **TOUR RUBY WINGS T·∫†I ƒê√ÇY:**\n"
        for i, tour in enumerate(location_tours[:4], 1):
            reply += f"{i}. **{tour.name}**\n"
            if tour.duration:
                reply += f"   ‚è±Ô∏è {tour.duration}\n"
            if i == 1 and tour.price:
                price_short = tour.price[:60] + "..." if len(tour.price) > 60 else tour.price
                reply += f"   üí∞ {price_short}\n"
            reply += "\n"
    
    reply += "üìû **ƒê·∫∑t tour kh√°m ph√°:** 0332510486"
    return reply


def _get_food_culture_response(message_lower, tour_indices):
    """Tr·∫£ l·ªùi v·ªÅ ·∫©m th·ª±c v√† vƒÉn h√≥a"""
    if 'b√°nh b√®o' in message_lower or '·∫©m th·ª±c hu·∫ø' in message_lower:
        reply = "üçú **B√ÅNH B√àO HU·∫æ - ƒê·∫∂C S·∫¢N N·ªîI TI·∫æNG** üçú\n\n"
        reply += "**NGU·ªíN G·ªêC & √ù NGHƒ®A:**\n"
        reply += "‚Ä¢ M√≥n ƒÉn cung ƒë√¨nh, sau ph·ªï bi·∫øn ra d√¢n gian\n"
        reply += "‚Ä¢ T√™n g·ªçi t·ª´ h√¨nh d√°ng gi·ªëng l√° b√®o\n"
        reply += "‚Ä¢ Bi·ªÉu t∆∞·ª£ng ·∫©m th·ª±c tinh t·∫ø c·ªßa Hu·∫ø\n\n"
        
        reply += "**TH√ÄNH PH·∫¶N CH√çNH:**\n"
        reply += "‚Ä¢ B·ªôt g·∫°o h·∫•p trong ch√©n nh·ªè\n"
        reply += "‚Ä¢ Nh√¢n: T√¥m ch√°y, th·ªãt xay, m·ª° h√†nh\n"
        reply += "‚Ä¢ N∆∞·ªõc ch·∫•m: M·∫Øm n√™m Hu·∫ø ƒë·∫∑c tr∆∞ng\n"
        reply += "‚Ä¢ Rau s·ªëng: X√† l√°ch, rau th∆°m, ·ªõt xanh\n\n"
        
        reply += "**C√ÅCH TH∆Ø·ªûNG TH·ª®C:**\n"
        reply += "1. D√πng th√¨a nh·ªè x√∫c t·ª´ng ch√©n\n"
        reply += "2. Chan n∆∞·ªõc m·∫Øm v·ª´a ph·∫£i\n"
        reply += "3. ƒÇn k√®m rau s·ªëng cho c√¢n b·∫±ng\n"
        reply += "4. Nh√¢m nhi v·ªõi tr√† n√≥ng\n\n"
        
        reply += "üéØ **TR·∫¢I NGHI·ªÜM TRONG TOUR:**\n"
        reply += "‚Ä¢ **Tour ·∫®m th·ª±c Hu·∫ø:** H·ªçc l√†m b√°nh b√®o t·ª´ ngh·ªá nh√¢n\n"
        reply += "‚Ä¢ **Tour VƒÉn h√≥a:** ThƒÉm l√†ng ngh·ªÅ truy·ªÅn th·ªëng\n"
        reply += "‚Ä¢ **Tour ƒê√™m Hu·∫ø:** Th∆∞·ªüng th·ª©c t·∫°i qu√°n ƒë·∫∑c s·∫£n\n\n"
        
        reply += "üìû **ƒê·∫∑t tour ·∫©m th·ª±c Hu·∫ø:** 0332510486"
    
    elif 'vƒÉn h√≥a' in message_lower or 'l·ªãch s·ª≠' in message_lower or 'di s·∫£n' in message_lower:
        reply = "üèõÔ∏è **VƒÇN H√ìA & DI S·∫¢N MI·ªÄN TRUNG** üèõÔ∏è\n\n"
        
        reply += "**DI S·∫¢N UNESCO T·∫†I HU·∫æ:**\n"
        reply += "‚Ä¢ Qu·∫ßn th·ªÉ di t√≠ch C·ªë ƒë√¥ Hu·∫ø\n"
        reply += "‚Ä¢ Nh√£ nh·∫°c cung ƒë√¨nh Hu·∫ø\n"
        reply += "‚Ä¢ M·ªôc b·∫£n tri·ªÅu Nguy·ªÖn\n"
        reply += "‚Ä¢ Ch√¢u b·∫£n tri·ªÅu Nguy·ªÖn\n\n"
        
        reply += "**DI T√çCH L·ªäCH S·ª¨ QU·∫¢NG TR·ªä:**\n"
        reply += "‚Ä¢ Th√†nh c·ªï Qu·∫£ng Tr·ªã\n"
        reply += "‚Ä¢ ƒê·ªãa ƒë·∫°o V·ªãnh M·ªëc\n"
        reply += "‚Ä¢ C·∫ßu Hi·ªÅn L∆∞∆°ng - s√¥ng B·∫øn H·∫£i\n"
        reply += "‚Ä¢ Nghƒ©a trang Tr∆∞·ªùng S∆°n\n\n"
        
        reply += "**VƒÇN H√ìA B·∫¢N ƒê·ªäA:**\n"
        reply += "‚Ä¢ D√¢n t·ªôc V√¢n Ki·ªÅu, Pa K√¥\n"
        reply += "‚Ä¢ Ki·∫øn tr√∫c nh√† r∆∞·ªùng Hu·∫ø\n"
        reply += "‚Ä¢ L·ªÖ h·ªôi cung ƒë√¨nh, d√¢n gian\n"
        reply += "‚Ä¢ Ngh·ªÅ th·ªß c√¥ng truy·ªÅn th·ªëng\n\n"
        
        reply += "üéØ **TOUR VƒÇN H√ìA N·ªîI B·∫¨T:**\n"
        
        # T√¨m tour vƒÉn h√≥a
        culture_tours = []
        for idx, tour in TOURS_DB.items():
            tour_text = f"{tour.summary or ''}".lower()
            if any(keyword in tour_text for keyword in ['vƒÉn h√≥a', 'l·ªãch s·ª≠', 'di s·∫£n', 'di t√≠ch', 'truy·ªÅn th·ªëng']):
                culture_tours.append(tour)
        
        if culture_tours:
            for i, tour in enumerate(culture_tours[:4], 1):
                reply += f"{i}. **{tour.name}**\n"
                if tour.duration:
                    reply += f"   ‚è±Ô∏è {tour.duration}\n"
                if i <= 2 and tour.summary:
                    summary_short = tour.summary[:80] + "..." if len(tour.summary) > 80 else tour.summary
                    reply += f"   üìù {summary_short}\n"
                reply += "\n"
        else:
            reply += "‚Ä¢ M∆∞a ƒê·ªè v√† Tr∆∞·ªùng S∆°n\n"
            reply += "‚Ä¢ K√Ω ·ª©c - L·ªãch S·ª≠ v√† ƒê·∫°i Ng√†n\n"
            reply += "‚Ä¢ Di s·∫£n Hu·∫ø & ƒê·∫ßm Chu·ªìn\n"
            reply += "‚Ä¢ H√†nh tr√¨nh v·ªÅ ngu·ªìn\n\n"
        
        reply += "üìû **T∆∞ v·∫•n tour vƒÉn h√≥a:** 0332510486"
    
    else:
        reply = "Mi·ªÅn Trung Vi·ªát Nam l√† v√πng ƒë·∫•t c·ªßa:\n\n"
        reply += "üçú **·∫®M TH·ª∞C PHONG PH√ö:**\n"
        reply += "‚Ä¢ Hu·∫ø: B√∫n b√≤, b√°nh b√®o, c∆°m h·∫øn\n"
        reply += "‚Ä¢ Qu·∫£ng Tr·ªã: B√°nh ∆∞·ªõt, m√¨ qu·∫£ng\n"
        reply += "‚Ä¢ ƒê·∫∑c s·∫£n: M·∫Øm n√™m, ru·ªëc Hu·∫ø\n\n"
        
        reply += "üèõÔ∏è **DI S·∫¢N ƒêA D·∫†NG:**\n"
        reply += "‚Ä¢ Di t√≠ch l·ªãch s·ª≠ chi·∫øn tranh\n"
        reply += "‚Ä¢ Ki·∫øn tr√∫c cung ƒë√¨nh Hu·∫ø\n"
        reply += "‚Ä¢ VƒÉn h√≥a c√°c d√¢n t·ªôc thi·ªÉu s·ªë\n\n"
        
        reply += "Ruby Wings c√≥ nhi·ªÅu tour kh√°m ph√° ·∫©m th·ª±c v√† vƒÉn h√≥a ƒë·∫∑c s·∫Øc. üìû 0332510486"
    
    return reply


def _get_sustainability_response():
    """Tr·∫£ l·ªùi v·ªÅ ph√°t tri·ªÉn b·ªÅn v·ªØng"""
    reply = "üå± **DU L·ªäCH B·ªÄN V·ªÆNG T·∫†I RUBY WINGS** üå±\n\n"
    
    reply += "Ruby Wings cam k·∫øt ph√°t tri·ªÉn du l·ªãch b·ªÅn v·ªØng qua 3 tr·ª• c·ªôt:\n\n"
    
    reply += "üèûÔ∏è **1. B·∫¢O V·ªÜ M√îI TR∆Ø·ªúNG:**\n"
    reply += "‚Ä¢ Thi·∫øt k·∫ø tour t√°c ƒë·ªông t·ªëi thi·ªÉu ƒë·∫øn thi√™n nhi√™n\n"
    reply += "‚Ä¢ Khuy·∫øn kh√≠ch du kh√°ch kh√¥ng x·∫£ r√°c, ti·∫øt ki·ªám n∆∞·ªõc\n"
    reply += "‚Ä¢ T·ªï ch·ª©c ho·∫°t ƒë·ªông d·ªçn d·∫πp m√¥i tr∆∞·ªùng\n"
    reply += "‚Ä¢ S·ª≠ d·ª•ng v·∫≠t li·ªáu th√¢n thi·ªán, t√°i ch·∫ø\n\n"
    
    reply += "üë• **2. H·ªñ TR·ª¢ C·ªòNG ƒê·ªíNG ƒê·ªäA PH∆Ø∆†NG:**\n"
    reply += "‚Ä¢ H·ª£p t√°c v·ªõi doanh nghi·ªáp ƒë·ªãa ph∆∞∆°ng\n"
    reply += "‚Ä¢ T·∫°o vi·ªác l√†m cho ng∆∞·ªùi d√¢n b·∫£n ƒë·ªãa\n"
    reply += "‚Ä¢ Mua s·∫Øm nguy√™n li·ªáu t·∫°i ch·ªó\n"
    reply += "‚Ä¢ T√¥n tr·ªçng v√† ph√°t huy vƒÉn h√≥a ƒë·ªãa ph∆∞∆°ng\n\n"
    
    reply += "üìö **3. GI√ÅO D·ª§C V√Ä N√ÇNG CAO NH·∫¨N TH·ª®C:**\n"
    reply += "‚Ä¢ Cung c·∫•p th√¥ng tin v·ªÅ m√¥i tr∆∞·ªùng v√† vƒÉn h√≥a\n"
    reply += "‚Ä¢ H∆∞·ªõng d·∫´n du kh√°ch ·ª©ng x·ª≠ c√≥ tr√°ch nhi·ªám\n"
    reply += "‚Ä¢ T·ªï ch·ª©c ho·∫°t ƒë·ªông h·ªçc t·∫≠p v·ªÅ b·∫£o t·ªìn\n"
    reply += "‚Ä¢ Khuy·∫øn kh√≠ch du kh√°ch tr·ªü th√†nh ƒë·∫°i s·ª© m√¥i tr∆∞·ªùng\n\n"
    
    reply += "üéØ **TOUR B·ªÄN V·ªÆNG TI√äU BI·ªÇU:**\n"
    reply += "‚Ä¢ Tour thi√™n nhi√™n B·∫°ch M√£: B·∫£o v·ªá r·ª´ng nguy√™n sinh\n"
    reply += "‚Ä¢ Tour vƒÉn h√≥a b·∫£n ƒë·ªãa: H·ªó tr·ª£ c·ªông ƒë·ªìng d√¢n t·ªôc\n"
    reply += "‚Ä¢ Tour ·∫©m th·ª±c ƒë·ªãa ph∆∞∆°ng: Ph√°t tri·ªÉn kinh t·∫ø ƒë·ªãa ph∆∞∆°ng\n\n"
    
    reply += "üìû **Tham gia tour b·ªÅn v·ªØng:** 0332510486"
    
    return reply


def _get_experience_response(message_lower, tour_indices):
    """Tr·∫£ l·ªùi v·ªÅ tr·∫£i nghi·ªám"""
    reply = "üåü **TR·∫¢I NGHI·ªÜM ƒê·ªòC ƒê√ÅO RUBY WINGS** üåü\n\n"
    
    # X√°c ƒë·ªãnh lo·∫°i tr·∫£i nghi·ªám ƒë∆∞·ª£c h·ªèi
    if 'thi·ªÅn' in message_lower or 'tƒ©nh t√¢m' in message_lower:
        reply += "üßò **TR·∫¢I NGHI·ªÜM THI·ªÄN ƒê·ªäNH:**\n\n"
        reply += "**Kh√¥ng gian:**\n"
        reply += "‚Ä¢ Gi·ªØa r·ª´ng nguy√™n sinh B·∫°ch M√£\n"
        reply += "‚Ä¢ B√™n d√≤ng su·ªëi trong l√†nh\n"
        reply += "‚Ä¢ Tr√™n ƒë·ªânh n√∫i v·ªõi t·∫ßm nh√¨n bao la\n\n"
        
        reply += "**Ho·∫°t ƒë·ªông:**\n"
        reply += "‚Ä¢ Thi·ªÅn tƒ©nh t√¢m c√≥ h∆∞·ªõng d·∫´n\n"
        reply += "‚Ä¢ Kh√≠ c√¥ng d∆∞·ª°ng sinh\n"
        reply += "‚Ä¢ Yoga bu·ªïi s√°ng v·ªõi s∆∞∆°ng mai\n"
        reply += "‚Ä¢ Thi·ªÅn h√†nh trong r·ª´ng\n\n"
        
        reply += "**L·ª£i √≠ch:**\n"
        reply += "‚Ä¢ Gi·∫£m stress, c√¢n b·∫±ng c·∫£m x√∫c\n"
        reply += "‚Ä¢ TƒÉng c∆∞·ªùng s·ª©c kh·ªèe tinh th·∫ßn\n"
        reply += "‚Ä¢ K·∫øt n·ªëi s√¢u v·ªõi b·∫£n th√¢n\n"
        reply += "‚Ä¢ H·ªçc c√°ch s·ªëng ch·∫≠m, s·ªëng s√¢u\n\n"
        
    elif 'l·ªãch s·ª≠' in message_lower or 'tri √¢n' in message_lower:
        reply += "üéñÔ∏è **TR·∫¢I NGHI·ªÜM L·ªäCH S·ª¨ S·ªêNG ƒê·ªòNG:**\n\n"
        reply += "**Ho·∫°t ƒë·ªông ƒë·∫∑c bi·ªát:**\n"
        reply += "‚Ä¢ ThƒÉm di t√≠ch chi·∫øn tr∆∞·ªùng x∆∞a\n"
        reply += "‚Ä¢ G·∫∑p g·ª° nh√¢n ch·ª©ng l·ªãch s·ª≠\n"
        reply += "‚Ä¢ Tham quan b·∫£o t√†ng, ƒë·ªãa ƒë·∫°o\n"
        reply += "‚Ä¢ L·ªÖ tri √¢n c√°c anh h√πng li·ªát sƒ©\n\n"
        
        reply += "**C·∫£m x√∫c:**\n"
        reply += "‚Ä¢ X√∫c ƒë·ªông tr∆∞·ªõc s·ª± hy sinh\n"
        reply += "‚Ä¢ T·ª± h√†o v·ªÅ truy·ªÅn th·ªëng d√¢n t·ªôc\n"
        reply += "‚Ä¢ Hi·ªÉu s√¢u h∆°n v·ªÅ l·ªãch s·ª≠\n"
        reply += "‚Ä¢ Truy·ªÅn c·∫£m h·ª©ng cho th·∫ø h·ªá tr·∫ª\n\n"
        
    elif 'thi√™n nhi√™n' in message_lower or 'r·ª´ng' in message_lower:
        reply += "üåø **TR·∫¢I NGHI·ªÜM THI√äN NHI√äN HOANG D√É:**\n\n"
        reply += "**Kh√°m ph√°:**\n"
        reply += "‚Ä¢ Trekking r·ª´ng nguy√™n sinh\n"
        reply += "‚Ä¢ Ng·∫Øm th√°c, su·ªëi, hang ƒë·ªông\n"
        reply += "‚Ä¢ Quan s√°t ƒë·ªông th·ª±c v·∫≠t hoang d√£\n"
        reply += "‚Ä¢ C·∫Øm tr·∫°i gi·ªØa r·ª´ng\n\n"
        
        reply += "**K·∫øt n·ªëi:**\n"
        reply += "‚Ä¢ C·∫£m nh·∫≠n s·ª©c s·ªëng c·ªßa thi√™n nhi√™n\n"
        reply += "‚Ä¢ Th∆∞ gi√£n v·ªõi √¢m thanh r·ª´ng n√∫i\n"
        reply += "‚Ä¢ T·∫≠n h∆∞·ªüng kh√¥ng kh√≠ trong l√†nh\n"
        reply += "‚Ä¢ H·ªçc v·ªÅ h·ªá sinh th√°i ƒëa d·∫°ng\n\n"
        
    else:
        reply += "‚ú® **ƒêA D·∫†NG TR·∫¢I NGHI·ªÜM:**\n\n"
        reply += "1. **Tr·∫£i nghi·ªám vƒÉn h√≥a:**\n"
        reply += "   ‚Ä¢ H·ªçc l√†m ƒë·∫∑c s·∫£n ƒë·ªãa ph∆∞∆°ng\n"
        reply += "   ‚Ä¢ Tham gia l·ªÖ h·ªôi truy·ªÅn th·ªëng\n"
        reply += "   ‚Ä¢ Giao l∆∞u v·ªõi ng∆∞·ªùi d√¢n b·∫£n ƒë·ªãa\n\n"
        
        reply += "2. **Tr·∫£i nghi·ªám thi√™n nhi√™n:**\n"
        reply += "   ‚Ä¢ Trekking, leo n√∫i\n"
        reply += "   ‚Ä¢ Ng·∫Øm b√¨nh minh, ho√†ng h√¥n\n"
        reply += "   ‚Ä¢ T·∫Øm su·ªëi, th√°c\n\n"
        
        reply += "3. **Tr·∫£i nghi·ªám tinh th·∫ßn:**\n"
        reply += "   ‚Ä¢ Thi·ªÅn, yoga gi·ªØa thi√™n nhi√™n\n"
        reply += "   ‚Ä¢ Workshop ph√°t tri·ªÉn b·∫£n th√¢n\n"
        reply += "   ‚Ä¢ Ho·∫°t ƒë·ªông team building\n\n"
    
    if tour_indices:
        reply += "üéØ **TOUR C√ì TR·∫¢I NGHI·ªÜM ƒê·∫∂C S·∫ÆC:**\n"
        for idx in tour_indices[:3]:
            tour = TOURS_DB.get(idx)
            if tour:
                reply += f"‚Ä¢ **{tour.name}**\n"
                if tour.duration:
                    reply += f"  ‚è±Ô∏è {tour.duration}\n"
                reply += "\n"
    
    reply += "üìû **ƒê·∫∑t tour tr·∫£i nghi·ªám ƒë·ªôc ƒë√°o:** 0332510486"
    return reply


def _get_group_custom_response(message_lower):
    """Tr·∫£ l·ªùi v·ªÅ tour nh√≥m v√† t√πy ch·ªânh"""
    if 'nh√≥m' in message_lower or 'ƒëo√†n' in message_lower or 'c√¥ng ty' in message_lower:
        reply = "üë• **TOUR NH√ìM & TEAM BUILDING** üë•\n\n"
        
        reply += "üéØ **CH√çNH S√ÅCH ∆ØU ƒê√ÉI NH√ìM:**\n"
        reply += "‚Ä¢ **5-9 ng∆∞·ªùi:** Gi·∫£m 5% + t·∫∑ng ·∫£nh l∆∞u ni·ªám\n"
        reply += "‚Ä¢ **10-15 ng∆∞·ªùi:** Gi·∫£m 10% + t·∫∑ng video tour\n"
        reply += "‚Ä¢ **16-20 ng∆∞·ªùi:** Gi·∫£m 15% + t·∫∑ng team building\n"
        reply += "‚Ä¢ **21+ ng∆∞·ªùi:** Gi·∫£m 20% + t·∫∑ng teambuilding chuy√™n nghi·ªáp\n"
        reply += "‚Ä¢ **C·ª±u chi·∫øn binh:** Th√™m 5% ∆∞u ƒë√£i\n\n"
        
        reply += "üèÜ **TOUR PH√ô H·ª¢P NH√ìM:**\n"
        reply += "1. **Team building c√¥ng ty:**\n"
        reply += "   ‚Ä¢ K·∫øt h·ª£p ho·∫°t ƒë·ªông g·∫Øn k·∫øt\n"
        reply += "   ‚Ä¢ Thi·∫øt k·∫ø theo vƒÉn h√≥a doanh nghi·ªáp\n"
        reply += "   ‚Ä¢ C√≥ chuy√™n gia ƒë·ªìng h√†nh\n\n"
        
        reply += "2. **Tour gia ƒë√¨nh ƒëa th·∫ø h·ªá:**\n"
        reply += "   ‚Ä¢ Ho·∫°t ƒë·ªông ph√π h·ª£p m·ªçi l·ª©a tu·ªïi\n"
        reply += "   ‚Ä¢ D·ªãch v·ª• h·ªó tr·ª£ ƒë·∫∑c bi·ªát\n"
        reply += "   ‚Ä¢ Kh√¥ng gian ri√™ng t∆∞\n\n"
        
        reply += "3. **Tour nh√≥m b·∫°n/sinh vi√™n:**\n"
        reply += "   ‚Ä¢ Nhi·ªÅu tr·∫£i nghi·ªám m·ªõi l·∫°\n"
        reply += "   ‚Ä¢ Chi ph√≠ h·ª£p l√Ω\n"
        reply += "   ‚Ä¢ Linh ho·∫°t l·ªãch tr√¨nh\n\n"
        
        reply += "‚ú® **D·ªäCH V·ª§ ƒê·∫∂C BI·ªÜT CHO NH√ìM:**\n"
        reply += "‚Ä¢ H∆∞·ªõng d·∫´n vi√™n chuy√™n bi·ªát\n"
        reply += "‚Ä¢ Ph∆∞∆°ng ti·ªán ri√™ng, linh ho·∫°t\n"
        reply += "‚Ä¢ Thi·∫øt k·∫ø l·ªãch tr√¨nh ri√™ng\n"
        reply += "‚Ä¢ H·ªó tr·ª£ quay phim, ch·ª•p ·∫£nh\n"
        reply += "‚Ä¢ T·ªï ch·ª©c s·ª± ki·ªán ƒë·∫∑c bi·ªát\n\n"
        
        reply += "üìû **T∆∞ v·∫•n tour nh√≥m:** 0332510486"
    
    elif 'c√° nh√¢n h√≥a' in message_lower or 'ri√™ng' in message_lower or 'theo y√™u c·∫ßu' in message_lower:
        reply = "‚ú® **TOUR C√Å NH√ÇN H√ìA THEO Y√äU C·∫¶U** ‚ú®\n\n"
        
        reply += "üéØ **QUY TR√åNH THI·∫æT K·∫æ TOUR RI√äNG:**\n"
        reply += "1. **T∆∞ v·∫•n nhu c·∫ßu:** Hi·ªÉu r√µ mong mu·ªën, s·ªü th√≠ch\n"
        reply += "2. **Thi·∫øt k·∫ø concept:** √ù t∆∞·ªüng ƒë·ªôc ƒë√°o, s√°ng t·∫°o\n"
        reply += "3. **L√™n l·ªãch tr√¨nh chi ti·∫øt:** Ph√π h·ª£p th·ªùi gian, ng√¢n s√°ch\n"
        reply += "4. **B√°o gi√° minh b·∫°ch:** Kh√¥ng ph√°t sinh chi ph√≠ ·∫©n\n"
        reply += "5. **Ch·ªânh s·ª≠a & ho√†n thi·ªán:** Theo feedback c·ªßa b·∫°n\n"
        reply += "6. **Tri·ªÉn khai tour:** Chuy√™n nghi·ªáp, t·∫≠n t√¢m\n\n"
        
        reply += "üèÜ **TOUR RI√äNG N·ªîI B·∫¨T ƒê√É TH·ª∞C HI·ªÜN:**\n"
        reply += "‚Ä¢ **Tour gia ƒë√¨nh 3 th·∫ø h·ªá** (t·ª´ 6-75 tu·ªïi)\n"
        reply += "‚Ä¢ **Team building c√¥ng ty 50 ng∆∞·ªùi**\n"
        reply += "‚Ä¢ **Retreat thi·ªÅn 7 ng√†y cho nh√≥m ƒë·∫∑c bi·ªát**\n"
        reply += "‚Ä¢ **Tour nhi·∫øp ·∫£nh chuy√™n nghi·ªáp**\n"
        reply += "‚Ä¢ **H√†nh tr√¨nh t√¢m linh cho nh√≥m t√¥n gi√°o**\n\n"
        
        reply += "üí° **TH√îNG TIN C·∫¶N CUNG C·∫§P:**\n"
        reply += "‚Ä¢ S·ªë l∆∞·ª£ng ng∆∞·ªùi v√† ƒë·ªô tu·ªïi\n"
        reply += "‚Ä¢ Th·ªùi gian d·ª± ki·∫øn\n"
        reply += "‚Ä¢ Ng√¢n s√°ch ∆∞·ªõc t√≠nh\n"
        reply += "‚Ä¢ S·ªü th√≠ch, y√™u c·∫ßu ƒë·∫∑c bi·ªát\n"
        reply += "‚Ä¢ M·ª•c ƒë√≠ch chuy·∫øn ƒëi\n\n"
        
        reply += "üìû **Li√™n h·ªá thi·∫øt k·∫ø tour ri√™ng:** 0332510486"
    
    else:
        reply = "Ruby Wings c√≥ ch√≠nh s√°ch ∆∞u ƒë√£i ƒë·∫∑c bi·ªát cho nh√≥m v√† d·ªãch v·ª• thi·∫øt k·∫ø tour theo y√™u c·∫ßu. Li√™n h·ªá hotline ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt."
    
    return reply


def _get_booking_policy_response(message_lower):
    """Tr·∫£ l·ªùi v·ªÅ ƒë·∫∑t tour v√† ch√≠nh s√°ch"""
    if 'ƒë·∫∑t tour' in message_lower or 'booking' in message_lower or 'ƒëƒÉng k√Ω' in message_lower:
        reply = "üìù **QUY TR√åNH ƒê·∫∂T TOUR RUBY WINGS** üìù\n\n"
        
        reply += "**B∆Ø·ªöC 1: T∆Ø V·∫§N & CH·ªåN TOUR**\n"
        reply += "‚Ä¢ Li√™n h·ªá hotline 0332510486\n"
        reply += "‚Ä¢ Nh·∫≠n t∆∞ v·∫•n tour ph√π h·ª£p\n"
        reply += "‚Ä¢ X√°c nh·∫≠n l·ªãch tr√¨nh, gi√° c·∫£\n"
        reply += "‚Ä¢ Nh·∫≠n b√°o gi√° chi ti·∫øt\n\n"
        
        reply += "**B∆Ø·ªöC 2: ƒê·∫∂T C·ªåC & X√ÅC NH·∫¨N**\n"
        reply += "‚Ä¢ ƒê·∫∑t c·ªçc 30% gi√° tr·ªã tour\n"
        reply += "‚Ä¢ K√Ω h·ª£p ƒë·ªìng d·ªãch v·ª• r√µ r√†ng\n"
        reply += "‚Ä¢ Nh·∫≠n x√°c nh·∫≠n booking ch√≠nh th·ª©c\n"
        reply += "‚Ä¢ Cung c·∫•p th√¥ng tin c√° nh√¢n\n\n"
        
        reply += "**B∆Ø·ªöC 3: CHU·∫®N B·ªä & THANH TO√ÅN**\n"
        reply += "‚Ä¢ Thanh to√°n 70% c√≤n l·∫°i tr∆∞·ªõc 7 ng√†y\n"
        reply += "‚Ä¢ Nh·∫≠n th√¥ng tin chi ti·∫øt tour\n"
        reply += "‚Ä¢ Chu·∫©n b·ªã h√†nh l√Ω, gi·∫•y t·ªù\n"
        reply += "‚Ä¢ Tham gia briefing tr∆∞·ªõc tour\n\n"
        
        reply += "**B∆Ø·ªöC 4: KH·ªûI H√ÄNH & TR·∫¢I NGHI·ªÜM**\n"
        reply += "‚Ä¢ ƒê√≥n kh√°ch t·∫°i ƒëi·ªÉm h·∫πn\n"
        reply += "‚Ä¢ Tr·∫£i nghi·ªám tour tuy·ªát v·ªùi\n"
        reply += "‚Ä¢ H·ªó tr·ª£ 24/7 trong su·ªët tour\n"
        reply += "‚Ä¢ Feedback v√† ƒë√°nh gi√° sau tour\n\n"
        
        reply += "**PH∆Ø∆†NG TH·ª®C THANH TO√ÅN:**\n"
        reply += "‚Ä¢ Chuy·ªÉn kho·∫£n ng√¢n h√†ng\n"
        reply += "‚Ä¢ V√≠ ƒëi·ªán t·ª≠ (Momo, ZaloPay)\n"
        reply += "‚Ä¢ Ti·ªÅn m·∫∑t (t·∫°i vƒÉn ph√≤ng)\n"
        reply += "‚Ä¢ Th·∫ª t√≠n d·ª•ng (s·∫Øp tri·ªÉn khai)\n\n"
        
        reply += "üìû **ƒê·∫∑t tour ngay:** 0332510486"
    
    elif 'gi·∫£m gi√°' in message_lower or '∆∞u ƒë√£i' in message_lower or 'khuy·∫øn m√£i' in message_lower:
        reply = "üéÅ **CH√çNH S√ÅCH ∆ØU ƒê√ÉI & KHUY·∫æN M√ÉI** üéÅ\n\n"
        
        reply += "**1. ∆ØU ƒê√ÉI THEO NH√ìM:**\n"
        reply += "‚Ä¢ 5-9 ng∆∞·ªùi: Gi·∫£m 5%\n"
        reply += "‚Ä¢ 10-15 ng∆∞·ªùi: Gi·∫£m 10%\n"
        reply += "‚Ä¢ 16-20 ng∆∞·ªùi: Gi·∫£m 15%\n"
        reply += "‚Ä¢ 21+ ng∆∞·ªùi: Gi·∫£m 20%\n\n"
        
        reply += "**2. ∆ØU ƒê√ÉI ƒê·∫∂T S·ªöM:**\n"
        reply += "‚Ä¢ ƒê·∫∑t tr∆∞·ªõc 30 ng√†y: Gi·∫£m 5%\n"
        reply += "‚Ä¢ ƒê·∫∑t tr∆∞·ªõc 60 ng√†y: Gi·∫£m 8%\n"
        reply += "‚Ä¢ ƒê·∫∑t tr∆∞·ªõc 90 ng√†y: Gi·∫£m 10%\n\n"
        
        reply += "**3. ∆ØU ƒê√ÉI ƒê·∫∂C BI·ªÜT:**\n"
        reply += "‚Ä¢ C·ª±u chi·∫øn binh: Th√™m 5%\n"
        reply += "‚Ä¢ H·ªçc sinh/sinh vi√™n: Gi·∫£m 10%\n"
        reply += "‚Ä¢ Kh√°ch quay l·∫°i: Gi·∫£m 5%\n"
        reply += "‚Ä¢ ƒêƒÉng k√Ω nh√≥m 5 ng∆∞·ªùi tr·ªü l√™n: T·∫∑ng ·∫£nh l∆∞u ni·ªám\n\n"
        
        reply += "**4. CH∆Ø∆†NG TR√åNH T√çCH ƒêI·ªÇM:**\n"
        reply += "‚Ä¢ M·ªói tour: T√≠ch 1 ƒëi·ªÉm\n"
        reply += "‚Ä¢ 5 ƒëi·ªÉm: Gi·∫£m 10% tour ti·∫øp theo\n"
        reply += "‚Ä¢ 10 ƒëi·ªÉm: T·∫∑ng 1 tour 1 ng√†y\n"
        reply += "‚Ä¢ 15 ƒëi·ªÉm: T·∫∑ng 1 tour 2 ng√†y 1 ƒë√™m\n\n"
        
        reply += "**L∆ØU √ù:**\n"
        reply += "‚Ä¢ ∆Øu ƒë√£i kh√¥ng √°p d·ª•ng ƒë·ªìng th·ªùi\n"
        reply += "‚Ä¢ √Åp d·ª•ng cho tour ti√™u chu·∫©n\n"
        reply += "‚Ä¢ C√≥ th·ªÉ thay ƒë·ªïi m√† kh√¥ng b√°o tr∆∞·ªõc\n\n"
        
        reply += "üìû **Nh·∫≠n ∆∞u ƒë√£i t·ªët nh·∫•t:** 0332510486"
    
    elif 'h·ªßy tour' in message_lower or 'ho√†n ti·ªÅn' in message_lower or 'ch√≠nh s√°ch h·ªßy' in message_lower:
        reply = "‚ö†Ô∏è **CH√çNH S√ÅCH H·ª¶Y TOUR & HO√ÄN TI·ªÄN** ‚ö†Ô∏è\n\n"
        
        reply += "**TH·ªúI GIAN H·ª¶Y & M·ª®C PH√ç:**\n"
        reply += "‚Ä¢ **Tr∆∞·ªõc 30 ng√†y:** Ho√†n 100% ti·ªÅn c·ªçc\n"
        reply += "‚Ä¢ **Tr∆∞·ªõc 15-29 ng√†y:** Ho√†n 50% ti·ªÅn c·ªçc\n"
        reply += "‚Ä¢ **Tr∆∞·ªõc 7-14 ng√†y:** Ho√†n 30% ti·ªÅn c·ªçc\n"
        reply += "‚Ä¢ **D∆∞·ªõi 7 ng√†y:** Kh√¥ng ho√†n ti·ªÅn c·ªçc\n\n"
        
        reply += "**TR∆Ø·ªúNG H·ª¢P ƒê·∫∂C BI·ªÜT:**\n"
        reply += "‚Ä¢ Thi√™n tai, d·ªãch b·ªánh: Ho√†n 100%\n"
        reply += "‚Ä¢ C√≥ gi·∫•y t·ªù y t·∫ø: Ho√†n 80-100%\n"
        reply += "‚Ä¢ L√Ω do kh·∫©n c·∫•p: Xem x√©t t·ª´ng tr∆∞·ªùng h·ª£p\n\n"
        
        reply += "**QUY TR√åNH HO√ÄN TI·ªÄN:**\n"
        reply += "1. Th√¥ng b√°o h·ªßy b·∫±ng vƒÉn b·∫£n\n"
        reply += "2. Cung c·∫•p l√Ω do v√† gi·∫•y t·ªù (n·∫øu c√≥)\n"
        reply += "3. X·ª≠ l√Ω trong 7-10 ng√†y l√†m vi·ªác\n"
        reply += "4. Ho√†n ti·ªÅn v·ªÅ t√†i kho·∫£n ƒë√£ chuy·ªÉn\n\n"
        
        reply += "üìû **Li√™n h·ªá h·ªó tr·ª£:** 0332510486"
    
    else:
        reply = "Ruby Wings c√≥ ch√≠nh s√°ch ∆∞u ƒë√£i h·∫•p d·∫´n v√† quy tr√¨nh ƒë·∫∑t tour chuy√™n nghi·ªáp. Li√™n h·ªá hotline ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt."
    
    return reply


def _prepare_enhanced_llm_prompt(user_message, search_results, context_info, tours_db):
    """
    Prompt builder chu·∫©n RAG ‚Äì CH·ªêNG B·ªäA TUY·ªÜT ƒê·ªêI
    - C√≥ d·ªØ li·ªáu ‚Üí tr·∫£ l·ªùi t·ª´ d·ªØ li·ªáu
    - Kh√¥ng c√≥ d·ªØ li·ªáu ‚Üí b·∫Øt bu·ªôc th·ª´a nh·∫≠n kh√¥ng bi·∫øt
    """

    # ================== NO DATA CASE ==================
    if not search_results:
        return f"""
B·∫†N L√Ä TR·ª¢ L√ù AI C·ª¶A RUBY WINGS TRAVEL.

‚ö†Ô∏è QUY T·∫ÆC B·∫ÆT BU·ªòC:
- CH·ªà ƒë∆∞·ª£c tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu Ruby Wings cung c·∫•p
- KH√îNG ƒë∆∞·ª£c suy ƒëo√°n
- KH√îNG ƒë∆∞·ª£c t·ª± t·∫°o th√¥ng tin
- N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu ph√π h·ª£p ‚Üí PH·∫¢I N√ìI R√ï L√Ä KH√îNG C√ì

C√ÇU H·ªéI KH√ÅCH:
"{user_message}"

T√åNH TR·∫†NG:
H·ªá th·ªëng KH√îNG t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong c∆° s·ªü d·ªØ li·ªáu Ruby Wings.

C√ÅCH TR·∫¢ L·ªúI DUY NH·∫§T ƒê∆Ø·ª¢C PH√âP:
- N√≥i r√µ: "Hi·ªán t·∫°i t√¥i ch∆∞a c√≥ d·ªØ li·ªáu ƒë·ªÉ tr·∫£ l·ªùi ch√≠nh x√°c c√¢u h·ªèi n√†y."
- ƒê·ªÅ ngh·ªã kh√°ch h·ªèi c·ª• th·ªÉ h∆°n (t√™n tour / ƒë·ªãa ƒëi·ªÉm / th·ªùi gian / gi√°)
- M·ªùi li√™n h·ªá hotline 0332510486

üö´ TUY·ªÜT ƒê·ªêI KH√îNG:
- B·ªãa th√¥ng tin
- ƒêo√°n gi√°
- ƒê·ªÅ xu·∫•t tour kh√¥ng t·ªìn t·∫°i
"""


    # ================== DATA AVAILABLE CASE ==================
    # Chu·∫©n b·ªã context d·ªØ li·ªáu (KH√îNG c·∫Øt nghƒ©a, KH√îNG suy di·ªÖn)
    relevant_info = "TH√îNG TIN TR√çCH XU·∫§T T·ª™ C∆† S·ªû D·ªÆ LI·ªÜU RUBY WINGS:\n"
    for i, (score, passage) in enumerate(search_results[:3], 1):
        relevant_info += f"{i}. {passage.strip()}\n"

    # Th√¥ng tin tour n·∫øu c√≥
    tour_info = ""
    tour_indices = context_info.get("tour_indices") or []
    if tour_indices:
        tour_info = "TH√îNG TIN TOUR LI√äN QUAN (N·∫æU C√ì):\n"
        for idx in tour_indices[:3]:
            tour = tours_db.get(idx)
            if tour:
                summary = tour.summary.strip() if tour.summary else "Kh√¥ng c√≥ m√¥ t·∫£"
                tour_info += f"- {tour.name}: {summary}\n"

    return f"""
B·∫†N L√Ä TR·ª¢ L√ù AI C·ª¶A RUBY WINGS TRAVEL.

‚ö†Ô∏è QUY T·∫ÆC B·∫ÆT BU·ªòC:
- CH·ªà s·ª≠ d·ª•ng th√¥ng tin c√≥ trong ph·∫ßn "TH√îNG TIN TR√çCH XU·∫§T"
- KH√îNG s·ª≠ d·ª•ng ki·∫øn th·ª©c b√™n ngo√†i
- KH√îNG suy di·ªÖn, KH√îNG th√™m chi ti·∫øt kh√¥ng t·ªìn t·∫°i
- N·∫øu d·ªØ li·ªáu KH√îNG ƒë·ªß ‚Üí PH·∫¢I N√ìI R√ï l√† kh√¥ng ƒë·ªß

C√ÇU H·ªéI KH√ÅCH:
"{user_message}"

{relevant_info}

{tour_info}

CONTEXT PH√ÇN T√çCH (CH·ªà ƒê·ªÇ ƒê·ªäNH H∆Ø·ªöNG, KH√îNG ƒê∆Ø·ª¢C B·ªäA):
- √ù ƒë·ªãnh ch√≠nh: {context_info.get('primary_intent', 'Kh√¥ng x√°c ƒë·ªãnh')}
- ƒê·ªô ph·ª©c t·∫°p: {context_info.get('complexity_score', 0)}/10
- S·ªë tour li√™n quan: {len(tour_indices)}

Y√äU C·∫¶U TR·∫¢ L·ªúI:
1. Tr·∫£ l·ªùi NG·∫ÆN G·ªåN ‚Äì ƒê√öNG TR·ªåNG T√ÇM
2. Tr√≠ch d·∫´n ƒë√∫ng n·ªôi dung t·ª´ d·ªØ li·ªáu
3. Kh√¥ng m·ªü r·ªông ngo√†i ph·∫°m vi d·ªØ li·ªáu
4. N·∫øu thi·∫øu th√¥ng tin ‚Üí n√≥i r√µ thi·∫øu g√¨
5. K·∫øt th√∫c b·∫±ng l·ªùi m·ªùi li√™n h·ªá hotline 0332510486

üö´ C·∫§M TUY·ªÜT ƒê·ªêI:
- B·ªãa tour
- B·ªãa gi√°
- B·ªãa l·ªãch tr√¨nh
- Suy ƒëo√°n √Ω kh√°ch
"""



def _generate_enhanced_fallback_response(user_message, search_results, tour_indices, tours_db):
    """T·∫°o fallback response n√¢ng cao"""
    # C·ªë g·∫Øng t·∫°o response t·ª´ th√¥ng tin c√≥ s·∫µn
    if tour_indices:
        reply = "D·ª±a tr√™n c√¢u h·ªèi c·ªßa b·∫°n, t√¥i t√¨m th·∫•y m·ªôt s·ªë tour c√≥ th·ªÉ ph√π h·ª£p:\n\n"
        
        for idx in tour_indices[:3]:
            tour = tours_db.get(idx)
            if tour:
                reply += f"**{tour.name}**\n"
                if tour.duration:
                    reply += f"‚è±Ô∏è {tour.duration}\n"
                if tour.location:
                    location_short = tour.location[:50] + "..." if len(tour.location) > 50 else tour.location
                    reply += f"üìç {location_short}\n"
                if tour.summary:
                    summary_short = tour.summary[:100] + "..." if len(tour.summary) > 100 else tour.summary
                    reply += f"üìù {summary_short}\n"
                reply += "\n"
        
        reply += "ƒê·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt h∆°n v·ªÅ c√°c tour n√†y ho·∫∑c t√¨m tour ph√π h·ª£p nh·∫•t v·ªõi nhu c·∫ßu c·ªßa b·∫°n, vui l√≤ng li√™n h·ªá hotline 0332510486."
    elif search_results:
        reply = "D·ª±a tr√™n th√¥ng tin t√¥i c√≥, ƒë√¢y l√† m·ªôt s·ªë th√¥ng tin li√™n quan:\n\n"
        
        for i, (score, passage) in enumerate(search_results[:2], 1):
            reply += f"{i}. {passage[:150]}...\n\n"
        
        reply += "ƒê·ªÉ c√≥ th√¥ng tin ch√≠nh x√°c v√† ƒë·∫ßy ƒë·ªß h∆°n, vui l√≤ng li√™n h·ªá hotline 0332510486."
    else:
        reply = "C·∫£m ∆°n c√¢u h·ªèi c·ªßa b·∫°n. ƒê·ªÉ t∆∞ v·∫•n ch√≠nh x√°c nh·∫•t v·ªÅ c√°c tour c·ªßa Ruby Wings, b·∫°n c√≥ th·ªÉ:\n\n"
        reply += "1. Cung c·∫•p th√™m th√¥ng tin v·ªÅ nhu c·∫ßu c·ªßa b·∫°n\n"
        reply += "2. G·ªçi tr·ª±c ti·∫øp hotline 0332510486\n"
        reply += "3. Tham kh·∫£o c√°c tour ph·ªï bi·∫øn:\n"
        reply += "   ‚Ä¢ Tour thi√™n nhi√™n B·∫°ch M√£ (1 ng√†y)\n"
        reply += "   ‚Ä¢ Tour l·ªãch s·ª≠ Tr∆∞·ªùng S∆°n (2 ng√†y 1 ƒë√™m)\n"
        reply += "   ‚Ä¢ Tour retreat thi·ªÅn (1-2 ng√†y)\n\n"
        reply += "üìû **Hotline t∆∞ v·∫•n 24/7:** 0332510486"
    
    return reply


# ================== MODULE COMPATIBILITY CHECK ==================
# C√°c module c·∫ßn n√¢ng c·∫•p ƒë·ªÉ t∆∞∆°ng th√≠ch:

"""
1. MandatoryFilterSystem.apply_filters() c·∫ßn s·ª≠a l·ªói:
   - L·ªói "kh√¥ng c√≥ nh√≥m n√†o nh∆∞ v·∫≠y" 
   - Th√™m x·ª≠ l√Ω exception v√† fallback

2. FuzzyMatcher.find_similar_tours() c·∫ßn c·∫£i thi·ªán:
   - Gi·∫£m ng∆∞·ª°ng matching t·ª´ 0.7 xu·ªëng 0.6
   - TƒÉng s·ªë k·∫øt qu·∫£ tr·∫£ v·ªÅ

3. CacheSystem c·∫ßn h·ªó tr·ª£:
   - Cache v·ªõi expiry time
   - Key generation v·ªõi nhi·ªÅu tham s·ªë h∆°n

4. DeduplicationEngine c·∫ßn:
   - X·ª≠ l√Ω t·ªët h∆°n v·ªõi c√°c tour t∆∞∆°ng t·ª±
   - Gi·ªØ l·∫°i tour ch·∫•t l∆∞·ª£ng cao h∆°n

5. QueryIndex c·∫ßn:
   - Tr·∫£ v·ªÅ nhi·ªÅu k·∫øt qu·∫£ h∆°n (tƒÉng TOP_K)
   - C·∫£i thi·ªán relevance scoring
"""

# Th√™m c√°c h√†m helper m·ªõi v√†o c√°c module t∆∞∆°ng ·ª©ng


















# Th√™m c√°c h√†m helper m·ªõi v√†o c√°c module t∆∞∆°ng ·ª©ng
# =========== OTHER ENDPOINTS ===========
@app.route("/")
def home():
    """Home endpoint"""
    return jsonify({
        "status": "ok",
        "version": "4.0",
        "upgrades": UpgradeFlags.get_all_flags(),
        "services": {
            "openai": "available" if client else "unavailable",
            "faiss": "available" if HAS_FAISS else "unavailable",
            "google_sheets": "available" if HAS_GOOGLE_SHEETS else "unavailable",
            "meta_capi": "available" if HAS_META_CAPI else "unavailable",
        },
        "counts": {
            "tours": len(TOURS_DB),
            "passages": len(FLAT_TEXTS),
            "tour_names": len(TOUR_NAME_TO_INDEX),
        }
    })

@app.route("/reindex", methods=["POST"])
def reindex():
    """Rebuild index endpoint"""
    secret = request.headers.get("X-RBW-ADMIN", "")
    if not secret and os.environ.get("RBW_ALLOW_REINDEX", "") != "1":
        return jsonify({"error": "reindex not allowed"}), 403
    
    load_knowledge()
    build_index(force_rebuild=True)
    
    return jsonify({
        "ok": True,
        "count": len(FLAT_TEXTS),
        "tours": len(TOURS_DB)
    })

# =========== GOOGLE SHEETS INTEGRATION ===========
_gsheet_client = None
_gsheet_client_lock = threading.Lock()

def get_gspread_client(force_refresh: bool = False):
    """Get Google Sheets client"""
    global _gsheet_client
    
    if not GOOGLE_SERVICE_ACCOUNT_JSON:
        logger.error("GOOGLE_SERVICE_ACCOUNT_JSON not set")
        return None
    
    with _gsheet_client_lock:
        if _gsheet_client is not None and not force_refresh:
            return _gsheet_client
        
        try:
            info = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
            scopes = [
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/drive",
            ]
            creds = Credentials.from_service_account_info(info, scopes=scopes)
            _gsheet_client = gspread.authorize(creds)
            logger.info("‚úÖ Google Sheets client initialized")
            return _gsheet_client
        except Exception as e:
            logger.error(f"‚ùå Google Sheets client failed: {e}")
            return None

@app.route('/api/save-lead', methods=['POST', 'OPTIONS'])
def save_lead():
    """Save lead from form submission - ƒê·∫¶Y ƒê·ª¶ 9 TR∆Ø·ªúNG (A-I)"""
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200
    
    try:
        data = request.get_json() or {}
        
        # Extract data
        phone = data.get('phone', '').strip()
        name = data.get('name', '').strip()
        email = data.get('email', '').strip()
        tour_interest = data.get('tour_interest', '').strip()
        page_url = data.get('page_url', '').strip()
        note = data.get('note', '').strip()
        
        if not phone:
            return jsonify({'error': 'Phone number is required'}), 400
        
        # Clean phone
        phone_clean = re.sub(r'[^\d+]', '', phone)
        
        # Validate phone
        if not re.match(r'^(0|\+?84)\d{9,10}$', phone_clean):
            return jsonify({'error': 'Invalid phone number format'}), 400
        
        # Timestamp
        timestamp = datetime.now().isoformat()
        
        # Create lead data
        lead_data = {
            'timestamp': timestamp,
            'phone': phone_clean,
            'name': name,
            'email': email,
            'tour_interest': tour_interest,
            'page_url': page_url,
            'note': note,
            'source': 'Lead Form'
        }
        
        # Send to Meta CAPI
        if ENABLE_META_CAPI_CALL and HAS_META_CAPI:
            try:
                result = send_meta_lead(
                    request,
                    phone=phone_clean,
                    contact_name=name,
                    email=email,
                    content_name=f"Tour: {tour_interest}" if tour_interest else "General Inquiry",
                    value=200000,
                    currency="VND"
                )
                increment_stat('meta_capi_calls')
                logger.info(f"‚úÖ Form lead sent to Meta CAPI: {phone_clean[:4]}***")
                if DEBUG and HAS_META_CAPI:
                    logger.debug(f"Meta CAPI result: {result}")
            except Exception as e:
                increment_stat('meta_capi_errors')
                logger.error(f"Meta CAPI error: {e}")
        
        # Save to Google Sheets - ƒê·∫¶Y ƒê·ª¶ 9 TR∆Ø·ªúNG (A-I)
        if ENABLE_GOOGLE_SHEETS:
            try:
                import gspread
                from google.oauth2.service_account import Credentials
                
                if GOOGLE_SERVICE_ACCOUNT_JSON and GOOGLE_SHEET_ID:
                    creds_json = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
                    creds = Credentials.from_service_account_info(
                        creds_json,
                        scopes=['https://www.googleapis.com/auth/spreadsheets']
                    )
                    
                    gc = gspread.authorize(creds)
                    sh = gc.open_by_key(GOOGLE_SHEET_ID)
                    ws = sh.worksheet(GOOGLE_SHEET_NAME)
                    
                    # ƒê√öng 9 TR∆Ø·ªúNG THEO TH·ª® T·ª∞ A-I:
                    # A: created_at (timestamp)
                    # B: source_channel
                    # C: action_type
                    # D: page_url
                    # E: contact_name
                    # F: phone
                    # G: service_interest
                    # H: note
                    # I: raw_status
                    row = [
                        timestamp,                          # A: created_at
                        'Website - Lead Form',              # B: source_channel
                        'Form Submission',                  # C: action_type
                        page_url or '',                     # D: page_url
                        name or '',                         # E: contact_name
                        phone_clean,                        # F: phone
                        tour_interest or '',                # G: service_interest
                        note or email or '',                # H: note (d√πng email n·∫øu kh√¥ng c√≥ note)
                        'New'                               # I: raw_status
                    ]
                    
                    ws.append_row(row)
                    logger.info("‚úÖ Form lead saved to Google Sheets (9 fields)")
            except Exception as e:
                logger.error(f"Google Sheets error: {e}")
        
        # Fallback storage
        if ENABLE_FALLBACK_STORAGE:
            try:
                if os.path.exists(FALLBACK_STORAGE_PATH):
                    with open(FALLBACK_STORAGE_PATH, 'r', encoding='utf-8') as f:
                        leads = json.load(f)
                else:
                    leads = []
                
                leads.append(lead_data)
                leads = leads[-1000:]
                
                with open(FALLBACK_STORAGE_PATH, 'w', encoding='utf-8') as f:
                    json.dump(leads, f, ensure_ascii=False, indent=2)
                
                logger.info("‚úÖ Form lead saved to fallback storage")
            except Exception as e:
                logger.error(f"Fallback storage error: {e}")
        
        # Update stats
        increment_stat('leads')
        
        return jsonify({
            'success': True,
            'message': 'Lead ƒë√£ ƒë∆∞·ª£c l∆∞u! ƒê·ªôi ng≈© Ruby Wings s·∫Ω li√™n h·ªá s·ªõm nh·∫•t. üìû',
            'data': {
                'phone': phone_clean[:3] + '***' + phone_clean[-2:],
                'timestamp': timestamp
            }
        })
        
    except Exception as e:
        logger.error(f"‚ùå Save lead error: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/call-button', methods=['POST', 'OPTIONS'])
def call_button():
    """Track call button click"""
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200
    
    try:
        data = request.get_json() or {}
        
        page_url = data.get('page_url', '')
        call_type = data.get('call_type', 'regular')
        
        # Send to Meta CAPI
        if ENABLE_META_CAPI_CALL and HAS_META_CAPI:
            try:
                result = send_meta_call_button(
                    request,
                    page_url=page_url,
                    call_type=call_type,
                    button_location='fixed_bottom_left',
                    button_text='G·ªçi ngay'
                )
                increment_stat('meta_capi_calls')
                logger.info(f"üìû Call button tracked: {call_type}")
                if DEBUG and HAS_META_CAPI:
                    logger.debug(f"Meta CAPI result: {result}")
            except Exception as e:
                increment_stat('meta_capi_errors')
                logger.error(f"Meta CAPI call error: {e}")
        
        return jsonify({
            'success': True,
            'message': 'Call tracked',
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Call button error: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    try:
        return jsonify({
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "services": {
                "chatbot": "running",
                "openai": "available" if client else "unavailable",
                "faiss": "available" if INDEX else "unavailable",
                "tours_db": len(TOURS_DB),
                "upgrades": {k: v for k, v in UpgradeFlags.get_all_flags().items() 
                           if k.startswith("UPGRADE_")}
            },
            "memory_profile": {
                "ram_profile": RAM_PROFILE,
                "is_low_ram": IS_LOW_RAM,
                "is_high_ram": IS_HIGH_RAM,
                "tour_count": len(TOURS_DB),
                "context_count": len(SESSION_CONTEXTS)
            }
        })
    except Exception as e:
        return jsonify({
            "status": "unhealthy",
            "error": str(e)
        }), 500

# =========== INITIALIZATION ===========
def initialize_app():
    """Initialize the application"""
    logger.info("üöÄ Starting Ruby Wings Chatbot v4.0 (Dataclass Rewrite)...")
    
    # Apply memory optimizations
    optimize_for_memory_profile()
    
    # Load knowledge base
    load_knowledge()
    
    # Load or build tours database
    if os.path.exists(FAISS_MAPPING_PATH):
        try:
            with open(FAISS_MAPPING_PATH, 'r', encoding='utf-8') as f:
                MAPPING[:] = json.load(f)
            FLAT_TEXTS[:] = [m.get('text', '') for m in MAPPING]
            logger.info(f"üìÅ Loaded {len(MAPPING)} mappings from disk")
        except Exception as e:
            logger.error(f"Failed to load mappings: {e}")
    
    # Build tour databases
    index_tour_names()
    build_tours_db()
    
    # Build index in background
    def build_index_background():
        time.sleep(2)
        success = build_index(force_rebuild=False)
        if success:
            logger.info("‚úÖ Index ready")
        else:
            logger.warning("‚ö†Ô∏è Index building failed")
    
    threading.Thread(target=build_index_background, daemon=True).start()
    
    # Initialize Google Sheets client
    if ENABLE_GOOGLE_SHEETS:
        threading.Thread(target=get_gspread_client, daemon=True).start()
    
    # Log active upgrades
    active_upgrades = [name for name, enabled in UpgradeFlags.get_all_flags().items() 
                      if enabled and name.startswith("UPGRADE_")]
    logger.info(f"üîß Active upgrades: {len(active_upgrades)}")
    for upgrade in active_upgrades:
        logger.info(f"   ‚Ä¢ {upgrade}")
    
    # Log memory profile
    logger.info(f"üß† Memory Profile: {RAM_PROFILE}MB | Low RAM: {IS_LOW_RAM} | High RAM: {IS_HIGH_RAM}")
    logger.info(f"üìä Tours Database: {len(TOURS_DB)} tours loaded")
    
    logger.info("‚úÖ Application initialized successfully with dataclasses")

# =========== APPLICATION START ===========
if __name__ == "__main__":
    initialize_app()
    
    # Save mappings if not exists
    if MAPPING and not os.path.exists(FAISS_MAPPING_PATH):
        try:
            with open(FAISS_MAPPING_PATH, 'w', encoding='utf-8') as f:
                json.dump(MAPPING, f, ensure_ascii=False, indent=2)
            logger.info(f"üíæ Saved mappings to {FAISS_MAPPING_PATH}")
        except Exception as e:
            logger.error(f"Failed to save mappings: {e}")
    
    # Start server
    logger.info(f"üåê Starting server on {HOST}:{PORT}")
    app.run(host=HOST, port=PORT, debug=DEBUG, threaded=True)

else:
    # For WSGI
    initialize_app()