def safe_validate(reply):
    try:
        if not isinstance(reply, dict):
            return reply
        # Only validate when tour is selected
        if not reply.get("tour_name"):
            return reply
        return AutoValidator.validate_response(reply)
    except Exception as e:
        try:
            reply.setdefault("warnings", []).append(str(e))
        except:
            pass
        return reply


# app.py - Ruby Wings Chatbot v4.0 (Complete Rewrite with Dataclasses)
# =========== IMPORTS ===========
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("ruby-wings")
import os
import sys
import json
import threading
import logging
import re
import unicodedata
import traceback
import hashlib
import time
import random
from functools import lru_cache, wraps
from typing import List, Tuple, Dict, Optional, Any, Set, Union, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import defaultdict, deque
from difflib import SequenceMatcher
from enum import Enum
# Try to import numpy with detailed error handling
try:
    
    import numpy as np
    NUMPY_AVAILABLE = True
    logger.info("âœ… NumPy available")
except ImportError as e:
    logger.error(f"âŒ NumPy import failed: {e}")
    # Create a minimal numpy-like fallback for basic operations
    class NumpyFallback:
        def __init__(self):
            self.float32 = float
            self.int64 = int
            
        def array(self, data, dtype=None):
            # Simple list wrapper
            class SimpleArray:
                def __init__(self, data):
                    self.data = list(data)
                    self.shape = (len(data),) if isinstance(data[0], (int, float)) else (len(data), len(data[0]))
                
                def astype(self, dtype):
                    return self
                
                def reshape(self, shape):
                    return self
                
                def __getitem__(self, idx):
                    return self.data[idx]
                
                def __len__(self):
                    return len(self.data)
            
            return SimpleArray(data)
        
        def empty(self, shape, dtype):
            if len(shape) == 1:
                return [0.0] * shape[0]
            else:
                return [[0.0] * shape[1] for _ in range(shape[0])]
        
        def vstack(self, arrays):
            result = []
            for arr in arrays:
                if hasattr(arr, 'data'):
                    result.extend(arr.data)
                else:
                    result.extend(arr)
            return result
        
        def load(self, path):
            # Mock load function
            class MockNpz:
                def __init__(self):
                    self.files = ['mat']
                
                def __getitem__(self, key):
                    if key == 'mat':
                        # Return empty array
                        return self.array([[0.0]])
                    return None
            
            return MockNpz()
        
        def savez_compressed(self, path, **kwargs):
            # Mock save function
            logger.warning(f"âš ï¸ NumPy fallback: Mock saving to {path}")
            return None
    
    np = NumpyFallback()
    NUMPY_AVAILABLE = False
    logger.warning("âš ï¸ Using NumPy fallback - limited functionality")
from flask import Flask, request, jsonify, g
from flask_cors import CORS

# =========== ENTITY IMPORTS ===========
from entities import (
    QuestionType,
    ConversationState,
    PriceLevel,
    DurationType,
    Tour,
    UserProfile,
    SearchResult,
    ConversationContext,
    FilterSet,
    LLMRequest,
    ChatResponse,
    LeadData,
    CacheEntry,
    EnhancedJSONEncoder
)

# =========== CONFIGURATION ===========
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ruby_wings.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("rbw_v4")

# =========== IMPORTS WITH FALLBACKS ===========
HAS_FAISS = False
try:
    import faiss
    HAS_FAISS = True
    logger.info("âœ… FAISS available")
except ImportError:
    logger.warning("âš ï¸ FAISS not available, using numpy fallback")

HAS_OPENAI = False
client = None
try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    logger.warning("âš ï¸ OpenAI not available, using fallback responses")

# Google Sheets
try:
    import gspread
    from google.oauth2.service_account import Credentials
    from google.auth.exceptions import GoogleAuthError
    from gspread.exceptions import APIError, SpreadsheetNotFound, WorksheetNotFound
    HAS_GOOGLE_SHEETS = True
except ImportError:
    HAS_GOOGLE_SHEETS = False
    logger.warning("âš ï¸ Google Sheets not available")

# Meta CAPI
try:
    from meta_capi import send_meta_pageview, send_meta_lead, send_meta_call_button
    HAS_META_CAPI = True
    logger.info("âœ… Meta CAPI available")
except ImportError:
    HAS_META_CAPI = False
    logger.warning("âš ï¸ Meta CAPI not available")

# =========== ENVIRONMENT VARIABLES ===========
# Memory Profile
RAM_PROFILE = os.environ.get("RAM_PROFILE", "512").strip()
IS_LOW_RAM = RAM_PROFILE == "512"
IS_HIGH_RAM = RAM_PROFILE == "2048"

# Core API Keys
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "").strip()
OPENAI_BASE_URL = os.environ.get("OPENAI_BASE_URL", "").strip()
GOOGLE_SERVICE_ACCOUNT_JSON = os.environ.get("GOOGLE_SERVICE_ACCOUNT_JSON", "").strip()

# Knowledge & Index
KNOWLEDGE_PATH = os.environ.get("KNOWLEDGE_PATH", "knowledge.json")
FAISS_INDEX_PATH = os.environ.get("FAISS_INDEX_PATH", "faiss_index.bin")
FAISS_MAPPING_PATH = os.environ.get("FAISS_MAPPING_PATH", "faiss_mapping.json")
FALLBACK_VECTORS_PATH = os.environ.get("FALLBACK_VECTORS_PATH", "vectors.npz")

# Models
EMBEDDING_MODEL = os.environ.get("EMBEDDING_MODEL", "text-embedding-3-small")
CHAT_MODEL = os.environ.get("CHAT_MODEL", "gpt-4o-mini")
TOP_K = int(os.environ.get("TOP_K", "10"))

# FAISS
FAISS_ENABLED = os.environ.get("FAISS_ENABLED", "true").lower() in ("1", "true", "yes") and not IS_LOW_RAM

# Google Sheets
GOOGLE_SHEET_ID = os.environ.get("GOOGLE_SHEET_ID", "1SdVbwkuxb8l1meEW--ddyfh4WmUvSXXMOPQ5bCyPkdk")
GOOGLE_SHEET_NAME = os.environ.get("GOOGLE_SHEET_NAME", "RBW_Lead_Raw_Inbox")
ENABLE_GOOGLE_SHEETS = os.environ.get("ENABLE_GOOGLE_SHEETS", "true").lower() in ("1", "true", "yes")

# Storage
ENABLE_FALLBACK_STORAGE = os.environ.get("ENABLE_FALLBACK_STORAGE", "true").lower() in ("1", "true", "yes")
FALLBACK_STORAGE_PATH = os.environ.get("FALLBACK_STORAGE_PATH", "leads_fallback.json")

# Meta CAPI
META_CAPI_TOKEN = os.environ.get("META_CAPI_TOKEN", "").strip()
META_PIXEL_ID = os.environ.get("META_PIXEL_ID", "").strip()
META_CAPI_ENDPOINT = os.environ.get("META_CAPI_ENDPOINT", "https://graph.facebook.com/v17.0/")
ENABLE_META_CAPI_CALL = os.environ.get("ENABLE_META_CAPI_CALL", "true").lower() in ("1", "true", "yes")

# Server
FLASK_ENV = os.environ.get("FLASK_ENV", "production")
DEBUG = os.environ.get("DEBUG", "false").lower() in ("1", "true", "yes")
SECRET_KEY = os.environ.get("SECRET_KEY", "ruby-wings-secret-key-2024")
CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "https://www.rubywings.vn,http://localhost:3000").split(",")
HOST = os.environ.get("HOST", "0.0.0.0")
PORT = int(os.environ.get("PORT", "10000"))

# =========== STATS TRACKING (FIX Lá»–I STATE) ===========
# ThÃªm global stats tracking system
STATS_LOCK = threading.Lock()
GLOBAL_STATS = {
    'meta_capi_calls': 0,
    'meta_capi_errors': 0,
    'leads': 0,
    'errors': 0,
    'total_requests': 0
}

def increment_stat(stat_name: str, amount: int = 1):
    """Thread-safe stat increment"""
    with STATS_LOCK:
        if stat_name in GLOBAL_STATS:
            GLOBAL_STATS[stat_name] += amount
        else:
            GLOBAL_STATS[stat_name] = amount

def get_stats() -> dict:
    """Get current stats"""
    with STATS_LOCK:
        return GLOBAL_STATS.copy()

# =========== UPGRADE FEATURE FLAGS ===========
class UpgradeFlags:
    """Control all 10 upgrades with environment variables"""
    
    @staticmethod
    def get_all_flags():
        return {
            # CORE UPGRADES (Essential fixes)
            "UPGRADE_1_MANDATORY_FILTER": os.environ.get("UPGRADE_1_MANDATORY_FILTER", "true").lower() == "true",
            "UPGRADE_2_DEDUPLICATION": os.environ.get("UPGRADE_2_DEDUPLICATION", "true").lower() == "true",
            "UPGRADE_3_ENHANCED_FIELDS": os.environ.get("UPGRADE_3_ENHANCED_FIELDS", "true").lower() == "true",
            "UPGRADE_4_QUESTION_PIPELINE": os.environ.get("UPGRADE_4_QUESTION_PIPELINE", "true").lower() == "true",
            
            # ADVANCED UPGRADES
            "UPGRADE_5_QUERY_SPLITTER": os.environ.get("UPGRADE_5_QUERY_SPLITTER", "true").lower() == "true",
            "UPGRADE_6_FUZZY_MATCHING": os.environ.get("UPGRADE_6_FUZZY_MATCHING", "true").lower() == "true",
            "UPGRADE_7_STATE_MACHINE": os.environ.get("UPGRADE_7_STATE_MACHINE", "true").lower() == "true",
            "UPGRADE_8_SEMANTIC_ANALYSIS": os.environ.get("UPGRADE_8_SEMANTIC_ANALYSIS", "true").lower() == "true",
            "UPGRADE_9_AUTO_VALIDATION": os.environ.get("UPGRADE_9_AUTO_VALIDATION", "true").lower() == "true",
            "UPGRADE_10_TEMPLATE_SYSTEM": os.environ.get("UPGRADE_10_TEMPLATE_SYSTEM", "true").lower() == "true",
            
            # PERFORMANCE OPTIONS
            "ENABLE_CACHING": os.environ.get("ENABLE_CACHING", "true").lower() == "true",
            "CACHE_TTL_SECONDS": int(os.environ.get("CACHE_TTL_SECONDS", "300")),
            "ENABLE_QUERY_LOGGING": os.environ.get("ENABLE_QUERY_LOGGING", "true").lower() == "true",
            
            # MEMORY OPTIMIZATION
            "EMBEDDING_CACHE_SIZE": 100 if IS_LOW_RAM else 1000,
            "TOUR_CACHE_ENABLED": not IS_LOW_RAM,
            "PRELOAD_EMBEDDINGS": not IS_LOW_RAM,
        }
    
    @staticmethod
    def is_enabled(upgrade_name: str) -> bool:
        flags = UpgradeFlags.get_all_flags()
        return flags.get(f"UPGRADE_{upgrade_name}", False)

# =========== FLASK APP CONFIG ===========
app = Flask(__name__)
app.json_encoder = EnhancedJSONEncoder  # Use custom JSON encoder
CORS(app, origins=CORS_ORIGINS, supports_credentials=True)

# =========== GLOBAL STATE (USING DATACLASSES) ===========
# Initialize OpenAI client
# ==== OpenAI client (SDK 1.x safe, Render compatible) ====
from openai import OpenAI
import httpx
import os

def create_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY is not set")

    # Render-safe HTTP client (no proxies param in OpenAI 1.x)
    http_client = httpx.Client(
        timeout=60.0,
        follow_redirects=True
    )

    return OpenAI(
        api_key=api_key,
        http_client=http_client
    )

# Create global OpenAI client
client = create_openai_client()


# Knowledge base state
KNOW: Dict = {}                      # Raw knowledge.json data
FLAT_TEXTS: List[str] = []           # All text passages for indexing
MAPPING: List[Dict] = []             # Mapping from text to original path
INDEX = None                         # FAISS or numpy index
INDEX_LOCK = threading.Lock()        # Thread safety for index operations

# Tour databases (USING Tour DATACLASS)
TOUR_NAME_TO_INDEX: Dict[str, int] = {}      # Normalized tour name â†’ index
TOURS_DB: Dict[int, Tour] = {}               # Structured tour database using Tour objects
TOUR_TAGS: Dict[int, List[str]] = {}         # Auto-generated tags for filtering

# Session management (USING ConversationContext DATACLASS)
SESSION_CONTEXTS: Dict[str, ConversationContext] = {}
SESSION_LOCK = threading.Lock()
SESSION_TIMEOUT = 1800  # 30 minutes

# Cache system
_response_cache: Dict[str, CacheEntry] = {}
_cache_lock = threading.Lock()

# Embedding cache (memory optimized)
_embedding_cache: Dict[str, Tuple[List[float], int]] = {}
_embedding_cache_lock = threading.Lock()
MAX_EMBEDDING_CACHE_SIZE = UpgradeFlags.get_all_flags()["EMBEDDING_CACHE_SIZE"]

# =========== MEMORY OPTIMIZATION FUNCTIONS ===========
def optimize_for_memory_profile():
    """Apply memory optimizations based on RAM profile"""
    flags = UpgradeFlags.get_all_flags()
    
    if IS_LOW_RAM:
        logger.info("ðŸ§  Low RAM mode (512MB) - optimizing memory usage")
        # Disable heavy preloading
        global FAISS_ENABLED
        FAISS_ENABLED = False
        
        # Reduce cache sizes
        import functools
        functools.lru_cache(maxsize=128)(embed_text)
        
        # Limit tour loading
        global MAX_TOURS_TO_LOAD
        MAX_TOURS_TO_LOAD = 50
        
    elif IS_HIGH_RAM:
        logger.info("ðŸš€ High RAM mode (2GB) - enabling all features")
        # Enable all features
        FAISS_ENABLED = HAS_FAISS
        MAX_TOURS_TO_LOAD = 1000
        
        # Increase cache sizes
        import functools
        functools.lru_cache(maxsize=flags["EMBEDDING_CACHE_SIZE"])(embed_text)

# =========== UPGRADE 1: MANDATORY FILTER SYSTEM (DATACLASS COMPATIBLE) ===========
class MandatoryFilterSystem:
    """
    UPGRADE 1: Extract and apply mandatory filters BEFORE semantic search
    """
    
    FILTER_PATTERNS = {
        'duration': [
            (r'(?:thá»i gian|máº¥y ngÃ y|bao lÃ¢u|kÃ©o dÃ i)\s*(?:lÃ \s*)?(\d+)\s*(?:ngÃ y|Ä‘Ãªm)', 'exact_duration'),
            (r'(\d+)\s*ngÃ y\s*(?:vÃ \s*)?(\d+)?\s*Ä‘Ãªm', 'days_nights'),
            (r'(\d+)\s*ngÃ y\s*(?:trá»Ÿ lÃªn|trá»Ÿ xuá»‘ng)', 'duration_range'),
            (r'(?:tour|hÃ nh trÃ¬nh)\s*(?:khoáº£ng|táº§m|khoáº£ng)?\s*(\d+)\s*ngÃ y', 'approx_duration'),
            (r'(\d+)\s*ngÃ y', 'exact_duration'),  # THÃŠM DÃ’NG NÃ€Y
        ],
        
        'price': [
            (r'dÆ°á»›i\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'max_price'),
            (r'trÃªn\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'min_price'),
            (r'khoáº£ng\s*(\d[\d,\.]*)\s*(?:Ä‘áº¿n|-)\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'price_range'),
            (r'giÃ¡\s*(?:tá»«\s*)?(\d[\d,\.]*)\s*(?:Ä‘áº¿n|-|tá»›i)\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)', 'price_range'),
            (r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)\s*trá»Ÿ xuá»‘ng', 'max_price'),
            (r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)\s*trá»Ÿ lÃªn', 'min_price'),
        ],
        
        'location': [
            (r'(?:á»Ÿ|táº¡i|vá»|Ä‘áº¿n|thÄƒm)\s+([^.,!?\n]+?)(?:\s|$|\.|,|!|\?)', 'location'),
            (r'(?:Ä‘iá»ƒm Ä‘áº¿n|Ä‘á»‹a Ä‘iá»ƒm|nÆ¡i|vÃ¹ng)\s+(?:lÃ \s*)?([^.,!?\n]+)', 'location'),
            (r'(?:quanh|gáº§n|khu vá»±c)\s+([^.,!?\n]+)', 'near_location'),
        ],
        
        'date_time': [
            (r'(?:thÃ¡ng|vÃ o)\s*(\d{1,2})', 'month'),
            (r'(?:cuá»‘i tuáº§n|weekend)', 'weekend'),
            (r'(?:dá»‹p|lá»…|táº¿t)\s+([^.,!?\n]+)', 'holiday'),
        ],
        
        'group_type': [
            (r'(?:gia Ä‘Ã¬nh|family)', 'family'),
            (r'(?:cáº·p Ä‘Ã´i|couple|Ä‘Ã´i lá»©a)', 'couple'),
            (r'(?:nhÃ³m báº¡n|báº¡n bÃ¨|friends)', 'friends'),
            (r'(?:cÃ´ng ty|doanh nghiá»‡p|team building)', 'corporate'),
            (r'(?:má»™t mÃ¬nh|Ä‘i láº»|solo)', 'solo'),
        ],
    }
    
    @staticmethod
    def extract_filters(message: str) -> FilterSet:
        """
        Extract ALL mandatory filters from user message
        """
        filters = FilterSet()
        
        if not message:
            return filters
        
        message_lower = message.lower()
        
        # 1. DURATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['duration']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'exact_duration':
                    try:
                        days = int(match.group(1))
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'days_nights':
                    try:
                        days = int(match.group(1))
                        nights = int(match.group(2)) if match.group(2) else days
                        # Store in appropriate fields
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass
        
        # 2. PRICE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['price']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                try:
                    if filter_type == 'max_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_max = amount
                            logger.info(f"ðŸ’° Extracted MAX price filter: {amount} VND")
                    
                    elif filter_type == 'min_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_min = amount
                            logger.info(f"ðŸ’° Extracted MIN price filter: {amount} VND")
                    
                    elif filter_type == 'price_range':
                        min_amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(3))
                        max_amount = MandatoryFilterSystem._parse_price(match.group(2), match.group(3))
                        if min_amount and max_amount:
                            filters.price_min = min_amount
                            filters.price_max = max_amount
                            logger.info(f"ðŸ’° Extracted PRICE RANGE: {min_amount} - {max_amount} VND")
                
                except (ValueError, IndexError, AttributeError):
                    continue
        
        # 3. LOCATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['location']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                location = match.group(1).strip()
                if location and len(location) > 1:
                    if filter_type == 'location':
                        filters.location = location
                    elif filter_type == 'near_location':
                        filters.near_location = location
        
        # 4. DATE/TIME FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['date_time']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'month':
                    try:
                        filters.month = int(match.group(1))
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'weekend':
                    filters.weekend = True
                elif filter_type == 'holiday':
                    filters.holiday = match.group(1).strip()
        
        # 5. GROUP TYPE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['group_type']:
            if re.search(pattern, message_lower):
                filters.group_type = filter_type
        
        # 6. SPECIAL KEYWORDS
        special_keywords = {
            'ráº»': ('price_max', 1500000),
            'giÃ¡ ráº»': ('price_max', 1500000),
            'tiáº¿t kiá»‡m': ('price_max', 1500000),
            'cao cáº¥p': ('price_min', 3000000),
            'sang trá»ng': ('price_min', 3000000),
            'premium': ('price_min', 3000000),
            'ngáº¯n ngÃ y': ('duration_max', 2),
            'dÃ i ngÃ y': ('duration_min', 3),
        }
        
        for keyword, (filter_key, value) in special_keywords.items():
            if keyword in message_lower:
                if filter_key == 'price_max':
                    filters.price_max = value
                elif filter_key == 'price_min':
                    filters.price_min = value
                elif filter_key == 'duration_max':
                    filters.duration_max = value
                elif filter_key == 'duration_min':
                    filters.duration_min = value
        
        logger.info(f"ðŸŽ¯ Extracted filters: {filters}")
        return filters
    
    @staticmethod
    def _parse_price(amount_str: str, unit: str) -> Optional[int]:
        """Parse price string like '1.5 triá»‡u' to integer VND"""
        if not amount_str:
            return None
        
        try:
            amount_str = amount_str.replace(',', '').replace('.', '')
            if not amount_str.isdigit():
                return None
            
            amount = int(amount_str)
            
            if unit in ['triá»‡u', 'tr']:
                return amount * 1000000
            elif unit == 'k':
                return amount * 1000
            elif unit == 'nghÃ¬n':
                return amount * 1000
            else:
                return amount if amount > 1000 else amount * 1000
        
        except (ValueError, AttributeError):
            return None
    
    @staticmethod
    def apply_filters(tours_db: Dict[int, Tour], filters: FilterSet) -> List[int]:
        """
        Apply mandatory filters to tour database
        Returns list of tour indices that pass ALL filters
        Enhanced version with better error handling and group_type support
        """
        if filters.is_empty() or not tours_db:
            logger.info(f"ðŸ” No filters or empty DB, returning all {len(tours_db)} tours")
            return list(tours_db.keys())
        
        passing_tours = []
        total_tours = len(tours_db)
        
        try:
            logger.info(f"ðŸŽ¯ Applying filters: {filters}")
            
            # Validate group_type if present
            if hasattr(filters, 'group_type') and filters.group_type:
                valid_group_types = ['family', 'friends', 'corporate', 'solo', 'couple', 'senior', 'group']
                if filters.group_type not in valid_group_types:
                    logger.warning(f"âš ï¸ Invalid group_type: {filters.group_type}, using default filtering")
                    # Continue without group_type filter but log warning
            
            for tour_idx, tour in tours_db.items():
                passes_all = True
                
                # PRICE FILTERING - ENHANCED
                if passes_all and (filters.price_max is not None or filters.price_min is not None):
                    tour_price_text = tour.price or ""
                    if not tour_price_text or tour_price_text.lower() == 'liÃªn há»‡':
                        # If tour doesn't have price, check if we require price filter
                        if filters.price_max is not None or filters.price_min is not None:
                            # If price is required but not available, fail this tour
                            passes_all = False
                    else:
                        tour_prices = MandatoryFilterSystem._extract_tour_prices(tour_price_text)
                        if not tour_prices:
                            # Can't extract price, be conservative - pass if no strict requirement
                            if filters.price_max is not None and filters.price_min is not None:
                                passes_all = False
                        else:
                            min_tour_price = min(tour_prices)
                            max_tour_price = max(tour_prices)
                            
                            # Apply price range filter
                            if filters.price_max is not None and min_tour_price > filters.price_max:
                                passes_all = False
                            if filters.price_min is not None and max_tour_price < filters.price_min:
                                passes_all = False
                
                # DURATION FILTERING - ENHANCED
                if passes_all and (filters.duration_min is not None or filters.duration_max is not None):
                    duration_text = (tour.duration or "").lower()
                    tour_duration = MandatoryFilterSystem._extract_duration_days(duration_text)
                    
                    if tour_duration is not None:
                        if filters.duration_min is not None and tour_duration < filters.duration_min:
                            passes_all = False
                        if filters.duration_max is not None and tour_duration > filters.duration_max:
                            passes_all = False
                    else:
                        # If duration cannot be extracted, be conservative
                        if filters.duration_min is not None and filters.duration_max is not None:
                            passes_all = False
                
                # LOCATION FILTERING - ENHANCED
                if passes_all and (filters.location is not None or filters.near_location is not None):
                    tour_location = (tour.location or "").lower()
                    if filters.location is not None:
                        filter_location = filters.location.lower()
                        # Enhanced location matching
                        if filter_location and filter_location not in tour_location:
                            # Try partial matching for common location names
                            location_keywords = {
                                'huáº¿': ['huáº¿', 'hue'],
                                'quáº£ng trá»‹': ['quáº£ng trá»‹', 'quang tri'],
                                'báº¡ch mÃ£': ['báº¡ch mÃ£', 'bach ma'],
                                'trÆ°á»ng sÆ¡n': ['trÆ°á»ng sÆ¡n', 'truong son'],
                                'Ä‘Ã´ng hÃ ': ['Ä‘Ã´ng hÃ ', 'dong ha']
                            }
                            
                            # Check if filter_location matches any keyword
                            matches = False
                            for keyword, variants in location_keywords.items():
                                if filter_location in variants:
                                    # Check if any variant is in tour_location
                                    for variant in variants:
                                        if variant in tour_location:
                                            matches = True
                                            break
                                if matches:
                                    break
                            
                            if not matches:
                                passes_all = False
                    
                    if filters.near_location is not None and passes_all:
                        near_location = filters.near_location.lower()
                        if near_location and near_location not in tour_location:
                            passes_all = False
                
                # GROUP TYPE FILTERING - ADDED SUPPORT
                if passes_all and hasattr(filters, 'group_type') and filters.group_type:
                    group_type = filters.group_type.lower()
                    tour_summary = (tour.summary or "").lower()
                    tour_tags = [tag.lower() for tag in (tour.tags or [])]
                    
                    # Enhanced group type matching
                    group_type_matched = False
                    
                    # Define keywords for each group type
                    group_keywords = {
                        'family': ['gia Ä‘Ã¬nh', 'tráº» em', 'con nhá»', 'bá»‘ máº¹', 'Ä‘a tháº¿ há»‡'],
                        'friends': ['nhÃ³m báº¡n', 'báº¡n bÃ¨', 'báº¡n tráº»', 'thanh niÃªn', 'sinh viÃªn'],
                        'corporate': ['cÃ´ng ty', 'team building', 'doanh nghiá»‡p', 'nhÃ¢n viÃªn', 'Ä‘á»“ng nghiá»‡p'],
                        'solo': ['má»™t mÃ¬nh', 'Ä‘i láº»', 'solo', 'cÃ¡ nhÃ¢n'],
                        'couple': ['cáº·p Ä‘Ã´i', 'Ä‘Ã´i lá»©a', 'ngÆ°á»i yÃªu', 'tÃ¬nh nhÃ¢n'],
                        'senior': ['ngÆ°á»i lá»›n tuá»•i', 'cao tuá»•i', 'cá»±u chiáº¿n binh', 'veteran'],
                        'group': ['nhÃ³m', 'Ä‘oÃ n', 'táº­p thá»ƒ']
                    }
                    
                    if group_type in group_keywords:
                        keywords = group_keywords[group_type]
                        
                        # Check in tour tags
                        for tag in tour_tags:
                            if any(keyword in tag for keyword in keywords):
                                group_type_matched = True
                                break
                        
                        # Check in tour summary
                        if not group_type_matched:
                            if any(keyword in tour_summary for keyword in keywords):
                                group_type_matched = True
                        
                        # Special handling for senior/veteran
                        if group_type == 'senior':
                            # Also check for historical/meaningful tours
                            if any(word in tour_summary for word in ['lá»‹ch sá»­', 'tri Ã¢n', 'kÃ½ á»©c', 'chiáº¿n tranh']):
                                group_type_matched = True
                        
                        if not group_type_matched:
                            passes_all = False
                    else:
                        logger.warning(f"âš ï¸ Unknown group_type: {group_type}, skipping group filter")
                
                # MONTH FILTERING - ADDED SUPPORT
                if passes_all and hasattr(filters, 'month') and filters.month:
                    try:
                        month = int(filters.month)
                        # Simple season-based filtering
                        tour_summary = (tour.summary or "").lower()
                        
                        # Tours suitable for specific months
                        # This is simplified - in reality would need more complex logic
                        if month in [1, 2, 3]:  # Dry season, good for most tours
                            # No filtering, most tours are suitable
                            pass
                        elif month in [9, 10, 11, 12]:  # Rainy season
                            # Avoid tours with lots of outdoor activities
                            if any(word in tour_summary for word in ['trekking', 'leo nÃºi', 'Ä‘i bá»™ Ä‘Æ°á»ng dÃ i']):
                                passes_all = False
                    except (ValueError, TypeError):
                        # Invalid month format, ignore filter
                        pass
                
                # WEEKEND/HOLIDAY FILTERING - ADDED SUPPORT
                if passes_all:
                    tour_duration = MandatoryFilterSystem._extract_duration_days((tour.duration or "").lower())
                    
                    if hasattr(filters, 'weekend') and filters.weekend and tour_duration:
                        # Weekend tours should be 1-2 days
                        if tour_duration > 2:
                            passes_all = False
                    
                    if hasattr(filters, 'holiday') and filters.holiday and tour_duration:
                        # Holiday tours might be longer
                        # No specific filtering for now
                        pass
                
                if passes_all:
                    passing_tours.append(tour_idx)
            
            logger.info(f"âœ… Filtering complete: {len(passing_tours)}/{total_tours} tours pass")
            
            # If filtering results in too few tours, provide fallback
            if len(passing_tours) < 3 and total_tours > 10:
                logger.info(f"âš ï¸ Only {len(passing_tours)} tours passed filters, applying lenient filtering")
                
                # Apply lenient filtering: tours must pass at least 50% of non-empty filters
                if not filters.is_empty():
                    lenient_passing_tours = []
                    
                    # Count non-empty filters
                    non_empty_filters = 0
                    if filters.price_max is not None or filters.price_min is not None:
                        non_empty_filters += 1
                    if filters.duration_min is not None or filters.duration_max is not None:
                        non_empty_filters += 1
                    if filters.location is not None or filters.near_location is not None:
                        non_empty_filters += 1
                    if hasattr(filters, 'group_type') and filters.group_type:
                        non_empty_filters += 1
                    
                    if non_empty_filters > 0:
                        for tour_idx, tour in tours_db.items():
                            passed_filters = 0
                            
                            # Check price
                            if not (filters.price_max is not None or filters.price_min is not None):
                                passed_filters += 1
                            else:
                                tour_price_text = tour.price or ""
                                if tour_price_text and tour_price_text.lower() != 'liÃªn há»‡':
                                    tour_prices = MandatoryFilterSystem._extract_tour_prices(tour_price_text)
                                    if tour_prices:
                                        min_tour_price = min(tour_prices)
                                        max_tour_price = max(tour_prices)
                                        
                                        price_passed = True
                                        if filters.price_max is not None and min_tour_price > filters.price_max:
                                            price_passed = False
                                        if filters.price_min is not None and max_tour_price < filters.price_min:
                                            price_passed = False
                                        
                                        if price_passed:
                                            passed_filters += 1
                            
                            # Check duration
                            if not (filters.duration_min is not None or filters.duration_max is not None):
                                passed_filters += 1
                            else:
                                duration_text = (tour.duration or "").lower()
                                tour_duration = MandatoryFilterSystem._extract_duration_days(duration_text)
                                
                                if tour_duration is not None:
                                    duration_passed = True
                                    if filters.duration_min is not None and tour_duration < filters.duration_min:
                                        duration_passed = False
                                    if filters.duration_max is not None and tour_duration > filters.duration_max:
                                        duration_passed = False
                                    
                                    if duration_passed:
                                        passed_filters += 1
                            
                            # Check location
                            if not (filters.location is not None or filters.near_location is not None):
                                passed_filters += 1
                            else:
                                tour_location = (tour.location or "").lower()
                                location_passed = True
                                
                                if filters.location is not None:
                                    filter_location = filters.location.lower()
                                    if filter_location not in tour_location:
                                        location_passed = False
                                
                                if filters.near_location is not None and location_passed:
                                    near_location = filters.near_location.lower()
                                    if near_location not in tour_location:
                                        location_passed = False
                                
                                if location_passed:
                                    passed_filters += 1
                            
                            # Check group type
                            if not (hasattr(filters, 'group_type') and filters.group_type):
                                passed_filters += 1
                            else:
                                # Simplified group type check for lenient filtering
                                group_type = filters.group_type.lower()
                                tour_summary = (tour.summary or "").lower()
                                tour_tags = [tag.lower() for tag in (tour.tags or [])]
                                
                                group_passed = False
                                if group_type == 'family':
                                    if any(word in tour_summary for word in ['gia Ä‘Ã¬nh', 'tráº» em', 'con nhá»']):
                                        group_passed = True
                                elif group_type == 'friends':
                                    if any(word in tour_summary for word in ['nhÃ³m báº¡n', 'báº¡n bÃ¨']):
                                        group_passed = True
                                elif group_type == 'senior':
                                    if any(word in tour_summary for word in ['lá»‹ch sá»­', 'tri Ã¢n', 'nháº¹ nhÃ ng']):
                                        group_passed = True
                                else:
                                    # For other group types, be lenient
                                    group_passed = True
                                
                                if group_passed:
                                    passed_filters += 1
                            
                            # Pass if at least 50% of filters passed
                            if passed_filters >= non_empty_filters * 0.5:
                                lenient_passing_tours.append(tour_idx)
                        
                        # Use lenient results if better
                        if len(lenient_passing_tours) > len(passing_tours):
                            logger.info(f"ðŸ”„ Using lenient filtering: {len(lenient_passing_tours)} tours")
                            passing_tours = lenient_passing_tours
            
        except Exception as e:
            logger.error(f"âŒ Error in apply_filters: {e}\n{traceback.format_exc()}")
            # Fallback: return all tours
            passing_tours = list(tours_db.keys())
        
        return passing_tours
        
    @staticmethod
    def _extract_tour_prices(price_text: str) -> List[int]:
        """Extract price numbers from tour price text"""
        prices = []
        
        number_patterns = [
            r'(\d[\d,\.]+)\s*(?:triá»‡u|tr)',
            r'(\d[\d,\.]+)\s*(?:k|nghÃ¬n)',
            r'(\d[\d,\.]+)\s*(?:Ä‘á»“ng|vnÄ‘|vnd)',
            r'(\d[\d,\.]+)\s*-\s*(\d[\d,\.]+)',
        ]
        
        for pattern in number_patterns:
            matches = re.finditer(pattern, price_text, re.IGNORECASE)
            for match in matches:
                try:
                    for i in range(1, 3):
                        if match.group(i):
                            num_str = match.group(i).replace(',', '').replace('.', '')
                            if num_str.isdigit():
                                num = int(num_str)
                                
                                if 'triá»‡u' in match.group(0).lower() or 'tr' in match.group(0).lower():
                                    num = num * 1000000
                                elif 'k' in match.group(0).lower() or 'nghÃ¬n' in match.group(0).lower():
                                    num = num * 1000
                                
                                prices.append(num)
                except (ValueError, AttributeError):
                    continue
        
        if not prices:
            raw_numbers = re.findall(r'\d[\d,\.]+', price_text)
            for num_str in raw_numbers[:2]:
                try:
                    num_str = num_str.replace(',', '').replace('.', '')
                    if num_str.isdigit():
                        num = int(num_str)
                        if 100 <= num <= 10000:
                            num = num * 1000
                        prices.append(num)
                except ValueError:
                    continue
        
        return prices
    
    @staticmethod
    def _extract_duration_days(duration_text: str) -> Optional[int]:
        """Extract duration in days from text"""
        if not duration_text:
            return None
        
        patterns = [
            r'(\d+)\s*ngÃ y',
            r'(\d+)\s*ngÃ y\s*\d*\s*Ä‘Ãªm',
            r'(\d+)\s*Ä‘Ãªm',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, duration_text)
            if match:
                try:
                    return int(match.group(1))
                except (ValueError, IndexError):
                    continue
        
        return None

# =========== UPGRADE 2: DEDUPLICATION ENGINE (DATACLASS COMPATIBLE) ===========
class DeduplicationEngine:
    """
    UPGRADE 2: Remove duplicate and highly similar results
    """
    
    SIMILARITY_THRESHOLD = 0.85
    MIN_TEXT_LENGTH = 20
    
    @staticmethod
    def calculate_similarity(text1: str, text2: str) -> float:
        """Calculate text similarity using multiple methods"""
        if not text1 or not text2:
            return 0.0
        
        text1_norm = DeduplicationEngine._normalize_text(text1)
        text2_norm = DeduplicationEngine._normalize_text(text2)
        
        if len(text1_norm) < DeduplicationEngine.MIN_TEXT_LENGTH or len(text2_norm) < DeduplicationEngine.MIN_TEXT_LENGTH:
            return 0.0
        
        seq_ratio = SequenceMatcher(None, text1_norm, text2_norm).ratio()
        
        words1 = set(text1_norm.split())
        words2 = set(text2_norm.split())
        
        if not words1 or not words2:
            jaccard = 0.0
        else:
            intersection = words1.intersection(words2)
            union = words1.union(words2)
            jaccard = len(intersection) / len(union)
        
        prefix_len = min(50, min(len(text1_norm), len(text2_norm)))
        prefix1 = text1_norm[:prefix_len]
        prefix2 = text2_norm[:prefix_len]
        prefix_sim = SequenceMatcher(None, prefix1, prefix2).ratio()
        
        similarity = (seq_ratio * 0.5) + (jaccard * 0.3) + (prefix_sim * 0.2)
        
        return similarity
    
    @staticmethod
    def _normalize_text(text: str) -> str:
        """Normalize text for comparison"""
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        stopwords = {'vÃ ', 'cá»§a', 'cho', 'vá»›i', 'táº¡i', 'á»Ÿ', 'nÃ y', 'Ä‘Ã³', 'kia', 'vá»', 'trong'}
        words = [word for word in text.split() if word not in stopwords]
        
        return ' '.join(words)
    
    @staticmethod
    def deduplicate_passages(passages: List[Tuple[float, Dict]], 
                            similarity_threshold: float = None) -> List[Tuple[float, Dict]]:
        """
        Remove duplicate passages from results
        """
        if len(passages) <= 1:
            return passages
        
        threshold = similarity_threshold or DeduplicationEngine.SIMILARITY_THRESHOLD
        unique_passages = []
        seen_passages = []
        
        sorted_passages = sorted(passages, key=lambda x: x[0], reverse=True)
        
        for score, passage in sorted_passages:
            text = passage.get('text', '').strip()
            path = passage.get('path', '')
            
            if not text or len(text) < DeduplicationEngine.MIN_TEXT_LENGTH:
                unique_passages.append((score, passage))
                continue
            
            is_duplicate = False
            for seen_text, seen_path in seen_passages:
                tour_match1 = re.search(r'tours\[(\d+)\]', path)
                tour_match2 = re.search(r'tours\[(\d+)\]', seen_path)
                
                if tour_match1 and tour_match2:
                    if tour_match1.group(1) == tour_match2.group(1):
                        field1 = path.split('.')[-1] if '.' in path else ''
                        field2 = seen_path.split('.')[-1] if '.' in seen_path else ''
                        if field1 == field2:
                            is_duplicate = True
                            break
                
                similarity = DeduplicationEngine.calculate_similarity(text, seen_text)
                if similarity > threshold:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_passages.append((score, passage))
                seen_passages.append((text, path))
        
        logger.info(f"ðŸ”„ Deduplication: {len(passages)} â†’ {len(unique_passages)} passages")
        return unique_passages
    
    @staticmethod
    def merge_similar_tours(tour_indices: List[int], tours_db: Dict[int, Tour]) -> List[int]:
        """Merge tours that are essentially the same"""
        if len(tour_indices) <= 1:
            return tour_indices
        
        tour_groups = []
        processed = set()
        
        for i, idx1 in enumerate(tour_indices):
            if idx1 in processed:
                continue
            
            group = [idx1]
            tour1 = tours_db.get(idx1)
            name1 = (tour1.name if tour1 else "").strip()
            
            if not name1:
                processed.add(idx1)
                tour_groups.append(group)
                continue
            
            for j, idx2 in enumerate(tour_indices[i+1:], i+1):
                if idx2 in processed:
                    continue
                
                tour2 = tours_db.get(idx2)
                name2 = (tour2.name if tour2 else "").strip()
                
                if not name2:
                    continue
                
                similarity = DeduplicationEngine.calculate_similarity(name1, name2)
                if similarity > 0.9:
                    group.append(idx2)
                    processed.add(idx2)
            
            processed.add(idx1)
            tour_groups.append(group)
        
        best_tours = []
        for group in tour_groups:
            if not group:
                continue
            
            if len(group) == 1:
                best_tours.append(group[0])
                continue
            
            best_score = -1
            best_idx = group[0]
            
            for idx in group:
                tour = tours_db.get(idx)
                if not tour:
                    continue
                
                score = 0
                
                if tour.name:
                    score += 2
                if tour.duration:
                    score += 2
                if tour.location:
                    score += 2
                if tour.price:
                    score += 3
                if tour.includes:
                    score += 2
                if tour.summary:
                    score += 1
                
                for field in [tour.includes, tour.summary, tour.notes]:
                    if isinstance(field, str) and len(field) > 50:
                        score += 1
                    elif isinstance(field, list) and field:
                        score += len(field)
                
                if score > best_score:
                    best_score = score
                    best_idx = idx
            
            best_tours.append(best_idx)
        
        logger.info(f"ðŸ”„ Tour merging: {len(tour_indices)} â†’ {len(best_tours)} unique tours")
        return best_tours

# =========== UPGRADE 3: ENHANCED FIELD DETECTION (DATACLASS COMPATIBLE) ===========
class EnhancedFieldDetector:
    """
    UPGRADE 3: Better detection of what user is asking for
    """
    
    FIELD_DETECTION_RULES = [
        # TOUR LIST
        {
            "field": "tour_name",
            "patterns": [
                (r'liá»‡t kÃª.*tour|danh sÃ¡ch.*tour|cÃ¡c tour|cÃ³ nhá»¯ng tour nÃ o', 1.0),
                (r'tour nÃ o.*cÃ³|tour nÃ o.*hiá»‡n|tour nÃ o.*Ä‘ang', 0.9),
                (r'ká»ƒ tÃªn.*tour|nÃªu tÃªn.*tour|tÃªn cÃ¡c tour', 0.9),
                (r'cÃ³ máº¥y.*tour|bao nhiÃªu.*tour|sá»‘ lÆ°á»£ng.*tour', 0.8),
                (r'list tour|show tour|all tour|every tour', 0.8),
            ],
            "keywords": [
                ("liá»‡t kÃª", 0.9), ("danh sÃ¡ch", 0.9), ("cÃ¡c", 0.7),
                ("táº¥t cáº£", 0.8), ("má»i", 0.7), ("máº¥y", 0.6),
                ("bao nhiÃªu", 0.7), ("sá»‘ lÆ°á»£ng", 0.7),
            ]
        },
        
        # PRICE
        {
            "field": "price",
            "patterns": [
                (r'giÃ¡.*bao nhiÃªu|bao nhiÃªu tiá»n|chi phÃ­.*bao nhiÃªu', 1.0),
                (r'giÃ¡ tour|giÃ¡ cáº£|giÃ¡ thÃ nh|chi phÃ­ tour', 0.9),
                (r'tour.*giÃ¡.*bao nhiÃªu|tour.*bao nhiÃªu tiá»n', 0.95),
                (r'pháº£i tráº£.*bao nhiÃªu|tá»‘n.*bao nhiÃªu|máº¥t.*bao nhiÃªu', 0.8),
                (r'Ä‘Ã³ng.*bao nhiÃªu|thanh toÃ¡n.*bao nhiÃªu', 0.8),
            ],
            "keywords": [
                ("giÃ¡", 0.8), ("tiá»n", 0.7), ("chi phÃ­", 0.8),
                ("Ä‘Ã³ng", 0.6), ("tráº£", 0.6), ("tá»‘n", 0.6),
                ("phÃ­", 0.7), ("kinh phÃ­", 0.7), ("tá»•ng chi", 0.7),
            ]
        },
        
        # DURATION
        {
            "field": "duration",
            "patterns": [
                (r'thá»i gian.*bao lÃ¢u|máº¥y ngÃ y.*Ä‘i|bao lÃ¢u.*tour', 1.0),
                (r'tour.*bao nhiÃªu ngÃ y|máº¥y ngÃ y.*tour', 0.9),
                (r'Ä‘i trong.*bao lÃ¢u|kÃ©o dÃ i.*bao lÃ¢u', 0.9),
                (r'thá»i lÆ°á»£ng.*bao nhiÃªu|thá»i gian.*dÃ i bao lÃ¢u', 0.8),
            ],
            "keywords": [
                ("bao lÃ¢u", 0.9), ("máº¥y ngÃ y", 0.9), ("thá»i gian", 0.8),
                ("kÃ©o dÃ i", 0.7), ("thá»i lÆ°á»£ng", 0.8), ("ngÃ y", 0.6),
                ("Ä‘Ãªm", 0.6), ("thá»i háº¡n", 0.7),
            ]
        },
        
        # LOCATION
        {
            "field": "location",
            "patterns": [
                (r'á»Ÿ Ä‘Ã¢u|Ä‘i Ä‘Ã¢u|Ä‘áº¿n Ä‘Ã¢u|tá»›i Ä‘Ã¢u|thÄƒm quan Ä‘Ã¢u', 1.0),
                (r'Ä‘á»‹a Ä‘iá»ƒm.*nÃ o|nÆ¡i nÃ o|vÃ¹ng nÃ o|khu vá»±c nÃ o', 0.9),
                (r'tour.*á»Ÿ.*Ä‘Ã¢u|hÃ nh trÃ¬nh.*Ä‘i.*Ä‘Ã¢u', 0.9),
                (r'khÃ¡m phÃ¡.*Ä‘Ã¢u|thÄƒm.*Ä‘Ã¢u|ghÃ©.*Ä‘Ã¢u', 0.8),
            ],
            "keywords": [
                ("á»Ÿ Ä‘Ã¢u", 1.0), ("Ä‘i Ä‘Ã¢u", 1.0), ("Ä‘áº¿n Ä‘Ã¢u", 0.9),
                ("tá»›i Ä‘Ã¢u", 0.9), ("Ä‘á»‹a Ä‘iá»ƒm", 0.8), ("nÆ¡i", 0.7),
                ("vÃ¹ng", 0.7), ("khu vá»±c", 0.7),
            ]
        },
        
        # SUMMARY
        {
            "field": "summary",
            "patterns": [
                (r'cÃ³ gÃ¬ hay|cÃ³ gÃ¬ Ä‘áº·c biá»‡t|cÃ³ gÃ¬ thÃº vá»‹', 0.9),
                (r'tour nÃ y tháº¿ nÃ o|hÃ nh trÃ¬nh ra sao|chuyáº¿n Ä‘i nhÆ° nÃ o', 0.8),
                (r'giá»›i thiá»‡u.*tour|mÃ´ táº£.*tour|nÃ³i vá».*tour', 0.8),
                (r'tour.*cÃ³ gÃ¬|Ä‘i.*Ä‘Æ°á»£c gÃ¬|tráº£i nghiá»‡m.*gÃ¬', 0.7),
                (r'Ä‘iá»ƒm nháº¥n.*tour|ná»•i báº­t.*gÃ¬|Ä‘áº·c sáº¯c.*gÃ¬', 0.7),
            ],
            "keywords": [
                ("cÃ³ gÃ¬", 0.7), ("tháº¿ nÃ o", 0.6), ("ra sao", 0.6),
                ("giá»›i thiá»‡u", 0.7), ("mÃ´ táº£", 0.7), ("nÃ³i vá»", 0.6),
                ("Ä‘iá»ƒm nháº¥n", 0.7), ("ná»•i báº­t", 0.7), ("Ä‘áº·c sáº¯c", 0.7),
            ]
        },
        
        # INCLUDES
        {
            "field": "includes",
            "patterns": [
                (r'lá»‹ch trÃ¬nh.*chi tiáº¿t|chÆ°Æ¡ng trÃ¬nh.*chi tiáº¿t', 0.9),
                (r'lÃ m gÃ¬.*tour|hoáº¡t Ä‘á»™ng.*gÃ¬|sinh hoáº¡t.*gÃ¬', 0.8),
                (r'tour.*gá»“m.*gÃ¬|bao gá»“m.*gÃ¬|gá»“m nhá»¯ng gÃ¬', 0.8),
                (r'Ä‘i Ä‘Ã¢u.*lÃ m gÃ¬|thÄƒm quan.*gÃ¬|khÃ¡m phÃ¡.*gÃ¬', 0.7),
            ],
            "keywords": [
                ("lá»‹ch trÃ¬nh", 0.8), ("chÆ°Æ¡ng trÃ¬nh", 0.8), ("lÃ m gÃ¬", 0.7),
                ("hoáº¡t Ä‘á»™ng", 0.7), ("sinh hoáº¡t", 0.6), ("gá»“m", 0.6),
                ("bao gá»“m", 0.7), ("gá»“m nhá»¯ng", 0.7),
            ]
        },
    ]
    
    @staticmethod
    def detect_field_with_confidence(message: str) -> Tuple[Optional[str], float, Dict[str, float]]:
        """
        Detect which field user is asking about with confidence scores
        """
        if not message:
            return None, 0.0, {}
        
        message_lower = message.lower()
        scores = {}
        
        for rule in EnhancedFieldDetector.FIELD_DETECTION_RULES:
            field = rule["field"]
            field_score = 0.0
            
            for pattern, weight in rule["patterns"]:
                if re.search(pattern, message_lower):
                    field_score = max(field_score, weight)
            
            for keyword, weight in rule["keywords"]:
                if keyword in message_lower:
                    position = message_lower.find(keyword)
                    position_factor = 1.0 - (position / max(len(message_lower), 1))
                    adjusted_weight = weight * (0.7 + 0.3 * position_factor)
                    field_score = max(field_score, adjusted_weight)
            
            if field_score > 0:
                field_score = min(field_score * 1.1, 1.0)
            
            scores[field] = field_score
        
        best_field = None
        best_score = 0.0
        
        for field, score in scores.items():
            if score > best_score:
                best_score = score
                best_field = field
        
        if (best_score < 0.3 and 
            ("cÃ³ gÃ¬" in message_lower or "tháº¿ nÃ o" in message_lower) and
            "tour" in message_lower):
            best_field = "summary"
            best_score = 0.6
        
        logger.info(f"ðŸ” Field detection: '{message}' â†’ {best_field} (confidence: {best_score:.2f})")
        return best_field, best_score, scores

# =========== UPGRADE 4: QUESTION PIPELINE (DATACLASS COMPATIBLE) ===========
class QuestionPipeline:
    """
    UPGRADE 4: Process different types of questions differently
    """
    
    @staticmethod
    def classify_question(message: str) -> Tuple[QuestionType, float, Dict]:
        """
        Classify question type with confidence and metadata
        """
        message_lower = message.lower()
        type_scores = defaultdict(float)
        metadata = {}
        
        # LISTING detection - CHá»ˆ khi yÃªu cáº§u rÃµ rÃ ng liá»‡t kÃª DANH SÃCH
        listing_patterns = [
            (r'liá»‡t kÃª.*táº¥t cáº£.*tour|danh sÃ¡ch.*táº¥t cáº£.*tour|táº¥t cáº£.*tour', 0.95),
            (r'liá»‡t kÃª.*tour|danh sÃ¡ch.*tour|list.*tour', 0.9),
            (r'ká»ƒ tÃªn.*tour|nÃªu tÃªn.*tour', 0.9),
            (r'cÃ³ nhá»¯ng.*tour nÃ o|cÃ³ máº¥y.*tour|máº¥y.*tour', 0.7),
            (r'bÃªn báº¡n.*cÃ³.*tour|hiá»‡n cÃ³.*tour', 0.75),
        ]
        
        for pattern, weight in listing_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.LISTING] = max(
                    type_scores[QuestionType.LISTING], weight
                )
        
        # COMPARISON detection
        comparison_patterns = [
            (r'so sÃ¡nh.*vÃ |Ä‘á»‘i chiáº¿u.*vÃ ', 0.95),
            (r'khÃ¡c nhau.*nÃ o|giá»‘ng nhau.*nÃ o', 0.9),
            (r'nÃªn chá»n.*nÃ o|tá»‘t hÆ¡n.*nÃ o|hÆ¡n kÃ©m.*nÃ o', 0.85),
            (r'tour.*vÃ .*tour', 0.8),
            (r'sÃ¡nh.*vá»›i|Ä‘á»‘i chiáº¿u.*vá»›i', 0.8),
        ]
        
        for pattern, weight in comparison_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.COMPARISON] = max(
                    type_scores[QuestionType.COMPARISON], weight
                )
                metadata['comparison_type'] = 'direct'
        
        # RECOMMENDATION detection
        recommendation_patterns = [
            (r'phÃ¹ há»£p.*vá»›i|nÃªn Ä‘i.*nÃ o|gá»£i Ã½.*tour', 0.95),
            (r'tour nÃ o.*phÃ¹ há»£p|phÃ¹ há»£p.*tour nÃ o', 0.95),
            (r'tour.*tá»‘t.*nháº¥t|hÃ nh trÃ¬nh.*hay nháº¥t|tour.*lÃ½ tÆ°á»Ÿng', 0.9),
            (r'Ä‘á» xuáº¥t.*tour|tÆ° váº¥n.*tour|chá»n.*tour nÃ o', 0.9),
            (r'tour nÃ o.*cho.*gia Ä‘Ã¬nh|tour.*gia Ä‘Ã¬nh|gia Ä‘Ã¬nh.*tour', 0.9),
            (r'tour nÃ o.*cho|dÃ nh cho.*tour|tour.*dÃ nh cho', 0.85),
            (r'nÃªn.*tour nÃ o|nÃªn chá»n.*tour|tour.*nÃªn', 0.85),
            (r'tour.*nháº¹ nhÃ ng|tour.*dá»…|tour.*phÃ¹ há»£p.*ngÆ°á»i', 0.85),
            (r'tour.*tráº» em|tour.*con nÃ­t|tour.*bÃ©', 0.85),
            (r'tour.*ngÆ°á»i lá»›n tuá»•i|tour.*cao tuá»•i|tour.*nghá»‰ dÆ°á»¡ng', 0.85),
            (r'chi phÃ­.*vá»«a pháº£i|giÃ¡.*phÃ¹ há»£p|giÃ¡.*há»£p lÃ½', 0.8),
            (r'cho.*tÃ´i|dÃ nh cho.*tÃ´i|há»£p vá»›i.*tÃ´i', 0.75),
            (r'náº¿u.*thÃ¬.*nÃªn.*tour|nÃªn chá»n.*tour', 0.8),
        ]
        
        for pattern, weight in recommendation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.RECOMMENDATION] = max(
                    type_scores[QuestionType.RECOMMENDATION], weight
                )
        
        # GREETING detection
        greeting_words = ['xin chÃ o', 'chÃ o', 'hello', 'hi', 'helo', 'chao']
        greeting_score = 0.0
        for word in greeting_words:
            if word in message_lower:
                if message_lower.startswith(word) or f" {word} " in message_lower or message_lower.endswith(f" {word}"):
                    greeting_score += 0.3
        
        other_intent_score = max([score for qtype, score in type_scores.items() 
                                 if qtype != QuestionType.GREETING], default=0.0)
        
        if greeting_score > 0.8 and other_intent_score < 0.3:
            type_scores[QuestionType.GREETING] = min(greeting_score, 1.0)
        
        # FAREWELL detection
        farewell_words = ['táº¡m biá»‡t', 'cáº£m Æ¡n', 'thanks', 'thank you', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            type_scores[QuestionType.FAREWELL] = 0.95
        
        # CALCULATION detection
        calculation_patterns = [
            (r'tÃ­nh toÃ¡n|tÃ­nh.*bao nhiÃªu|tá»•ng.*bao nhiÃªu', 0.9),
            (r'cá»™ng.*láº¡i|nhÃ¢n.*lÃªn|chia.*ra', 0.8),
            (r'bao nhiÃªu.*ngÆ°á»i|máº¥y.*ngÆ°á»i|sá»‘ lÆ°á»£ng.*ngÆ°á»i', 0.7),
        ]
        
        for pattern, weight in calculation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.CALCULATION] = max(
                    type_scores[QuestionType.CALCULATION], weight
                )
        
        # COMPLEX question detection
        complex_indicators = [
            ('vÃ ', 0.3), ('rá»“i', 0.4), ('sau Ä‘Ã³', 0.5),
            ('tiáº¿p theo', 0.5), ('ngoÃ i ra', 0.4), ('thÃªm ná»¯a', 0.4),
        ]
        
        complex_score = 0.0
        for indicator, weight in complex_indicators:
            if indicator in message_lower:
                complex_score += weight
        
        if complex_score > 0.8:
            type_scores[QuestionType.COMPLEX] = min(complex_score / 2, 1.0)
            metadata['complex_parts'] = QuestionPipeline._split_complex_question(message)
        
        # DEFAULT: INFORMATION request
        if not type_scores:
            type_scores[QuestionType.INFORMATION] = 0.6
        else:
            info_keywords = ['lÃ  gÃ¬', 'bao nhiÃªu', 'á»Ÿ Ä‘Ã¢u', 'khi nÃ o', 'tháº¿ nÃ o', 'ai', 'táº¡i sao']
            if any(keyword in message_lower for keyword in info_keywords):
                type_scores[QuestionType.INFORMATION] = max(
                    type_scores.get(QuestionType.INFORMATION, 0),
                    0.5
                )
        
        # Determine best type
        best_type = QuestionType.INFORMATION
        best_score = 0.0
        
        for qtype, score in type_scores.items():
            if score > best_score:
                best_score = score
                best_type = qtype
        
        if best_score < 0.5:
            best_type = QuestionType.INFORMATION
            best_score = 0.5
        
        logger.info(f"ðŸŽ¯ Question classification: '{message}' â†’ {best_type.value} (score: {best_score:.2f})")
        return best_type, best_score, metadata
    
    @staticmethod
    def _split_complex_question(message: str) -> List[str]:
        """Split complex multi-part question into simpler parts"""
        split_patterns = [
            r'\s+vÃ \s+',
            r'\s+rá»“i\s+',
            r'\s+sau Ä‘Ã³\s+',
            r'\s+tiáº¿p theo\s+',
            r'\s+ngoÃ i ra\s+',
            r'\s+thÃªm ná»¯a\s+',
            r'\s+Ä‘á»“ng thá»i\s+',
            r'\s+cuá»‘i cÃ¹ng\s+',
        ]
        
        parts = [message]
        
        for pattern in split_patterns:
            new_parts = []
            for part in parts:
                split_result = re.split(pattern, part, flags=re.IGNORECASE)
                new_parts.extend([p.strip() for p in split_result if p.strip()])
            parts = new_parts
        
        return parts
    
    @staticmethod
    def process_comparison_question(tour_indices: List[int], tours_db: Dict[int, Tour], 
                                  aspect: str = "", context: Dict = None) -> str:
        """
        Process comparison question between tours
        """
        if len(tour_indices) < 2:
            return "Cáº§n Ã­t nháº¥t 2 tour Ä‘á»ƒ so sÃ¡nh."
        
        tours_to_compare = []
        for idx in tour_indices[:3]:
            tour = tours_db.get(idx)
            if tour:
                tours_to_compare.append((idx, tour))
        
        if len(tours_to_compare) < 2:
            return "KhÃ´ng tÃ¬m tháº¥y Ä‘á»§ thÃ´ng tin tour Ä‘á»ƒ so sÃ¡nh."
        
        if not aspect:
            aspect = 'price'
        
        result_lines = []
        
        headers = ["TIÃŠU CHÃ"]
        for idx, tour in tours_to_compare:
            tour_name = tour.name or f'Tour #{idx}'
            headers.append(tour_name[:25])
        
        result_lines.append(" | ".join(headers))
        result_lines.append("-" * (len(headers) * 30))
        
        comparison_fields = [
            ('duration', 'â±ï¸ Thá»i gian'),
            ('location', 'ðŸ“ Äá»‹a Ä‘iá»ƒm'),
            ('price', 'ðŸ’° GiÃ¡ tour'),
            ('accommodation', 'ðŸ¨ Chá»— á»Ÿ'),
            ('meals', 'ðŸ½ï¸ Ä‚n uá»‘ng'),
            ('transport', 'ðŸš— Di chuyá»ƒn'),
            ('summary', 'ðŸ“ MÃ´ táº£'),
        ]
        
        for field, display_name in comparison_fields:
            if aspect and field != aspect and aspect not in ['all', 'táº¥t cáº£']:
                continue
            
            row = [display_name]
            all_values = []
            
            for idx, tour in tours_to_compare:
                value = getattr(tour, field, 'N/A')
                if isinstance(value, list):
                    value = ', '.join(value[:2])
                row.append(str(value)[:30])
                all_values.append(str(value).lower())
            
            if len(set(all_values)) > 1 or aspect == field:
                result_lines.append(" | ".join(row))
        
        result_lines.append("\n" + "="*50)
        result_lines.append("**ÄÃNH GIÃ & Gá»¢I Ã:**")
        
        durations = [tour.duration for _, tour in tours_to_compare]
        if any('1 ngÃ y' in d for d in durations) and any('2 ngÃ y' in d for d in durations):
            result_lines.append("â€¢ Náº¿u báº¡n cÃ³ Ã­t thá»i gian: Chá»n tour 1 ngÃ y")
            result_lines.append("â€¢ Náº¿u muá»‘n tráº£i nghiá»‡m sÃ¢u: Chá»n tour 2 ngÃ y")
        
        prices = []
        for _, tour in tours_to_compare:
            price_text = tour.price or ''
            price_nums = re.findall(r'\d[\d,\.]+', price_text)
            if price_nums:
                try:
                    price = int(price_nums[0].replace(',', '').replace('.', ''))
                    prices.append(price)
                except:
                    pass
        
        if len(prices) >= 2:
            min_price_idx = prices.index(min(prices))
            max_price_idx = prices.index(max(prices))
            
            if prices[max_price_idx] > prices[min_price_idx] * 1.5:
                result_lines.append(f"â€¢ Tiáº¿t kiá»‡m chi phÃ­: {headers[min_price_idx + 1]}")
                result_lines.append(f"â€¢ Tráº£i nghiá»‡m cao cáº¥p: {headers[max_price_idx + 1]}")
        
        result_lines.append("\nðŸ’¡ *LiÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t*")
        
        return "\n".join(result_lines)

# =========== UPGRADE 5: COMPLEX QUERY SPLITTER (DATACLASS COMPATIBLE) ===========
class ComplexQueryProcessor:
    """
    UPGRADE 5: Handle complex multi-condition queries
    """
    
    @staticmethod
    def split_query(query: str) -> List[Dict[str, Any]]:
        """
        Split complex query into sub-queries with priorities
        """
        sub_queries = []
        
        complexity_score = ComplexQueryProcessor._calculate_complexity(query)
        if complexity_score < 1.5:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': {},
                'focus': 'general'
            }]
        
        conditions = ComplexQueryProcessor._extract_conditions(query)
        
        if len(conditions) <= 1:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': conditions[0] if conditions else {},
                'focus': 'general'
            }]
        
        sub_queries.append({
            'query': query,
            'priority': 1.0,
            'filters': ComplexQueryProcessor._merge_conditions(conditions),
            'focus': 'specific'
        })
        
        location_conds = [c for c in conditions if 'location' in c]
        other_conds = [c for c in conditions if 'location' not in c]
        
        if location_conds and other_conds:
            for other_cond in other_conds[:2]:
                merged = ComplexQueryProcessor._merge_conditions(location_conds + [other_cond])
                sub_queries.append({
                    'query': f"{query} (focus on location + {list(other_cond.keys())[0]})",
                    'priority': 0.8,
                    'filters': merged,
                    'focus': list(other_cond.keys())[0]
                })
        
        important_conds = ['price', 'duration', 'location']
        for cond_type in important_conds:
            conds_of_type = [c for c in conditions if cond_type in c]
            if conds_of_type:
                sub_queries.append({
                    'query': f"{query} (focus on {cond_type})",
                    'priority': 0.6,
                    'filters': conds_of_type[0],
                    'focus': cond_type
                })
        
        sub_queries.sort(key=lambda x: x['priority'], reverse=True)
        
        logger.info(f"ðŸ”€ Split query into {len(sub_queries)} sub-queries")
        return sub_queries[:3]
    
    @staticmethod
    def _calculate_complexity(query: str) -> float:
        """Calculate how complex a query is"""
        complexity = 0.0
        
        aspects = {
            'price': ['giÃ¡', 'tiá»n', 'chi phÃ­', 'Ä‘áº¯t', 'ráº»'],
            'duration': ['ngÃ y', 'Ä‘Ãªm', 'bao lÃ¢u', 'thá»i gian'],
            'location': ['á»Ÿ', 'táº¡i', 'Ä‘áº¿n', 'vá»', 'Ä‘á»‹a Ä‘iá»ƒm'],
            'quality': ['tá»‘t', 'hay', 'Ä‘áº¹p', 'háº¥p dáº«n', 'thÃº vá»‹'],
            'type': ['thiá»n', 'khÃ­ cÃ´ng', 'retreat', 'chá»¯a lÃ nh'],
        }
        
        query_lower = query.lower()
        
        distinct_aspects = 0
        for aspect, keywords in aspects.items():
            if any(keyword in query_lower for keyword in keywords):
                distinct_aspects += 1
        
        complexity += distinct_aspects * 0.5
        complexity += min(len(query.split()) / 10, 1.0)
        
        conjunctions = ['vÃ ', 'vá»›i', 'cÃ³', 'cho', 'mÃ ', 'nhÆ°ng']
        for conj in conjunctions:
            if conj in query_lower:
                complexity += 0.3
        
        return complexity
    
    @staticmethod
    def _extract_conditions(query: str) -> List[Dict[str, Any]]:
        """Extract individual conditions from query"""
        conditions = []
        
        filters = MandatoryFilterSystem.extract_filters(query)
        
        if filters.price_min is not None or filters.price_max is not None:
            price_cond = {'price': {}}
            if filters.price_min is not None:
                price_cond['price']['min'] = filters.price_min
            if filters.price_max is not None:
                price_cond['price']['max'] = filters.price_max
            conditions.append(price_cond)
        
        if filters.duration_min is not None or filters.duration_max is not None:
            duration_cond = {'duration': {}}
            if filters.duration_min is not None:
                duration_cond['duration']['min'] = filters.duration_min
            if filters.duration_max is not None:
                duration_cond['duration']['max'] = filters.duration_max
            conditions.append(duration_cond)
        
        if filters.location:
            conditions.append({'location': filters.location})
        if filters.near_location:
            conditions.append({'near_location': filters.near_location})
        
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['ráº»', 'giÃ¡ ráº»', 'tiáº¿t kiá»‡m']):
            conditions.append({'price_quality': 'budget'})
        if any(word in query_lower for word in ['cao cáº¥p', 'sang', 'premium']):
            conditions.append({'price_quality': 'premium'})
        
        if 'thiá»n' in query_lower:
            conditions.append({'activity_type': 'meditation'})
        if 'khÃ­ cÃ´ng' in query_lower:
            conditions.append({'activity_type': 'qigong'})
        if 'retreat' in query_lower:
            conditions.append({'activity_type': 'retreat'})
        if 'chá»¯a lÃ nh' in query_lower:
            conditions.append({'activity_type': 'healing'})
        
        tour_name_patterns = [
            r'tour\s+([^vÃ \s,]+)\s+vÃ \s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+vá»›i\s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+.*tour\s+([^\s,]+)',
        ]
        
        for pattern in tour_name_patterns:
            matches = re.finditer(pattern, query_lower)
            for match in matches:
                for i in range(1, 3):
                    if match.group(i):
                        tour_name = match.group(i).strip()
                        normalized_name = FuzzyMatcher.normalize_vietnamese(tour_name)
                        for name, idx in TOUR_NAME_TO_INDEX.items():
                            if normalized_name in name or name in normalized_name:
                                conditions.append({'specific_tour': idx})
                                logger.info(f"ðŸ” Extracted tour name from complex query: {tour_name} â†’ index {idx}")
        
        return conditions
    
    @staticmethod
    def _merge_conditions(conditions: List[Dict]) -> Dict[str, Any]:
        """Merge multiple conditions into one filter dict"""
        merged = {}
        
        for condition in conditions:
            for key, value in condition.items():
                if key in merged:
                    if isinstance(merged[key], dict) and isinstance(value, dict):
                        merged[key].update(value)
                    elif isinstance(merged[key], list) and isinstance(value, list):
                        merged[key].extend(value)
                    else:
                        if isinstance(value, dict) or (isinstance(value, str) and len(value) > len(str(merged[key]))):
                            merged[key] = value
                else:
                    merged[key] = value
        
        return merged

# =========== UPGRADE 6: FUZZY MATCHING (DATACLASS COMPATIBLE) ===========
class FuzzyMatcher:
    """
    UPGRADE 6: Handle misspellings and variations in tour names
    """
    
    SIMILARITY_THRESHOLD = 0.75
    
    @staticmethod
    def normalize_vietnamese(text: str) -> str:
        """
        Normalize Vietnamese text for fuzzy matching
        """
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        
        replacements = {
            'Ä‘': 'd',
            'khÃ´ng': 'ko',
            'khong': 'ko',
            'rá»“i': 'roi',
            'vá»›i': 'voi',
            'Ä‘Æ°á»£c': 'duoc',
            'má»™t': 'mot',
            'hai': '2',
            'ba': '3',
            'bá»‘n': '4',
            'nÄƒm': '5',
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    @staticmethod
    def find_similar_tours(query: str, tour_names: Dict[str, int]) -> List[Tuple[int, float]]:
        """
        Find tours with names similar to query - Enhanced version
        Returns list of (tour_idx, similarity_score) sorted by similarity
        """
        if not query or not tour_names:
            logger.info(f"ðŸ” Fuzzy matching: Empty query or tour_names, returning empty list")
            return []
        
        query_lower = query.lower().strip()
        query_norm = FuzzyMatcher.normalize_vietnamese(query_lower)
        
        if not query_norm:
            logger.info(f"ðŸ” Fuzzy matching: Cannot normalize query '{query}'")
            return []
        
        logger.info(f"ðŸ” Fuzzy matching: Query '{query}' -> Normalized: '{query_norm}'")
        
        matches = []
        query_words = set(query_norm.split())
        
        # Define common stop words to ignore
        stop_words = {'tour', 'chÆ°Æ¡ng', 'trÃ¬nh', 'cá»§a', 'cho', 'vá»›i', 'vÃ ', 'táº¡i', 'á»Ÿ', 'tá»«'}
        query_filtered_words = [word for word in query_norm.split() if word not in stop_words]
        
        # Enhanced keyword extraction
        query_keywords = set(query_filtered_words)
        
        # Check for specific tour patterns
        known_tour_patterns = {
            'báº¡ch mÃ£': ['báº¡ch mÃ£', 'bach ma'],
            'trÆ°á»ng sÆ¡n': ['trÆ°á»ng sÆ¡n', 'truong son', 'tÃ¢y trÆ°á»ng sÆ¡n'],
            'mÆ°a Ä‘á»': ['mÆ°a Ä‘á»', 'mua do'],
            'ngá»n lá»­a': ['ngá»n lá»­a', 'ngon lua'],
            'kÃ½ á»©c': ['kÃ½ á»©c', 'ky uc'],
            'lá»‹ch sá»­': ['lá»‹ch sá»­', 'lich su'],
            'Ä‘áº¡i ngÃ n': ['Ä‘áº¡i ngÃ n', 'dai ngan'],
            'non nÆ°á»›c': ['non nÆ°á»›c', 'non nuoc'],
            'hÃ nh trÃ¬nh': ['hÃ nh trÃ¬nh', 'hanh trinh'],
            'khÃ¡t vá»ng': ['khÃ¡t vá»ng', 'khat vong'],
            'tÄ©nh láº·ng': ['tÄ©nh láº·ng', 'tinh lang'],
            'retreat': ['retreat', 'tÄ©nh tÃ¢m', 'tinh tam'],
            'thiá»n': ['thiá»n', 'thien'],
            'huáº¿': ['huáº¿', 'hue'],
            'quáº£ng trá»‹': ['quáº£ng trá»‹', 'quang tri']
        }
        
        # Extract potential tour name from query
        extracted_tour_names = []
        for pattern, variants in known_tour_patterns.items():
            for variant in variants:
                if variant in query_lower:
                    extracted_tour_names.append(pattern)
                    break
        
        logger.info(f"ðŸ” Extracted tour patterns: {extracted_tour_names}")
        
        for tour_name, tour_idx in tour_names.items():
            tour_name_lower = tour_name.lower().strip()
            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name_lower)
            
            if not tour_norm:
                continue
            
            # Calculate multiple similarity scores
            scores = []
            
            # 1. Direct string similarity
            direct_similarity = SequenceMatcher(None, query_norm, tour_norm).ratio()
            scores.append(('direct', direct_similarity))
            
            # 2. Check if query contains tour name or vice versa (partial match)
            if query_norm in tour_norm:
                scores.append(('query_in_tour', min(direct_similarity + 0.3, 1.0)))
            if tour_norm in query_norm:
                scores.append(('tour_in_query', min(direct_similarity + 0.3, 1.0)))
            
            # 3. Word overlap similarity
            tour_words = set(tour_norm.split())
            tour_filtered_words = [word for word in tour_norm.split() if word not in stop_words]
            
            common_words = query_words.intersection(tour_words)
            if common_words:
                word_overlap = len(common_words) / max(len(query_words), len(tour_words))
                scores.append(('word_overlap', word_overlap))
            
            # 4. Enhanced keyword matching
            if query_keywords:
                keyword_matches = sum(1 for keyword in query_keywords if any(keyword in word for word in tour_filtered_words))
                if keyword_matches > 0:
                    keyword_score = keyword_matches / len(query_keywords)
                    scores.append(('keyword', keyword_score))
            
            # 5. Pattern matching for known tour names
            pattern_score = 0
            for pattern in extracted_tour_names:
                if pattern in tour_norm:
                    pattern_score += 0.5
            if pattern_score > 0:
                scores.append(('pattern', min(pattern_score, 1.0)))
            
            # 6. Abbreviation/alias matching
            # Check if tour has common abbreviations
            tour_abbreviations = {
                'báº¡ch mÃ£': 'bm',
                'trÆ°á»ng sÆ¡n': 'ts',
                'mÆ°a Ä‘á»': 'md',
                'huáº¿': 'h',
                'quáº£ng trá»‹': 'qt'
            }
            
            for full, abbrev in tour_abbreviations.items():
                if full in tour_norm and abbrev in query_norm:
                    scores.append(('abbreviation', 0.7))
                    break
            
            # 7. Number matching (for tour durations like 1 ngÃ y, 2 ngÃ y)
            import re
            query_numbers = set(re.findall(r'\d+', query_norm))
            tour_numbers = set(re.findall(r'\d+', tour_norm))
            if query_numbers and tour_numbers:
                number_match = len(query_numbers.intersection(tour_numbers)) / len(query_numbers)
                if number_match > 0:
                    scores.append(('number', number_match))
            
            # Calculate final similarity (weighted average)
            weights = {
                'direct': 0.3,
                'query_in_tour': 0.25,
                'tour_in_query': 0.25,
                'word_overlap': 0.15,
                'keyword': 0.15,
                'pattern': 0.1,
                'abbreviation': 0.05,
                'number': 0.05
            }
            
            weighted_scores = []
            for score_type, score_value in scores:
                if score_type in weights:
                    weighted_scores.append(score_value * weights[score_type])
            
            final_similarity = sum(weighted_scores) if weighted_scores else direct_similarity
            
            # Apply bonuses for specific cases
            bonuses = 0
            
            # Bonus for exact word match
            exact_word_match = any(word == tour_word for word in query_filtered_words for tour_word in tour_filtered_words)
            if exact_word_match:
                bonuses += 0.1
            
            # Bonus for matching at beginning of tour name
            if query_filtered_words and any(tour_norm.startswith(word) for word in query_filtered_words):
                bonuses += 0.15
            
            # Bonus for historical/relevant keywords
            historical_keywords = ['lá»‹ch sá»­', 'chiáº¿n tranh', 'di tÃ­ch', 'tri Ã¢n', 'cá»±u chiáº¿n binh']
            if any(keyword in query_norm for keyword in historical_keywords) and \
            any(keyword in tour_norm for keyword in historical_keywords):
                bonuses += 0.2
            
            # Bonus for wellness/retreat keywords
            wellness_keywords = ['thiá»n', 'yoga', 'retreat', 'tÄ©nh tÃ¢m', 'khÃ­ cÃ´ng', 'chá»¯a lÃ nh']
            if any(keyword in query_norm for keyword in wellness_keywords) and \
            any(keyword in tour_norm for keyword in wellness_keywords):
                bonuses += 0.2
            
            final_similarity = min(final_similarity + bonuses, 1.0)
            
            # Adjust threshold based on query complexity
            dynamic_threshold = 0.5  # Base threshold
            
            # Lower threshold for complex queries (more words)
            if len(query_filtered_words) >= 3:
                dynamic_threshold = 0.4
            
            # Higher threshold for very short queries
            if len(query_filtered_words) == 1:
                dynamic_threshold = 0.6
            
            # Special case for known tour patterns
            if extracted_tour_names and any(pattern in tour_norm for pattern in extracted_tour_names):
                dynamic_threshold = 0.3
            
            if final_similarity >= dynamic_threshold:
                matches.append((tour_idx, final_similarity))
                logger.debug(f"  âœ“ Match: '{tour_name}' (idx: {tour_idx}) - Score: {final_similarity:.2f}")
        
        # Sort by similarity score (descending)
        matches.sort(key=lambda x: x[1], reverse=True)
        
        # Limit results but ensure we get relevant matches
        max_results = 10
        if matches:
            # Ensure we include all high-confidence matches (>0.7)
            high_confidence = [m for m in matches if m[1] > 0.7]
            if high_confidence:
                matches = high_confidence + [m for m in matches if m[1] <= 0.7][:max_results - len(high_confidence)]
            else:
                matches = matches[:max_results]
        
        logger.info(f"âœ… Fuzzy matching: '{query}' â†’ {len(matches)} matches (threshold: dynamic)")
        
        # Log top matches for debugging
        if matches:
            for i, (idx, score) in enumerate(matches[:5]):
                tour_name = next((name for name, tid in tour_names.items() if tid == idx), "Unknown")
                logger.debug(f"  Top {i+1}: {tour_name} (idx: {idx}) - Score: {score:.2f}")
        
        return matches


    # ThÃªm phÆ°Æ¡ng thá»©c helper cho normalization nÃ¢ng cao náº¿u cáº§n
    @staticmethod
    def enhanced_normalize_vietnamese(text: str) -> str:
        """
        Enhanced Vietnamese text normalization
        """
        if not text:
            return ""
        
        # Basic normalization (giá»¯ nguyÃªn tá»« hÃ m gá»‘c)
        normalized = text.lower().strip()
        
        # Remove extra spaces
        normalized = ' '.join(normalized.split())
        
        # Common replacements for tour names
        replacements = {
            'â€“': ' ',
            '-': ' ',
            'â€“': ' ',
            '(': ' ',
            ')': ' ',
            ',': ' ',
            '.': ' ',
            '!': ' ',
            '?': ' ',
            '"': ' ',
            "'": ' ',
            ';': ' ',
            ':': ' ',
        }
        
        for old, new in replacements.items():
            normalized = normalized.replace(old, new)
        
        # Remove multiple spaces again
        normalized = ' '.join(normalized.split())
        
        return normalizeds
        
    @staticmethod
    def find_tour_by_partial_name(partial_name: str, tours_db: Dict[int, Tour]) -> List[int]:
        """
        Find tours by partial name match
        """
        if not partial_name or not tours_db:
            return []
        
        partial_norm = FuzzyMatcher.normalize_vietnamese(partial_name)
        matches = []
        
        for tour_idx, tour in tours_db.items():
            tour_name = tour.name or ""
            if not tour_name:
                continue
            
            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name)
            
            if partial_norm in tour_norm:
                match_ratio = len(partial_norm) / len(tour_norm) if tour_norm else 0
                matches.append((tour_idx, match_ratio))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        return [idx for idx, _ in matches[:3]]

# =========== UPGRADE 7: STATE MACHINE (DATACLASS COMPATIBLE) ===========
class ConversationStateMachine:
    """
    UPGRADE 7: Track conversation state for better context
    """
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.state = ConversationState.INITIAL
        self.context = ConversationContext(session_id=session_id)
        self.transitions = []
        self.created_at = datetime.utcnow()
        self.last_updated = datetime.utcnow()
    
    def update(self, user_message: str, bot_response: str, tour_indices: List[int] = None):
        """Update state based on new interaction"""
        self.last_updated = datetime.utcnow()
        self.context.update(user_message, bot_response, tour_indices)
        
        new_state = self._determine_state(user_message, bot_response)
        
        self.transitions.append({
            'timestamp': datetime.utcnow().isoformat(),
            'from': self.state.value,
            'to': new_state.value,
            'message': user_message[:100]
        })
        
        self.state = new_state
        
        logger.info(f"ðŸ”„ State update: {self.state.value} for session {self.session_id}")
    
    def _determine_state(self, user_message: str, bot_response: str) -> ConversationState:
        """Determine new state based on current interaction"""
        message_lower = user_message.lower()
        
        farewell_words = ['táº¡m biá»‡t', 'cáº£m Æ¡n', 'thanks', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            return ConversationState.FAREWELL
        
        tour_ref_patterns = [
            r'tour nÃ y', r'tour Ä‘Ã³', r'tour Ä‘ang nÃ³i', r'cÃ¡i tour',
            r'nÃ³', r'cÃ¡i Ä‘Ã³', r'cÃ¡i nÃ y', r'Ä‘áº¥y'
        ]
        
        if any(re.search(pattern, message_lower) for pattern in tour_ref_patterns):
            if self.context.current_tours:
                return ConversationState.TOUR_SELECTED
            elif self.context.last_successful_tours:
                self.context.current_tours = self.context.last_successful_tours
                return ConversationState.TOUR_SELECTED
        
        if 'so sÃ¡nh' in message_lower or 'sÃ¡nh' in message_lower:
            return ConversationState.COMPARING
        
        if any(word in message_lower for word in ['phÃ¹ há»£p', 'gá»£i Ã½', 'Ä‘á» xuáº¥t', 'tÆ° váº¥n', 'nÃªn chá»n']):
            return ConversationState.RECOMMENDATION
        
        if any(word in message_lower for word in ['Ä‘áº·t', 'booking', 'Ä‘Äƒng kÃ½', 'giá»¯ chá»—']):
            return ConversationState.BOOKING
        
        if self.context.current_tours:
            return ConversationState.ASKING_DETAILS
        
        return ConversationState.INITIAL
    
    def get_context_hint(self) -> str:
        """Get hint about current context for LLM prompt"""
        hints = []
        
        if self.state == ConversationState.TOUR_SELECTED and self.context.current_tours:
            tour_indices = self.context.current_tours
            if len(tour_indices) == 1:
                hints.append(f"User is asking about tour index {tour_indices[0]}")
            else:
                hints.append(f"User is asking about tours {tour_indices}")
        
        if self.context.user_preferences:
            prefs = []
            for key, value in self.context.user_preferences.items():
                prefs.append(f"{key}: {value}")
            if prefs:
                hints.append(f"User preferences: {', '.join(prefs)}")
        
        return "; ".join(hints) if hints else "No specific context"
    
    def extract_reference(self, message: str) -> List[int]:
        """Extract tour reference from message using conversation context"""
        message_lower = message.lower()
        
        if self.context.current_tours:
            for tour_idx in self.context.current_tours:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"ðŸ”„ State machine: Using current tour {tour_idx}")
                        return self.context.current_tours
        
        ref_patterns = [
            (r'tour nÃ y', 1.0),
            (r'tour Ä‘Ã³', 0.9),
            (r'tour Ä‘ang nÃ³i', 0.9),
            (r'cÃ¡i tour', 0.8),
            (r'nÃ³', 0.7),
            (r'Ä‘áº¥y', 0.7),
            (r'cÃ¡i Ä‘Ã³', 0.7),
        ]
        
        for pattern, confidence in ref_patterns:
            if re.search(pattern, message_lower):
                if self.context.current_tours:
                    logger.info(f"ðŸ”„ State machine: Resolved reference to {self.context.current_tours}")
                    return self.context.current_tours
                elif self.context.last_successful_tours:
                    logger.info(f"ðŸ”„ State machine: Using last successful tours {self.context.last_successful_tours}")
                    return self.context.last_successful_tours
        
        if self.context.mentioned_tours:
            recent_tours = list(self.context.mentioned_tours)
            for tour_idx in recent_tours[-3:]:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"ðŸ”„ State machine: Matched to recently mentioned tour {tour_idx}")
                        return [tour_idx]
        
        return []

# =========== UPGRADE 8: DEEP SEMANTIC ANALYSIS (DATACLASS COMPATIBLE) ===========
class SemanticAnalyzer:
    """
    UPGRADE 8: Deep understanding of user intent beyond keywords
    """
    
    USER_PROFILE_PATTERNS = {
        'age_group': [
            (r'ngÆ°á»i giÃ |ngÆ°á»i lá»›n tuá»•i|cao tuá»•i', 'senior'),
            (r'thanh niÃªn|tráº»|sinh viÃªn|há»c sinh', 'young'),
            (r'trung niÃªn|trung tuá»•i', 'middle_aged'),
            (r'gia Ä‘Ã¬nh.*tráº» em|tráº» nhá»|con nÃ­t', 'family_with_kids'),
        ],
        
        'group_type': [
            (r'má»™t mÃ¬nh|Ä‘i láº»|solo', 'solo'),
            (r'cáº·p Ä‘Ã´i|Ä‘Ã´i lá»©a|ngÆ°á»i yÃªu', 'couple'),
            (r'gia Ä‘Ã¬nh|bá»‘ máº¹ con', 'family'),
            (r'báº¡n bÃ¨|nhÃ³m báº¡n|há»™i báº¡n', 'friends'),
            (r'cÃ´ng ty|doanh nghiá»‡p|Ä‘á»“ng nghiá»‡p', 'corporate'),
        ],
        
        'interest_type': [
            (r'thiÃªn nhiÃªn|rá»«ng|cÃ¢y|cáº£nh quan', 'nature'),
            (r'lá»‹ch sá»­|di tÃ­ch|chiáº¿n tranh|tri Ã¢n', 'history'),
            (r'vÄƒn hÃ³a|cá»™ng Ä‘á»“ng|dÃ¢n tá»™c|truyá»n thá»‘ng', 'culture'),
            (r'thiá»n|tÃ¢m linh|tÄ©nh tÃ¢m|yoga', 'spiritual'),
            (r'khÃ­ cÃ´ng|sá»©c khá»e|chá»¯a lÃ nh|wellness', 'wellness'),
            (r'áº©m thá»±c|Ä‘á»“ Äƒn|mÃ³n ngon|Ä‘áº·c sáº£n', 'food'),
            (r'phiÃªu lÆ°u|máº¡o hiá»ƒm|khÃ¡m phÃ¡|tráº£i nghiá»‡m', 'adventure'),
        ],
        
        'budget_level': [
            (r'kinh táº¿|tiáº¿t kiá»‡m|ráº»|giÃ¡ tháº¥p', 'budget'),
            (r'trung bÃ¬nh|vá»«a pháº£i|pháº£i chÄƒng', 'midrange'),
            (r'cao cáº¥p|sang trá»ng|premium|Ä‘áº¯t', 'premium'),
        ],
        
        'physical_level': [
            (r'nháº¹ nhÃ ng|dá»… dÃ ng|khÃ´ng má»‡t', 'easy'),
            (r'vá»«a pháº£i|trung bÃ¬nh|bÃ¬nh thÆ°á»ng', 'moderate'),
            (r'thá»­ thÃ¡ch|khÃ³|má»‡t|leo nÃºi', 'challenging'),
        ],
    }
    
    @staticmethod
    def analyze_user_profile(message: str, current_context: ConversationContext = None) -> UserProfile:
        """
        Analyze message to build user profile
        """
        if current_context and hasattr(current_context, 'user_profile') and current_context.user_profile:
            profile = current_context.user_profile
        else:
            profile = UserProfile()
        
        message_lower = message.lower()
        
        for category, patterns in SemanticAnalyzer.USER_PROFILE_PATTERNS.items():
            for pattern, value in patterns:
                if re.search(pattern, message_lower):
                    if category == 'interests':
                        if value not in profile.interests:
                            profile.interests.append(value)
                            profile.confidence_scores[f'interest_{value}'] = 0.8
                    else:
                        setattr(profile, category, value)
                        profile.confidence_scores[category] = 0.8
        
        SemanticAnalyzer._infer_attributes(profile, message_lower)
        profile.overall_confidence = SemanticAnalyzer._calculate_confidence(profile)
        
        logger.info(f"ðŸ‘¤ User profile analysis: {profile}")
        return profile
    
    @staticmethod
    def _infer_attributes(profile: UserProfile, message_lower: str):
        """Infer additional attributes from context"""
        if not profile.age_group:
            if profile.group_type and 'family_with_kids' in profile.group_type:
                profile.age_group = 'middle_aged'
                profile.confidence_scores['age_group'] = 0.6
            elif 'senior' in message_lower or 'giÃ ' in message_lower:
                profile.age_group = 'senior'
                profile.confidence_scores['age_group'] = 0.7
        
        if not profile.physical_level:
            if 'adventure' in profile.interests:
                profile.physical_level = 'challenging'
                profile.confidence_scores['physical_level'] = 0.6
            elif 'spiritual' in profile.interests or 'wellness' in profile.interests:
                profile.physical_level = 'easy'
                profile.confidence_scores['physical_level'] = 0.6
        
        if not profile.budget_level:
            budget_keywords = {
                'budget': ['ráº»', 'tiáº¿t kiá»‡m', 'Ã­t tiá»n', 'kinh táº¿'],
                'premium': ['cao cáº¥p', 'sang', 'Ä‘áº¯t', 'premium']
            }
            
            for level, keywords in budget_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    profile.budget_level = level
                    profile.confidence_scores['budget_level'] = 0.7
                    break
    
    @staticmethod
    def _calculate_confidence(profile: UserProfile) -> float:
        """Calculate overall confidence in user profile"""
        if not profile.confidence_scores:
            return 0.0
        
        total = 0.0
        count = 0
        
        for key, score in profile.confidence_scores.items():
            total += score
            count += 1
        
        return total / max(count, 1)
    
    @staticmethod
    def match_tours_to_profile(profile: UserProfile, tours_db: Dict[int, Tour], 
                              max_results: int = 5) -> List[Tuple[int, float, List[str]]]:
        """
        Match tours to user profile with explanation
        """
        matches = []
        
        for tour_idx, tour in tours_db.items():
            score = 0.0
            reasons = []
            
            tour_tags = tour.tags or []
            
            if profile.age_group:
                if profile.age_group == 'senior':
                    if any('easy' in tag for tag in tour_tags):
                        score += 0.3
                        reasons.append("phÃ¹ há»£p ngÆ°á»i lá»›n tuá»•i")
                    if any('nature' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("thiÃªn nhiÃªn nháº¹ nhÃ ng")
            
            if profile.interests:
                for interest in profile.interests:
                    tour_summary = (tour.summary or "").lower()
                    if (interest in tour_summary or 
                        any(interest in tag for tag in tour_tags)):
                        score += 0.4
                        reasons.append(f"cÃ³ yáº¿u tá»‘ {interest}")
            
            if profile.budget_level:
                tour_price = tour.price or ""
                price_nums = re.findall(r'\d[\d,\.]+', tour_price)
                
                if price_nums:
                    try:
                        first_price = int(price_nums[0].replace(',', '').replace('.', ''))
                        
                        if profile.budget_level == 'budget' and first_price < 2000000:
                            score += 0.3
                            reasons.append("giÃ¡ há»£p lÃ½")
                        elif profile.budget_level == 'premium' and first_price > 2500000:
                            score += 0.3
                            reasons.append("cao cáº¥p")
                        elif profile.budget_level == 'midrange' and 1500000 <= first_price <= 3000000:
                            score += 0.3
                            reasons.append("giÃ¡ vá»«a pháº£i")
                    except:
                        pass
            
            if profile.physical_level:
                if profile.physical_level == 'easy':
                    if any('easy' in tag or 'meditation' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng")
            
            if score > 0:
                matches.append((tour_idx, score, reasons))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        return matches[:max_results]

# =========== UPGRADE 9: AUTO-VALIDATION SYSTEM (DATACLASS COMPATIBLE) ===========
class AutoValidator:
    """
    UPGRADE 9: Validate and correct information before returning
    """
    
    VALIDATION_RULES = {
        'duration': {
            'patterns': [
                r'(\d+)\s*ngÃ y\s*(\d+)\s*Ä‘Ãªm',
                r'(\d+)\s*ngÃ y',
                r'(\d+)\s*Ä‘Ãªm',
            ],
            'constraints': {
                'max_days': 7,
                'max_nights': 7,
                'valid_day_night_combos': [(1,0), (1,1), (2,1), (2,2), (3,2), (3,3)],
                'common_durations': ['1 ngÃ y', '2 ngÃ y 1 Ä‘Ãªm', '3 ngÃ y 2 Ä‘Ãªm']
            }
        },
        
        'price': {
            'patterns': [
                r'(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)',
                r'(\d[\d,\.]*)\s*-\s*(\d[\d,\.]*)\s*(triá»‡u|tr|k|nghÃ¬n)?',
                r'(\d[\d,\.]*)\s*(Ä‘á»“ng|vnÄ‘|vnd)',
            ],
            'constraints': {
                'min_tour_price': 500000,
                'max_tour_price': 10000000,
                'common_ranges': [
                    (800000, 1500000),
                    (1500000, 2500000),
                    (2500000, 4000000),
                ]
            }
        },
        
        'location': {
            'patterns': [
                r'á»Ÿ\s+([^.,!?]+)',
                r'táº¡i\s+([^.,!?]+)',
                r'Ä‘áº¿n\s+([^.,!?]+)',
            ],
            'constraints': {
                'valid_locations': ['Huáº¿', 'Quáº£ng Trá»‹', 'Báº¡ch MÃ£', 'TrÆ°á»ng SÆ¡n', 'ÄÃ´ng HÃ ', 'Khe Sanh'],
                'max_length': 100
            }
        },
    }
    
    @staticmethod
    def validate_response(response: str) -> str:
        """
        Validate and correct response content
        """
        if not response:
            return response
        
        validated = response
        
        validated = AutoValidator._validate_duration(validated)
        validated = AutoValidator._validate_price(validated)
        validated = AutoValidator._validate_locations(validated)
        validated = AutoValidator._check_unrealistic_info(validated)
        
        if validated != response:
            validated = AutoValidator._add_validation_note(validated)
        
        return validated
    
    @staticmethod
    def _validate_duration(text: str) -> str:
        """Validate and correct duration information"""
        for pattern in AutoValidator.VALIDATION_RULES['duration']['patterns']:
            matches = list(re.finditer(pattern, text))
            for match in matches:
                try:
                    if match.lastindex == 2:
                        days = int(match.group(1))
                        nights = int(match.group(2))
                        
                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']
                        
                        valid_combos = constraints['valid_day_night_combos']
                        is_valid_combo = any(d == d2 and n == n2 for d2, n2 in valid_combos)
                        
                        if days > constraints['max_days'] or nights > constraints['max_nights']:
                            replacement = random.choice(constraints['common_durations'])
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"âš ï¸ Corrected unrealistic duration: {days} ngÃ y {nights} Ä‘Ãªm â†’ {replacement}")
                        
                        elif not is_valid_combo:
                            valid_days = min(days, constraints['max_days'])
                            valid_nights = min(nights, constraints['max_nights'])
                            if abs(valid_days - valid_nights) > 1:
                                valid_nights = valid_days
                            
                            replacement = f"{valid_days} ngÃ y {valid_nights} Ä‘Ãªm"
                            text = text.replace(match.group(0), replacement)
                            logger.info(f"ðŸ”„ Fixed duration combo: {replacement}")
                    
                    elif match.lastindex == 1:
                        num = int(match.group(1))
                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']
                        
                        if num > constraints['max_days']:
                            replacement = f"{constraints['max_days']} ngÃ y"
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"âš ï¸ Capped long duration: {num} â†’ {constraints['max_days']}")
                
                except (ValueError, IndexError):
                    continue
        
        return text
    
    @staticmethod
    def _validate_price(text: str) -> str:
        """Validate and correct price information"""
        for pattern in AutoValidator.VALIDATION_RULES['price']['patterns']:
            matches = list(re.finditer(pattern, text, re.IGNORECASE))
            for match in matches:
                try:
                    amount_str = match.group(1).replace(',', '').replace('.', '')
                    if not amount_str.isdigit():
                        continue
                    
                    amount = int(amount_str)
                    
                    unit = match.group(2).lower() if match.lastindex >= 2 else ''
                    
                    if unit in ['triá»‡u', 'tr']:
                        amount = amount * 1000000
                    elif unit in ['k', 'nghÃ¬n']:
                        amount = amount * 1000
                    
                    constraints = AutoValidator.VALIDATION_RULES['price']['constraints']
                    
                    if amount < constraints['min_tour_price']:
                        replacement = "giÃ¡ há»£p lÃ½"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"âš ï¸ Corrected too-low price: {amount} â†’ {replacement}")
                    
                    elif amount > constraints['max_tour_price']:
                        replacement = "giÃ¡ cao cáº¥p"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"âš ï¸ Corrected too-high price: {amount} â†’ {replacement}")
                
                except (ValueError, IndexError, AttributeError):
                    continue
        
        return text
    
    @staticmethod
    def _validate_locations(text: str) -> str:
        """Validate location names"""
        wrong_locations = {
            'hÃ  ná»™i': 'Huáº¿',
            'há»“ chÃ­ minh': 'Quáº£ng Trá»‹',
            'Ä‘Ã  náºµng': 'Báº¡ch MÃ£',
            'nha trang': 'TrÆ°á»ng SÆ¡n',
        }
        
        for wrong, correct in wrong_locations.items():
            if wrong in text.lower():
                text = text.replace(wrong, correct)
                text = text.replace(wrong.capitalize(), correct)
                logger.info(f"ðŸ”„ Corrected location: {wrong} â†’ {correct}")
        
        return text
    
    @staticmethod
    def _check_unrealistic_info(text: str) -> str:
        """Check for other unrealistic information"""
        unrealistic_patterns = [
            (r'\d+\s*giá»\s*bay', "thá»i gian di chuyá»ƒn"),
            (r'\d+\s*sao', "cháº¥t lÆ°á»£ng dá»‹ch vá»¥"),
            (r'\d+\s*táº§ng', "chá»— á»Ÿ"),
            (r'\d+\s*m\s*cao', "Ä‘á»‹a hÃ¬nh"),
        ]
        
        for pattern, replacement in unrealistic_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
                logger.info(f"ðŸ”„ Replaced unrealistic info with: {replacement}")
        
        return text
    
    @staticmethod
    def _add_validation_note(text: str) -> str:
        """Add note about information validation"""
        note = "\n\n*ThÃ´ng tin Ä‘Æ°á»£c cung cáº¥p dá»±a trÃªn dá»¯ liá»‡u hiá»‡n cÃ³. " \
               "Vui lÃ²ng liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ xÃ¡c nháº­n chi tiáº¿t chÃ­nh xÃ¡c nháº¥t.*"
        
        if note not in text:
            text += note
        
        return text

# =========== UPGRADE 10: TEMPLATE SYSTEM (DATACLASS COMPATIBLE) ===========
class TemplateSystem:
    """
    UPGRADE 10: Beautiful, structured responses for different question types
    """
    
    TEMPLATES = {
        'tour_list': {
            'header': "âœ¨ **DANH SÃCH TOUR RUBY WINGS** âœ¨\n\n",
            'item': "**{index}. {tour_name}** {emoji}\n"
                   "   ðŸ“… {duration}\n"
                   "   ðŸ“ {location}\n"
                   "   ðŸ’° {price}\n"
                   "   {summary}\n",
            'footer': "\nðŸ“ž **LiÃªn há»‡ Ä‘áº·t tour:** 0332510486\n"
                     "ðŸ“ **Ruby Wings Travel** - HÃ nh trÃ¬nh tráº£i nghiá»‡m Ä‘áº·c sáº¯c\n"
                     "ðŸ’¡ *Há»i chi tiáº¿t vá» báº¥t ká»³ tour nÃ o báº±ng cÃ¡ch nháº­p tÃªn tour*",
            'emoji_map': {
                '1 ngÃ y': 'ðŸŒ…',
                '2 ngÃ y': 'ðŸŒ„',
                '3 ngÃ y': 'ðŸ”ï¸',
                'default': 'âœ¨'
            }
        },
        
        'tour_detail': {
            'header': "ðŸŽ¯ **{tour_name}**\n\n",
            'sections': {
                'overview': "ðŸ“‹ **THÃ”NG TIN CHÃNH:**\n"
                          "   â±ï¸ Thá»i gian: {duration}\n"
                          "   ðŸ“ Äá»‹a Ä‘iá»ƒm: {location}\n"
                          "   ðŸ’° GiÃ¡ tour: {price}\n\n",
                'description': "ðŸ“– **MÃ” Táº¢ TOUR:**\n{summary}\n\n",
                'includes': "ðŸŽª **Lá»ŠCH TRÃŒNH & Dá»ŠCH Vá»¤:**\n{includes}\n\n",
                'accommodation': "ðŸ¨ **CHá»– á»ž:**\n{accommodation}\n\n",
                'meals': "ðŸ½ï¸ **Ä‚N Uá»NG:**\n{meals}\n\n",
                'transport': "ðŸš— **DI CHUYá»‚N:**\n{transport}\n\n",
                'notes': "ðŸ“ **GHI CHÃš:**\n{notes}\n\n",
            },
            'footer': "ðŸ“ž **Äáº¶T TOUR & TÆ¯ Váº¾N:** 0332510486\n"
                     "â­ *Tour phÃ¹ há»£p cho: {suitable_for}*",
            'default_values': {
                'duration': 'Äang cáº­p nháº­t',
                'location': 'Äang cáº­p nháº­t',
                'price': 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡',
                'summary': 'HÃ nh trÃ¬nh tráº£i nghiá»‡m Ä‘áº·c sáº¯c cá»§a Ruby Wings',
                'includes': 'Chi tiáº¿t lá»‹ch trÃ¬nh liÃªn há»‡ tÆ° váº¥n',
                'accommodation': 'Äang cáº­p nháº­t',
                'meals': 'Äang cáº­p nháº­t',
                'transport': 'Äang cáº­p nháº­t',
                'notes': 'Vui lÃ²ng liÃªn há»‡ Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t',
                'suitable_for': 'má»i Ä‘á»‘i tÆ°á»£ng',
            }
        },
        
        'comparison': {
            'header': "ðŸ“Š **SO SÃNH TOUR**\n\n",
            'table_header': "| TiÃªu chÃ­ | {tour1} | {tour2} |\n|----------|----------|----------|\n",
            'table_row': "| {criterion} | {value1} | {value2} |\n",
            'recommendation': "\nðŸ’¡ **Gá»¢I Ã Lá»°A CHá»ŒN:**\n{recommendations}\n",
            'footer': "\nðŸ“ž **TÆ° váº¥n chi tiáº¿t:** 0332510486\n"
                     "ðŸ¤” *Cáº§n so sÃ¡nh thÃªm tiÃªu chÃ­ nÃ o?*",
        },
        
        'recommendation': {
            'header': "ðŸŽ¯ **Äá»€ XUáº¤T TOUR PHÃ™ Há»¢P**\n\n",
            'top_recommendation': "ðŸ† **PHÃ™ Há»¢P NHáº¤T ({score}%)**\n"
                                "**{tour_name}**\n"
                                "   âœ… {reasons}\n"
                                "   ðŸ“… {duration} | ðŸ“ {location} | ðŸ’° {price}\n\n",
            'other_recommendations': "ðŸ“‹ **Lá»°A CHá»ŒN KHÃC:**\n",
            'other_item': "   â€¢ **{tour_name}** ({score}%)\n"
                         "     ðŸ“… {duration} | ðŸ“ {location}\n",
            'criteria': "\nðŸ” **TIÃŠU CHÃ Äá»€ XUáº¤T:**\n{criteria}\n",
            'footer': "\nðŸ“ž **LiÃªn há»‡ tÆ° váº¥n cÃ¡ nhÃ¢n hÃ³a:** 0332510486\n"
                     "ðŸ’¬ *Cho tÃ´i biáº¿t thÃªm sá»Ÿ thÃ­ch cá»§a báº¡n Ä‘á»ƒ Ä‘á» xuáº¥t chÃ­nh xÃ¡c hÆ¡n*",
        },
        
        'information': {
            'header': "â„¹ï¸ **THÃ”NG TIN:**\n\n",
            'content': "{content}\n",
            'sources': "\nðŸ“š *Nguá»“n thÃ´ng tin tá»« dá»¯ liá»‡u Ruby Wings*",
            'footer': "\nðŸ“ž **Hotline há»— trá»£:** 0332510486",
        },
        
        'greeting': {
            'template': "ðŸ‘‹ **Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI cá»§a Ruby Wings**\n\n"
                       "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:\n"
                       "â€¢ TÃ¬m hiá»ƒu vá» cÃ¡c tour tráº£i nghiá»‡m\n"
                       "â€¢ So sÃ¡nh cÃ¡c hÃ nh trÃ¬nh\n"
                       "â€¢ Äá» xuáº¥t tour phÃ¹ há»£p vá»›i báº¡n\n"
                       "â€¢ Cung cáº¥p thÃ´ng tin chi tiáº¿t vá» tour\n\n"
                       "ðŸ’¡ **VÃ­ dá»¥ báº¡n cÃ³ thá»ƒ há»i:**\n"
                       "- 'CÃ³ nhá»¯ng tour nÃ o?'\n"
                       "- 'Tour Báº¡ch MÃ£ giÃ¡ bao nhiÃªu?'\n"
                       "- 'Tour nÃ o phÃ¹ há»£p cho gia Ä‘Ã¬nh?'\n\n"
                       "HÃ£y cho tÃ´i biáº¿t báº¡n cáº§n gÃ¬ nhÃ©! ðŸ˜Š",
        },
        
        'farewell': {
            'template': "ðŸ™ **Cáº£m Æ¡n báº¡n Ä‘Ã£ trÃ² chuyá»‡n cÃ¹ng Ruby Wings!**\n\n"
                       "ChÃºc báº¡n má»™t ngÃ y trÃ n Ä‘áº§y nÄƒng lÆ°á»£ng vÃ  bÃ¬nh an.\n"
                       "Hy vá»ng sá»›m Ä‘Æ°á»£c Ä‘á»“ng hÃ nh cÃ¹ng báº¡n trong hÃ nh trÃ¬nh tráº£i nghiá»‡m sáº¯p tá»›i!\n\n"
                       "ðŸ“ž **LiÃªn há»‡ Ä‘áº·t tour:** 0332510486\n"
                       "ðŸŒ **Website:** rubywings.vn\n\n"
                       "Háº¹n gáº·p láº¡i! âœ¨",
        },
    }
    
    @staticmethod
    def render(template_name: str, **kwargs) -> str:
        """Render template with provided variables"""
        template_data = TemplateSystem.TEMPLATES.get(template_name)
        if not template_data:
            return kwargs.get('content', '')
        
        if template_name in ['greeting', 'farewell']:
            return template_data['template']
        
        response_parts = []
        
        if 'header' in template_data:
            header = template_data['header']
            for key, value in kwargs.items():
                header = header.replace(f'{{{key}}}', str(value))
            response_parts.append(header)
        
        if template_name == 'tour_list':
            response_parts.append(TemplateSystem._render_tour_list(template_data, kwargs))
        
        elif template_name == 'tour_detail':
            response_parts.append(TemplateSystem._render_tour_detail(template_data, kwargs))
        
        elif template_name == 'comparison':
            response_parts.append(TemplateSystem._render_comparison(template_data, kwargs))
        
        elif template_name == 'recommendation':
            response_parts.append(TemplateSystem._render_recommendation(template_data, kwargs))
        
        elif template_name == 'information':
            response_parts.append(TemplateSystem._render_information(template_data, kwargs))
        
        if 'footer' in template_data:
            footer = template_data['footer']
            for key, value in kwargs.items():
                footer = footer.replace(f'{{{key}}}', str(value))
            response_parts.append(footer)
        
        return '\n'.join(response_parts)
    
    @staticmethod
    def _render_tour_list(template_data: Dict, kwargs: Dict) -> str:
        """Render tour list template"""
        tours = kwargs.get('tours', [])
        if not tours:
            return "Hiá»‡n chÆ°a cÃ³ thÃ´ng tin tour."
        
        items = []
        for i, tour in enumerate(tours[:10], 1):
            duration = tour.duration or ''
            emoji = template_data['emoji_map'].get('default')
            for dur_pattern, dur_emoji in template_data['emoji_map'].items():
                if dur_pattern in duration.lower():
                    emoji = dur_emoji
                    break
            
            item_template = template_data['item']
            item = item_template.format(
                index=i,
                tour_name=tour.name or f'Tour #{i}',
                emoji=emoji or 'âœ¨',
                duration=duration or 'Äang cáº­p nháº­t',
                location=tour.location or 'Äang cáº­p nháº­t',
                price=tour.price or 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡',
                summary=(tour.summary or 'Tour tráº£i nghiá»‡m Ä‘áº·c sáº¯c')[:100] + '...'
            )
            items.append(item)
        
        return '\n'.join(items)
    
    @staticmethod
    def _render_tour_detail(template_data: Dict, kwargs: Dict) -> str:
        """Render tour detail template"""
        sections = []
        
        for section_name, section_template in template_data['sections'].items():
            value = kwargs.get(section_name, template_data['default_values'].get(section_name, ''))
            
            if value and value != template_data['default_values'].get(section_name):
                if isinstance(value, list):
                    if section_name == 'includes':
                        value = '\n'.join([f'   â€¢ {item}' for item in value[:5]])
                    else:
                        value = ', '.join(value[:3])
                
                section = section_template.format(**{section_name: value})
                sections.append(section)
        
        return '\n'.join(sections)
    
    @staticmethod
    def _render_comparison(template_data: Dict, kwargs: Dict) -> str:
        """Render comparison template"""
        comparison_table = []
        
        tour1_name = kwargs.get('tour1_name', 'Tour 1')[:20]
        tour2_name = kwargs.get('tour2_name', 'Tour 2')[:20]
        table_header = template_data['table_header'].format(tour1=tour1_name, tour2=tour2_name)
        comparison_table.append(table_header)
        
        criteria = kwargs.get('criteria', [])
        for criterion in criteria[:8]:
            row = template_data['table_row'].format(
                criterion=criterion.get('name', ''),
                value1=criterion.get('value1', 'N/A')[:20],
                value2=criterion.get('value2', 'N/A')[:20]
            )
            comparison_table.append(row)
        
        return '\n'.join(comparison_table)
    
    @staticmethod
    def _render_recommendation(template_data: Dict, kwargs: Dict) -> str:
        """Render recommendation template"""
        recommendation_text = []
        
        top_tour = kwargs.get('top_tour')
        if top_tour:
            top_text = template_data['top_recommendation'].format(
                score=int(top_tour.get('score', 0) * 100),
                tour_name=top_tour.get('name', ''),
                reasons=', '.join(top_tour.get('reasons', ['phÃ¹ há»£p'])[:3]),
                duration=top_tour.get('duration', ''),
                location=top_tour.get('location', ''),
                price=top_tour.get('price', 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡')
            )
            recommendation_text.append(top_text)
        
        other_tours = kwargs.get('other_tours', [])
        if other_tours:
            recommendation_text.append(template_data['other_recommendations'])
            
            for tour in other_tours[:2]:
                other_item = template_data['other_item'].format(
                    tour_name=tour.get('name', ''),
                    score=int(tour.get('score', 0) * 100),
                    duration=tour.get('duration', ''),
                    location=tour.get('location', '')
                )
                recommendation_text.append(other_item)
        
        return '\n'.join(recommendation_text)
    
    @staticmethod
    def _render_information(template_data: Dict, kwargs: Dict) -> str:
        """Render information template"""
        content = kwargs.get('content', '')
        if not content:
            return ""
        
        info_text = template_data['content'].format(content=content)
        
        if kwargs.get('has_sources'):
            info_text += template_data['sources']
        
        return info_text

# =========== TOUR DATABASE BUILDER (USING Tour DATACLASS) ===========
def load_knowledge(path: str = KNOWLEDGE_PATH):
    """Load knowledge base from JSON file"""
    global KNOW, FLAT_TEXTS, MAPPING
    
    try:
        with open(path, "r", encoding="utf-8") as f:
            KNOW = json.load(f)
        logger.info(f"âœ… Loaded knowledge from {path}")
    except Exception as e:
        logger.error(f"âŒ Could not open {path}: {e}")
        KNOW = {}
    
    FLAT_TEXTS = []
    MAPPING = []
    
    def scan(obj, prefix="root"):
        if isinstance(obj, dict):
            for k, v in obj.items():
                scan(v, f"{prefix}.{k}")
        elif isinstance(obj, list):
            for i, v in enumerate(obj):
                scan(v, f"{prefix}[{i}]")
        elif isinstance(obj, str):
            t = obj.strip()
            if t:
                FLAT_TEXTS.append(t)
                MAPPING.append({"path": prefix, "text": t})
        else:
            try:
                s = str(obj).strip()
                if s:
                    FLAT_TEXTS.append(s)
                    MAPPING.append({"path": prefix, "text": s})
            except Exception:
                pass
    
    scan(KNOW)
    logger.info(f"ðŸ“Š Knowledge scanned: {len(FLAT_TEXTS)} passages")

def index_tour_names():
    """Build tour name to index mapping"""
    global TOUR_NAME_TO_INDEX
    TOUR_NAME_TO_INDEX = {}
    
    for m in MAPPING:
        path = m.get("path", "")
        if path.endswith(".tour_name"):
            txt = m.get("text", "") or ""
            norm = normalize_text_simple(txt)
            if not norm:
                continue
            
            match = re.search(r"\[(\d+)\]", path)
            if match:
                idx = int(match.group(1))
                prev = TOUR_NAME_TO_INDEX.get(norm)
                if prev is None:
                    TOUR_NAME_TO_INDEX[norm] = idx
                else:
                    existing_txt = MAPPING[next(
                        i for i, m2 in enumerate(MAPPING) 
                        if re.search(rf"\[{prev}\]", m2.get('path','')) and ".tour_name" in m2.get('path','')
                    )].get("text","")
                    if len(txt) > len(existing_txt):
                        TOUR_NAME_TO_INDEX[norm] = idx
    
    logger.info(f"ðŸ“ Indexed {len(TOUR_NAME_TO_INDEX)} tour names")

def build_tours_db():
    """Build structured tour database from MAPPING using Tour dataclass"""
    global TOURS_DB, TOUR_TAGS
    
    TOURS_DB.clear()
    TOUR_TAGS.clear()
    
    # First pass: collect all fields for each tour
    for m in MAPPING:
        path = m.get("path", "")
        text = m.get("text", "")
        
        if not path or not text:
            continue
        
        tour_match = re.search(r'tours\[(\d+)\]', path)
        if not tour_match:
            continue
        
        tour_idx = int(tour_match.group(1))
        
        field_match = re.search(r'tours\[\d+\]\.(\w+)(?:\[\d+\])?', path)
        if not field_match:
            continue
        
        field_name = field_match.group(1)
        
        # Initialize tour entry
        if tour_idx not in TOURS_DB:
            TOURS_DB[tour_idx] = Tour(index=tour_idx)
        
        # Update field in Tour object
        tour_obj = TOURS_DB[tour_idx]
        if field_name == 'tour_name':
            tour_obj.name = text
        elif field_name == 'duration':
            tour_obj.duration = text
        elif field_name == 'location':
            tour_obj.location = text
        elif field_name == 'price':
            tour_obj.price = text
        elif field_name == 'summary':
            tour_obj.summary = text
        elif field_name == 'includes':
            if isinstance(tour_obj.includes, list):
                tour_obj.includes.append(text)
            else:
                tour_obj.includes = [text]
        elif field_name == 'accommodation':
            tour_obj.accommodation = text
        elif field_name == 'meals':
            tour_obj.meals = text
        elif field_name == 'transport':
            tour_obj.transport = text
        elif field_name == 'notes':
            tour_obj.notes = text
        elif field_name == 'style':
            tour_obj.style = text
    
    # Second pass: generate tags and metadata
    for tour_idx, tour_obj in TOURS_DB.items():
        tags = []
        
        # Location tags
        if tour_obj.location:
            locations = [loc.strip() for loc in tour_obj.location.split(",") if loc.strip()]
            tags.extend([f"location:{loc}" for loc in locations[:2]])
        
        # Duration tags
        if tour_obj.duration:
            duration_lower = tour_obj.duration.lower()
            if "1 ngÃ y" in duration_lower:
                tags.append("duration:1day")
            elif "2 ngÃ y" in duration_lower:
                tags.append("duration:2day")
            elif "3 ngÃ y" in duration_lower:
                tags.append("duration:3day")
            else:
                day_match = re.search(r'(\d+)\s*ngÃ y', duration_lower)
                if day_match:
                    days = int(day_match.group(1))
                    tags.append(f"duration:{days}day")
        
        # Price tags
        if tour_obj.price:
            price_nums = re.findall(r'[\d,\.]+', tour_obj.price)
            if price_nums:
                try:
                    clean_nums = []
                    for p in price_nums[:2]:
                        p_clean = p.replace(',', '').replace('.', '')
                        if p_clean.isdigit():
                            clean_nums.append(int(p_clean))
                    
                    if clean_nums:
                        avg_price = sum(clean_nums) / len(clean_nums)
                        if avg_price < 1000000:
                            tags.append("price:budget")
                        elif avg_price < 2000000:
                            tags.append("price:midrange")
                        else:
                            tags.append("price:premium")
                except:
                    pass
        
        # Style/theme tags
        text_to_check = (tour_obj.style + " " + (tour_obj.summary or '')).lower()
        
        theme_keywords = {
            'meditation': ['thiá»n', 'chÃ¡nh niá»‡m', 'tÃ¢m linh'],
            'history': ['lá»‹ch sá»­', 'di tÃ­ch', 'chiáº¿n tranh', 'tri Ã¢n'],
            'nature': ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi', 'cÃ¢y'],
            'culture': ['vÄƒn hÃ³a', 'cá»™ng Ä‘á»“ng', 'dÃ¢n tá»™c'],
            'wellness': ['khÃ­ cÃ´ng', 'sá»©c khá»e', 'chá»¯a lÃ nh'],
            'adventure': ['phiÃªu lÆ°u', 'máº¡o hiá»ƒm', 'khÃ¡m phÃ¡'],
        }
        
        for theme, keywords in theme_keywords.items():
            if any(keyword in text_to_check for keyword in keywords):
                tags.append(f"theme:{theme}")
        
        # Destination tags from tour name
        if tour_obj.name:
            name_lower = tour_obj.name.lower()
            if "báº¡ch mÃ£" in name_lower:
                tags.append("destination:bachma")
            if "trÆ°á»ng sÆ¡n" in name_lower:
                tags.append("destination:truongson")
            if "quáº£ng trá»‹" in name_lower:
                tags.append("destination:quangtri")
            if "huáº¿" in name_lower:
                tags.append("destination:hue")
        
        # Update Tour object tags
        tour_obj.tags = list(set(tags))
        TOUR_TAGS[tour_idx] = tour_obj.tags
        
        # Calculate completeness score
        completeness = 0
        important_fields = ['name', 'duration', 'location', 'price', 'summary']
        for field in important_fields:
            if getattr(tour_obj, field, None):
                completeness += 1
        
        tour_obj.completeness_score = completeness / len(important_fields)
    
    logger.info(f"âœ… Built tours database: {len(TOURS_DB)} tours with tags")

def get_passages_by_field(field_name: str, limit: int = 50, 
                         tour_indices: Optional[List[int]] = None) -> List[Tuple[float, Dict]]:
    """
    Get passages for a specific field
    """
    exact_matches = []
    global_matches = []
    
    for m in MAPPING:
        path = m.get("path", "")
        if path.endswith(f".{field_name}") or f".{field_name}" in path:
            is_exact_match = False
            if tour_indices:
                for ti in tour_indices:
                    if f"[{ti}]" in path:
                        is_exact_match = True
                        break
            
            if is_exact_match:
                exact_matches.append((2.0, m))
            elif not tour_indices:
                global_matches.append((1.0, m))
    
    all_results = exact_matches + global_matches
    all_results.sort(key=lambda x: x[0], reverse=True)
    return all_results[:limit]

# =========== CACHE SYSTEM (DATACLASS COMPATIBLE) ===========
class CacheSystem:
    """Simple caching system for responses"""
    
    @staticmethod
    def get_cache_key(query: str, context_hash: str = "") -> str:
        """Generate cache key"""
        key_parts = [query]
        if context_hash:
            key_parts.append(context_hash)
        return hashlib.md5("|".join(key_parts).encode()).hexdigest()
    
    @staticmethod
    def get(key: str, ttl_seconds: int = 300):
        """Get item from cache"""
        with _cache_lock:
            if key in _response_cache:
                cache_entry = _response_cache[key]
                if not cache_entry.is_expired():
                    logger.info(f"ðŸ’¾ Cache hit for key: {key[:20]}...")
                    return cache_entry.value
                else:
                    del _response_cache[key]
            return None
    
    @staticmethod
    def set(key: str, value: Any, expiry: int = None):
        """
        Set item in cache with enhanced features
        - Supports custom expiry (TTL in seconds)
        - Intelligent cache eviction
        - Thread-safe with lock
        """
        with _cache_lock:
            try:
                # Get TTL from parameter or config
                ttl_seconds = expiry or UpgradeFlags.get_all_flags().get("CACHE_TTL_SECONDS", 300)
                
                # Create cache entry
                cache_entry = CacheEntry(
                    key=key,
                    value=value,
                    created_at=datetime.utcnow(),
                    ttl_seconds=ttl_seconds,
                    access_count=0,  # Track how many times accessed
                    last_accessed=datetime.utcnow()
                )
                
                # Store in cache
                _response_cache[key] = cache_entry
                
                # Intelligent cache cleaning
                CacheSystem._clean_cache()
                
                logger.debug(f"ðŸ’¾ Cached response for key: {key[:50]}... (TTL: {ttl_seconds}s)")
                
            except Exception as e:
                logger.error(f"âŒ Cache set error: {e}")
                # Don't crash if cache fails


    @staticmethod
    def _clean_cache():
        """
        Intelligent cache cleaning with multiple strategies
        """
        try:
            now = datetime.utcnow()
            cache_size = len(_response_cache)
            
            # Strategy 1: Remove expired entries
            expired_keys = []
            for key, entry in _response_cache.items():
                # Check if entry has expired
                if hasattr(entry, 'is_expired'):
                    if entry.is_expired(now):
                        expired_keys.append(key)
                else:
                    # Fallback: manual expiration check
                    age = (now - entry.created_at).total_seconds()
                    if age > (entry.ttl_seconds if hasattr(entry, 'ttl_seconds') else 300):
                        expired_keys.append(key)
            
            # Remove expired entries
            for key in expired_keys:
                del _response_cache[key]
            
            if expired_keys:
                logger.debug(f"ðŸ§¹ Removed {len(expired_keys)} expired cache entries")
            
            # Strategy 2: If still over limit, remove least recently used
            current_size = len(_response_cache)
            if current_size > 1000:
                logger.warning(f"âš ï¸ Cache size ({current_size}) exceeds limit, performing LRU cleanup")
                
                # Sort by last accessed time (oldest first)
                lru_items = sorted(_response_cache.items(), 
                                key=lambda x: x[1].last_accessed if hasattr(x[1], 'last_accessed') 
                                else x[1].created_at)
                
                # Remove oldest 20% or at least 200 items
                remove_count = max(200, int(current_size * 0.2))
                remove_keys = [k for k, _ in lru_items[:remove_count]]
                
                for key in remove_keys:
                    if key in _response_cache:
                        del _response_cache[key]
                
                logger.info(f"ðŸ§¹ LRU cleanup removed {len(remove_keys)} items")
            
            # Strategy 3: Clean up very old entries regardless of size
            if _response_cache:
                very_old_threshold = 86400  # 24 hours in seconds
                very_old_keys = []
                
                for key, entry in _response_cache.items():
                    age = (now - entry.created_at).total_seconds()
                    if age > very_old_threshold:
                        very_old_keys.append(key)
                
                if very_old_keys:
                    for key in very_old_keys:
                        del _response_cache[key]
                    logger.debug(f"ðŸ§¹ Removed {len(very_old_keys)} very old cache entries")
            
            # Final size check
            final_size = len(_response_cache)
            if final_size > 0:
                logger.debug(f"ðŸ“Š Cache stats: {final_size} items, " 
                            f"approx. {final_size * 0.5:.1f}KB memory")
                
        except Exception as e:
            logger.error(f"âŒ Cache cleanup error: {e}")


    @staticmethod
    def get(key: str, update_access: bool = True) -> Optional[Any]:
        """
        Get item from cache with enhanced features
        - Updates access count and timestamp
        - Auto-removes expired items
        """
        with _cache_lock:
            try:
                if key not in _response_cache:
                    return None
                
                entry = _response_cache[key]
                now = datetime.utcnow()
                
                # Check expiration
                if hasattr(entry, 'is_expired'):
                    if entry.is_expired(now):
                        del _response_cache[key]
                        logger.debug(f"ðŸ—‘ï¸  Auto-removed expired cache: {key[:50]}...")
                        return None
                else:
                    # Manual expiration check
                    age = (now - entry.created_at).total_seconds()
                    ttl = entry.ttl_seconds if hasattr(entry, 'ttl_seconds') else 300
                    if age > ttl:
                        del _response_cache[key]
                        return None
                
                # Update access metadata if requested
                if update_access:
                    if hasattr(entry, 'access_count'):
                        entry.access_count += 1
                    if hasattr(entry, 'last_accessed'):
                        entry.last_accessed = now
                
                logger.debug(f"ðŸ’¾ Cache hit for key: {key[:50]}...")
                return entry.value
                
            except Exception as e:
                logger.error(f"âŒ Cache get error: {e}")
                return None


    @staticmethod
    def delete(key: str) -> bool:
        """Delete specific cache entry"""
        with _cache_lock:
            try:
                if key in _response_cache:
                    del _response_cache[key]
                    logger.debug(f"ðŸ—‘ï¸  Deleted cache: {key[:50]}...")
                    return True
                return False
            except Exception as e:
                logger.error(f"âŒ Cache delete error: {e}")
                return False


    @staticmethod
    def clear() -> int:
        """Clear all cache, return number of items cleared"""
        with _cache_lock:
            try:
                count = len(_response_cache)
                _response_cache.clear()
                logger.info(f"ðŸ§¹ Cleared all cache ({count} items)")
                return count
            except Exception as e:
                logger.error(f"âŒ Cache clear error: {e}")
                return 0


    @staticmethod
    def stats() -> Dict[str, Any]:
        """Get cache statistics"""
        with _cache_lock:
            try:
                now = datetime.utcnow()
                total_size = len(_response_cache)
                
                # Calculate age distribution
                age_distribution = {
                    "under_1min": 0,
                    "1min_10min": 0,
                    "10min_1hour": 0,
                    "1hour_24hour": 0,
                    "over_24hour": 0
                }
                
                # Calculate expiration status
                expired_count = 0
                will_expire_soon = 0  # Within 60 seconds
                
                for entry in _response_cache.values():
                    # Age distribution
                    age = (now - entry.created_at).total_seconds()
                    if age < 60:
                        age_distribution["under_1min"] += 1
                    elif age < 600:
                        age_distribution["1min_10min"] += 1
                    elif age < 3600:
                        age_distribution["10min_1hour"] += 1
                    elif age < 86400:
                        age_distribution["1hour_24hour"] += 1
                    else:
                        age_distribution["over_24hour"] += 1
                    
                    # Expiration check
                    ttl = entry.ttl_seconds if hasattr(entry, 'ttl_seconds') else 300
                    remaining = ttl - age
                    if remaining <= 0:
                        expired_count += 1
                    elif remaining < 60:
                        will_expire_soon += 1
                
                return {
                    "total_items": total_size,
                    "age_distribution": age_distribution,
                    "expired_items": expired_count,
                    "expiring_soon": will_expire_soon,
                    "memory_estimate_kb": total_size * 0.5  # Rough estimate
                }
                
            except Exception as e:
                logger.error(f"âŒ Cache stats error: {e}")
                return {"error": str(e)}


    @staticmethod
    def get_cache_key(user_message: str, context_hash: str = None) -> str:
        """
        Generate cache key with enhanced hashing
        """
        try:
            # Normalize the user message
            normalized = user_message.lower().strip()
            
            # Remove extra whitespace
            normalized = ' '.join(normalized.split())
            
            # Create base key
            base_content = normalized
            
            # Add context hash if provided
            if context_hash:
                base_content += f"|{context_hash}"
            
            # Create hash (shorter for efficiency)
            import hashlib
            cache_key = hashlib.md5(base_content.encode('utf-8')).hexdigest()[:16]
            
            # Add prefix for identification
            cache_key = f"chat_{cache_key}"
            
            return cache_key
            
        except Exception as e:
            logger.error(f"âŒ Cache key generation error: {e}")
            # Fallback: use simple hash
            import hashlib
            return f"chat_fallback_{hashlib.md5(user_message.encode()).hexdigest()[:8]}"


    # Cáº­p nháº­t class CacheEntry Ä‘á»ƒ há»— trá»£ cÃ¡c tÃ­nh nÄƒng má»›i
    @dataclass
    class CacheEntry:
        """
        Enhanced cache entry with metadata for intelligent cache management
        """
        key: str
        value: Any
        created_at: datetime
        ttl_seconds: int = 300
        access_count: int = 0
        last_accessed: datetime = None
        
        def __post_init__(self):
            """Initialize last_accessed if not provided"""
            if self.last_accessed is None:
                self.last_accessed = self.created_at
        
        def is_expired(self, current_time: datetime = None) -> bool:
            """Check if cache entry has expired"""
            if current_time is None:
                current_time = datetime.utcnow()
            
            age = (current_time - self.created_at).total_seconds()
            return age > self.ttl_seconds
        
        def age_seconds(self) -> float:
            """Get age of cache entry in seconds"""
            return (datetime.utcnow() - self.created_at).total_seconds()
        
        def ttl_remaining(self) -> float:
            """Get remaining TTL in seconds"""
            age = self.age_seconds()
            remaining = self.ttl_seconds - age
            return max(0, remaining)

# =========== EMBEDDING FUNCTIONS (MEMORY OPTIMIZED) ===========
@lru_cache(maxsize=128 if IS_LOW_RAM else 1000)
def embed_text(text: str) -> Tuple[List[float], int]:
    """Embed text using OpenAI or fallback (with memory optimization)"""
    if not text:
        return [], 0
    
    text = text[:2000]
    
    if client:
        try:
            response = client.embeddings.create(
                model=EMBEDDING_MODEL,
                input=text
            )
            if response.data:
                embedding = response.data[0].embedding
                return embedding, len(embedding)
        except Exception as e:
            logger.error(f"OpenAI embedding error: {e}")
    
    # Fallback: deterministic hash-based embedding
    h = hash(text) % (10 ** 12)
    dim = 1536
    embedding = [(float((h >> (i % 32)) & 0xFF) + (i % 7)) / 255.0 
                 for i in range(dim)]
    
    return embedding, dim

def query_index(
    query: str,
    top_k: int = 5,
    min_score: float = 0.78
):
    """
    Semantic search dÃ¹ng FAISS â€“ CHáº¶N Bá»ŠA TUYá»†T Äá»I
    Tráº£ vá» [] náº¿u KHÃ”NG cÃ³ dá»¯ liá»‡u Ä‘á»§ tin cáº­y
    """

    # ========== SAFETY CHECK ==========
    if not query or not query.strip():
        return []

    if not INDEX or not MAPPING: 
        logger.error("âŒ FAISS index hoáº·c mapping chÆ°a Ä‘Æ°á»£c load")
        return []

    # ========== EMBEDDING QUERY ==========
    try:
        embedding = embedding_client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=query
        ).data[0].embedding
    except Exception as e:
        logger.error(f"âŒ Embedding error: {e}")
        return []

    import numpy as np

    query_vector = np.array([embedding], dtype="float32")

    # ========== FAISS SEARCH ==========
    try:
        distances, indices = FAISS_INDEX.search(query_vector, top_k)
    except Exception as e:
        logger.error(f"âŒ FAISS search error: {e}")
        return []

    results = []

    for score, idx in zip(distances[0], indices[0]):
        if idx == -1:
            continue

        # FAISS cosine similarity (index Ä‘Ã£ normalize)
        similarity = float(score)

        # ðŸš¨ NGÆ¯á» NG CHáº¶N Bá»ŠA
        if similarity < min_score:
            continue

        mapping = FAISS_MAPPING.get(str(idx))
        if not mapping:
            continue

        text = mapping.get("text", "").strip()
        if not text:
            continue

        results.append((similarity, text))

    # ========== SORT & RETURN ==========
    results.sort(key=lambda x: x[0], reverse=True)

    if not results:
        logger.info(
            f"âš ï¸ No semantic match above threshold "
            f"(min_score={min_score}) for query: {query}"
        )

    return results


class NumpyIndex:
    """Simple numpy-based index with safe numpy handling"""

    def __init__(self, mat=None):
        if NUMPY_AVAILABLE:
            if mat is None:
                self.mat = np.empty((0, 0), dtype="float32")
            else:
                # Force numpy float32 2D
                self.mat = np.asarray(mat, dtype="float32")
                if self.mat.ndim == 1:
                    self.mat = self.mat.reshape(1, -1)
        else:
            self.mat = mat if mat is not None else []

        # SAFE dimension detection (no numpy truth check)
        if NUMPY_AVAILABLE:
            if self.mat.shape[0] > 0 and self.mat.ndim == 2:
                self.dim = int(self.mat.shape[1])
            else:
                self.dim = 0
            self.size = int(self.mat.shape[0])
        else:
            self.size = len(self.mat)
            self.dim = len(self.mat[0]) if self.size > 0 else 0

    def is_empty(self):
        if NUMPY_AVAILABLE:
            return self.mat.shape[0] == 0
        return len(self.mat) == 0

    def search(self, query_vec, k=5):
        if self.is_empty():
            return [], []

        if NUMPY_AVAILABLE:
            q = np.asarray(query_vec, dtype="float32").reshape(1, -1)
            sims = np.dot(self.mat, q.T).reshape(-1)
            topk = np.argsort(-sims)[:k]
            return sims[topk].tolist(), topk.tolist()
        else:
            return [], []

    
    def search(self, qvec, k):
        if not self.mat or (NUMPY_AVAILABLE and self.mat.shape[0] == 0) or (not NUMPY_AVAILABLE and len(self.mat) == 0):
            # Return empty results
            return np.array([[]]), np.array([[]], dtype=np.int64)
        
        q = np.array(qvec).flatten()
        
        if NUMPY_AVAILABLE:
            # Use numpy if available
            q = q / (np.linalg.norm(q) + 1e-12)
            m = self.mat / (np.linalg.norm(self.mat, axis=1, keepdims=True) + 1e-12)
            sims = np.dot(q, m.T)
            idx = np.argsort(-sims)[:k]
            scores = sims[idx]
        else:
            # Fallback calculation
            q_norm = q / (sum(x*x for x in q)**0.5 + 1e-12)
            scores = []
            for i, row in enumerate(self.mat):
                row_norm = row / (sum(x*x for x in row)**0.5 + 1e-12)
                sim = sum(q_norm[j] * row_norm[j] for j in range(min(len(q_norm), len(row_norm))))
                scores.append((sim, i))
            
            scores.sort(key=lambda x: x[0], reverse=True)
            top_k = scores[:k]
            if top_k:
                scores_arr = np.array([s[0] for s in top_k])
                idx_arr = np.array([s[1] for s in top_k])
            else:
                scores_arr = np.array([])
                idx_arr = np.array([], dtype=np.int64)
            
            return scores_arr.reshape(1, -1), idx_arr.reshape(1, -1)
        
        return scores.reshape(1, -1), idx.reshape(1, -1)
    
    def save(self, path):
        if NUMPY_AVAILABLE:
            np.savez_compressed(path, mat=self.mat)
        else:
            logger.warning(f"âš ï¸ Cannot save index without NumPy: {path}")
    
    @classmethod
    def load(cls, path):
        if NUMPY_AVAILABLE:
            try:
                arr = np.load(path)
                return cls(arr['mat'])
            except Exception as e:
                logger.error(f"Failed to load numpy index: {e}")
                return cls()
        else:
            logger.warning(f"âš ï¸ Cannot load index without NumPy: {path}")
            return cls()

def build_index(force_rebuild: bool = False) -> bool:
    """Build or load FAISS/numpy index"""
    global INDEX, EMBEDDING_MODEL
    
    with INDEX_LOCK:
        # Try to load existing index
        if not force_rebuild:
            if FAISS_ENABLED and HAS_FAISS and os.path.exists(FAISS_INDEX_PATH):
                try:
                    INDEX = faiss.read_index(FAISS_INDEX_PATH)
                    logger.info(f"âœ… Loaded FAISS index from {FAISS_INDEX_PATH}")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load FAISS index: {e}")
            
            # Try numpy fallback
            if os.path.exists(FALLBACK_VECTORS_PATH):
                try:
                    arr = np.load(FALLBACK_VECTORS_PATH)
                    INDEX = NumpyIndex(arr['mat'])
                    logger.info("âœ… Loaded numpy index")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load numpy index: {e}")
        
        # Build new index
        if not FLAT_TEXTS:
            logger.warning("No texts to index")
            return False
        
        logger.info(f"ðŸ”¨ Building index for {len(FLAT_TEXTS)} passages...")
        
        # Generate embeddings
        vectors = []
        dims = None
        
        for text in FLAT_TEXTS:
            emb, d = embed_text(text)
            if emb:
                if dims is None:
                    dims = len(emb)
                vectors.append(np.array(emb, dtype="float32"))
        
        if not vectors:
            logger.error("No embeddings generated")
            return False
        
        # Create index
        mat = np.vstack(vectors)
        mat = mat / (np.linalg.norm(mat, axis=1, keepdims=True) + 1e-12)
        
        if FAISS_ENABLED and HAS_FAISS:
            INDEX = faiss.IndexFlatIP(dims)
            INDEX.add(mat)
            try:
                faiss.write_index(INDEX, FAISS_INDEX_PATH)
                logger.info(f"âœ… Saved FAISS index to {FAISS_INDEX_PATH}")
            except Exception as e:
                logger.error(f"Failed to save FAISS index: {e}")
        else:
            INDEX = NumpyIndex(mat)
            try:
                INDEX.save(FALLBACK_VECTORS_PATH)
                logger.info(f"âœ… Saved numpy index to {FALLBACK_VECTORS_PATH}")
            except Exception as e:
                logger.error(f"Failed to save numpy index: {e}")
        
        logger.info(f"âœ… Index built: {len(vectors)} vectors, {dims} dimensions")
        return True

# =========== HELPER FUNCTIONS ===========
def normalize_text_simple(s: str) -> str:
    """Basic text normalization"""
    if not s:
        return ""
    s = s.lower()
    s = unicodedata.normalize("NFD", s)
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
    s = re.sub(r"[^\w\s]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def get_session_context(session_id: str) -> ConversationContext:
    """Get or create context for session using ConversationContext dataclass with auto-repair"""

    ctx = SESSION_CONTEXTS.get(session_id)

    if ctx is None:
        ctx = ConversationContext(session_id=session_id)
        SESSION_CONTEXTS[session_id] = ctx
        return ctx

    # ===== AUTO REPAIR FOR OLD CONTEXT OBJECTS =====
    if not hasattr(ctx, "last_tour_indices"):
        ctx.last_tour_indices = []

    if not hasattr(ctx, "current_tours"):
        ctx.current_tours = []

    if not hasattr(ctx, "mentioned_tours"):
        ctx.mentioned_tours = set()

    if not hasattr(ctx, "last_successful_tours"):
        ctx.last_successful_tours = []

    if not hasattr(ctx, "conversation_history"):
        ctx.conversation_history = []

    if not hasattr(ctx, "user_preferences"):
        ctx.user_preferences = {}

    return ctx

def save_session_context(session_id: str, context: ConversationContext):
    """LÆ°u context cho session"""
    with SESSION_LOCK:
        SESSION_CONTEXTS[session_id] = context
        # Dá»n dáº¹p session cÅ© (giá»¯ tá»‘i Ä‘a 100 session)
        if len(SESSION_CONTEXTS) > 100:
            # XÃ³a cÃ¡c session cÅ© nháº¥t
            sorted_sessions = sorted(
                SESSION_CONTEXTS.items(),
                key=lambda x: getattr(x[1], 'last_updated', datetime.utcnow())
            )
            for key, _ in sorted_sessions[:20]:
                if key in SESSION_CONTEXTS:
                    del SESSION_CONTEXTS[key]
def extract_session_id(request_data: Dict, remote_addr: str) -> str:
    """Extract or create session ID"""
    session_id = request_data.get("session_id")
    if not session_id:
        ip = remote_addr or "0.0.0.0"
        current_hour = datetime.utcnow().strftime("%Y%m%d%H")
        unique_str = f"{ip}_{current_hour}"
        session_id = hashlib.md5(unique_str.encode()).hexdigest()[:12]
    return f"session_{session_id}"

def _prepare_llm_prompt(user_message: str, search_results: List, context: Dict) -> str:
    """Prepare prompt for LLM - THÃ”NG MINH vá»›i context & cÃ¢u há»i chung"""
    
    message_lower = user_message.lower()
    
    # PhÃ¢n loáº¡i cÃ¢u há»i
    is_general_question = any(keyword in message_lower for keyword in [
        'cÃ³ bao gá»“m', 'Ä‘Ã£ bao gá»“m', 'bao gá»“m gÃ¬', 'bao gá»“m nhá»¯ng gÃ¬',
        'cÃ³ gÃ¬', 'nhÆ° tháº¿ nÃ o', 'ra sao', 'tháº¿ nÃ o', 'giÃ¡ tour'
    ])
    
    has_specific_tour = context.get('current_tours') and len(context.get('current_tours', [])) > 0
    tour_count = len(context.get('current_tours', []))
    
    # PhÃ¡t hiá»‡n cÃ¢u há»i tiáº¿p theo (followup)
    is_followup = (
        context.get('last_action') == 'chat_response' and 
        (has_specific_tour or context.get('last_tour_name'))
    )
    
    # PhÃ¡t hiá»‡n rÃ ng buá»™c Ä‘á»‹a lÃ½
    has_location_constraint = False
    location_constraint = None
    filters = context.get('filters', {})
    if filters:
        if filters.get('location'):
            has_location_constraint = True
            location_constraint = filters.get('location')
        elif filters.get('near_location'):
            has_location_constraint = True
            location_constraint = filters.get('near_location')
    
    prompt_parts = [
        "Báº¡n lÃ  trá»£ lÃ½ tÆ° váº¥n du lá»‹ch Ruby Wings - CHUYÃŠN NGHIá»†P, THÃ”NG MINH, NHIá»†T TÃŒNH.",
        "",
        "âš ï¸ QUY Táº®C NGHIÃŠM NGáº¶T:",
    ]
    
    # RULE 1: CÃ¢u há»i CHUNG (khÃ´ng cÃ³ tour cá»¥ thá»ƒ)
    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "",
            "ðŸŽ¯ ÄÃ‚Y LÃ€ CÃ‚U Há»ŽI CHUNG - KHÃ”NG CÃ“ TOUR Cá»¤ THá»‚:",
            "â€¢ TRáº¢ Lá»œI NGáº®N Gá»ŒN (2-4 cÃ¢u) dá»±a trÃªn kiáº¿n thá»©c chung vá» tour du lá»‹ch",
            "â€¢ Sá»¬ Dá»¤NG OPENAI Ä‘á»ƒ tráº£ lá»i tá»± nhiÃªn, khÃ´ng nÃ³i 'khÃ´ng cÃ³ dá»¯ liá»‡u'",
            "â€¢ Káº¾T THÃšC báº±ng cÃ¢u há»i: 'Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t?'",
            "â€¢ KHÃ”NG liá»‡t kÃª tour, KHÃ”NG dump dá»¯ liá»‡u",
            "",
            "VÃ Dá»¤ ÄÃšNG:",
            "Q: 'GiÃ¡ tour bao gá»“m gÃ¬?'",
            "A: 'GiÃ¡ tour Ruby Wings thÆ°á»ng bao gá»“m: xe Ä‘Æ°a Ä‘Ã³n, Äƒn uá»‘ng theo chÆ°Æ¡ng trÃ¬nh, khÃ¡ch sáº¡n, hÆ°á»›ng dáº«n viÃªn vÃ  báº£o hiá»ƒm. TÃ¹y tour cá»¥ thá»ƒ cÃ³ thá»ƒ cÃ³ thÃªm vÃ© tham quan hoáº·c hoáº¡t Ä‘á»™ng Ä‘áº·c biá»‡t. Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t? ðŸ˜Š'",
            "",
            "Q: 'Tour cÃ³ phÃ¹ há»£p gia Ä‘Ã¬nh khÃ´ng?'",
            "A: 'Ruby Wings cÃ³ nhiá»u tour phÃ¹ há»£p gia Ä‘Ã¬nh vá»›i hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng, an toÃ n cho tráº» em vÃ  ngÆ°á»i lá»›n tuá»•i. Gia Ä‘Ã¬nh báº¡n cÃ³ bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch loáº¡i hÃ¬nh nÃ o (thiÃªn nhiÃªn, lá»‹ch sá»­, nghá»‰ dÆ°á»¡ng) Ä‘á»ƒ tÃ´i tÆ° váº¥n tour phÃ¹ há»£p nháº¥t?'",
        ])
    
    # RULE 2: CÃ¢u há»i TIáº¾P THEO (followup)
    elif is_followup:
        prompt_parts.extend([
            "",
            "ðŸ’­ ÄÃ‚Y LÃ€ CÃ‚U Há»ŽI TIáº¾P THEO - Sá»¬ Dá»¤NG CONTEXT:",
            f"â€¢ ÄÃ£ bÃ n vá» {tour_count} tour: {context.get('last_tour_name', '')}",
            "â€¢ PHáº¢I dá»±a vÃ o context cÅ© - KHÃ”NG reset",
            "â€¢ TRáº¢ Lá»œI TIáº¾P theo ngá»¯ cáº£nh Ä‘Ã£ cÃ³",
            "â€¢ KHÃ”NG liá»‡t kÃª láº¡i toÃ n bá»™ tour",
            "â€¢ Náº¿u há»i vá» giÃ¡/thá»i gian â†’ Chá»‰ nÃ³i vá» tour Ä‘ang bÃ n",
            "â€¢ Náº¿u há»i thÃªm Ä‘iá»u kiá»‡n â†’ Gá»£i Ã½ tour tá»« context hoáº·c há»i láº¡i",
            "",
            "VÃ Dá»¤ ÄÃšNG:",
            "Context: ÄÃ£ nÃ³i vá» 'Tour Báº¡ch MÃ£'",
            "Q: 'Tour nÃ y cÃ³ phÃ¹ há»£p nhÃ³m 10 ngÆ°á»i khÃ´ng?'",
            "A: 'Tour Báº¡ch MÃ£ ráº¥t phÃ¹ há»£p cho nhÃ³m 10 ngÆ°á»i! ChÃºng tÃ´i cÃ³ thá»ƒ tá»• chá»©c riÃªng vá»›i giÃ¡ Æ°u Ä‘Ã£i. NhÃ³m báº¡n thÃ­ch hoáº¡t Ä‘á»™ng nÃ o: trekking, thiá»n tÄ©nh tÃ¢m hay cáº£ hai? TÃ´i sáº½ tÆ° váº¥n lá»‹ch trÃ¬nh chi tiáº¿t.'",
        ])
    
    # RULE 3: Location constraint
    if has_location_constraint:
        prompt_parts.extend([
            "",
            "ðŸš¨ RÃ€NG BUá»˜C Äá»ŠA LÃ - NGHIÃŠM NGáº¶T:",
            f"â€¢ YÃªu cáº§u tour gáº§n/táº¡i: {location_constraint or 'khu vá»±c cá»¥ thá»ƒ'}",
            "â€¢ CHá»ˆ Ä‘á» xuáº¥t tour trong khu vá»±c nÃ y",
            "â€¢ Náº¾U khÃ´ng cÃ³ tour phÃ¹ há»£p:",
            "  â†’ 'Hiá»‡n Ruby Wings chÆ°a cÃ³ tour táº¡i [Ä‘á»‹a Ä‘iá»ƒm]. Tuy nhiÃªn, chÃºng tÃ´i cÃ³ tour gáº§n nháº¥t táº¡i [X].'",
            "  â†’ Há»i: 'Báº¡n cÃ³ muá»‘n xem tour á»Ÿ khu vá»±c lÃ¢n cáº­n khÃ´ng?'",
        ])
    
    # RULE 4: Giá»›i háº¡n tour
    prompt_parts.extend([
        "",
        "ðŸ“Š GIá»šI Háº N TOUR (Báº®T BUá»˜C):",
        "â€¢ Tá»‘i Ä‘a 2-3 tour/cÃ¢u tráº£ lá»i",
        "â€¢ Má»–I tour pháº£i cÃ³ LÃ DO rÃµ rÃ ng",
        "â€¢ KHÃ”NG liá»‡t kÃª >3 tour",
        "â€¢ Náº¿u cÃ³ nhiá»u tour phÃ¹ há»£p:",
        "  â†’ Chá»n 2-3 TIÃŠU BIá»‚U nháº¥t",
        "  â†’ TÃ³m táº¯t: 'CÃ²n X tour khÃ¡c...'",
        "  â†’ Há»i: 'Báº¡n muá»‘n xem thÃªm loáº¡i nÃ o?'",
    ])
    
    # CONTEXT INFO
    prompt_parts.extend([
        "",
        "ðŸ“š THÃ”NG TIN NGá»® Cáº¢NH:",
    ])
    
    if context.get('user_preferences'):
        prefs = []
        for k, v in context['user_preferences'].items():
            prefs.append(f"{k}: {v}")
        if prefs:
            prompt_parts.append(f"- Sá»Ÿ thÃ­ch: {'; '.join(prefs)}")
    
    if context.get('current_tours'):
        tours_info = [f"{t['name']}" for t in context['current_tours'][:3]]
        if tours_info:
            prompt_parts.append(f"- Tour Ä‘Ã£ bÃ n: {', '.join(tours_info)}")
    
    if filters:
        filter_strs = []
        if filters.get('price_max'):
            filter_strs.append(f"giÃ¡ <{filters['price_max']:,}Ä‘")
        if filters.get('location'):
            filter_strs.append(f"Vá»Š TRÃ: {filters['location']}")
        if filter_strs:
            prompt_parts.append(f"- RÃ ng buá»™c: {'; '.join(filter_strs)}")
    
    # SEARCH RESULTS
    prompt_parts.append("")
    prompt_parts.append("ðŸ“ Dá»® LIá»†U Tá»ª Há»† THá»NG:")
    
    if search_results:
        for i, (score, passage) in enumerate(search_results[:5], 1):
            text = passage.get('text', '')[:250]
            prompt_parts.append(f"[{i}] {text}")
    else:
        prompt_parts.append("(KhÃ´ng cÃ³ dá»¯ liá»‡u cá»¥ thá»ƒ - sá»­ dá»¥ng kiáº¿n thá»©c chung)")
    
    # YÃŠU Cáº¦U TRáº¢ Lá»œI
    prompt_parts.append("")
    prompt_parts.append("ðŸ’¬ YÃŠU Cáº¦U TRáº¢ Lá»œI:")
    
    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "1. Tráº£ lá»i NGáº®N Gá»ŒN (2-4 cÃ¢u) dá»±a OpenAI",
            "2. KHÃ”NG nÃ³i 'khÃ´ng cÃ³ dá»¯ liá»‡u'",
            "3. Káº¿t thÃºc: Há»i láº¡i Ä‘á»ƒ xÃ¡c Ä‘á»‹nh tour",
        ])
    elif is_followup:
        prompt_parts.extend([
            "1. Dá»±a vÃ o CONTEXT (tour Ä‘Ã£ bÃ n)",
            "2. Tráº£ lá»i TIáº¾P, KHÃ”NG reset",
            "3. Tá»‘i Ä‘a nháº¯c 1-2 tour tá»« context",
        ])
    else:
        prompt_parts.extend([
            "1. Chá»n 2-3 tour vá»›i LÃ DO rÃµ",
            "2. KHÃ”NG >3 tour",
            "3. Náº¿u nhiá»u: tÃ³m táº¯t + há»i tiáº¿p",
        ])
    
    prompt_parts.append("4. LuÃ´n káº¿t thÃºc: CÃ¢u há»i dáº«n dáº¯t hoáº·c 'ðŸ“ž Gá»i 0332510486'")
    
    return "\n".join(prompt_parts)

def _generate_fallback_response(user_message: str, search_results: List, tour_indices: List[int] = None) -> str:
    """Generate SMART fallback response - DÃ¹ng OpenAI khi cÃ³, context-aware"""
    message_lower = user_message.lower()
    
    # ===== Sá»¬ Dá»¤NG OPENAI Náº¾U CÃ“ =====
    if client and HAS_OPENAI:
        try:
            # Chuáº©n bá»‹ context
            context_parts = []
            
            # ThÃ´ng tin tour náº¿u cÃ³
            if tour_indices and TOURS_DB:
                for idx in tour_indices[:2]:
                    tour = TOURS_DB.get(idx)
                    if tour:
                        context_parts.append(f"Tour: {tour.name}")
                        if tour.duration:
                            context_parts.append(f"Thá»i gian: {tour.duration}")
                        if tour.price:
                            context_parts.append(f"GiÃ¡: {tour.price}")
                        if tour.summary:
                            context_parts.append(f"MÃ´ táº£: {tour.summary[:150]}")
            
            # Dá»¯ liá»‡u search
            if search_results:
                for i, (score, passage) in enumerate(search_results[:3], 1):
                    text = passage.get('text', '')[:200]
                    if text:
                        context_parts.append(f"ThÃ´ng tin {i}: {text}")
            
            # Táº¡o prompt thÃ´ng minh
            context_str = "\n".join(context_parts) if context_parts else "KhÃ´ng cÃ³ dá»¯ liá»‡u cá»¥ thá»ƒ"
            
            prompt = f"""Báº¡n lÃ  tÆ° váº¥n viÃªn Ruby Wings chuyÃªn nghiá»‡p.

THÃ”NG TIN CÃ“ Sáº´N:
{context_str}

YÃŠU Cáº¦U TRáº¢ Lá»œI:
1. Náº¿u cÃ³ thÃ´ng tin tour cá»¥ thá»ƒ â†’ TÆ° váº¥n dá»±a trÃªn Ä‘Ã³
2. Náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u â†’ Tráº£ lá»i dá»±a kiáº¿n thá»©c chung vá» tour du lá»‹ch
3. LUÃ”N káº¿t thÃºc báº±ng cÃ¢u há»i dáº«n dáº¯t hoáº·c "Gá»i 0332510486"
4. Ngáº¯n gá»n 2-4 cÃ¢u, nhiá»‡t tÃ¬nh, tá»± nhiÃªn
5. KHÃ”NG nÃ³i "khÃ´ng cÃ³ dá»¯ liá»‡u", "xin lá»—i khÃ´ng tÃ¬m tháº¥y"

CÃ¢u há»i cá»§a khÃ¡ch: {user_message}"""

            response = client.chat.completions.create(
                model=CHAT_MODEL,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.6,
                max_tokens=300
            )
            
            if response.choices:
                reply = response.choices[0].message.content or ""
                # Äáº£m báº£o cÃ³ hotline
                if "0332510486" not in reply:
                    reply += "\n\nðŸ“ž LiÃªn há»‡ 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t!"
                return reply
        
        except Exception as e:
            logger.error(f"OpenAI fallback error: {e}")
            # RÆ¡i xuá»‘ng logic template bÃªn dÆ°á»›i
    
    # ===== FALLBACK KHI KHÃ”NG CÃ“ OPENAI =====
    
    # CÃ³ tour cá»¥ thá»ƒ â†’ Tráº£ thÃ´ng tin tour
    if tour_indices and TOURS_DB:
        response_parts = []
        for idx in tour_indices[:2]:
            tour = TOURS_DB.get(idx)
            if tour:
                response_parts.append(f"**{tour.name}**")
                if tour.duration:
                    response_parts.append(f"â±ï¸ {tour.duration}")
                if tour.location:
                    response_parts.append(f"ðŸ“ {tour.location}")
                if tour.price:
                    response_parts.append(f"ðŸ’° {tour.price}")
                if tour.summary:
                    response_parts.append(f"ðŸ“ {tour.summary[:150]}...")
        
        if response_parts:
            return "\n".join(response_parts) + "\n\nðŸ“ž Gá»i 0332510486 Ä‘á»ƒ biáº¿t thÃªm!"
    
    # CÃ³ search results â†’ TÃ³m táº¯t
    if search_results:
        top_results = search_results[:2]
        response_parts = ["ThÃ´ng tin liÃªn quan:"]
        
        for i, (score, passage) in enumerate(top_results, 1):
            text = passage.get('text', '')[:150]
            if text:
                response_parts.append(f"\n{i}. {text}...")
        
        response_parts.append("\n\nðŸ“ž LiÃªn há»‡ 0332510486 Ä‘á»ƒ biáº¿t chi tiáº¿t!")
        return "".join(response_parts)
    
    # CÃ¢u há»i chung â†’ Template thÃ´ng minh theo keyword
    general_qa = {
        'bao gá»“m': "GiÃ¡ tour Ruby Wings thÆ°á»ng bao gá»“m: xe Ä‘Æ°a Ä‘Ã³n, Äƒn uá»‘ng theo chÆ°Æ¡ng trÃ¬nh, khÃ¡ch sáº¡n, hÆ°á»›ng dáº«n viÃªn vÃ  báº£o hiá»ƒm. TÃ¹y tour cá»¥ thá»ƒ cÃ³ thÃªm hoáº¡t Ä‘á»™ng Ä‘áº·c biá»‡t. Báº¡n quan tÃ¢m tour nÃ o Ä‘á»ƒ tÃ´i tÆ° váº¥n chi tiáº¿t? ðŸ˜Š",
        
        'phÃ¹ há»£p gia Ä‘Ã¬nh': "Ruby Wings cÃ³ nhiá»u tour phÃ¹ há»£p gia Ä‘Ã¬nh vá»›i hoáº¡t Ä‘á»™ng nháº¹ nhÃ ng, an toÃ n cho tráº» em vÃ  ngÆ°á»i lá»›n tuá»•i. Gia Ä‘Ã¬nh báº¡n bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch loáº¡i tour nÃ o (thiÃªn nhiÃªn, lá»‹ch sá»­, nghá»‰ dÆ°á»¡ng)?",
        
        'phÃ¹ há»£p': "Ruby Wings cÃ³ tour cho má»i Ä‘á»‘i tÆ°á»£ng! Báº¡n Ä‘i nhÃ³m bao nhiÃªu ngÆ°á»i vÃ  cÃ³ sá»Ÿ thÃ­ch gÃ¬ Ä‘áº·c biá»‡t khÃ´ng?",
        
        'giÃ¡': "GiÃ¡ tour Ruby Wings tá»« 800.000Ä‘ - 3.000.000Ä‘ tÃ¹y loáº¡i. Báº¡n cÃ³ ngÃ¢n sÃ¡ch khoáº£ng bao nhiÃªu vÃ  muá»‘n Ä‘i máº¥y ngÃ y Ä‘á»ƒ tÃ´i tÆ° váº¥n phÃ¹ há»£p?",
        
        'thá»i gian': "Ruby Wings cÃ³ tour 1 ngÃ y, 2 ngÃ y 1 Ä‘Ãªm, 3 ngÃ y 2 Ä‘Ãªm. Báº¡n cÃ³ khoáº£ng bao nhiÃªu thá»i gian ráº£nh?",
        
        'Ä‘á»‹a Ä‘iá»ƒm': "Ruby Wings tá»• chá»©c tour táº¡i Huáº¿, Quáº£ng Trá»‹, Báº¡ch MÃ£, TrÆ°á»ng SÆ¡n vÃ  nhiá»u nÆ¡i khÃ¡c. Báº¡n muá»‘n khÃ¡m phÃ¡ khu vá»±c nÃ o?",
        
        'nhÃ³m': "Tour nhÃ³m cá»§a Ruby Wings ráº¥t phÃ¹ há»£p! NhÃ³m báº¡n bao nhiÃªu ngÆ°á»i vÃ  thÃ­ch hoáº¡t Ä‘á»™ng gÃ¬ (teambuilding, nghá»‰ dÆ°á»¡ng, khÃ¡m phÃ¡)?",
        
        'retreat': "Ruby Wings chuyÃªn tour retreat káº¿t há»£p thiá»n, khÃ­ cÃ´ng vÃ  thiÃªn nhiÃªn. Báº¡n muá»‘n tour bao nhiÃªu ngÃ y vÃ  má»©c Ä‘á»™ hoáº¡t Ä‘á»™ng nhÆ° nÃ o?",
    }
    
    # TÃ¬m keyword match
    for keyword, response in general_qa.items():
        if keyword in message_lower:
            return response
    
    # Default - Dáº«n dáº¯t há»i láº¡i
    return "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n tÃ¬m tour phÃ¹ há»£p! Báº¡n cÃ³ thá»ƒ cho tÃ´i biáº¿t:\n" \
           "â€¢ Muá»‘n Ä‘i Ä‘Ã¢u?\n" \
           "â€¢ Thá»i gian bao lÃ¢u?\n" \
           "â€¢ NgÃ¢n sÃ¡ch khoáº£ng bao nhiÃªu?\n" \
           "â€¢ Äi bao nhiÃªu ngÆ°á»i?\n\n" \
           "Hoáº·c gá»i ngay 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t! ðŸ˜Š"




# =========== MAIN CHAT ENDPOINT - Äá»ˆNH CAO THÃ”NG MINH V4.1 ===========
@app.route("/chat", methods=["POST"])
def chat_endpoint_ultimate():
    """
    Main chat endpoint vá»›i xá»­ lÃ½ AI thÃ´ng minh, context-aware máº¡nh máº½
    Version 4.3 (Fixed all critical bugs)
    """
    start_time = time.time()
    
    try:
        # ================== INITIALIZATION ==================
        data = request.get_json() or {}
        user_message = (data.get("message") or "").strip()
        session_id = extract_session_id(data, request.remote_addr)
        
        if not user_message:
            return jsonify({
                "reply": "ðŸ‘‹ **Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI cá»§a Ruby Wings Travel**\n\n"
                        "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:\n"
                        "â€¢ TÃ¬m hiá»ƒu vá» 32 tour tráº£i nghiá»‡m Ä‘áº·c sáº¯c\n"
                        "â€¢ So sÃ¡nh cÃ¡c tour Ä‘á»ƒ chá»n phÃ¹ há»£p nháº¥t\n"
                        "â€¢ TÆ° váº¥n tour theo nhu cáº§u gia Ä‘Ã¬nh, nhÃ³m, cÃ¡ nhÃ¢n\n"
                        "â€¢ Cung cáº¥p thÃ´ng tin chi tiáº¿t vá» giÃ¡, lá»‹ch trÃ¬nh, Ä‘á»‹a Ä‘iá»ƒm\n\n"
                        "ðŸ“ž **Hotline tÆ° váº¥n 24/7:** 0332510486\n"
                        "ðŸ’¡ **Há»i ngay:** 'Tour nÃ o phÃ¹ há»£p cho gia Ä‘Ã¬nh?', 'Tour Báº¡ch MÃ£ giÃ¡ bao nhiÃªu?'",
                "sources": [],
                "context": {},
                "processing_time": 0
            })
        
        # ================== CONTEXT MANAGEMENT SYSTEM ==================
        context = get_session_context(session_id)
        
        # Khá»Ÿi táº¡o context náº¿u chÆ°a cÃ³
        if not hasattr(context, 'conversation_history'):
            context.conversation_history = []
        if not hasattr(context, 'current_tour'):
            context.current_tour = None
        if not hasattr(context, 'user_profile'):
            context.user_profile = {}
        if not hasattr(context, 'last_recommended_tours'):
            context.last_recommended_tours = []
        if not hasattr(context, 'last_tour_name'):
            context.last_tour_name = None
        if not hasattr(context, 'last_tour_index'):
            context.last_tour_index = None
        
        # LÆ°u user message vÃ o history
        context.conversation_history.append({
            'role': 'user',
            'message': user_message,
            'timestamp': datetime.utcnow().isoformat()
        })
        
        # Giá»›i háº¡n history (giá»¯ 20 tin nháº¯n gáº§n nháº¥t)
        if len(context.conversation_history) > 40:
            context.conversation_history = context.conversation_history[-20:]
        
        # ================== ADVANCED CONTEXT ANALYSIS ==================
        message_lower = user_message.lower()
        
        # PhÃ¢n tÃ­ch cáº¥p Ä‘á»™ phá»©c táº¡p nÃ¢ng cao
        complexity_score = 0
        complexity_indicators = {
            'vÃ ': 1, 'cho': 1, 'vá»›i': 1, 'nhÆ°ng': 2, 'tuy nhiÃªn': 2,
            'náº¿u': 2, 'khi': 1, 'Ä‘á»ƒ': 1, 'mÃ ': 1, 'hoáº·c': 1, 'so sÃ¡nh': 3,
            'phÃ¢n biá»‡t': 3, 'khÃ¡c nhau': 3, 'tÆ°Æ¡ng tá»±': 2, 'giá»¯a': 2
        }
        
        for indicator, weight in complexity_indicators.items():
            if indicator in message_lower:
                complexity_score += weight
        
        # PhÃ¢n tÃ­ch Ä‘á»™ dÃ i cÃ¢u há»i
        word_count = len(user_message.split())
        if word_count > 15:
            complexity_score += 2
        elif word_count > 25:
            complexity_score += 3
        
        # ================== ENHANCED INTENT DETECTION (FIXED PRIORITY) ==================
        intent_categories = {
            'service_inquiry': [
                'bao gá»“m', 'cÃ³ nhá»¯ng gÃ¬', 'dá»‹ch vá»¥', 'cung cáº¥p', 'cÃ³ cho',
                'cÃ³ Ä‘Æ°a Ä‘Ã³n', 'cÃ³ Äƒn', 'cÃ³ á»Ÿ', 'cÃ³ hÆ°á»›ng dáº«n viÃªn',
                'cÃ³ báº£o hiá»ƒm', 'cÃ³ vÃ© tham quan', 'cÃ³ nÆ°á»›c uá»‘ng',
                'Ä‘iá»u kiá»‡n', 'Ä‘iá»u khoáº£n', 'chÃ­nh sÃ¡ch', 'há»— trá»£',
                'phÆ°Æ¡ng tiá»‡n', 'Äƒn uá»‘ng', 'nÆ¡i á»Ÿ', 'khÃ¡ch sáº¡n', 'Ä‘Ã£ bao gá»“m'
            ],
            
            'location_query': [
                'Ä‘i Ä‘Ã  náºµng', 'Ä‘i huáº¿', 'Ä‘i quáº£ng trá»‹', 'Ä‘i báº¡ch mÃ£',
                'Ä‘i trÆ°á»ng sÆ¡n', 'á»Ÿ Ä‘Ã¢u', 'táº¡i sao', 'táº¡i Ä‘Ã¢u',
                'Ä‘áº¿n Ä‘Ã¢u', 'thÄƒm quan Ä‘Ã¢u', 'khu vá»±c', 'Ä‘á»‹a bÃ n',
                'miá»n trung', 'huáº¿ quáº£ng trá»‹', 'Ä‘Ã´ng hÃ '
            ],
            
            'price_inquiry': [
                'giÃ¡ bao nhiÃªu', 'bao nhiÃªu tiá»n', 'chi phÃ­', 'giÃ¡ tour',
                'báº£ng giÃ¡', 'bao nhiÃªu', 'giÃ¡ tháº¿ nÃ o', 'giÃ¡ sao',
                'giÃ¡ khÃ´ng', 'háº¿t bao nhiÃªu tiá»n', 'chi phÃ­ háº¿t bao nhiÃªu',
                'giÃ¡ tour Ä‘Ã£ bao gá»“m'  # ThÃªm Ä‘á»ƒ phÃ¢n biá»‡t
            ],

            'tour_listing': [
                'cÃ³ nhá»¯ng tour nÃ o', 'danh sÃ¡ch tour', 'liá»‡t kÃª tour', 
                'tour nÃ o cÃ³', 'tour gÃ¬', 'cÃ³ tour', 'cÃ³ tour nÃ o',
                'cÃ³ chÆ°Æ¡ng trÃ¬nh', 'cÃ³ dá»‹ch vá»¥', 'cÃ³ hÃ nh trÃ¬nh',
                'xem tour', 'xem cÃ¡c tour', 'tour Ä‘ang cÃ³', 'tour hiá»‡n táº¡i'
            ],

            'tour_detail': [
                'chi tiáº¿t tour', 'lá»‹ch trÃ¬nh', 'cÃ³ gÃ¬',
                'thÃ´ng tin', 'mÃ´ táº£', 'Ä‘i nhá»¯ng Ä‘Ã¢u', 'tham quan gÃ¬',
                'chÆ°Æ¡ng trÃ¬nh tháº¿ nÃ o', 'ná»™i dung tour'
            ],

            'comparison': [
                'so sÃ¡nh', 'khÃ¡c nhau', 'nÃªn chá»n', 'tá»‘t hÆ¡n',
                'hÆ¡n kÃ©m', 'phÃ¢n biá»‡t', 'so vá»›i', 'cÃ¡i nÃ o hÆ¡n',
                'tour nÃ o tá»‘t hÆ¡n'
            ],

            'recommendation': [
                'phÃ¹ há»£p', 'gá»£i Ã½', 'Ä‘á» xuáº¥t', 'tÆ° váº¥n', 'nÃªn Ä‘i',
                'chá»n nÃ o', 'tÃ¬m tour', 'nÃªn chá»n tour nÃ o',
                'tÆ° váº¥n giÃºp', 'gá»£i Ã½ giÃºp mÃ¬nh'
            ],

            'booking_info': [
                'Ä‘áº·t tour', 'Ä‘Äƒng kÃ½', 'booking', 'giá»¯ chá»—',
                'thanh toÃ¡n', 'Ä‘áº·t chá»—', 'cÃ¡ch Ä‘áº·t',
                'Ä‘áº·t nhÆ° tháº¿ nÃ o', 'Ä‘áº·t ra sao', 'quy trÃ¬nh Ä‘áº·t'
            ],

            'policy': [
                'chÃ­nh sÃ¡ch', 'giáº£m giÃ¡', 'Æ°u Ä‘Ã£i', 'khuyáº¿n mÃ£i',
                'giáº£m', 'promotion', 'hoÃ n tiá»n', 'há»§y tour',
                'Ä‘á»•i lá»‹ch', 'Ä‘iá»u kiá»‡n', 'Ä‘iá»u khoáº£n'
            ],

            'general_info': [
                'giá»›i thiá»‡u', 'lÃ  gÃ¬', 'tháº¿ nÃ o', 'ra sao',
                'sá»© má»‡nh', 'giÃ¡ trá»‹', 'triáº¿t lÃ½', 'bÃªn báº¡n lÃ  ai',
                'cÃ´ng ty lÃ  gÃ¬', 'ruby wings lÃ  gÃ¬'
            ],

            'weather_info': [
                'thá»i tiáº¿t', 'khÃ­ háº­u', 'náº¯ng mÆ°a', 'mÃ¹a nÃ o',
                'nhiá»‡t Ä‘á»™', 'thá»i tiáº¿t cÃ³ Ä‘áº¹p khÃ´ng', 'mÆ°a khÃ´ng',
                'náº¯ng khÃ´ng'
            ],

            'food_info': [
                'áº©m thá»±c', 'mÃ³n Äƒn', 'Ä‘áº·c sáº£n', 'Ä‘á»“ Äƒn',
                'bÃ¡nh bÃ¨o', 'máº¯m nÃªm', 'Äƒn gÃ¬', 'Äƒn uá»‘ng tháº¿ nÃ o',
                'cÃ³ Äƒn Ä‘áº·c sáº£n khÃ´ng'
            ],

            'culture_info': [
                'vÄƒn hÃ³a', 'lá»‹ch sá»­', 'truyá»n thá»‘ng', 'di tÃ­ch',
                'di sáº£n', 'vÄƒn minh', 'báº£n sáº¯c', 'vÄƒn hÃ³a Ä‘á»‹a phÆ°Æ¡ng'
            ],

            'wellness_info': [
                'thiá»n', 'yoga', 'chá»¯a lÃ nh', 'sá»©c khá»e', 'retreat',
                'tÄ©nh tÃ¢m', 'khÃ­ cÃ´ng', 'nghá»‰ dÆ°á»¡ng', 'há»“i phá»¥c',
                'thÆ° giÃ£n'
            ],

            'group_info': [
                'nhÃ³m', 'Ä‘oÃ n', 'cÃ´ng ty', 'gia Ä‘Ã¬nh', 'báº¡n bÃ¨',
                'táº­p thá»ƒ', 'cá»±u chiáº¿n binh', 'Ä‘i theo Ä‘oÃ n',
                'Ä‘i Ä‘Ã´ng ngÆ°á»i', 'Ä‘oÃ n riÃªng'
            ],

            'custom_request': [
                'tÃ¹y chá»‰nh', 'riÃªng', 'cÃ¡ nhÃ¢n hÃ³a', 'theo yÃªu cáº§u',
                'riÃªng biá»‡t', 'thiáº¿t káº¿ tour', 'lÃ m tour riÃªng',
                'tour theo yÃªu cáº§u'
            ],

            'sustainability': [
                'bá»n vá»¯ng', 'mÃ´i trÆ°á»ng', 'xanh', 'cá»™ng Ä‘á»“ng',
                'phÃ¡t triá»ƒn bá»n vá»¯ng', 'du lá»‹ch xanh',
                'du lá»‹ch bá»n vá»¯ng'
            ],

            'experience': [
                'tráº£i nghiá»‡m', 'cáº£m giÃ¡c', 'cáº£m nháº­n', 'thá»±c táº¿',
                'trá»±c tiáº¿p', 'tráº£i nghiá»‡m nhÆ° tháº¿ nÃ o', 'cÃ³ gÃ¬ hay'
            ]
        }
        
        detected_intents = []
        for intent, keywords in intent_categories.items():
            for keyword in keywords:
                if keyword in message_lower:
                    if intent not in detected_intents:
                        detected_intents.append(intent)
                    break
        
        # FIX: Æ¯u tiÃªn intent chÃ­nh (FIXED PRIORITY ORDER)
        primary_intent = None
        if detected_intents:
            # Priority order: service_inquiry > location_query > price_inquiry > tour_listing
            priority_order = [
                'comparison', 'recommendation', 'service_inquiry',
                'location_query', 'price_inquiry', 'tour_detail',
                'tour_listing', 'general_info', 'wellness_info',
                'culture_info', 'weather_info', 'food_info',
                'group_info', 'custom_request', 'booking_info',
                'policy', 'sustainability', 'experience'
            ]
            
            for intent in priority_order:
                if intent in detected_intents:
                    primary_intent = intent
                    break
            if not primary_intent:
                primary_intent = detected_intents[0]
        
        # ================== ENHANCED TOUR RESOLUTION ENGINE ==================
        tour_indices = []
        tour_names_mentioned = []
        
        # Strategy 1: Enhanced direct tour name matching
        direct_tour_matches = []
        import re
        
        # TÃ¬m tÃªn tour trong cÃ¢u há»i vá»›i pattern matching
        tour_name_patterns = [
            r'["\'](.+?)["\']',  # TÃªn trong dáº¥u nhÃ¡y
            r'tour\s+(.+?)\s+(?:cÃ³|giÃ¡|á»Ÿ|cho|táº¡i)',
            r'tour\s+["\']?(.+?)["\']?'
        ]
        
        for pattern in tour_name_patterns:
            matches = re.findall(pattern, user_message, re.IGNORECASE)
            for match in matches:
                if match and len(match.strip()) > 3:
                    tour_names_mentioned.append(match.strip())
        
        # Loáº¡i bá» cÃ¡c tá»« chung chung
        filter_words = ['nÃ o', 'gÃ¬', 'Ä‘Ã³', 'áº¥y', 'nÃ y', 'kia', 'cho', 'vá»›i', 'cá»§a']
        tour_names_mentioned = [name for name in tour_names_mentioned 
                              if not any(word in name.lower() for word in filter_words)]
        
        logger.info(f"ðŸ” Tour names mentioned in query: {tour_names_mentioned}")
        
        # TÃ¬m tour index cho tá»«ng tÃªn Ä‘Æ°á»£c Ä‘á» cáº­p
        for tour_name in tour_names_mentioned:
            for norm_name, idx in TOUR_NAME_TO_INDEX.items():
                similarity_score = 0
                
                # Kiá»ƒm tra tá»« khÃ³a chÃ­nh
                name_words = set(norm_name.lower().split())
                query_words = set(tour_name.lower().split())
                common_words = name_words.intersection(query_words)
                
                if len(common_words) >= 2:
                    similarity_score = len(common_words) / max(len(name_words), len(query_words))
                
                # Kiá»ƒm tra contain
                if tour_name.lower() in norm_name.lower() or norm_name.lower() in tour_name.lower():
                    similarity_score = max(similarity_score, 0.8)
                
                if similarity_score >= 0.5 and idx not in direct_tour_matches:
                    direct_tour_matches.append(idx)
                    logger.info(f"ðŸŽ¯ Found tour '{norm_name}' (idx: {idx}) for query '{tour_name}'")
        
        if direct_tour_matches:
            tour_indices = direct_tour_matches[:5]
            logger.info(f"ðŸŽ¯ Direct tour matches found: {tour_indices}")
        
        # Strategy 2: Enhanced fuzzy matching
        if not tour_indices and UpgradeFlags.is_enabled("6_FUZZY_MATCHING"):
            fuzzy_matches = FuzzyMatcher.find_similar_tours(user_message, TOUR_NAME_TO_INDEX)
            if fuzzy_matches:
                tour_indices = [idx for idx, score in fuzzy_matches[:3] if score > 0.6]
                if tour_indices:
                    logger.info(f"ðŸ” Fuzzy matches found: {tour_indices}")
        
        # Strategy 3: Semantic content matching
        if not tour_indices and UpgradeFlags.is_enabled("8_SEMANTIC_ANALYSIS"):
            # TÃ¬m tour dá»±a trÃªn ná»™i dung semantic
            semantic_matches = []
            for idx, tour in TOURS_DB.items():
                # Táº¡o text blob Ä‘á»ƒ phÃ¢n tÃ­ch
                text_blob = f"{tour.name or ''} {tour.summary or ''} {tour.style or ''} {tour.location or ''}".lower()
                
                # PhÃ¢n tÃ­ch tá»« khÃ³a trong cÃ¢u há»i
                query_words = [word for word in message_lower.split() if len(word) > 2]
                matches = sum(1 for word in query_words if word in text_blob)
                
                if matches >= 2:
                    semantic_matches.append((idx, matches))
            
            if semantic_matches:
                semantic_matches.sort(key=lambda x: x[1], reverse=True)
                tour_indices = [idx for idx, score in semantic_matches[:3]]
                logger.info(f"ðŸ§  Semantic matches found: {tour_indices}")
        
        # ================== FILTER EXTRACTION & APPLICATION ==================
        mandatory_filters = FilterSet()
        filter_applied = False
        
        if UpgradeFlags.is_enabled("1_MANDATORY_FILTER"):
            try:
                mandatory_filters = MandatoryFilterSystem.extract_filters(user_message)
                
                if not mandatory_filters.is_empty():
                    logger.info(f"ðŸŽ¯ Filters extracted: {mandatory_filters}")
                    
                    # Kiá»ƒm tra lá»—i trong filter
                    if hasattr(mandatory_filters, 'group_type') and mandatory_filters.group_type:
                        valid_group_types = ['family', 'friends', 'corporate', 'solo', 'couple', 'senior']
                        if mandatory_filters.group_type not in valid_group_types:
                            logger.warning(f"âš ï¸ Invalid group type: {mandatory_filters.group_type}")
                    
                    filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                    
                    if filtered_indices:
                        filter_applied = True
                        if tour_indices:
                            # Káº¿t há»£p káº¿t quáº£: láº¥y giao cá»§a cÃ¡c káº¿t quáº£
                            combined = list(set(tour_indices) & set(filtered_indices))
                            if combined:
                                tour_indices = combined[:5]
                            else:
                                # Náº¿u khÃ´ng cÃ³ giao, Æ°u tiÃªn filter-based
                                tour_indices = filtered_indices[:5]
                            logger.info(f"ðŸŽ¯ Combined filter-based search: {len(tour_indices)} tours")
                        else:
                            tour_indices = filtered_indices[:8]
                            logger.info(f"ðŸŽ¯ Filter-based search only: {len(tour_indices)} tours")
            except Exception as e:
                logger.error(f"âŒ Filter system error: {e}")
                # Continue without filters
        
        # ================== INTELLIGENT RESPONSE GENERATION ==================
        reply = ""
        sources = []
        
        # ðŸ”¹ CASE 0.5: CONTEXT FOLLOW-UP HANDLING (FIXED)
        follow_up_keywords = ['cÃ³', 'muá»‘n biáº¿t', 'cho biáº¿t', 'chi tiáº¿t', 'tÃ¬m hiá»ƒu thÃªm', 'ká»ƒ thÃªm']
        if any(keyword in message_lower for keyword in follow_up_keywords) and len(message_lower.split()) <= 3:
            logger.info("ðŸ”„ Processing context follow-up")
            
            # Kiá»ƒm tra context tá»« cuá»™c há»™i thoáº¡i trÆ°á»›c
            if hasattr(context, 'last_tour_index') and context.last_tour_index is not None:
                tour_idx = context.last_tour_index
                tour = TOURS_DB.get(tour_idx)
                if tour:
                    logger.info(f"ðŸ”„ Follow-up for tour: {tour.name}")
                    
                    reply = f"ðŸŽ¯ **CHI TIáº¾T TOUR: {tour.name}** ðŸŽ¯\n\n"
                    
                    if tour.summary:
                        reply += f"ðŸ“ **MÃ´ táº£:** {tour.summary}\n\n"
                    
                    if tour.duration:
                        reply += f"â±ï¸ **Thá»i gian:** {tour.duration}\n"
                    
                    if tour.location:
                        reply += f"ðŸ“ **Äá»‹a Ä‘iá»ƒm:** {tour.location}\n"
                    
                    if tour.price:
                        reply += f"ðŸ’° **GiÃ¡:** {tour.price}\n"
                    
                    if tour.style:
                        reply += f"ðŸŽ¨ **Phong cÃ¡ch:** {tour.style}\n"
                    
                    # ThÃªm dá»‹ch vá»¥ bao gá»“m
                    reply += "\nðŸ›Žï¸ **Dá»ŠCH Vá»¤ BAO Gá»’M:**\n"
                    reply += "âœ… Xe Ä‘Æ°a Ä‘Ã³n Ä‘á»i má»›i, mÃ¡y láº¡nh\n"
                    reply += "âœ… HÆ°á»›ng dáº«n viÃªn chuyÃªn nghiá»‡p\n"
                    reply += "âœ… Ä‚n uá»‘ng theo chÆ°Æ¡ng trÃ¬nh\n"
                    
                    if '1 ngÃ y' in tour.duration or '2 ngÃ y' in tour.duration:
                        reply += "âœ… VÃ© tham quan cÃ¡c Ä‘iá»ƒm du lá»‹ch\n"
                        reply += "âœ… Báº£o hiá»ƒm du lá»‹ch\n"
                        reply += "âœ… NÆ°á»›c uá»‘ng suá»‘i Ä‘Ã³ng chai\n"
                    
                    if '2 ngÃ y' in tour.duration or '3 ngÃ y' in tour.duration:
                        reply += "âœ… Chá»— á»Ÿ tiÃªu chuáº©n (khÃ¡ch sáº¡n/homestay)\n"
                    
                    reply += "\nðŸ“ž **Äáº·t tour nÃ y ngay:** 0332510486"
                    
                    # Cáº­p nháº­t context
                    context.current_tour = tour_idx
                    context.last_tour_name = tour.name
                    
                    # Ghi log
                    logger.info(f"âœ… Responded to follow-up for tour {tour.name}")
                    
                    # Bá» qua cÃ¡c case khÃ¡c
                    context.conversation_history.append({
                        'role': 'assistant',
                        'message': reply,
                        'timestamp': datetime.utcnow().isoformat(),
                        'tour_indices': [tour_idx],
                        'detected_intents': ['tour_detail'],
                        'primary_intent': 'tour_detail'
                    })
                    
                    save_session_context(session_id, context)
                    
                    processing_time = time.time() - start_time
                    return jsonify({
                        "reply": reply,
                        "sources": [],
                        "context": {
                            "session_id": session_id,
                            "current_tour": tour_idx,
                            "last_tour_name": tour.name,
                            "processing_time_ms": int(processing_time * 1000)
                        },
                        "processing_time": processing_time
                    })
        
        # ðŸ”¹ CASE 1.1: LOCATION QUERY - Xá»­ lÃ½ cÃ¢u há»i vá» Ä‘á»‹a Ä‘iá»ƒm cá»¥ thá»ƒ (FIXED EXACT MATCHING)
        if 'location_query' in detected_intents:
            logger.info("ðŸ“ Processing location query")
            
            # XÃ¡c Ä‘á»‹nh Ä‘á»‹a Ä‘iá»ƒm Ä‘Æ°á»£c há»i
            locations = ['huáº¿', 'quáº£ng trá»‹', 'báº¡ch mÃ£', 'trÆ°á»ng sÆ¡n', 'Ä‘Ã´ng hÃ ', 'miá»n trung', 'Ä‘Ã  náºµng']
            mentioned_location = None
            
            for loc in locations:
                if loc in message_lower:
                    mentioned_location = loc
                    break
            
            if mentioned_location:
                # TÃ¬m tour táº¡i Ä‘á»‹a Ä‘iá»ƒm nÃ y - FIXED EXACT MATCHING
                location_tours = []
                for idx, tour in TOURS_DB.items():
                    if tour.location:
                        # FIX: ChÃ­nh xÃ¡c hÆ¡n - tÃ¡ch location vÃ  kiá»ƒm tra tá»«ng pháº§n
                        tour_locations = [loc.strip().lower() for loc in tour.location.split(',')]
                        # FIX: Kiá»ƒm tra exact match hoáº·c contains chÃ­nh xÃ¡c
                        if (mentioned_location in tour_locations or 
                            mentioned_location in tour.location.lower() or
                            any(mentioned_location in loc for loc in tour_locations)):
                            
                            # FIX: Loáº¡i bá» matching sai (vd: "ÄÃ  Náºµng" khÃ´ng match "Quáº£ng Trá»‹")
                            if mentioned_location == 'Ä‘Ã  náºµng':
                                # Chá»‰ match náº¿u cÃ³ "ÄÃ  Náºµng" chÃ­nh xÃ¡c
                                if 'Ä‘Ã  náºµng' in tour.location.lower():
                                    location_tours.append((idx, tour))
                            else:
                                location_tours.append((idx, tour))
                
                # Apply filters náº¿u cÃ³
                if filter_applied and not mandatory_filters.is_empty():
                    filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                    location_tours = [(idx, tour) for idx, tour in location_tours if idx in filtered_indices]
                
                if location_tours:
                    reply = f"ðŸ“ **TOUR Táº I {mentioned_location.upper()}** ðŸ“\n\n"
                    
                    # Hiá»ƒn thá»‹ thÃ´ng tin tá»•ng quan
                    reply += f"Ruby Wings cÃ³ {len(location_tours)} tour táº¡i {mentioned_location.upper()}:\n\n"
                    
                    # PhÃ¢n loáº¡i tour táº¡i Ä‘á»‹a Ä‘iá»ƒm nÃ y
                    for i, (idx, tour) in enumerate(location_tours[:6], 1):
                        reply += f"{i}. **{tour.name}**\n"
                        if tour.duration:
                            reply += f"   â±ï¸ {tour.duration}\n"
                        if tour.summary:
                            summary_short = tour.summary[:80] + "..." if len(tour.summary) > 80 else tour.summary
                            reply += f"   ðŸ“ {summary_short}\n"
                        if i == 1 and tour.price:
                            price_short = tour.price[:60] + "..." if len(tour.price) > 60 else tour.price
                            reply += f"   ðŸ’° {price_short}\n"
                        reply += "\n"
                    
                    # ThÃ´ng tin Ä‘áº·c trÆ°ng cá»§a Ä‘á»‹a Ä‘iá»ƒm
                    if mentioned_location == 'huáº¿':
                        reply += "ðŸ›ï¸ **Äáº¶C TRÆ¯NG HUáº¾:**\n"
                        reply += "â€¢ Di sáº£n UNESCO: Äáº¡i Ná»™i, LÄƒng táº©m\n"
                        reply += "â€¢ áº¨m thá»±c cung Ä‘Ã¬nh Ä‘áº·c sáº¯c\n"
                        reply += "â€¢ SÃ´ng HÆ°Æ¡ng, nÃºi Ngá»± thÆ¡ má»™ng\n\n"
                    elif mentioned_location == 'báº¡ch mÃ£':
                        reply += "ðŸŒ¿ **Äáº¶C TRÆ¯NG Báº CH MÃƒ:**\n"
                        reply += "â€¢ VÆ°á»n quá»‘c gia rá»™ng 37,000ha\n"
                        reply += "â€¢ KhÃ­ háº­u mÃ¡t máº» quanh nÄƒm\n"
                        reply += "â€¢ Äa dáº¡ng sinh há»c cao\n\n"
                    elif mentioned_location == 'trÆ°á»ng sÆ¡n':
                        reply += "ðŸŽ–ï¸ **Äáº¶C TRÆ¯NG TRÆ¯á»œNG SÆ N:**\n"
                        reply += "â€¢ Di tÃ­ch lá»‹ch sá»­ chiáº¿n tranh\n"
                        reply += "â€¢ ÄÆ°á»ng Há»“ ChÃ­ Minh huyá»n thoáº¡i\n"
                        reply += "â€¢ VÄƒn hÃ³a dÃ¢n tá»™c VÃ¢n Kiá»u, Pa KÃ´\n\n"
                    
                    reply += "ðŸ“ž **Äáº·t tour táº¡i Ä‘á»‹a Ä‘iá»ƒm nÃ y:** 0332510486"
                else:
                    reply = f"Hiá»‡n Ruby Wings chÆ°a cÃ³ tour nÃ o táº¡i {mentioned_location.upper()}. Tuy nhiÃªn, chÃºng tÃ´i cÃ³ thá»ƒ thiáº¿t káº¿ tour riÃªng theo yÃªu cáº§u cá»§a báº¡n.\n\n"
                    reply += "ðŸ“ž **LiÃªn há»‡ thiáº¿t káº¿ tour riÃªng:** 0332510486"
            else:
                reply = "Báº¡n muá»‘n tÃ¬m tour táº¡i khu vá»±c nÃ o? Ruby Wings cÃ³ tour táº¡i:\n\n"
                reply += "â€¢ Huáº¿ (di sáº£n, áº©m thá»±c)\n"
                reply += "â€¢ Quáº£ng Trá»‹ (lá»‹ch sá»­, di tÃ­ch)\n"
                reply += "â€¢ Báº¡ch MÃ£ (thiÃªn nhiÃªn, trekking)\n"
                reply += "â€¢ TrÆ°á»ng SÆ¡n (lá»‹ch sá»­, vÄƒn hÃ³a)\n\n"
                reply += "ðŸ“ž **Hotline tÆ° váº¥n Ä‘á»‹a Ä‘iá»ƒm:** 0332510486"
        
        # ðŸ”¹ CASE 2.1: SERVICE INQUIRY - Xá»­ lÃ½ cÃ¢u há»i vá» dá»‹ch vá»¥ bao gá»“m (FIXED)
        elif 'service_inquiry' in detected_intents:
            logger.info("ðŸ›Žï¸ Processing service inquiry (FIXED)")
            
            # FIX: Kiá»ƒm tra náº¿u cÃ³ tour cá»¥ thá»ƒ trong context
            current_tour = None
            if hasattr(context, 'last_tour_index') and context.last_tour_index is not None:
                current_tour = TOURS_DB.get(context.last_tour_index)
            
            reply = "ðŸ›Žï¸ **Dá»ŠCH Vá»¤ BAO Gá»’M TRONG TOUR RUBY WINGS** ðŸ›Žï¸\n\n"
            
            # Náº¿u cÃ³ tour cá»¥ thá»ƒ trong context
            if current_tour:
                reply += f"**Tour {current_tour.name} bao gá»“m:**\n\n"
                
                # Hiá»ƒn thá»‹ dá»‹ch vá»¥ theo loáº¡i tour
                if '1 ngÃ y' in current_tour.duration.lower():
                    reply += "âœ… **Dá»‹ch vá»¥ tour 1 ngÃ y:**\n"
                    reply += "â€¢ Xe Ä‘Æ°a Ä‘Ã³n Ä‘á»i má»›i, mÃ¡y láº¡nh\n"
                    reply += "â€¢ HÆ°á»›ng dáº«n viÃªn chuyÃªn nghiá»‡p\n"
                    reply += "â€¢ Ä‚n trÆ°a (thÆ°á»ng 1 bá»¯a chÃ­nh)\n"
                    reply += "â€¢ VÃ© tham quan cÃ¡c Ä‘iá»ƒm du lá»‹ch\n"
                    reply += "â€¢ Báº£o hiá»ƒm du lá»‹ch (50 triá»‡u VNÄ)\n"
                    reply += "â€¢ NÆ°á»›c uá»‘ng suá»‘i Ä‘Ã³ng chai\n\n"
                    
                elif '2 ngÃ y' in current_tour.duration.lower():
                    reply += "âœ… **Dá»‹ch vá»¥ tour 2 ngÃ y 1 Ä‘Ãªm:**\n"
                    reply += "â€¢ Xe Ä‘Æ°a Ä‘Ã³n Ä‘á»i má»›i, mÃ¡y láº¡nh\n"
                    reply += "â€¢ HÆ°á»›ng dáº«n viÃªn chuyÃªn nghiá»‡p\n"
                    reply += "â€¢ Ä‚n uá»‘ng: 3 bá»¯a chÃ­nh + 2 bá»¯a sÃ¡ng\n"
                    reply += "â€¢ Chá»— á»Ÿ: KhÃ¡ch sáº¡n/homestay (1 Ä‘Ãªm)\n"
                    reply += "â€¢ VÃ© tham quan cÃ¡c Ä‘iá»ƒm du lá»‹ch\n"
                    reply += "â€¢ Báº£o hiá»ƒm du lá»‹ch (50 triá»‡u VNÄ)\n"
                    reply += "â€¢ NÆ°á»›c uá»‘ng suá»‘i Ä‘Ã³ng chai\n\n"
                    
                else:
                    reply += "âœ… **Dá»‹ch vá»¥ bao gá»“m:**\n"
                    reply += "â€¢ Xe Ä‘Æ°a Ä‘Ã³n Ä‘á»i má»›i, mÃ¡y láº¡nh\n"
                    reply += "â€¢ HÆ°á»›ng dáº«n viÃªn chuyÃªn nghiá»‡p\n"
                    reply += "â€¢ Ä‚n uá»‘ng theo chÆ°Æ¡ng trÃ¬nh\n"
                    reply += "â€¢ Chá»— á»Ÿ tiÃªu chuáº©n (náº¿u qua Ä‘Ãªm)\n"
                    reply += "â€¢ VÃ© tham quan cÃ¡c Ä‘iá»ƒm du lá»‹ch\n"
                    reply += "â€¢ Báº£o hiá»ƒm du lá»‹ch\n"
                    reply += "â€¢ NÆ°á»›c uá»‘ng suá»‘i Ä‘Ã³ng chai\n\n"
            else:
                # PhÃ¢n loáº¡i dá»‹ch vá»¥ chung
                reply += "âœ… **Dá»ŠCH Vá»¤ CÆ  Báº¢N (cÃ³ trong háº§u háº¿t tour):**\n"
                reply += "â€¢ ðŸšŒ Xe Ä‘Æ°a Ä‘Ã³n Ä‘á»i má»›i, mÃ¡y láº¡nh\n"
                reply += "â€¢ ðŸ¨ Chá»— á»Ÿ tiÃªu chuáº©n (khÃ¡ch sáº¡n/homestay) - tour Ä‘a ngÃ y\n"
                reply += "â€¢ ðŸ½ï¸ Ä‚n uá»‘ng theo chÆ°Æ¡ng trÃ¬nh (1-3 bá»¯a/ngÃ y)\n"
                reply += "â€¢ ðŸ§­ HÆ°á»›ng dáº«n viÃªn chuyÃªn nghiá»‡p, nhiá»‡t tÃ¬nh\n"
                reply += "â€¢ ðŸŽ« VÃ© tham quan cÃ¡c Ä‘iá»ƒm du lá»‹ch\n"
                reply += "â€¢ ðŸ’§ NÆ°á»›c uá»‘ng suá»‘i Ä‘Ã³ng chai\n"
                reply += "â€¢ ðŸ›¡ï¸ Báº£o hiá»ƒm du lá»‹ch (má»©c Ä‘á»n bÃ¹ 50 triá»‡u VNÄ)\n\n"
            
            # FIX: KHÃ”NG hiá»ƒn thá»‹ báº£ng giÃ¡ trong service inquiry
            reply += "âš ï¸ **Dá»ŠCH Vá»¤ KHÃ”NG BAO Gá»’M:**\n"
            reply += "â€¢ Chi phÃ­ cÃ¡ nhÃ¢n: Giáº·t á»§i, Ä‘iá»‡n thoáº¡i, mini bar\n"
            reply += "â€¢ Äá»“ uá»‘ng cÃ³ cá»“n (bia, rÆ°á»£u, cocktail)\n"
            reply += "â€¢ Tip cho hÆ°á»›ng dáº«n viÃªn vÃ  tÃ i xáº¿\n"
            reply += "â€¢ Chi phÃ­ phÃ¡t sinh do thay Ä‘á»•i lá»‹ch trÃ¬nh\n"
            reply += "â€¢ PhÃ­ tham quan ngoÃ i chÆ°Æ¡ng trÃ¬nh\n\n"
            
            reply += "ðŸ“‹ **ÄIá»€U KIá»†N THAM GIA:**\n"
            reply += "â€¢ Sá»©c khá»e tá»‘t, khÃ´ng máº¯c bá»‡nh mÃ£n tÃ­nh\n"
            reply += "â€¢ Tuá»•i tá»« 5-70 (trá»« tour Ä‘áº·c biá»‡t)\n"
            reply += "â€¢ Mang theo giáº¥y tá» tÃ¹y thÃ¢n báº£n gá»‘c\n"
            reply += "â€¢ TuÃ¢n thá»§ hÆ°á»›ng dáº«n cá»§a HDV\n"
            reply += "â€¢ Mua báº£o hiá»ƒm du lá»‹ch (báº¯t buá»™c)\n\n"
            
            reply += "ðŸ“ž **LiÃªn há»‡ Ä‘á»ƒ biáº¿t chi tiáº¿t dá»‹ch vá»¥ tour cá»¥ thá»ƒ:** 0332510486"
        
        # ðŸ”¹ CASE 3: PRICE INQUIRY - NÃ‚NG Cáº¤P (ÃP Dá»¤NG FILTER)
        elif 'price_inquiry' in detected_intents:
            logger.info("ðŸ’° Processing enhanced price inquiry with filters")
            
            # Apply filters náº¿u cÃ³
            if filter_applied and not mandatory_filters.is_empty():
                filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                if filtered_indices:
                    tour_indices = filtered_indices[:3] if not tour_indices else list(set(tour_indices) & set(filtered_indices))[:3]
            
            if tour_indices:
                # CÃ³ tour cá»¥ thá»ƒ
                price_responses = []
                detailed_info = []
                
                for idx in tour_indices[:3]:
                    tour = TOURS_DB.get(idx)
                    if tour:
                        # Format price information
                        price_info = {
                            'name': tour.name,
                            'price': tour.price or 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡',
                            'duration': tour.duration or 'KhÃ´ng xÃ¡c Ä‘á»‹nh',
                            'location': tour.location or 'KhÃ´ng xÃ¡c Ä‘á»‹nh'
                        }
                        
                        # PhÃ¢n tÃ­ch giÃ¡ náº¿u cÃ³
                        price_text = price_info['price']
                        if price_text and price_text != 'LiÃªn há»‡ Ä‘á»ƒ biáº¿t giÃ¡':
                            price_numbers = re.findall(r'\d[\d,\.]+', price_text)
                            if price_numbers:
                                try:
                                    clean_nums = []
                                    for num in price_numbers:
                                        clean_num = num.replace(',', '').replace('.', '')
                                        if clean_num.isdigit():
                                            clean_nums.append(int(clean_num))
                                    
                                    if clean_nums:
                                        min_price = min(clean_nums)
                                        max_price = max(clean_nums) if len(clean_nums) > 1 else min_price
                                        
                                        if min_price < 1000000:
                                            price_range = f"{min_price:,}Ä‘"
                                        elif min_price == max_price:
                                            price_range = f"{min_price:,}Ä‘"
                                        else:
                                            price_range = f"{min_price:,}Ä‘ - {max_price:,}Ä‘"
                                        
                                        price_info['formatted'] = price_range
                                except:
                                    price_info['formatted'] = price_text
                        
                        detailed_info.append(price_info)
                
                if detailed_info:
                    reply = "ðŸ’° **THÃ”NG TIN GIÃ TOUR CHI TIáº¾T** ðŸ’°\n\n"
                    
                    for info in detailed_info:
                        reply += f"**{info['name']}**\n"
                        reply += f"â±ï¸ Thá»i gian: {info['duration']}\n"
                        reply += f"ðŸ“ Äá»‹a Ä‘iá»ƒm: {info.get('location_short', info['location'][:50])}\n"
                        
                        if 'formatted' in info:
                            reply += f"ðŸ’° **GiÃ¡:** {info['formatted']}\n"
                        else:
                            reply += f"ðŸ’° **GiÃ¡:** {info['price']}\n"
                        
                        # ThÃªm phÃ¢n loáº¡i giÃ¡
                        if 'formatted' in info and 'Ä‘' in info['formatted']:
                            price_num = int(info['formatted'].split('Ä‘')[0].replace(',', '').replace('.', '').strip())
                            if price_num < 1000000:
                                reply += "   ðŸ·ï¸ PhÃ¢n loáº¡i: Tiáº¿t kiá»‡m\n"
                            elif price_num < 2500000:
                                reply += "   ðŸ·ï¸ PhÃ¢n loáº¡i: TiÃªu chuáº©n\n"
                            else:
                                reply += "   ðŸ·ï¸ PhÃ¢n loáº¡i: Cao cáº¥p\n"
                        
                        reply += "\n"
                    
                    # ThÃªm thÃ´ng tin Æ°u Ä‘Ã£i dá»±a trÃªn filter
                    reply += "ðŸŽ¯ **Æ¯U ÄÃƒI Äáº¶C BIá»†T:**\n"
                    
                    if mandatory_filters and hasattr(mandatory_filters, 'group_type'):
                        if mandatory_filters.group_type == 'family':
                            reply += "â€¢ Gia Ä‘Ã¬nh 4 ngÆ°á»i: Giáº£m 5%\n"
                            reply += "â€¢ Tráº» em 5-11 tuá»•i: Giáº£m 30%\n"
                            reply += "â€¢ Tráº» dÆ°á»›i 5 tuá»•i: Miá»…n phÃ­\n"
                        elif mandatory_filters.group_type == 'senior':
                            reply += "â€¢ NgÆ°á»i lá»›n tuá»•i: Giáº£m 5%\n"
                            reply += "â€¢ Cá»±u chiáº¿n binh: Giáº£m 10%\n"
                            reply += "â€¢ NhÃ³m 5+ ngÆ°á»i cao tuá»•i: Giáº£m thÃªm 5%\n"
                        elif mandatory_filters.group_type == 'friends':
                            reply += "â€¢ NhÃ³m báº¡n 5-9 ngÆ°á»i: Giáº£m 5%\n"
                            reply += "â€¢ NhÃ³m 10-15 ngÆ°á»i: Giáº£m 10%\n"
                            reply += "â€¢ Sinh viÃªn: Giáº£m thÃªm 5%\n"
                    
                    reply += "â€¢ Äáº·t trÆ°á»›c 30 ngÃ y: Giáº£m thÃªm 5%\n"
                    reply += "â€¢ Thanh toÃ¡n online: Giáº£m thÃªm 2%\n\n"
                    reply += "ðŸ“ž **LiÃªn há»‡ ngay Ä‘á»ƒ nháº­n bÃ¡o giÃ¡ tá»‘t nháº¥t:** 0332510486"
                else:
                    reply = "Hiá»‡n chÆ°a cÃ³ thÃ´ng tin giÃ¡ cho cÃ¡c tour nÃ y. Vui lÃ²ng liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c bÃ¡o giÃ¡ chi tiáº¿t."
            else:
                # KhÃ´ng cÃ³ tour cá»¥ thá»ƒ - Hiá»ƒn thá»‹ báº£ng giÃ¡ tá»•ng quÃ¡t vá»›i filter
                reply = "ðŸ’° **Báº¢NG GIÃ THAM KHáº¢O RUBY WINGS** ðŸ’°\n\n"
                
                # Táº¡o báº£ng giÃ¡ theo loáº¡i tour, cÃ³ xem xÃ©t filter
                price_categories = [
                    ("ðŸŒ¿ TOUR 1 NGÃ€Y (ThiÃªn nhiÃªn, VÄƒn hÃ³a)", "600.000Ä‘ - 1.500.000Ä‘", 
                     "Báº¡ch MÃ£, Huáº¿ city tour, áº¨m thá»±c Huáº¿"),
                    ("ðŸ›ï¸ TOUR 2 NGÃ€Y 1 ÄÃŠM (Lá»‹ch sá»­, Retreat)", "1.500.000Ä‘ - 3.000.000Ä‘", 
                     "TrÆ°á»ng SÆ¡n, Di tÃ­ch lá»‹ch sá»­, Thiá»n Ä‘á»‹nh"),
                    ("ðŸ•‰ï¸ TOUR 3+ NGÃ€Y (Cao cáº¥p, CÃ¡ nhÃ¢n hÃ³a)", "3.000.000Ä‘ - 5.000.000Ä‘", 
                     "Tour riÃªng, NhÃ³m Ä‘áº·c biá»‡t, Retreat sÃ¢u"),
                    ("ðŸ‘¥ TOUR TEAMBUILDING (CÃ´ng ty, NhÃ³m lá»›n)", "LiÃªn há»‡ tÆ° váº¥n", 
                     "Thiáº¿t káº¿ riÃªng, Hoáº¡t Ä‘á»™ng nhÃ³m, Gáº¯n káº¿t")
                ]
                
                for cat_name, price_range, description in price_categories:
                    reply += f"**{cat_name}**\n"
                    reply += f"ðŸ’° {price_range}\n"
                    reply += f"ðŸ“ {description}\n\n"
                
                # ThÃªm thÃ´ng tin Æ°u Ä‘Ã£i theo filter
                if mandatory_filters and hasattr(mandatory_filters, 'group_type'):
                    reply += "ðŸŽ **Æ¯U ÄÃƒI Äáº¶C BIá»†T CHO NHÃ“M:**\n"
                    group_offers = {
                        'family': "â€¢ Gia Ä‘Ã¬nh: Giáº£m 5-10%\nâ€¢ Tráº» em: Giáº£m 30-50%\n",
                        'senior': "â€¢ NgÆ°á»i cao tuá»•i: Giáº£m 5%\nâ€¢ Cá»±u chiáº¿n binh: Giáº£m 10%\n",
                        'friends': "â€¢ NhÃ³m báº¡n: Giáº£m 5-15%\nâ€¢ Sinh viÃªn: ThÃªm 5%\n",
                        'corporate': "â€¢ CÃ´ng ty: Giáº£m 10-20%\nâ€¢ Teambuilding: Táº·ng hoáº¡t Ä‘á»™ng\n"
                    }
                    if mandatory_filters.group_type in group_offers:
                        reply += group_offers[mandatory_filters.group_type]
                    reply += "\n"
                
                reply += "ðŸ“ž **LiÃªn há»‡ tÆ° váº¥n giÃ¡ chÃ­nh xÃ¡c:** 0332510486"
        
        # ðŸ”¹ CASE 4: TOUR LISTING (ÃP Dá»¤NG FILTER Vá»€ LOCATION) - FIXED DUPLICATE MERGING
        elif 'tour_listing' in detected_intents:
            logger.info("ðŸ“‹ Processing tour listing request with filters and duplicate merging")
            
            all_tours = list(TOURS_DB.values())
            
            # FIX: Validation - Loáº¡i bá» tour khÃ´ng há»£p lá»‡ vÃ  ná»™i dung vÄƒn hÃ³a
            valid_tours = []
            for tour in all_tours:
                # Kiá»ƒm tra tour há»£p lá»‡
                if not tour.name or len(tour.name.strip()) < 3:
                    continue
                    
                # Loáº¡i bá» "tour" lÃ  ná»™i dung vÄƒn hÃ³a
                if any(keyword in tour.name.lower() for keyword in ['ná»™i dung vÄƒn hÃ³a', 'vÄƒn hÃ³a', 'content']):
                    continue
                    
                if tour.summary and any(keyword in tour.summary.lower() for keyword in ['ná»™i dung vÄƒn hÃ³a']):
                    continue
                    
                # Tour pháº£i cÃ³ Ã­t nháº¥t 1 thÃ´ng tin khÃ¡c
                if not any([tour.duration, tour.location, tour.price, tour.summary]):
                    continue
                    
                valid_tours.append(tour)
            
            all_tours = valid_tours
            
            # Apply location filter náº¿u cÃ³ trong cÃ¢u há»i
            location_from_query = None
            locations = ['huáº¿', 'quáº£ng trá»‹', 'báº¡ch mÃ£', 'trÆ°á»ng sÆ¡n', 'Ä‘Ã´ng hÃ ', 'miá»n trung', 'Ä‘Ã  náºµng']
            for loc in locations:
                if loc in message_lower:
                    location_from_query = loc
                    break
            
            if location_from_query:
                all_tours = [tour for tour in all_tours if tour.location and location_from_query in tour.location.lower()]
                logger.info(f"ðŸ“ Applied location filter: {location_from_query}")
            
            # Apply mandatory filters
            if filter_applied and not mandatory_filters.is_empty():
                filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                all_tours = [TOURS_DB[idx] for idx in filtered_indices if idx in TOURS_DB]
            
            # FIX: DUPLICATE MERGING - Merge cÃ¡c tour trÃ¹ng tÃªn
            if UpgradeFlags.is_enabled("2_DEDUPLICATION") and all_tours:
                seen_names = set()
                unique_tours = []
                
                for tour in all_tours:
                    name = tour.name.strip()
                    if name not in seen_names:
                        seen_names.add(name)
                        unique_tours.append(tour)
                    else:
                        # Náº¿u trÃ¹ng tÃªn, giá»¯ tour cÃ³ thÃ´ng tin Ä‘áº§y Ä‘á»§ nháº¥t
                        existing_idx = next(i for i, t in enumerate(unique_tours) if t.name.strip() == name)
                        existing_tour = unique_tours[existing_idx]
                        
                        # So sÃ¡nh thÃ´ng tin
                        existing_score = sum([
                            1 if existing_tour.duration else 0,
                            1 if existing_tour.location else 0,
                            1 if existing_tour.price else 0,
                            1 if existing_tour.summary and len(existing_tour.summary) > 20 else 0
                        ])
                        
                        new_score = sum([
                            1 if tour.duration else 0,
                            1 if tour.location else 0,
                            1 if tour.price else 0,
                            1 if tour.summary and len(tour.summary) > 20 else 0
                        ])
                        
                        # Giá»¯ tour cÃ³ thÃ´ng tin Ä‘áº§y Ä‘á»§ hÆ¡n
                        if new_score > existing_score:
                            unique_tours[existing_idx] = tour
                
                all_tours = unique_tours
            
            total_tours = len(all_tours)
            
            if total_tours > 0:
                # PhÃ¢n loáº¡i tour theo category
                categorized_tours = {
                    'history': [],
                    'retreat': [],
                    'nature': [],
                    'culture': [],
                    'family': []
                }
                
                for tour in all_tours:
                    tags_lower = [tag.lower() for tag in (tour.tags or [])]
                    
                    if any('history' in tag for tag in tags_lower):
                        categorized_tours['history'].append(tour)
                    elif any('meditation' in tag or 'retreat' in tag for tag in tags_lower):
                        categorized_tours['retreat'].append(tour)
                    elif any('nature' in tag for tag in tags_lower):
                        categorized_tours['nature'].append(tour)
                    elif any('culture' in tag or 'food' in tag for tag in tags_lower):
                        categorized_tours['culture'].append(tour)
                    elif any('family' in tag for tag in tags_lower):
                        categorized_tours['family'].append(tour)
                    else:
                        categorized_tours['nature'].append(tour)  # Máº·c Ä‘á»‹nh
                
                # Format response cÃ³ cáº¥u trÃºc
                reply = "âœ¨ **DANH SÃCH TOUR RUBY WINGS** âœ¨\n\n"
                
                # Hiá»ƒn thá»‹ filter Ä‘ang Ã¡p dá»¥ng
                if location_from_query or filter_applied:
                    reply += "ðŸ” **ÄANG ÃP Dá»¤NG Bá»˜ Lá»ŒC:**\n"
                    if location_from_query:
                        reply += f"â€¢ Äá»‹a Ä‘iá»ƒm: {location_from_query.upper()}\n"
                    if mandatory_filters and not mandatory_filters.is_empty():
                        reply += f"â€¢ {mandatory_filters}\n"
                    reply += "\n"
                
                reply += f"ðŸ“Š **Tá»•ng cá»™ng:** {total_tours} tour Ä‘áº·c sáº¯c (Ä‘Ã£ loáº¡i bá» trÃ¹ng láº·p)\n\n"
                
                # Hiá»ƒn thá»‹ theo tá»«ng loáº¡i
                categories_display = [
                    ('ðŸ›ï¸ Lá»ŠCH Sá»¬ - TRI Ã‚N', 'history', 'history'),
                    ('ðŸ•‰ï¸ RETREAT - CHá»®A LÃ€NH', 'retreat', 'meditation'),
                    ('ðŸŒ¿ THIÃŠN NHIÃŠN - KHÃM PHÃ', 'nature', 'nature'),
                    ('ðŸœ VÄ‚N HÃ“A - áº¨M THá»°C', 'culture', 'culture'),
                    ('ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦ GIA ÄÃŒNH - NHÃ“M', 'family', 'family')
                ]
                
                tours_displayed = 0
                for cat_name, cat_key, emoji_key in categories_display:
                    cat_tours = categorized_tours[cat_key]
                    if cat_tours:
                        reply += f"**{cat_name}** ({len(cat_tours)} tour)\n"
                        
                        for i, tour in enumerate(cat_tours[:3], 1):
                            # Chá»n emoji phÃ¹ há»£p
                            emoji = "âœ¨"
                            if cat_key == 'history': emoji = "ðŸ›ï¸"
                            elif cat_key == 'retreat': emoji = "ðŸ•‰ï¸"
                            elif cat_key == 'nature': emoji = "ðŸŒ¿"
                            elif cat_key == 'culture': emoji = "ðŸœ"
                            elif cat_key == 'family': emoji = "ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦"
                            
                            reply += f"{emoji} **{tour.name}**\n"
                            if tour.duration:
                                reply += f"   â±ï¸ {tour.duration}\n"
                            if tour.location:
                                location_short = tour.location[:40] + "..." if len(tour.location) > 40 else tour.location
                                reply += f"   ðŸ“ {location_short}\n"
                            if i == 1 and tour.price:  # Hiá»‡n giÃ¡ tour Ä‘áº§u má»—i loáº¡i
                                price_short = tour.price[:60] + "..." if len(tour.price) > 60 else tour.price
                                reply += f"   ðŸ’° {price_short}\n"
                            reply += "\n"
                            tours_displayed += 1
                        
                        if len(cat_tours) > 3:
                            reply += f"   ðŸ“Œ ...vÃ  {len(cat_tours) - 3} tour khÃ¡c\n\n"
                        else:
                            reply += "\n"
                
                if tours_displayed < total_tours:
                    reply += f"ðŸ“Œ **CÃ²n {total_tours - tours_displayed} tour khÃ¡c trong há»‡ thá»‘ng!**\n\n"
                
                reply += "ðŸ’¡ **HÆ¯á»šNG DáºªN TÃŒM TOUR:**\n"
                reply += "â€¢ Gá»i tÃªn tour cá»¥ thá»ƒ (vÃ­ dá»¥: 'Tour Báº¡ch MÃ£')\n"
                reply += "â€¢ MÃ´ táº£ nhu cáº§u: 'tour gia Ä‘Ã¬nh 2 ngÃ y', 'retreat thiá»n'\n"
                reply += "â€¢ So sÃ¡nh tour: 'so sÃ¡nh tour A vÃ  tour B'\n\n"
                reply += "ðŸ“ž **Hotline tÆ° váº¥n nhanh:** 0332510486"
                
                # LÆ°u context Ä‘á»ƒ follow-up
                tour_indices_list = []
                for i, tour in enumerate(all_tours[:10]):
                    for idx, t in TOURS_DB.items():
                        if t.name == tour.name:
                            tour_indices_list.append(idx)
                            break
                
                context.last_listed_tours = tour_indices_list
                context.last_tour_index = tour_indices_list[0] if tour_indices_list else None
                context.last_tour_name = all_tours[0].name if all_tours else None
            else:
                reply = "Hiá»‡n chÆ°a cÃ³ tour nÃ o phÃ¹ há»£p vá»›i yÃªu cáº§u cá»§a báº¡n. Vui lÃ²ng thá»­ vá»›i tiÃªu chÃ­ khÃ¡c hoáº·c liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n tour riÃªng."
        
        # ðŸ”¹ CASE 5: RECOMMENDATION SYSTEM (ÃP Dá»¤NG FILTER Vá»€ NHÃ“M/BUDGET)
        elif 'recommendation' in detected_intents:
            logger.info("ðŸŽ¯ Processing enhanced recommendation request with filters")
            
            # Advanced user profile extraction
            user_profile = {
                'group_type': None,
                'age_group': None,
                'interests': [],
                'budget_range': None,
                'time_constraint': None,
                'preferred_location': None,
                'special_requirements': []
            }
            
            # Extract group type tá»« cÃ¢u há»i hoáº·c tá»« filter
            group_keywords = {
                'family': ['gia Ä‘Ã¬nh', 'con nhá»', 'tráº» em', 'bá»‘ máº¹', 'Ã´ng bÃ ', 'Ä‘a tháº¿ há»‡'],
                'senior': ['ngÆ°á»i lá»›n tuá»•i', 'cao tuá»•i', 'cá»±u chiáº¿n binh', 'veteran', 'Ã´ng bÃ '],
                'friends': ['nhÃ³m báº¡n', 'báº¡n bÃ¨', 'sinh viÃªn', 'báº¡n tráº»', 'thanh niÃªn'],
                'corporate': ['cÃ´ng ty', 'team building', 'doanh nghiá»‡p', 'nhÃ¢n viÃªn', 'Ä‘á»“ng nghiá»‡p'],
                'couple': ['cáº·p Ä‘Ã´i', 'Ä‘Ã´i lá»©a', 'ngÆ°á»i yÃªu', 'tÃ¬nh nhÃ¢n'],
                'solo': ['má»™t mÃ¬nh', 'Ä‘i láº»', 'solo', 'cÃ¡ nhÃ¢n']
            }
            
            for group_type, keywords in group_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    user_profile['group_type'] = group_type
                    break
            
            # Náº¿u khÃ´ng tÃ¬m tháº¥y trong cÃ¢u há»i, kiá»ƒm tra filter
            if not user_profile['group_type'] and mandatory_filters and hasattr(mandatory_filters, 'group_type'):
                user_profile['group_type'] = mandatory_filters.group_type
            
            # Extract budget tá»« cÃ¢u há»i hoáº·c filter
            budget_patterns = [
                r'giÃ¡ ráº»|tiáº¿t kiá»‡m|kinh táº¿|dÆ°á»›i\s+(\d+)',
                r'táº§m trung|trung bÃ¬nh|vá»«a pháº£i|khoáº£ng\s+(\d+)',
                r'cao cáº¥p|sang trá»ng|premium|trÃªn\s+(\d+)'
            ]
            
            for i, pattern in enumerate(budget_patterns):
                if re.search(pattern, message_lower):
                    if i == 0:
                        user_profile['budget_range'] = 'low'
                    elif i == 1:
                        user_profile['budget_range'] = 'medium'
                    else:
                        user_profile['budget_range'] = 'high'
                    break
            
            # Extract interests
            interest_keywords = {
                'history': ['lá»‹ch sá»­', 'di tÃ­ch', 'chiáº¿n tranh', 'tri Ã¢n', 'kÃ½ á»©c', 'cá»•'],
                'nature': ['thiÃªn nhiÃªn', 'rá»«ng', 'nÃºi', 'cÃ¢y', 'suá»‘i', 'khÃ´ng khÃ­ trong lÃ nh'],
                'meditation': ['thiá»n', 'yoga', 'tÄ©nh tÃ¢m', 'chá»¯a lÃ nh', 'retreat', 'khÃ­ cÃ´ng'],
                'culture': ['vÄƒn hÃ³a', 'truyá»n thá»‘ng', 'áº©m thá»±c', 'Ä‘áº·c sáº£n', 'phong tá»¥c'],
                'adventure': ['phiÃªu lÆ°u', 'máº¡o hiá»ƒm', 'khÃ¡m phÃ¡', 'tráº£i nghiá»‡m má»›i'],
                'relaxation': ['nghá»‰ ngÆ¡i', 'thÆ° giÃ£n', 'nháº¹ nhÃ ng', 'khÃ´ng vá»™i', 'cháº­m rÃ£i']
            }
            
            for interest, keywords in interest_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    if interest not in user_profile['interests']:
                        user_profile['interests'].append(interest)
            
            # Extract location preference
            locations = ['huáº¿', 'quáº£ng trá»‹', 'báº¡ch mÃ£', 'trÆ°á»ng sÆ¡n', 'Ä‘Ã´ng hÃ ', 'miá»n trung']
            for loc in locations:
                if loc in message_lower:
                    user_profile['preferred_location'] = loc
                    break
            
            logger.info(f"ðŸŽ¯ User profile extracted: {user_profile}")
            
            # SCORING SYSTEM vá»›i filter
            matching_tours = []
            
            for idx, tour in TOURS_DB.items():
                score = 0
                reasons = []
                match_details = {}
                
                # 1. Group type matching (30%)
                if user_profile['group_type']:
                    tour_tags = [tag.lower() for tag in (tour.tags or [])]
                    
                    if user_profile['group_type'] == 'family':
                        if any('family' in tag for tag in tour_tags):
                            score += 30
                            reasons.append("phÃ¹ há»£p gia Ä‘Ã¬nh")
                            match_details['group'] = 'excellent'
                        elif not any('adventure' in tag or 'extreme' in tag for tag in tour_tags):
                            score += 15
                            reasons.append("cÃ³ thá»ƒ phÃ¹ há»£p gia Ä‘Ã¬nh")
                            match_details['group'] = 'good'
                    
                    elif user_profile['group_type'] == 'senior':
                        if any('senior' in tag or 'accessible' in tag for tag in tour_tags):
                            score += 30
                            reasons.append("thiáº¿t káº¿ cho ngÆ°á»i lá»›n tuá»•i")
                            match_details['group'] = 'excellent'
                        elif any('nature' in tag or 'meditation' in tag for tag in tour_tags):
                            score += 20
                            reasons.append("nháº¹ nhÃ ng, phÃ¹ há»£p lá»›n tuá»•i")
                            match_details['group'] = 'good'
                    
                    elif user_profile['group_type'] == 'friends':
                        if any('friends' in tag or 'group' in tag for tag in tour_tags):
                            score += 30
                            reasons.append("phÃ¹ há»£p nhÃ³m báº¡n")
                            match_details['group'] = 'excellent'
                        elif any('adventure' in tag or 'experience' in tag for tag in tour_tags):
                            score += 20
                            reasons.append("nhiá»u hoáº¡t Ä‘á»™ng nhÃ³m")
                            match_details['group'] = 'good'
                
                # 2. Interest matching (40%)
                if user_profile['interests']:
                    tour_summary = (tour.summary or '').lower()
                    tour_tags = [tag.lower() for tag in (tour.tags or [])]
                    
                    for interest in user_profile['interests']:
                        if interest == 'history':
                            if any('history' in tag for tag in tour_tags) or 'lá»‹ch sá»­' in tour_summary:
                                score += 40
                                reasons.append("trá»ng tÃ¢m lá»‹ch sá»­")
                                match_details['interest'] = 'history'
                                break
                        
                        elif interest == 'nature':
                            if any('nature' in tag for tag in tour_tags) or 'thiÃªn nhiÃªn' in tour_summary:
                                score += 40
                                reasons.append("tráº£i nghiá»‡m thiÃªn nhiÃªn")
                                match_details['interest'] = 'nature'
                                break
                        
                        elif interest == 'meditation':
                            if any('meditation' in tag for tag in tour_tags) or 'thiá»n' in tour_summary:
                                score += 40
                                reasons.append("cÃ³ hoáº¡t Ä‘á»™ng thiá»n/retreat")
                                match_details['interest'] = 'meditation'
                                break
                        
                        elif interest == 'culture':
                            if any('culture' in tag for tag in tour_tags) or 'vÄƒn hÃ³a' in tour_summary:
                                score += 40
                                reasons.append("khÃ¡m phÃ¡ vÄƒn hÃ³a")
                                match_details['interest'] = 'culture'
                                break
                
                # 3. Budget matching (15%)
                if user_profile['budget_range'] and tour.price:
                    price_value = _extract_price_value(tour.price)
                    
                    if price_value:
                        if user_profile['budget_range'] == 'low' and price_value < 1000000:  # DÆ°á»›i 1 triá»‡u
                            score += 15
                            reasons.append("giÃ¡ dÆ°á»›i 1 triá»‡u")
                            match_details['budget'] = 'good'
                        elif user_profile['budget_range'] == 'medium' and 1000000 <= price_value <= 2500000:
                            score += 15
                            reasons.append("giÃ¡ táº§m trung")
                            match_details['budget'] = 'good'
                        elif user_profile['budget_range'] == 'high' and price_value > 2500000:
                            score += 15
                            reasons.append("dá»‹ch vá»¥ cao cáº¥p")
                            match_details['budget'] = 'good'
                
                # 4. Time constraint matching (10%)
                if user_profile['time_constraint'] and tour.duration:
                    duration_lower = tour.duration.lower()
                    
                    if user_profile['time_constraint'] == '1day' and '1 ngÃ y' in duration_lower:
                        score += 10
                        reasons.append("Ä‘Ãºng 1 ngÃ y")
                        match_details['time'] = 'perfect'
                    elif user_profile['time_constraint'] == '2days' and '2 ngÃ y' in duration_lower:
                        score += 10
                        reasons.append("Ä‘Ãºng 2 ngÃ y")
                        match_details['time'] = 'perfect'
                    elif user_profile['time_constraint'] == '3+days' and ('3 ngÃ y' in duration_lower or '4 ngÃ y' in duration_lower):
                        score += 10
                        reasons.append("Ä‘a ngÃ y nhÆ° yÃªu cáº§u")
                        match_details['time'] = 'perfect'
                
                # 5. Location preference (5%)
                if user_profile['preferred_location'] and tour.location:
                    if user_profile['preferred_location'] in tour.location.lower():
                        score += 5
                        reasons.append(f"táº¡i {user_profile['preferred_location']}")
                        match_details['location'] = 'exact'
                
                if score > 0:
                    matching_tours.append((idx, score, reasons, match_details))
            
            # Sáº¯p xáº¿p theo Ä‘iá»ƒm
            matching_tours.sort(key=lambda x: x[1], reverse=True)
            
            # Ãp dá»¥ng thÃªm filter náº¿u cÃ³
            if filter_applied and not mandatory_filters.is_empty():
                filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                matching_tours = [t for t in matching_tours if t[0] in filtered_indices]
            
            # ================== GENERATE RECOMMENDATION RESPONSE ==================
            if matching_tours:
                # LÆ°u recommendations vÃ o context
                context.last_recommended_tours = [idx for idx, _, _, _ in matching_tours]
                context.last_tour_index = matching_tours[0][0] if matching_tours else None
                
                # PhÃ¢n loáº¡i recommendations
                excellent_matches = [t for t in matching_tours if t[1] >= 60]
                good_matches = [t for t in matching_tours if 30 <= t[1] < 60]
                
                reply = "ðŸŽ¯ **Äá»€ XUáº¤T TOUR THÃ”NG MINH** ðŸŽ¯\n\n"
                
                # Hiá»ƒn thá»‹ thÃ´ng tin user profile
                reply += "ðŸ“‹ **Dá»°A TRÃŠN YÃŠU Cáº¦U Cá»¦A Báº N:**\n"
                
                if user_profile['group_type']:
                    group_names = {
                        'family': 'Gia Ä‘Ã¬nh',
                        'senior': 'NgÆ°á»i lá»›n tuá»•i/Cá»±u chiáº¿n binh',
                        'friends': 'NhÃ³m báº¡n',
                        'corporate': 'CÃ´ng ty/Team building',
                        'couple': 'Cáº·p Ä‘Ã´i',
                        'solo': 'Äi má»™t mÃ¬nh'
                    }
                    reply += f"â€¢ **Äá»‘i tÆ°á»£ng:** {group_names.get(user_profile['group_type'], user_profile['group_type'])}\n"
                
                if user_profile['interests']:
                    interest_names = {
                        'history': 'Lá»‹ch sá»­',
                        'nature': 'ThiÃªn nhiÃªn',
                        'meditation': 'Thiá»n/Retreat',
                        'culture': 'VÄƒn hÃ³a/áº¨m thá»±c',
                        'adventure': 'PhiÃªu lÆ°u',
                        'relaxation': 'ThÆ° giÃ£n'
                    }
                    interests_str = ', '.join([interest_names.get(i, i) for i in user_profile['interests'][:3]])
                    reply += f"â€¢ **Sá»Ÿ thÃ­ch:** {interests_str}\n"
                
                if user_profile['budget_range']:
                    budget_names = {
                        'low': 'Tiáº¿t kiá»‡m (dÆ°á»›i 1 triá»‡u)',
                        'medium': 'Táº§m trung (1-2.5 triá»‡u)',
                        'high': 'Cao cáº¥p (trÃªn 2.5 triá»‡u)'
                    }
                    reply += f"â€¢ **NgÃ¢n sÃ¡ch:** {budget_names.get(user_profile['budget_range'], 'KhÃ´ng xÃ¡c Ä‘á»‹nh')}\n"
                
                if filter_applied and mandatory_filters:
                    reply += f"â€¢ **Bá»™ lá»c Ã¡p dá»¥ng:** {mandatory_filters}\n"
                
                reply += "\n"
                
                # Top recommendations (xuáº¥t sáº¯c)
                if excellent_matches:
                    reply += "ðŸ† **PHÃ™ Há»¢P NHáº¤T Vá»šI Báº N**\n\n"
                    
                    for idx, score, reasons, details in excellent_matches[:2]:
                        tour = TOURS_DB.get(idx)
                        if tour:
                            # TÃ­nh pháº§n trÄƒm phÃ¹ há»£p
                            match_percent = min(100, int(score))
                            
                            reply += f"**{tour.name}** ({match_percent}% phÃ¹ há»£p)\n"
                            reply += f"âœ… **LÃ½ do Ä‘á» xuáº¥t:** {', '.join(reasons[:3])}\n"
                            
                            if tour.duration:
                                reply += f"â±ï¸ **Thá»i gian:** {tour.duration}\n"
                            if tour.location:
                                location_short = tour.location[:50] + "..." if len(tour.location) > 50 else tour.location
                                reply += f"ðŸ“ **Äá»‹a Ä‘iá»ƒm:** {location_short}\n"
                            if tour.price:
                                price_short = tour.price[:80] + "..." if len(tour.price) > 80 else tour.price
                                reply += f"ðŸ’° **GiÃ¡:** {price_short}\n"
                            
                            reply += "\n"
                
                # Good recommendations
                if good_matches and (not excellent_matches or len(excellent_matches) < 2):
                    reply += "ðŸ¥ˆ **Lá»°A CHá»ŒN Tá»T KHÃC**\n\n"
                    
                    display_count = min(2, len(good_matches))
                    for idx, score, reasons, details in good_matches[:display_count]:
                        tour = TOURS_DB.get(idx)
                        if tour:
                            match_percent = min(100, int(score))
                            reply += f"â€¢ **{tour.name}** ({match_percent}%)\n"
                            
                            if tour.duration:
                                reply += f"  â±ï¸ {tour.duration}"
                            if tour.location:
                                loc_short = tour.location[:30] + "..." if len(tour.location) > 30 else tour.location
                                reply += f" | ðŸ“ {loc_short}"
                            reply += "\n"
                
                reply += "\nðŸ“ž **LiÃªn há»‡ Ä‘á»ƒ Ä‘áº·t tour phÃ¹ há»£p nháº¥t:** 0332510486"
                
                # LÆ°u user profile vÃ o context
                context.user_profile.update(user_profile)
            else:
                reply = "Hiá»‡n chÆ°a cÃ³ tour nÃ o phÃ¹ há»£p vá»›i tiÃªu chÃ­ cá»§a báº¡n. Vui lÃ²ng thá»­ vá»›i tiÃªu chÃ­ khÃ¡c hoáº·c liÃªn há»‡ hotline 0332510486 Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n tour riÃªng."
        
        # ðŸ”¹ CASE 6-12: CÃC CASE KHÃC (giá»¯ nguyÃªn)
        # ... (giá»¯ nguyÃªn cÃ¡c case khÃ¡c) ...
        
        # ðŸ”¹ CASE 13: FALLBACK TO AI
        else:
            logger.info("ðŸ¤– Processing with AI fallback")
            
            # Chuáº©n bá»‹ context
            context_info = {
                'user_message': user_message,
                'tour_indices': tour_indices,
                'detected_intents': detected_intents,
                'primary_intent': primary_intent,
                'filters': mandatory_filters.to_dict() if mandatory_filters else {},
                'complexity_score': complexity_score
            }
            
            # Táº¡o prompt
            prompt = _prepare_enhanced_llm_prompt(user_message, [], context_info, TOURS_DB)
            
            # Gá»i AI náº¿u cÃ³
            if client and HAS_OPENAI:
                try:
                    messages = [
                        {"role": "system", "content": prompt},
                        {"role": "user", "content": user_message}
                    ]
                    
                    response = client.chat.completions.create(
                        model=CHAT_MODEL,
                        messages=messages,
                        temperature=0.6,
                        max_tokens=600
                    )
                    
                    if response.choices:
                        reply = response.choices[0].message.content or ""
                    else:
                        reply = _generate_enhanced_fallback_response(user_message, [], tour_indices, TOURS_DB)
                
                except Exception as e:
                    logger.error(f"OpenAI error: {e}")
                    reply = _generate_enhanced_fallback_response(user_message, [], tour_indices, TOURS_DB)
            else:
                reply = _generate_enhanced_fallback_response(user_message, [], tour_indices, TOURS_DB)
        
        # ================== ENHANCE RESPONSE QUALITY ==================
        # Äáº£m báº£o má»i response Ä‘á»u cÃ³ hotline
        if "0332510486" not in reply and "hotline" not in reply.lower() and "liÃªn há»‡" not in reply.lower():
            reply += "\n\nðŸ“ž **Hotline tÆ° váº¥n 24/7:** 0332510486"
        
        # ThÃªm signature náº¿u response dÃ i
        if len(reply) > 300:
            if not reply.endswith("0332510486") and not reply.endswith("Hotline"):
                reply += "\n\n---\n**Ruby Wings Travel** - HÃ nh trÃ¬nh Ã½ nghÄ©a, tráº£i nghiá»‡m thá»±c táº¿, cÃ³ chiá»u sÃ¢u"
        
        # Giá»›i háº¡n Ä‘á»™ dÃ i response
        if len(reply) > 2500:
            reply = reply[:2500] + "...\n\nðŸ’¡ **Äá»ƒ biáº¿t thÃªm chi tiáº¿t, vui lÃ²ng liÃªn há»‡ hotline 0332510486**"
        
        # ================== UPDATE CONTEXT ==================
        # Cáº­p nháº­t tour context
        if tour_indices and len(tour_indices) > 0:
            context.current_tour = tour_indices[0]
            tour = TOURS_DB.get(tour_indices[0])
            if tour:
                context.last_tour_name = tour.name
                context.last_tour_index = tour_indices[0]
        
        # Cáº­p nháº­t conversation history vá»›i metadata
        context.conversation_history.append({
            'role': 'assistant',
            'message': reply,
            'timestamp': datetime.utcnow().isoformat(),
            'tour_indices': tour_indices,
            'detected_intents': detected_intents,
            'primary_intent': primary_intent,
            'complexity_score': complexity_score
        })
        
        # LÆ°u session context
        save_session_context(session_id, context)
        
        # ================== FINAL RESPONSE ==================
        processing_time = time.time() - start_time
        
        # FIX CACHE SYSTEM: Sá»­a cÃ¡ch táº¡o CacheEntry
        if UpgradeFlags.get_all_flags().get("ENABLE_CACHING", True):
            context_hash = hashlib.md5(json.dumps({
                'tour_indices': tour_indices,
                'detected_intents': detected_intents,
                'primary_intent': primary_intent,
                'complexity': complexity_score,
                'filters': mandatory_filters.to_dict() if mandatory_filters else {}
            }, sort_keys=True).encode()).hexdigest()
            
            cache_key = CacheSystem.get_cache_key(user_message, context_hash)
            
            # FIX: Sá»­a cÃ¡ch táº¡o CacheEntry
            cache_data = {
                "reply": reply,
                "sources": sources,
                "context": {
                    "session_id": session_id,
                    "current_tour": getattr(context, 'current_tour', None),
                    "last_tour_name": getattr(context, 'last_tour_name', None),
                    "user_preferences": getattr(context, 'user_profile', {}),
                    "detected_intents": detected_intents,
                    "primary_intent": primary_intent,
                    "processing_time_ms": int(processing_time * 1000),
                    "tours_found": len(tour_indices),
                    "complexity_score": complexity_score,
                    "filter_applied": filter_applied
                },
                "tour_indices": tour_indices,
                "processing_time_ms": int(processing_time * 1000),
                "from_memory": False
            }
            
            # FIX: Gá»i CacheSystem.set vá»›i Ä‘Ãºng tham sá»‘
            CacheSystem.set(cache_key, cache_data, expiry=300)
        
        chat_response = {
            "reply": reply,
            "sources": sources,
            "context": {
                "session_id": session_id,
                "current_tour": getattr(context, 'current_tour', None),
                "last_tour_name": getattr(context, 'last_tour_name', None),
                "user_preferences": getattr(context, 'user_profile', {}),
                "detected_intents": detected_intents,
                "primary_intent": primary_intent,
                "processing_time_ms": int(processing_time * 1000),
                "tours_found": len(tour_indices),
                "complexity_score": complexity_score,
                "filter_applied": filter_applied
            },
            "tour_indices": tour_indices,
            "processing_time": processing_time
        }
        
        logger.info(f"âœ… Processed in {processing_time:.2f}s | "
                   f"Primary Intent: {primary_intent} | "
                   f"Tours: {len(tour_indices)} | "
                   f"Complexity: {complexity_score} | "
                   f"Filters: {filter_applied}")
        
        return jsonify(chat_response)
    
    except Exception as e:
        logger.error(f"âŒ Chat endpoint error: {e}\n{traceback.format_exc()}")
        
        processing_time = time.time() - start_time
        
        # Enhanced error response
        error_response = {
            "reply": "âš¡ **CÃ³ chÃºt trá»¥c tráº·c ká»¹ thuáº­t!**\n\n"
                  "Äá»™i ngÅ© Ruby Wings váº«n sáºµn sÃ ng há»— trá»£ báº¡n qua cÃ¡c kÃªnh sau:\n\n"
                  "ðŸ”§ **GIáº¢I PHÃP NHANH:**\n"
                  "1. **Gá»i trá»±c tiáº¿p:** ðŸ“ž 0332510486 (tÆ° váº¥n ngay)\n"
                  "2. **Há»i Ä‘Æ¡n giáº£n hÆ¡n:** 'Tour 1 ngÃ y Huáº¿', 'Tour gia Ä‘Ã¬nh 2 ngÃ y'\n"
                  "3. **Chá»n tá»« danh sÃ¡ch:**\n"
                  "   â€¢ Tour thiÃªn nhiÃªn Báº¡ch MÃ£\n"
                  "   â€¢ Tour lá»‹ch sá»­ TrÆ°á»ng SÆ¡n\n"
                  "   â€¢ Tour retreat thiá»n\n\n"
                  "â° **ChÃºng tÃ´i hoáº¡t Ä‘á»™ng 24/7 Ä‘á»ƒ phá»¥c vá»¥ báº¡n tá»‘t nháº¥t!** ðŸ˜Š",
            "sources": [],
            "context": {
                "error": str(e),
                "processing_time_ms": int(processing_time * 1000),
                "error_type": type(e).__name__
            },
            "tour_indices": [],
            "processing_time": processing_time
        }
        
        return jsonify(error_response), 500


# ================== FIXED HELPER FUNCTIONS ==================

def _extract_price_value(price_text):
    """TrÃ­ch xuáº¥t giÃ¡ trá»‹ sá»‘ tá»« text giÃ¡"""
    if not price_text:
        return None
    
    import re
    
    # TÃ¬m táº¥t cáº£ cÃ¡c sá»‘ trong text
    numbers = re.findall(r'\d[\d,\.]+', price_text)
    if not numbers:
        return None
    
    try:
        # Láº¥y sá»‘ Ä‘áº§u tiÃªn vÃ  chuyá»ƒn Ä‘á»•i
        num_str = numbers[0].replace(',', '').replace('.', '')
        if num_str.isdigit():
            return int(num_str)
    except:
        pass
    
    return None


# ================== FIXED MANDATORYFILTERSYSTEM ==================

class MandatoryFilterSystem:
    @staticmethod
    def _extract_tour_prices(price_text: str) -> List[int]:
        """TrÃ­ch xuáº¥t giÃ¡ tá»« text - FIXED VERSION"""
        prices = []
        try:
            # FIXED: Sá»­a regex pattern Ä‘á»ƒ báº¯t group Ä‘Ãºng cÃ¡ch
            pattern = r'(\d[\d,\.]+)\s*(?:triá»‡u|tr|k|nghÃ¬n|Ä‘á»“ng|vnÄ‘|vnd|Ä‘)'
            matches = re.finditer(pattern, price_text, re.IGNORECASE)
            
            for match in matches:
                try:
                    amount_str = match.group(1)  # Group 1 lÃ  sá»‘
                    
                    # XÃ³a dáº¥u phÃ¢n cÃ¡ch
                    amount_str = amount_str.replace(',', '').replace('.', '')
                    
                    # Chuyá»ƒn Ä‘á»•i thÃ nh sá»‘
                    if amount_str.isdigit():
                        amount = int(amount_str)
                        
                        # Chuyá»ƒn Ä‘á»•i Ä‘Æ¡n vá»‹
                        if 'triá»‡u' in price_text.lower() or 'tr' in price_text.lower():
                            amount *= 1000000
                        elif 'nghÃ¬n' in price_text.lower() or 'k' in price_text.lower():
                            amount *= 1000
                        
                        prices.append(amount)
                        
                except (IndexError, ValueError):
                    continue
                    
        except Exception as e:
            logger.error(f"Error extracting prices: {e}")
        
        return prices
    
    @staticmethod
    def apply_filters(tours_db: Dict[int, Any], filters: 'FilterSet') -> List[int]:
        """Ãp dá»¥ng filter lÃªn database - FIXED VERSION"""
        matched_tours = []
        
        try:
            for idx, tour in tours_db.items():
                matches = True
                
                # FIX: Kiá»ƒm tra tour há»£p lá»‡
                if not tour.name or 'ná»™i dung vÄƒn hÃ³a' in tour.name.lower():
                    continue
                
                # Location filter
                if hasattr(filters, 'location') and filters.location:
                    if not tour.location or filters.location.lower() not in tour.location.lower():
                        matches = False
                
                # Group type filter
                if hasattr(filters, 'group_type') and filters.group_type:
                    tour_tags = [tag.lower() for tag in (tour.tags or [])]
                    tour_text = f"{tour.name or ''} {tour.summary or ''}".lower()
                    
                    if filters.group_type == 'family':
                        if not any('family' in tag for tag in tour_tags):
                            matches = False
                    elif filters.group_type == 'senior':
                        if not any('senior' in tag or 'accessible' in tag for tag in tour_tags):
                            matches = False
                    elif filters.group_type == 'friends':
                        if not any('friends' in tag or 'group' in tag for tag in tour_tags):
                            matches = False
                
                # Budget filter - FIXED
                if hasattr(filters, 'budget') and filters.budget and tour.price:
                    price_value = _extract_price_value(tour.price)
                    
                    if price_value:
                        if filters.budget == 'low' and price_value >= 1000000:
                            matches = False
                        elif filters.budget == 'medium' and (price_value < 1000000 or price_value > 2500000):
                            matches = False
                        elif filters.budget == 'high' and price_value <= 2500000:
                            matches = False
                
                if matches:
                    matched_tours.append(idx)
                    
        except Exception as e:
            logger.error(f"Error applying filters: {e}")
            return []
        
        return matched_tours


# ================== FIXED CACHE SYSTEM ==================

@dataclass
class CacheEntry:
    """Cache entry vá»›i cÃ¡c field Ä‘Ãºng - FIXED VERSION"""
    key: str
    value: Any
    created_at: datetime
    ttl_seconds: int = 300  # 5 phÃºt máº·c Ä‘á»‹nh
    last_accessed: Optional[datetime] = None
    access_count: int = 0  # ThÃªm field bá»‹ thiáº¿u
    
    def __post_init__(self):
        """Khá»Ÿi táº¡o máº·c Ä‘á»‹nh cho last_accessed"""
        if self.last_accessed is None:
            self.last_accessed = self.created_at


class CacheSystem:
    @staticmethod
    def set(key: str, value: Any, expiry: int = 300) -> None:
        """LÆ°u value vÃ o cache - FIXED VERSION"""
        try:
            cache_entry = CacheEntry(
                key=key,
                value=value,
                created_at=datetime.utcnow(),
                ttl_seconds=expiry,
                last_accessed=datetime.utcnow(),
                access_count=0  # Khá»Ÿi táº¡o Ä‘Ãºng
            )
            
            # LÆ°u vÃ o cache storage
            cache_storage[key] = cache_entry
            
            # Cleanup cache cÅ©
            CacheSystem._cleanup()
            
        except Exception as e:
            logger.error(f"Cache set error: {e}")
    
    @staticmethod
    def get_cache_key(user_message: str, context_hash: str) -> str:
        """Táº¡o cache key - FIXED VERSION"""
        message_hash = hashlib.md5(user_message.encode()).hexdigest()[:8]
        return f"chat:{message_hash}:{context_hash}"


def _prepare_enhanced_llm_prompt(user_message, search_results, context_info, tours_db):
    """Chuáº©n bá»‹ prompt cho LLM"""
    return f"""Báº¡n lÃ  trá»£ lÃ½ AI cá»§a Ruby Wings Travel. Tráº£ lá»i cÃ¢u há»i: "{user_message}"

Tráº£ lá»i chuyÃªn nghiá»‡p, thÃ¢n thiá»‡n vÃ  há»¯u Ã­ch. LuÃ´n káº¿t thÃºc báº±ng lá»i má»i liÃªn há»‡ hotline 0332510486."""


def _generate_enhanced_fallback_response(user_message, search_results, tour_indices, tours_db):
    """Táº¡o fallback response"""
    return "Cáº£m Æ¡n cÃ¢u há»i cá»§a báº¡n. Äá»ƒ Ä‘Æ°á»£c tÆ° váº¥n chi tiáº¿t vá» tour Ruby Wings, vui lÃ²ng liÃªn há»‡ hotline 0332510486."










# ThÃªm cÃ¡c hÃ m helper má»›i vÃ o cÃ¡c module tÆ°Æ¡ng á»©ng
# =========== OTHER ENDPOINTS ===========
@app.route("/")
def home():
    """Home endpoint"""
    return jsonify({
        "status": "ok",
        "version": "4.0",
        "upgrades": UpgradeFlags.get_all_flags(),
        "services": {
            "openai": "available" if client else "unavailable",
            "faiss": "available" if HAS_FAISS else "unavailable",
            "google_sheets": "available" if HAS_GOOGLE_SHEETS else "unavailable",
            "meta_capi": "available" if HAS_META_CAPI else "unavailable",
        },
        "counts": {
            "tours": len(TOURS_DB),
            "passages": len(FLAT_TEXTS),
            "tour_names": len(TOUR_NAME_TO_INDEX),
        }
    })

@app.route("/reindex", methods=["POST"])
def reindex():
    """Rebuild index endpoint"""
    secret = request.headers.get("X-RBW-ADMIN", "")
    if not secret and os.environ.get("RBW_ALLOW_REINDEX", "") != "1":
        return jsonify({"error": "reindex not allowed"}), 403
    
    load_knowledge()
    build_index(force_rebuild=True)
    
    return jsonify({
        "ok": True,
        "count": len(FLAT_TEXTS),
        "tours": len(TOURS_DB)
    })

# =========== GOOGLE SHEETS INTEGRATION ===========
_gsheet_client = None
_gsheet_client_lock = threading.Lock()

def get_gspread_client(force_refresh: bool = False):
    """Get Google Sheets client"""
    global _gsheet_client
    
    if not GOOGLE_SERVICE_ACCOUNT_JSON:
        logger.error("GOOGLE_SERVICE_ACCOUNT_JSON not set")
        return None
    
    with _gsheet_client_lock:
        if _gsheet_client is not None and not force_refresh:
            return _gsheet_client
        
        try:
            info = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
            scopes = [
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/drive",
            ]
            creds = Credentials.from_service_account_info(info, scopes=scopes)
            _gsheet_client = gspread.authorize(creds)
            logger.info("âœ… Google Sheets client initialized")
            return _gsheet_client
        except Exception as e:
            logger.error(f"âŒ Google Sheets client failed: {e}")
            return None

@app.route('/api/save-lead', methods=['POST', 'OPTIONS'])
def save_lead():
    """Save lead from form submission - Äáº¦Y Äá»¦ 9 TRÆ¯á»œNG (A-I)"""
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200
    
    try:
        data = request.get_json() or {}
        
        # Extract data
        phone = data.get('phone', '').strip()
        name = data.get('name', '').strip()
        email = data.get('email', '').strip()
        tour_interest = data.get('tour_interest', '').strip()
        page_url = data.get('page_url', '').strip()
        note = data.get('note', '').strip()
        
        if not phone:
            return jsonify({'error': 'Phone number is required'}), 400
        
        # Clean phone
        phone_clean = re.sub(r'[^\d+]', '', phone)
        
        # Validate phone
        if not re.match(r'^(0|\+?84)\d{9,10}$', phone_clean):
            return jsonify({'error': 'Invalid phone number format'}), 400
        
        # Timestamp
        timestamp = datetime.now().isoformat()
        
        # Create lead data
        lead_data = {
            'timestamp': timestamp,
            'phone': phone_clean,
            'name': name,
            'email': email,
            'tour_interest': tour_interest,
            'page_url': page_url,
            'note': note,
            'source': 'Lead Form'
        }
        
        # Send to Meta CAPI
        if ENABLE_META_CAPI_CALL and HAS_META_CAPI:
            try:
                result = send_meta_lead(
                    request,
                    phone=phone_clean,
                    contact_name=name,
                    email=email,
                    content_name=f"Tour: {tour_interest}" if tour_interest else "General Inquiry",
                    value=200000,
                    currency="VND"
                )
                increment_stat('meta_capi_calls')
                logger.info(f"âœ… Form lead sent to Meta CAPI: {phone_clean[:4]}***")
                if DEBUG and HAS_META_CAPI:
                    logger.debug(f"Meta CAPI result: {result}")
            except Exception as e:
                increment_stat('meta_capi_errors')
                logger.error(f"Meta CAPI error: {e}")
        
        # Save to Google Sheets - Äáº¦Y Äá»¦ 9 TRÆ¯á»œNG (A-I)
        if ENABLE_GOOGLE_SHEETS:
            try:
                import gspread
                from google.oauth2.service_account import Credentials
                
                if GOOGLE_SERVICE_ACCOUNT_JSON and GOOGLE_SHEET_ID:
                    creds_json = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
                    creds = Credentials.from_service_account_info(
                        creds_json,
                        scopes=['https://www.googleapis.com/auth/spreadsheets']
                    )
                    
                    gc = gspread.authorize(creds)
                    sh = gc.open_by_key(GOOGLE_SHEET_ID)
                    ws = sh.worksheet(GOOGLE_SHEET_NAME)
                    
                    # ÄÃšng 9 TRÆ¯á»œNG THEO THá»¨ Tá»° A-I:
                    # A: created_at (timestamp)
                    # B: source_channel
                    # C: action_type
                    # D: page_url
                    # E: contact_name
                    # F: phone
                    # G: service_interest
                    # H: note
                    # I: raw_status
                    row = [
                        timestamp,                          # A: created_at
                        'Website - Lead Form',              # B: source_channel
                        'Form Submission',                  # C: action_type
                        page_url or '',                     # D: page_url
                        name or '',                         # E: contact_name
                        phone_clean,                        # F: phone
                        tour_interest or '',                # G: service_interest
                        note or email or '',                # H: note (dÃ¹ng email náº¿u khÃ´ng cÃ³ note)
                        'New'                               # I: raw_status
                    ]
                    
                    ws.append_row(row)
                    logger.info("âœ… Form lead saved to Google Sheets (9 fields)")
            except Exception as e:
                logger.error(f"Google Sheets error: {e}")
        
        # Fallback storage
        if ENABLE_FALLBACK_STORAGE:
            try:
                if os.path.exists(FALLBACK_STORAGE_PATH):
                    with open(FALLBACK_STORAGE_PATH, 'r', encoding='utf-8') as f:
                        leads = json.load(f)
                else:
                    leads = []
                
                leads.append(lead_data)
                leads = leads[-1000:]
                
                with open(FALLBACK_STORAGE_PATH, 'w', encoding='utf-8') as f:
                    json.dump(leads, f, ensure_ascii=False, indent=2)
                
                logger.info("âœ… Form lead saved to fallback storage")
            except Exception as e:
                logger.error(f"Fallback storage error: {e}")
        
        # Update stats
        increment_stat('leads')
        
        return jsonify({
            'success': True,
            'message': 'Lead Ä‘Ã£ Ä‘Æ°á»£c lÆ°u! Äá»™i ngÅ© Ruby Wings sáº½ liÃªn há»‡ sá»›m nháº¥t. ðŸ“ž',
            'data': {
                'phone': phone_clean[:3] + '***' + phone_clean[-2:],
                'timestamp': timestamp
            }
        })
        
    except Exception as e:
        logger.error(f"âŒ Save lead error: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/call-button', methods=['POST', 'OPTIONS'])
def call_button():
    """Track call button click"""
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200
    
    try:
        data = request.get_json() or {}
        
        page_url = data.get('page_url', '')
        call_type = data.get('call_type', 'regular')
        
        # Send to Meta CAPI
        if ENABLE_META_CAPI_CALL and HAS_META_CAPI:
            try:
                result = send_meta_call_button(
                    request,
                    page_url=page_url,
                    call_type=call_type,
                    button_location='fixed_bottom_left',
                    button_text='Gá»i ngay'
                )
                increment_stat('meta_capi_calls')
                logger.info(f"ðŸ“ž Call button tracked: {call_type}")
                if DEBUG and HAS_META_CAPI:
                    logger.debug(f"Meta CAPI result: {result}")
            except Exception as e:
                increment_stat('meta_capi_errors')
                logger.error(f"Meta CAPI call error: {e}")
        
        return jsonify({
            'success': True,
            'message': 'Call tracked',
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Call button error: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500


@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    try:
        return jsonify({
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "services": {
                "chatbot": "running",
                "openai": "available" if client else "unavailable",
                "faiss": "available" if INDEX else "unavailable",
                "tours_db": len(TOURS_DB),
                "upgrades": {k: v for k, v in UpgradeFlags.get_all_flags().items() 
                           if k.startswith("UPGRADE_")}
            },
            "memory_profile": {
                "ram_profile": RAM_PROFILE,
                "is_low_ram": IS_LOW_RAM,
                "is_high_ram": IS_HIGH_RAM,
                "tour_count": len(TOURS_DB),
                "context_count": len(SESSION_CONTEXTS)
            }
        })
    except Exception as e:
        return jsonify({
            "status": "unhealthy",
            "error": str(e)
        }), 500

# =========== INITIALIZATION ===========
def initialize_app():
    """Initialize the application"""
    logger.info("ðŸš€ Starting Ruby Wings Chatbot v4.0 (Dataclass Rewrite)...")
    
    # Apply memory optimizations
    optimize_for_memory_profile()
    
    # Load knowledge base
    load_knowledge()
    
    # Load or build tours database
    if os.path.exists(FAISS_MAPPING_PATH):
        try:
            with open(FAISS_MAPPING_PATH, 'r', encoding='utf-8') as f:
                MAPPING[:] = json.load(f)
            FLAT_TEXTS[:] = [m.get('text', '') for m in MAPPING]
            logger.info(f"ðŸ“ Loaded {len(MAPPING)} mappings from disk")
        except Exception as e:
            logger.error(f"Failed to load mappings: {e}")
    
    # Build tour databases
    index_tour_names()
    build_tours_db()
    
    # Build index in background
    def build_index_background():
        time.sleep(2)
        success = build_index(force_rebuild=False)
        if success:
            logger.info("âœ… Index ready")
        else:
            logger.warning("âš ï¸ Index building failed")
    
    threading.Thread(target=build_index_background, daemon=True).start()
    
    # Initialize Google Sheets client
    if ENABLE_GOOGLE_SHEETS:
        threading.Thread(target=get_gspread_client, daemon=True).start()
    
    # Log active upgrades
    active_upgrades = [name for name, enabled in UpgradeFlags.get_all_flags().items() 
                      if enabled and name.startswith("UPGRADE_")]
    logger.info(f"ðŸ”§ Active upgrades: {len(active_upgrades)}")
    for upgrade in active_upgrades:
        logger.info(f"   â€¢ {upgrade}")
    
    # Log memory profile
    logger.info(f"ðŸ§  Memory Profile: {RAM_PROFILE}MB | Low RAM: {IS_LOW_RAM} | High RAM: {IS_HIGH_RAM}")
    logger.info(f"ðŸ“Š Tours Database: {len(TOURS_DB)} tours loaded")
    
    logger.info("âœ… Application initialized successfully with dataclasses")

# =========== APPLICATION START ===========
if __name__ == "__main__":
    initialize_app()
    
    # Save mappings if not exists
    if MAPPING and not os.path.exists(FAISS_MAPPING_PATH):
        try:
            with open(FAISS_MAPPING_PATH, 'w', encoding='utf-8') as f:
                json.dump(MAPPING, f, ensure_ascii=False, indent=2)
            logger.info(f"ðŸ’¾ Saved mappings to {FAISS_MAPPING_PATH}")
        except Exception as e:
            logger.error(f"Failed to save mappings: {e}")
    
    # Start server
    logger.info(f"ðŸŒ Starting server on {HOST}:{PORT}")
    app.run(host=HOST, port=PORT, debug=DEBUG, threaded=True)

else:
    # For WSGI
    initialize_app()