def safe_validate(reply):
    
    try:
        if not isinstance(reply, dict):
            return reply
        # Only validate when tour is selected
        if not reply.get("tour_name"):
            return reply
        return AutoValidator.validate_response(reply)
    except Exception as e:
        try:
            reply.setdefault("warnings", []).append(str(e))
        except:
            pass
        return reply
from meta_param_builder import MetaParamService


# app.py - Ruby Wings Chatbot v4.0 (Complete Rewrite with Dataclasses)
# =========== IMPORTS ===========
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("ruby-wings")
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
import json
import threading
import logging
import re
import unicodedata
import traceback
import hashlib
import time
from typing import List, Dict, Tuple, Any, Optional
from dataclasses import dataclass, field
# =========== DATACLASS DEFINITIONS ===========
@dataclass
class Tour:
    """Tour dataclass with all required fields"""
    index: int = 0
    name: str = ""
    summary: str = ""
    location: str = ""
    duration: str = ""
    price: str = ""
    includes: List[str] = field(default_factory=list)
    notes: str = ""
    style: str = ""
    transport: str = ""
    accommodation: str = ""
    meals: str = ""
    tags: List[str] = field(default_factory=list)
    event_support: str = ""
    
    def __str__(self):
        return f"Tour({self.name})"
from common_utils import flatten_json

import random
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    print("‚ùå NumPy not installed!")
    sys.exit(1)
from functools import lru_cache, wraps
from typing import List, Tuple, Dict, Optional, Any, Set, Union, Callable
from datetime import datetime, timedelta
from collections import defaultdict, deque
from difflib import SequenceMatcher
from enum import Enum
# Try to import numpy with detailed error handling
try:
    import numpy as np
    NUMPY_AVAILABLE = True
    logger.info("‚úÖ NumPy available")
except ImportError as e:
    logger.error(f"‚ùå NumPy import failed: {e}")
    # Create a minimal numpy-like fallback for basic operations
    class NumpyFallback:
        def __init__(self):
            self.float32 = float
            self.int64 = int
            
        def array(self, data, dtype=None):
            # Simple list wrapper
            class SimpleArray:
                def __init__(self, data):
                    self.data = list(data)
                    self.shape = (len(data),) if isinstance(data[0], (int, float)) else (len(data), len(data[0]))
                
                def astype(self, dtype):
                    return self
                
                def reshape(self, shape):
                    return self
                
                def __getitem__(self, idx):
                    return self.data[idx]
                
                def __len__(self):
                    return len(self.data)
            
            return SimpleArray(data)
        
        def empty(self, shape, dtype):
            if len(shape) == 1:
                return [0.0] * shape[0]
            else:
                return [[0.0] * shape[1] for _ in range(shape[0])]
        
        def vstack(self, arrays):
            result = []
            for arr in arrays:
                if hasattr(arr, 'data'):
                    result.extend(arr.data)
                else:
                    result.extend(arr)
            return result
        
        def load(self, path):
            # Mock load function
            class MockNpz:
                def __init__(self):
                    self.files = ['mat']
                
                def __getitem__(self, key):
                    if key == 'mat':
                        # Return empty array
                        return self.array([[0.0]])
                    return None
            
            return MockNpz()
        
        def savez_compressed(self, path, **kwargs):
            # Mock save function
            logger.warning(f"‚ö†Ô∏è NumPy fallback: Mock saving to {path}")
            return None
    
    np = NumpyFallback()
    NUMPY_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Using NumPy fallback - limited functionality")
from flask import Flask, request, jsonify, g
from flask_cors import CORS

# =========== ENTITY IMPORTS ===========
from entities import (
    QuestionType,
    ConversationState,
    PriceLevel,
    DurationType,
    Tour,
    UserProfile,
    SearchResult,
    ConversationContext,
    FilterSet,
    LLMRequest,
    ChatResponse,
    LeadData,
    CacheEntry,
    EnhancedJSONEncoder
)

# =========== CONFIGURATION ===========
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ruby_wings.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("rbw_v4")

# =========== IMPORTS WITH FALLBACKS ===========
HAS_FAISS = False
try:
    import faiss
    HAS_FAISS = True
    logger.info("‚úÖ FAISS available")
except ImportError:
    logger.warning("‚ö†Ô∏è FAISS not available, using numpy fallback")

HAS_OPENAI = False
client = None
try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    logger.warning("‚ö†Ô∏è OpenAI not available, using fallback responses")

# Google Sheets
try:
    import gspread
    from google.oauth2.service_account import Credentials
    from google.auth.exceptions import GoogleAuthError
    from gspread.exceptions import APIError, SpreadsheetNotFound, WorksheetNotFound
    HAS_GOOGLE_SHEETS = True
except ImportError:
    HAS_GOOGLE_SHEETS = False
    logger.warning("‚ö†Ô∏è Google Sheets not available")

# ===== META CAPI FLAGS =====
ENABLE_META_CAPI_LEAD = os.getenv("ENABLE_META_CAPI_LEAD", "false").lower() == "true"

# ===== META CAPI IMPORT =====
try:
    from meta_capi import send_meta_pageview, send_meta_lead
    HAS_META_CAPI = True
    logger.info("‚úÖ Meta CAPI available")
except Exception as e:
    HAS_META_CAPI = False
    logger.error(f"‚ùå Meta CAPI init failed: {e}")





# =========== ENVIRONMENT VARIABLES ===========
# Memory Profile
RAM_PROFILE = os.environ.get("RAM_PROFILE", "512").strip()
IS_LOW_RAM = RAM_PROFILE == "512"
IS_HIGH_RAM = RAM_PROFILE == "2048"

# Core API Keys
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "").strip()
OPENAI_BASE_URL = os.environ.get("OPENAI_BASE_URL", "").strip()
GOOGLE_SERVICE_ACCOUNT_JSON = os.environ.get("GOOGLE_SERVICE_ACCOUNT_JSON", "").strip()

# Knowledge & Index
KNOWLEDGE_PATH = os.environ.get("KNOWLEDGE_PATH", "knowledge.json")
FAISS_INDEX_PATH = os.environ.get("FAISS_INDEX_PATH", "faiss_index.bin")
FAISS_MAPPING_PATH = os.environ.get("FAISS_MAPPING_PATH", "faiss_mapping.json")
FALLBACK_VECTORS_PATH = os.environ.get("FALLBACK_VECTORS_PATH", "vectors.npz")

# Models
EMBEDDING_MODEL = os.environ.get("EMBEDDING_MODEL", "text-embedding-3-small")
CHAT_MODEL = os.environ.get("CHAT_MODEL", "gpt-4o-mini")
TOP_K = int(os.environ.get("TOP_K", "5"))

# FAISS
FAISS_ENABLED = os.environ.get("FAISS_ENABLED", "true").lower() in ("1", "true", "yes") and not IS_LOW_RAM

# Google Sheets
GOOGLE_SHEET_ID = os.environ.get("GOOGLE_SHEET_ID", "1SdVbwkuxb8l1meEW--ddyfh4WmUvSXXMOPQ5bCyPkdk")
GOOGLE_SHEET_NAME = os.environ.get("GOOGLE_SHEET_NAME", "RBW_Lead_Raw_Inbox")
ENABLE_GOOGLE_SHEETS = os.environ.get("ENABLE_GOOGLE_SHEETS", "true").lower() in ("1", "true", "yes")

# Storage
ENABLE_FALLBACK_STORAGE = os.environ.get("ENABLE_FALLBACK_STORAGE", "true").lower() in ("1", "true", "yes")
FALLBACK_STORAGE_PATH = os.environ.get("FALLBACK_STORAGE_PATH", "leads_fallback.json")

# Meta CAPI
META_CAPI_TOKEN = os.environ.get("META_CAPI_TOKEN", "").strip()
META_PIXEL_ID = os.environ.get("META_PIXEL_ID", "").strip()
META_CAPI_ENDPOINT = os.environ.get("META_CAPI_ENDPOINT", "https://graph.facebook.com/v17.0/")
ENABLE_META_CAPI_CALL = os.environ.get("ENABLE_META_CAPI_CALL", "true").lower() in ("1", "true", "yes")

# Server
FLASK_ENV = os.environ.get("FLASK_ENV", "production")
DEBUG = os.environ.get("DEBUG", "false").lower() in ("1", "true", "yes")
SECRET_KEY = os.environ.get("SECRET_KEY", "ruby-wings-secret-key-2024")
CORS_ORIGINS = os.environ.get("CORS_ORIGINS", "https://www.rubywings.vn,http://localhost:3000").split(",")
HOST = os.environ.get("HOST", "0.0.0.0")
PORT = int(os.environ.get("PORT", "10000"))

# =========== STATS TRACKING (FIX L·ªñI STATE) ===========
# Th√™m global stats tracking system
STATS_LOCK = threading.Lock()
GLOBAL_STATS = {
    'meta_capi_calls': 0,
    'meta_capi_errors': 0,
    'leads': 0,
    'errors': 0,
    'total_requests': 0
}

def increment_stat(stat_name: str, amount: int = 1):
    """Thread-safe stat increment"""
    with STATS_LOCK:
        if stat_name in GLOBAL_STATS:
            GLOBAL_STATS[stat_name] += amount
        else:
            GLOBAL_STATS[stat_name] = amount

def get_stats() -> dict:
    """Get current stats"""
    with STATS_LOCK:
        return GLOBAL_STATS.copy()
    def resolve_best_tour_indices(user_message: str, top_k: int = 3) -> List[int]:
        """Resolve tour by exact-normalized match first, then token overlap score."""
        msg_norm = normalize_tour_key(user_message)
        if not msg_norm:
            return []

        scored = []
        for norm_name, idx in TOUR_NAME_TO_INDEX.items():
            name_norm = normalize_tour_key(norm_name)
            if not name_norm:
                continue

            # Exact/contains boost
            score = 0
            if name_norm in msg_norm:
                score += 100

            # Token overlap
            msg_tokens = set(msg_norm.split())
            name_tokens = set(name_norm.split())
            overlap = len(msg_tokens.intersection(name_tokens))
            score += overlap * 5

            if score > 0:
                scored.append((idx, score))

        scored.sort(key=lambda x: x[1], reverse=True)

        ordered = []
        seen = set()
        for idx, _ in scored:
            if idx not in seen:
                seen.add(idx)
                ordered.append(idx)
            if len(ordered) >= top_k:
                break
        return ordered

# =========== UPGRADE FEATURE FLAGS ===========
def format_tour_program_response(tour) -> str:
    """Build detailed response from knowledge fields (12 fields + event_support)."""
    if not tour:
        return ""

    name = getattr(tour, 'name', '') or 'Tour'
    summary = getattr(tour, 'summary', '') or ''
    location = getattr(tour, 'location', '') or ''
    duration = getattr(tour, 'duration', '') or ''
    price = getattr(tour, 'price', '') or ''
    includes = getattr(tour, 'includes', []) or []
    notes = getattr(tour, 'notes', '') or ''
    style = getattr(tour, 'style', '') or ''
    transport = getattr(tour, 'transport', '') or ''
    accommodation = getattr(tour, 'accommodation', '') or ''
    meals = getattr(tour, 'meals', '') or ''
    event_support = getattr(tour, 'event_support', '') or ''

    lines = [f"üìò **CH∆Ø∆†NG TR√åNH: {name}**"]
    if summary:
        lines.append(f"- T·ªïng quan: {summary}")
    if location:
        lines.append(f"- ƒê·ªãa ƒëi·ªÉm: {location}")
    if duration:
        lines.append(f"- Th·ªùi l∆∞·ª£ng: {duration}")
    if price:
        lines.append(f"- Gi√°: {price}")
    if style:
        lines.append(f"- Phong c√°ch: {style}")
    if transport:
        lines.append(f"- Ph∆∞∆°ng ti·ªán: {transport}")
    if accommodation:
        lines.append(f"- L∆∞u tr√∫: {accommodation}")
    if meals:
        lines.append(f"- B·ªØa ƒÉn: {meals}")

    if includes:
        lines.append("- L·ªãch tr√¨nh/bao g·ªìm:")
        for item in includes[:12]:
            lines.append(f"  ‚Ä¢ {item}")

    if notes:
        lines.append(f"- L∆∞u √Ω: {notes}")
    if event_support:
        lines.append(f"- H·ªó tr·ª£ ƒëo√†n: {event_support}")

    lines.append("üìû Hotline: 0332510486")
    return "\n".join(lines)

# ================== TOUR FIELD FORMATTERS ==================
def format_tour_price_response(tour):
    """Format price information for a tour"""
    logger.info(f"üîé format_tour_price_response called for tour index: {getattr(tour, 'index', 'N/A')}, name: '{getattr(tour, 'name', 'N/A')}'")
    price_value = getattr(tour, 'price', None)
    logger.info(f"   price attribute exists: {hasattr(tour, 'price')}, value: '{price_value}'")
    
    if hasattr(tour, 'price') and tour.price:
        logger.info(f"‚úÖ Price found, returning formatted response")
        return f"üí∞ **GI√Å TOUR: {tour.name}** üí∞\n\n{tour.price}"
    
    logger.warning(f"‚ö†Ô∏è No price data for tour: {getattr(tour, 'name', 'Unknown')}")
    return None

def format_tour_location_response(tour):
    """Format location information for a tour"""
    if hasattr(tour, 'location') and tour.location:
        return f"üìç **ƒê·ªäA ƒêI·ªÇM: {tour.name}** üìç\n\n{tour.location}"
    return None

def format_tour_duration_response(tour):
    """Format duration information for a tour"""
    if hasattr(tour, 'duration') and tour.duration:
        return f"‚è±Ô∏è **TH·ªúI GIAN: {tour.name}** ‚è±Ô∏è\n\n{tour.duration}"
    return None

def format_tour_includes_response(tour):
    """Format includes (bao g·ªìm) information for a tour"""
    if hasattr(tour, 'includes') and tour.includes:
        includes_list = tour.includes if isinstance(tour.includes, list) else [tour.includes]
        formatted = f"üìã **D·ªäCH V·ª§ BAO G·ªíM - {tour.name}** üìã\n\n"
        for item in includes_list:
            formatted += f"‚Ä¢ {item}\n"
        return formatted
    return None

def format_tour_notes_response(tour):
    """Format notes (l∆∞u √Ω) information for a tour"""
    if hasattr(tour, 'notes') and tour.notes:
        return f"üìå **L∆ØU √ù: {tour.name}** üìå\n\n{tour.notes}"
    return None

def format_tour_style_response(tour):
    """Format style (phong c√°ch) information for a tour"""
    if hasattr(tour, 'style') and tour.style:
        return f"üéØ **PHONG C√ÅCH TOUR: {tour.name}** üéØ\n\n{tour.style}"
    return None

def format_tour_transport_response(tour):
    """Format transport (ph∆∞∆°ng ti·ªán) information for a tour"""
    if hasattr(tour, 'transport') and tour.transport:
        return f"üöê **PH∆Ø∆†NG TI·ªÜN: {tour.name}** üöê\n\n{tour.transport}"
    return None

def format_tour_accommodation_response(tour):
    """Format accommodation (n∆°i ·ªü) information for a tour"""
    if hasattr(tour, 'accommodation') and tour.accommodation:
        return f"üè® **N∆†I ·ªû: {tour.name}** üè®\n\n{tour.accommodation}"
    return None

def format_tour_meals_response(tour):
    """Format meals (b·ªØa ƒÉn) information for a tour"""
    if hasattr(tour, 'meals') and tour.meals:
        return f"üçΩÔ∏è **B·ªÆA ƒÇN: {tour.name}** üçΩÔ∏è\n\n{tour.meals}"
    return None

def format_tour_event_support_response(tour):
    """Format event support (h·ªó tr·ª£ s·ª± ki·ªán) information for a tour"""
    if hasattr(tour, 'event_support') and tour.event_support:
        return f"üé™ **H·ªñ TR·ª¢ S·ª∞ KI·ªÜN: {tour.name}** üé™\n\n{tour.event_support}"
    return None
class UpgradeFlags:
    """Control all 10 upgrades with environment variables"""
    
    @staticmethod
    def get_all_flags():
        return {
            # CORE UPGRADES (Essential fixes)
            "UPGRADE_1_MANDATORY_FILTER": os.environ.get("UPGRADE_1_MANDATORY_FILTER", "true").lower() == "true",
            "UPGRADE_2_DEDUPLICATION": os.environ.get("UPGRADE_2_DEDUPLICATION", "true").lower() == "true",
            "UPGRADE_3_ENHANCED_FIELDS": os.environ.get("UPGRADE_3_ENHANCED_FIELDS", "true").lower() == "true",
            "UPGRADE_4_QUESTION_PIPELINE": os.environ.get("UPGRADE_4_QUESTION_PIPELINE", "true").lower() == "true",
            
            # ADVANCED UPGRADES
            "UPGRADE_5_QUERY_SPLITTER": os.environ.get("UPGRADE_5_QUERY_SPLITTER", "true").lower() == "true",
            "UPGRADE_6_FUZZY_MATCHING": os.environ.get("UPGRADE_6_FUZZY_MATCHING", "true").lower() == "true",
            "UPGRADE_7_STATE_MACHINE": os.environ.get("UPGRADE_7_STATE_MACHINE", "true").lower() == "true",
            "UPGRADE_8_SEMANTIC_ANALYSIS": os.environ.get("UPGRADE_8_SEMANTIC_ANALYSIS", "true").lower() == "true",
            "UPGRADE_9_AUTO_VALIDATION": os.environ.get("UPGRADE_9_AUTO_VALIDATION", "true").lower() == "true",
            "UPGRADE_10_TEMPLATE_SYSTEM": os.environ.get("UPGRADE_10_TEMPLATE_SYSTEM", "true").lower() == "true",
            
            # PERFORMANCE OPTIONS
            "ENABLE_CACHING": os.environ.get("ENABLE_CACHING", "true").lower() == "true",
            "CACHE_TTL_SECONDS": int(os.environ.get("CACHE_TTL_SECONDS", "300")),
            "ENABLE_QUERY_LOGGING": os.environ.get("ENABLE_QUERY_LOGGING", "true").lower() == "true",
            
            # MEMORY OPTIMIZATION
            "EMBEDDING_CACHE_SIZE": 100 if IS_LOW_RAM else 1000,
            "TOUR_CACHE_ENABLED": not IS_LOW_RAM,
            "PRELOAD_EMBEDDINGS": not IS_LOW_RAM,
        }
    
    @staticmethod
    def is_enabled(upgrade_name: str) -> bool:
        flags = UpgradeFlags.get_all_flags()
        return flags.get(f"UPGRADE_{upgrade_name}", False)

def resolve_best_tour_indices(query, top_k=3):
    """
    T√¨m index c·ªßa tour ph√π h·ª£p nh·∫•t d·ª±a tr√™n query.
    - ∆Øu ti√™n kh·ªõp ch√≠nh x√°c t√™n tour (normalized)
    - N·∫øu kh√¥ng, t√¨m t·ª´ kh√≥a xu·∫•t hi·ªán trong t√™n
    - D√πng fuzzy matching c∆° b·∫£n
    """
    if not query:
        logger.warning("‚ö†Ô∏è resolve_best_tour_indices: empty query")
        return []
    
    normalized_query = normalize_tour_key(query)
    query_words = set(normalized_query.split())
    
    # Debug: log danh s√°ch tour ƒëang c√≥
    logger.info(f"üîç TOUR_NAME_TO_INDEX size: {len(TOUR_NAME_TO_INDEX)}")
    if len(TOUR_NAME_TO_INDEX) == 0:
        logger.error("‚ùå TOUR_NAME_TO_INDEX is EMPTY! Tours may not be loaded correctly.")
    
    scores = []
    for norm_name, idx in TOUR_NAME_TO_INDEX.items():
        score = 0
        # 1. Kh·ªõp ch√≠nh x√°c c·∫£ chu·ªói
        if normalized_query == norm_name:
            score = 100
            logger.debug(f"üéØ Exact match: '{norm_name}' ‚Üí {idx}")
        # 2. Kh·ªõp ch·ª©a chu·ªói (query n·∫±m trong t√™n)
        elif normalized_query in norm_name:
            score = 80
            logger.debug(f"üîó Substring match: '{normalized_query}' in '{norm_name}' ‚Üí {idx}")
        # 3. Kh·ªõp t√™n n·∫±m trong query
        elif norm_name in normalized_query:
            score = 75
            logger.debug(f"üîó Reverse substring: '{norm_name}' in '{normalized_query}' ‚Üí {idx}")
        # 4. Kh·ªõp t·ª´ kh√≥a ri√™ng l·∫ª
        else:
            name_words = set(norm_name.split())
            common = query_words.intersection(name_words)
            if common:
                score = 50 + len(common) * 5
                logger.debug(f"üî§ Word match: {common} ‚Üí '{norm_name}' score {score}")
        
        if score > 0:
            scores.append((score, len(norm_name), idx, norm_name))
    
    # S·∫Øp x·∫øp theo ƒëi·ªÉm gi·∫£m d·∫ßn, ƒë·ªô d√†i t√™n gi·∫£m d·∫ßn
    scores.sort(key=lambda x: (-x[0], -x[1]))
    
    # Log top matches
    if scores:
        logger.info(f"üìä Top matches for '{query}':")
        for i, (score, _, idx, name) in enumerate(scores[:5]):
            logger.info(f"   #{i+1}: {name} (idx={idx}, score={score})")
    else:
        logger.warning(f"‚ö†Ô∏è No matches found for '{query}'")
    
    result = [idx for _, _, idx, _ in scores[:top_k]]
    logger.info(f"üéØ resolve_best_tour_indices('{query}') ‚Üí {result}")
    return result


# =========== FLASK APP CONFIG ===========
app = Flask(__name__)
@app.before_request
def ensure_data_loaded():
    """ƒê·∫£m b·∫£o d·ªØ li·ªáu ƒë∆∞·ª£c t·∫£i tr∆∞·ªõc khi x·ª≠ l√Ω request"""
    global APP_INITIALIZED
    
    if not APP_INITIALIZED:
        try:
            logger.info("üîÑ Kh·ªüi t·∫°o d·ªØ li·ªáu tr∆∞·ªõc request...")
            
            # Ki·ªÉm tra v√† t·∫°o th∆∞ m·ª•c data
            if not os.path.exists("data"):
                os.makedirs("data")
            
            # T·∫£i knowledge base
            load_knowledge()
            
            # Build index n·∫øu c√≥ d·ªØ li·ªáu
            if HAS_FAISS and len(FLAT_TEXTS) > 0:
                build_index()
                logger.info(f"‚úÖ ƒê√£ build FAISS index: {len(FLAT_TEXTS)} passages")
            
            APP_INITIALIZED = True
            logger.info(f"‚úÖ Ho√†n th√†nh kh·ªüi t·∫°o: {len(TOURS_DB)} tours")
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói kh·ªüi t·∫°o: {e}")
            traceback.print_exc()
            # V·∫´n ƒë√°nh d·∫•u ƒë√£ kh·ªüi t·∫°o ƒë·ªÉ kh√¥ng retry
            APP_INITIALIZED = True
app.json_encoder = EnhancedJSONEncoder  # Use custom JSON encoder
CORS(app, origins=CORS_ORIGINS, supports_credentials=True)
from meta_capi import send_meta_pageview

@app.before_request
def track_pageview_once():
    try:
        if request.method != "GET":
            return
        if not request.accept_mimetypes.accept_html:
            return
        if not request.headers.get("X-RW-EVENT-ID"):
            return

        send_meta_pageview(request)

    except Exception:
        pass

# =========== GLOBAL STATE (USING DATACLASSES) ===========
# Initialize OpenAI client
# ==== OpenAI client (SDK 1.x safe, Render compatible) ====
from openai import OpenAI
import httpx
import os

def create_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY is not set")

    # Render-safe HTTP client (no proxies param in OpenAI 1.x)
    http_client = httpx.Client(
        timeout=60.0,
        follow_redirects=True
    )

    return OpenAI(
        api_key=api_key,
        http_client=http_client
    )

# Create global OpenAI client
client = create_openai_client()


# Knowledge base state
KNOW: Dict = {}                      # Raw knowledge.json data
FLAT_TEXTS: List[str] = []           # All text passages for indexing
MAPPING: List[Dict] = []             # Mapping from text to original path
INDEX = None                         # FAISS or numpy index
INDEX_LOCK = threading.Lock()        # Thread safety for index operations

# Tour databases (USING Tour DATACLASS)
TOUR_NAME_TO_INDEX: Dict[str, int] = {}      # Normalized tour name ‚Üí index
TOURS_DB: Dict[int, Tour] = {}               # Structured tour database using Tour objects
TOUR_TAGS: Dict[int, List[str]] = {}         # Auto-generated tags for filtering

# Session management (USING ConversationContext DATACLASS)
SESSION_CONTEXTS: Dict[str, ConversationContext] = {}
SESSION_LOCK = threading.Lock()
SESSION_TIMEOUT = 1800  # 30 minutes

# Cache system
_response_cache: Dict[str, CacheEntry] = {}
_cache_lock = threading.Lock()

# Embedding cache (memory optimized)
_embedding_cache: Dict[str, Tuple[List[float], int]] = {}
_embedding_cache_lock = threading.Lock()
MAX_EMBEDDING_CACHE_SIZE = UpgradeFlags.get_all_flags()["EMBEDDING_CACHE_SIZE"]
# App initialization flag
APP_INITIALIZED = False

# =========== MEMORY OPTIMIZATION FUNCTIONS ===========
def optimize_for_memory_profile():
    """Apply memory optimizations based on RAM profile"""
    flags = UpgradeFlags.get_all_flags()
    
    if IS_LOW_RAM:
        logger.info("üß† Low RAM mode (512MB) - optimizing memory usage")
        # Disable heavy preloading
        global FAISS_ENABLED
        FAISS_ENABLED = False
        
        # Reduce cache sizes
        import functools
        functools.lru_cache(maxsize=128)(embed_text)
        
        # Limit tour loading
        global MAX_TOURS_TO_LOAD
        MAX_TOURS_TO_LOAD = 50
        
    elif IS_HIGH_RAM:
        logger.info("üöÄ High RAM mode (2GB) - enabling all features")
        # Enable all features
        FAISS_ENABLED = HAS_FAISS
        MAX_TOURS_TO_LOAD = 1000
        
        # Increase cache sizes
        import functools
        functools.lru_cache(maxsize=flags["EMBEDDING_CACHE_SIZE"])(embed_text)

# =========== UPGRADE 1: MANDATORY FILTER SYSTEM (DATACLASS COMPATIBLE) ===========
class MandatoryFilterSystem:
    """
    UPGRADE 1: Extract and apply mandatory filters BEFORE semantic search
    """
    
    FILTER_PATTERNS = {
        'duration': [
            (r'(?:th·ªùi gian|m·∫•y ng√†y|bao l√¢u|k√©o d√†i)\s*(?:l√†\s*)?(\d+)\s*(?:ng√†y|ƒë√™m)', 'exact_duration'),
            (r'(\d+)\s*ng√†y\s*(?:v√†\s*)?(\d+)?\s*ƒë√™m', 'days_nights'),
            (r'(\d+)\s*ng√†y\s*(?:tr·ªü l√™n|tr·ªü xu·ªëng)', 'duration_range'),
            (r'(?:tour|h√†nh tr√¨nh)\s*(?:kho·∫£ng|t·∫ßm|kho·∫£ng)?\s*(\d+)\s*ng√†y', 'approx_duration'),
        ],
        
        'price': [
            (r'd∆∞·ªõi\s*(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)', 'max_price'),
            (r'tr√™n\s*(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)', 'min_price'),
            (r'kho·∫£ng\s*(\d[\d,\.]*)\s*(?:ƒë·∫øn|-)\s*(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)', 'price_range'),
            (r'gi√°\s*(?:t·ª´\s*)?(\d[\d,\.]*)\s*(?:ƒë·∫øn|-|t·ªõi)\s*(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)', 'price_range'),
            (r'(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)\s*tr·ªü xu·ªëng', 'max_price'),
            (r'(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)\s*tr·ªü l√™n', 'min_price'),
        ],
        
        'location': [
            (r'(?:·ªü|t·∫°i|v·ªÅ|ƒë·∫øn|thƒÉm)\s+([^.,!?\n]+?)(?:\s|$|\.|,|!|\?)', 'location'),
            (r'(?:ƒëi·ªÉm ƒë·∫øn|ƒë·ªãa ƒëi·ªÉm|n∆°i|v√πng)\s+(?:l√†\s*)?([^.,!?\n]+)', 'location'),
            (r'(?:quanh|g·∫ßn|khu v·ª±c)\s+([^.,!?\n]+)', 'near_location'),
        ],
        
        'date_time': [
            (r'(?:th√°ng|v√†o)\s*(\d{1,2})', 'month'),
            (r'(?:cu·ªëi tu·∫ßn|weekend)', 'weekend'),
            (r'(?:d·ªãp|l·ªÖ|t·∫øt)\s+([^.,!?\n]+)', 'holiday'),
        ],
        
        'group_type': [
            (r'(?:gia ƒë√¨nh|family)', 'family'),
            (r'(?:c·∫∑p ƒë√¥i|couple|ƒë√¥i l·ª©a)', 'couple'),
            (r'(?:nh√≥m b·∫°n|b·∫°n b√®|friends)', 'friends'),
            (r'(?:c√¥ng ty|doanh nghi·ªáp|team building)', 'corporate'),
            (r'(?:m·ªôt m√¨nh|ƒëi l·∫ª|solo)', 'solo'),
        ],
    }
    
    @staticmethod
    def extract_filters(message: str) -> FilterSet:
        """
        Extract ALL mandatory filters from user message
        """
        filters = FilterSet()
        
        if not message:
            return filters
        
        message_lower = message.lower()
        
        # 1. DURATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['duration']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'exact_duration':
                    try:
                        days = int(match.group(1))
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'days_nights':
                    try:
                        days = int(match.group(1))
                        nights = int(match.group(2)) if match.group(2) else days
                        # Store in appropriate fields
                        filters.duration_min = days
                        filters.duration_max = days
                    except (ValueError, IndexError):
                        pass
        
        # 2. PRICE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['price']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                try:
                    if filter_type == 'max_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_max = amount
                            logger.info(f"üí∞ Extracted MAX price filter: {amount} VND")
                    
                    elif filter_type == 'min_price':
                        amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(2))
                        if amount:
                            filters.price_min = amount
                            logger.info(f"üí∞ Extracted MIN price filter: {amount} VND")
                    
                    elif filter_type == 'price_range':
                        min_amount = MandatoryFilterSystem._parse_price(match.group(1), match.group(3))
                        max_amount = MandatoryFilterSystem._parse_price(match.group(2), match.group(3))
                        if min_amount and max_amount:
                            filters.price_min = min_amount
                            filters.price_max = max_amount
                            logger.info(f"üí∞ Extracted PRICE RANGE: {min_amount} - {max_amount} VND")
                
                except (ValueError, IndexError, AttributeError):
                    continue
        
        # 3. LOCATION FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['location']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                location = match.group(1).strip()
                if location and len(location) > 1:
                    if filter_type == 'location':
                        filters.location = location
                    elif filter_type == 'near_location':
                        filters.near_location = location
        
        # 4. DATE/TIME FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['date_time']:
            matches = list(re.finditer(pattern, message_lower))
            for match in matches:
                if filter_type == 'month':
                    try:
                        filters.month = int(match.group(1))
                    except (ValueError, IndexError):
                        pass
                elif filter_type == 'weekend':
                    filters.weekend = True
                elif filter_type == 'holiday':
                    filters.holiday = match.group(1).strip()
        
        # 5. GROUP TYPE FILTERS
        for pattern, filter_type in MandatoryFilterSystem.FILTER_PATTERNS['group_type']:
            if re.search(pattern, message_lower):
                filters.group_type = filter_type
        
        # 6. SPECIAL KEYWORDS
        special_keywords = {
            'r·∫ª': ('price_max', 1500000),
            'gi√° r·∫ª': ('price_max', 1500000),
            'ti·∫øt ki·ªám': ('price_max', 1500000),
            'cao c·∫•p': ('price_min', 3000000),
            'sang tr·ªçng': ('price_min', 3000000),
            'premium': ('price_min', 3000000),
            'ng·∫Øn ng√†y': ('duration_max', 2),
            'd√†i ng√†y': ('duration_min', 3),
        }
        
        for keyword, (filter_key, value) in special_keywords.items():
            if keyword in message_lower:
                if filter_key == 'price_max':
                    filters.price_max = value
                elif filter_key == 'price_min':
                    filters.price_min = value
                elif filter_key == 'duration_max':
                    filters.duration_max = value
                elif filter_key == 'duration_min':
                    filters.duration_min = value
        
        logger.info(f"üéØ Extracted filters: {filters}")
        return filters
    
    @staticmethod
    def _parse_price(amount_str: str, unit: str) -> Optional[int]:
        """Parse price string like '1.5 tri·ªáu' to integer VND"""
        if not amount_str:
            return None
        
        try:
            amount_str = amount_str.replace(',', '').replace('.', '')
            if not amount_str.isdigit():
                return None
            
            amount = int(amount_str)
            
            if unit in ['tri·ªáu', 'tr']:
                return amount * 1000000
            elif unit == 'k':
                return amount * 1000
            elif unit == 'ngh√¨n':
                return amount * 1000
            else:
                return amount if amount > 1000 else amount * 1000
        
        except (ValueError, AttributeError):
            return None
    
    @staticmethod
    def apply_filters(tours_db: Dict[int, Tour], filters: FilterSet) -> List[int]:
        """
        Apply mandatory filters to tour database
        Returns list of tour indices that pass ALL filters
        """
        if filters.is_empty() or not tours_db:
            return list(tours_db.keys())
        
        passing_tours = []
        
        try:
            for tour_idx, tour in tours_db.items():
                passes_all = True
                
                # PRICE FILTERING
                if passes_all and (filters.price_max is not None or filters.price_min is not None):
                    tour_price_text = tour.price or ""
                    if not tour_price_text:
                        if filters.price_max is not None or filters.price_min is not None:
                            passes_all = False
                    else:
                        tour_prices = MandatoryFilterSystem._extract_tour_prices(tour_price_text)
                        if not tour_prices:
                            passes_all = False
                        else:
                            min_tour_price = min(tour_prices)
                            max_tour_price = max(tour_prices)
                            
                            if filters.price_max is not None and min_tour_price > filters.price_max:
                                passes_all = False
                            if filters.price_min is not None and max_tour_price < filters.price_min:
                                passes_all = False
                
                # DURATION FILTERING
                if passes_all and (filters.duration_min is not None or filters.duration_max is not None):
                    duration_text = (tour.duration or "").lower()
                    tour_duration = MandatoryFilterSystem._extract_duration_days(duration_text)
                    
                    if tour_duration is not None:
                        if filters.duration_min is not None and tour_duration < filters.duration_min:
                            passes_all = False
                        if filters.duration_max is not None and tour_duration > filters.duration_max:
                            passes_all = False
                    else:
                        if filters.duration_min is not None or filters.duration_max is not None:
                            passes_all = False
                
                # LOCATION FILTERING
                if passes_all and (filters.location is not None or filters.near_location is not None):
                    tour_location = (tour.location or "").lower()
                    if filters.location is not None:
                        filter_location = filters.location.lower()
                        if filter_location not in tour_location:
                            passes_all = False
                    if filters.near_location is not None:
                        near_location = filters.near_location.lower()
                        if near_location not in tour_location:
                            passes_all = False
                
                if passes_all:
                    passing_tours.append(tour_idx)
            
            logger.info(f"üîç After mandatory filtering: {len(passing_tours)}/{len(tours_db)} tours pass")
        except Exception as e:
            logger.error(f"‚ùå Error in apply_filters: {e}")
            passing_tours = list(tours_db.keys())
        
        return passing_tours
    
    @staticmethod
    def _extract_tour_prices(price_text: str) -> List[int]:
        """Extract price numbers from tour price text"""
        prices = []
        
        number_patterns = [
            r'(\d[\d,\.]+)\s*(?:tri·ªáu|tr)',
            r'(\d[\d,\.]+)\s*(?:k|ngh√¨n)',
            r'(\d[\d,\.]+)\s*(?:ƒë·ªìng|vnƒë|vnd)',
            r'(\d[\d,\.]+)\s*-\s*(\d[\d,\.]+)',
        ]
        
        for pattern in number_patterns:
            matches = re.finditer(pattern, price_text, re.IGNORECASE)
            for match in matches:
                try:
                    for i in range(1, 3):
                        if match.group(i):
                            num_str = match.group(i).replace(',', '').replace('.', '')
                            if num_str.isdigit():
                                num = int(num_str)
                                
                                if 'tri·ªáu' in match.group(0).lower() or 'tr' in match.group(0).lower():
                                    num = num * 1000000
                                elif 'k' in match.group(0).lower() or 'ngh√¨n' in match.group(0).lower():
                                    num = num * 1000
                                
                                prices.append(num)
                except (ValueError, AttributeError):
                    continue
        
        if not prices:
            raw_numbers = re.findall(r'\d[\d,\.]+', price_text)
            for num_str in raw_numbers[:2]:
                try:
                    num_str = num_str.replace(',', '').replace('.', '')
                    if num_str.isdigit():
                        num = int(num_str)
                        if 100 <= num <= 10000:
                            num = num * 1000
                        prices.append(num)
                except ValueError:
                    continue
        
        return prices
    
    @staticmethod
    def _extract_duration_days(duration_text: str) -> Optional[int]:
        """Extract duration in days from text"""
        if not duration_text:
            return None
        
        patterns = [
            r'(\d+)\s*ng√†y',
            r'(\d+)\s*ng√†y\s*\d*\s*ƒë√™m',
            r'(\d+)\s*ƒë√™m',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, duration_text)
            if match:
                try:
                    return int(match.group(1))
                except (ValueError, IndexError):
                    continue
        
        return None

# =========== UPGRADE 2: DEDUPLICATION ENGINE (DATACLASS COMPATIBLE) ===========
class DeduplicationEngine:
    """
    UPGRADE 2: Remove duplicate and highly similar results
    """
    
    SIMILARITY_THRESHOLD = 0.85
    MIN_TEXT_LENGTH = 20
    
    @staticmethod
    def calculate_similarity(text1: str, text2: str) -> float:
        """Calculate text similarity using multiple methods"""
        if not text1 or not text2:
            return 0.0
        
        text1_norm = DeduplicationEngine._normalize_text(text1)
        text2_norm = DeduplicationEngine._normalize_text(text2)
        
        if len(text1_norm) < DeduplicationEngine.MIN_TEXT_LENGTH or len(text2_norm) < DeduplicationEngine.MIN_TEXT_LENGTH:
            return 0.0
        
        seq_ratio = SequenceMatcher(None, text1_norm, text2_norm).ratio()
        
        words1 = set(text1_norm.split())
        words2 = set(text2_norm.split())
        
        if not words1 or not words2:
            jaccard = 0.0
        else:
            intersection = words1.intersection(words2)
            union = words1.union(words2)
            jaccard = len(intersection) / len(union)
        
        prefix_len = min(50, min(len(text1_norm), len(text2_norm)))
        prefix1 = text1_norm[:prefix_len]
        prefix2 = text2_norm[:prefix_len]
        prefix_sim = SequenceMatcher(None, prefix1, prefix2).ratio()
        
        similarity = (seq_ratio * 0.5) + (jaccard * 0.3) + (prefix_sim * 0.2)
        
        return similarity
    
    @staticmethod
    def _normalize_text(text: str) -> str:
        """Normalize text for comparison"""
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        stopwords = {'v√†', 'c·ªßa', 'cho', 'v·ªõi', 't·∫°i', '·ªü', 'n√†y', 'ƒë√≥', 'kia', 'v·ªÅ', 'trong'}
        words = [word for word in text.split() if word not in stopwords]
        
        return ' '.join(words)
    
    @staticmethod
    def deduplicate_passages(passages: List[Tuple[float, Dict]], 
                            similarity_threshold: float = None) -> List[Tuple[float, Dict]]:
        """
        Remove duplicate passages from results
        """
        if len(passages) <= 1:
            return passages
        
        threshold = similarity_threshold or DeduplicationEngine.SIMILARITY_THRESHOLD
        unique_passages = []
        seen_passages = []
        
        sorted_passages = sorted(passages, key=lambda x: x[0], reverse=True)
        
        for score, passage in sorted_passages:
            text = passage.get('text', '').strip()
            path = passage.get('path', '')
            
            if not text or len(text) < DeduplicationEngine.MIN_TEXT_LENGTH:
                unique_passages.append((score, passage))
                continue
            
            is_duplicate = False
            for seen_text, seen_path in seen_passages:
                tour_match1 = re.search(r'tours\[(\d+)\]', path)
                tour_match2 = re.search(r'tours\[(\d+)\]', seen_path)
                
                if tour_match1 and tour_match2:
                    if tour_match1.group(1) == tour_match2.group(1):
                        field1 = path.split('.')[-1] if '.' in path else ''
                        field2 = seen_path.split('.')[-1] if '.' in seen_path else ''
                        if field1 == field2:
                            is_duplicate = True
                            break
                
                similarity = DeduplicationEngine.calculate_similarity(text, seen_text)
                if similarity > threshold:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique_passages.append((score, passage))
                seen_passages.append((text, path))
        
        logger.info(f"üîÑ Deduplication: {len(passages)} ‚Üí {len(unique_passages)} passages")
        return unique_passages
    
    @staticmethod
    def merge_similar_tours(tour_indices: List[int], tours_db: Dict[int, Tour]) -> List[int]:
        """Merge tours that are essentially the same"""
        if len(tour_indices) <= 1:
            return tour_indices
        
        tour_groups = []
        processed = set()
        
        for i, idx1 in enumerate(tour_indices):
            if idx1 in processed:
                continue
            
            group = [idx1]
            tour1 = tours_db.get(idx1)
            name1 = (tour1.name if tour1 else "").strip()
            
            if not name1:
                processed.add(idx1)
                tour_groups.append(group)
                continue
            
            for j, idx2 in enumerate(tour_indices[i+1:], i+1):
                if idx2 in processed:
                    continue
                
                tour2 = tours_db.get(idx2)
                name2 = (tour2.name if tour2 else "").strip()
                
                if not name2:
                    continue
                
                similarity = DeduplicationEngine.calculate_similarity(name1, name2)
                if similarity > 0.9:
                    group.append(idx2)
                    processed.add(idx2)
            
            processed.add(idx1)
            tour_groups.append(group)
        
        best_tours = []
        for group in tour_groups:
            if not group:
                continue
            
            if len(group) == 1:
                best_tours.append(group[0])
                continue
            
            best_score = -1
            best_idx = group[0]
            
            for idx in group:
                tour = tours_db.get(idx)
                if not tour:
                    continue
                
                score = 0
                
                if tour.name:
                    score += 2
                if tour.duration:
                    score += 2
                if tour.location:
                    score += 2
                if tour.price:
                    score += 3
                if tour.includes:
                    score += 2
                if tour.summary:
                    score += 1
                
                for field in [tour.includes, tour.summary, tour.notes]:
                    if isinstance(field, str) and len(field) > 50:
                        score += 1
                    elif isinstance(field, list) and field:
                        score += len(field)
                
                if score > best_score:
                    best_score = score
                    best_idx = idx
            
            best_tours.append(best_idx)
        
        logger.info(f"üîÑ Tour merging: {len(tour_indices)} ‚Üí {len(best_tours)} unique tours")
        return best_tours
def normalize_tour_key(text: str) -> str:
    """Normalize tour name/text for stable matching & dedup."""
    if not text:
        return ""
    import unicodedata, re
    t = unicodedata.normalize("NFKD", str(text).lower())
    t = "".join(ch for ch in t if not unicodedata.combining(ch))
    t = re.sub(r"[^a-z0-9\s]", " ", t)
    t = re.sub(r"\s+", " ", t).strip()
    return t
# =========== UPGRADE 3: ENHANCED FIELD DETECTION (DATACLASS COMPATIBLE) ===========
class EnhancedFieldDetector:
    """
    UPGRADE 3: Better detection of what user is asking for
    """
    
    FIELD_DETECTION_RULES = [
        # TOUR LIST
        {
            "field": "tour_name",
            "patterns": [
                (r'li·ªát k√™.*tour|danh s√°ch.*tour|c√°c tour|c√≥ nh·ªØng tour n√†o', 1.0),
                (r'tour n√†o.*c√≥|tour n√†o.*hi·ªán|tour n√†o.*ƒëang', 0.9),
                (r'k·ªÉ t√™n.*tour|n√™u t√™n.*tour|t√™n c√°c tour', 0.9),
                (r'c√≥ m·∫•y.*tour|bao nhi√™u.*tour|s·ªë l∆∞·ª£ng.*tour', 0.8),
                (r'list tour|show tour|all tour|every tour', 0.8),
            ],
            "keywords": [
                ("li·ªát k√™", 0.9), ("danh s√°ch", 0.9), ("c√°c", 0.7),
                ("t·∫•t c·∫£", 0.8), ("m·ªçi", 0.7), ("m·∫•y", 0.6),
                ("bao nhi√™u", 0.7), ("s·ªë l∆∞·ª£ng", 0.7),
            ]
        },
        
        # PRICE
        {
            "field": "price",
            "patterns": [
                (r'gi√°.*bao nhi√™u|bao nhi√™u ti·ªÅn|chi ph√≠.*bao nhi√™u', 1.0),
                (r'gi√° tour|gi√° c·∫£|gi√° th√†nh|chi ph√≠ tour', 0.9),
                (r'tour.*gi√°.*bao nhi√™u|tour.*bao nhi√™u ti·ªÅn', 0.95),
                (r'ph·∫£i tr·∫£.*bao nhi√™u|t·ªën.*bao nhi√™u|m·∫•t.*bao nhi√™u', 0.8),
                (r'ƒë√≥ng.*bao nhi√™u|thanh to√°n.*bao nhi√™u', 0.8),
            ],
            "keywords": [
                ("gi√°", 0.8), ("ti·ªÅn", 0.7), ("chi ph√≠", 0.8),
                ("ƒë√≥ng", 0.6), ("tr·∫£", 0.6), ("t·ªën", 0.6),
                ("ph√≠", 0.7), ("kinh ph√≠", 0.7), ("t·ªïng chi", 0.7),
            ]
        },
        
        # DURATION
        {
            "field": "duration",
            "patterns": [
                (r'th·ªùi gian.*bao l√¢u|m·∫•y ng√†y.*ƒëi|bao l√¢u.*tour', 1.0),
                (r'tour.*bao nhi√™u ng√†y|m·∫•y ng√†y.*tour', 0.9),
                (r'ƒëi trong.*bao l√¢u|k√©o d√†i.*bao l√¢u', 0.9),
                (r'th·ªùi l∆∞·ª£ng.*bao nhi√™u|th·ªùi gian.*d√†i bao l√¢u', 0.8),
            ],
            "keywords": [
                ("bao l√¢u", 0.9), ("m·∫•y ng√†y", 0.9), ("th·ªùi gian", 0.8),
                ("k√©o d√†i", 0.7), ("th·ªùi l∆∞·ª£ng", 0.8), ("ng√†y", 0.6),
                ("ƒë√™m", 0.6), ("th·ªùi h·∫°n", 0.7),
            ]
        },
        
        # LOCATION
        {
            "field": "location",
            "patterns": [
                (r'·ªü ƒë√¢u|ƒëi ƒë√¢u|ƒë·∫øn ƒë√¢u|t·ªõi ƒë√¢u|thƒÉm quan ƒë√¢u', 1.0),
                (r'ƒë·ªãa ƒëi·ªÉm.*n√†o|n∆°i n√†o|v√πng n√†o|khu v·ª±c n√†o', 0.9),
                (r'tour.*·ªü.*ƒë√¢u|h√†nh tr√¨nh.*ƒëi.*ƒë√¢u', 0.9),
                (r'kh√°m ph√°.*ƒë√¢u|thƒÉm.*ƒë√¢u|gh√©.*ƒë√¢u', 0.8),
            ],
            "keywords": [
                ("·ªü ƒë√¢u", 1.0), ("ƒëi ƒë√¢u", 1.0), ("ƒë·∫øn ƒë√¢u", 0.9),
                ("t·ªõi ƒë√¢u", 0.9), ("ƒë·ªãa ƒëi·ªÉm", 0.8), ("n∆°i", 0.7),
                ("v√πng", 0.7), ("khu v·ª±c", 0.7),
            ]
        },
        
        # SUMMARY (t·ªïng quan)
        {
            "field": "summary",
            "patterns": [
                (r'c√≥ g√¨ hay|c√≥ g√¨ ƒë·∫∑c bi·ªát|c√≥ g√¨ th√∫ v·ªã', 0.9),
                (r'tour n√†y th·∫ø n√†o|h√†nh tr√¨nh ra sao|chuy·∫øn ƒëi nh∆∞ n√†o', 0.8),
                (r'gi·ªõi thi·ªáu.*tour|m√¥ t·∫£.*tour|n√≥i v·ªÅ.*tour', 0.8),
                (r'tour.*c√≥ g√¨|ƒëi.*ƒë∆∞·ª£c g√¨|tr·∫£i nghi·ªám.*g√¨', 0.7),
                (r'ƒëi·ªÉm nh·∫•n.*tour|n·ªïi b·∫≠t.*g√¨|ƒë·∫∑c s·∫Øc.*g√¨', 0.7),
            ],
            "keywords": [
                ("c√≥ g√¨", 0.7), ("th·∫ø n√†o", 0.6), ("ra sao", 0.6),
                ("gi·ªõi thi·ªáu", 0.7), ("m√¥ t·∫£", 0.7), ("n√≥i v·ªÅ", 0.6),
                ("ƒëi·ªÉm nh·∫•n", 0.7), ("n·ªïi b·∫≠t", 0.7), ("ƒë·∫∑c s·∫Øc", 0.7),
            ]
        },
        
        # INCLUDES (bao g·ªìm / l·ªãch tr√¨nh)
        {
            "field": "includes",
            "patterns": [
                (r'l·ªãch tr√¨nh.*chi ti·∫øt|ch∆∞∆°ng tr√¨nh.*chi ti·∫øt', 0.9),
                (r'l√†m g√¨.*tour|ho·∫°t ƒë·ªông.*g√¨|sinh ho·∫°t.*g√¨', 0.8),
                (r'tour.*g·ªìm.*g√¨|bao g·ªìm.*g√¨|g·ªìm nh·ªØng g√¨', 0.8),
                (r'ƒëi ƒë√¢u.*l√†m g√¨|thƒÉm quan.*g√¨|kh√°m ph√°.*g√¨', 0.7),
            ],
            "keywords": [
                ("l·ªãch tr√¨nh", 0.8), ("ch∆∞∆°ng tr√¨nh", 0.8), ("l√†m g√¨", 0.7),
                ("ho·∫°t ƒë·ªông", 0.7), ("sinh ho·∫°t", 0.6), ("g·ªìm", 0.6),
                ("bao g·ªìm", 0.7), ("g·ªìm nh·ªØng", 0.7),
            ]
        },
        
        # NOTES (l∆∞u √Ω)
        {
            "field": "notes",
            "patterns": [
                (r'l∆∞u √Ω.*g√¨|nh·ªØng l∆∞u √Ω|c·∫ßn bi·∫øt|ch√∫ √Ω', 0.9),
                (r'c√≥ l∆∞u √Ω g√¨ kh√¥ng|ƒëi·ªÅu ki·ªán.*g√¨', 0.8),
                (r'kh√¥ng bao g·ªìm|ngo·∫°i l·ªá|lo·∫°i tr·ª´', 0.7),
                (r'ch√≠nh s√°ch h·ªßy|h·ªßy tour|ho√†n ti·ªÅn', 0.8),
            ],
            "keywords": [
                ("l∆∞u √Ω", 0.9), ("ch√∫ √Ω", 0.8), ("c·∫ßn bi·∫øt", 0.8),
                ("kh√¥ng bao g·ªìm", 0.7), ("h·ªßy", 0.6), ("ho√†n", 0.6),
            ]
        },
        
        # STYLE (phong c√°ch)
        {
            "field": "style",
            "patterns": [
                (r'phong c√°ch.*tour|ki·ªÉu.*tour|lo·∫°i h√¨nh.*tour', 0.9),
                (r'tour.*ph√π h·ª£p.*v·ªõi ai|ƒë·ªëi t∆∞·ª£ng.*tour', 0.8),
                (r'ch·ªØa l√†nh|thi·ªÅn|yoga|retreat|tr·∫£i nghi·ªám s√¢u', 0.8),
                (r'nh·ªãp.*ch·∫≠m|ch·∫≠m.*s√¢u', 0.7),
            ],
            "keywords": [
                ("phong c√°ch", 0.9), ("ki·ªÉu", 0.7), ("lo·∫°i h√¨nh", 0.8),
                ("ƒë·ªëi t∆∞·ª£ng", 0.7), ("ai", 0.6), ("thi·ªÅn", 0.8),
                ("ch·ªØa l√†nh", 0.9), ("retreat", 0.9),
            ]
        },
        
        # TRANSPORT (ph∆∞∆°ng ti·ªán)
        {
            "field": "transport",
            "patterns": [
                (r'ph∆∞∆°ng ti·ªán.*g√¨|di chuy·ªÉn.*b·∫±ng g√¨|xe g√¨', 1.0),
                (r'ƒëi l·∫°i.*th·∫ø n√†o|ƒë∆∞a ƒë√≥n.*kh√¥ng', 0.9),
                (r'xe du l·ªãch|xe ƒë·ªùi m·ªõi|√¥ t√¥', 0.8),
            ],
            "keywords": [
                ("xe", 0.7), ("ph∆∞∆°ng ti·ªán", 0.9), ("di chuy·ªÉn", 0.8),
                ("ƒë∆∞a ƒë√≥n", 0.8), ("√¥t√¥", 0.7), ("bus", 0.6),
            ]
        },
        
        # ACCOMMODATION (n∆°i ·ªü)
        {
            "field": "accommodation",
            "patterns": [
                (r'·ªü ƒë√¢u|ng·ªß ·ªü ƒë√¢u|ch·ªó ·ªü|kh√°ch s·∫°n|homestay', 1.0),
                (r'l∆∞u tr√∫.*th·∫ø n√†o|ngh·ªâ ƒë√™m.*·ªü ƒë√¢u', 0.9),
                (r'ph√≤ng.*m·∫•y ng∆∞·ªùi|ti√™u chu·∫©n ph√≤ng', 0.8),
            ],
            "keywords": [
                ("·ªü", 0.6), ("ng·ªß", 0.7), ("ch·ªó ·ªü", 0.9),
                ("kh√°ch s·∫°n", 0.8), ("homestay", 0.8), ("l∆∞u tr√∫", 0.8),
            ]
        },
        
        # MEALS (b·ªØa ƒÉn)
        {
            "field": "meals",
            "patterns": [
                (r'ƒÉn g√¨|b·ªØa ƒÉn|ƒë·ªì ƒÉn|·∫©m th·ª±c|ƒë·∫∑c s·∫£n', 1.0),
                (r'b·ªØa s√°ng|b·ªØa tr∆∞a|b·ªØa t·ªëi|su·∫•t ƒÉn', 0.9),
                (r'c√≥ bao g·ªìm ƒÉn kh√¥ng|ƒÉn u·ªëng.*th·∫ø n√†o', 0.8),
            ],
            "keywords": [
                ("ƒÉn", 0.7), ("b·ªØa", 0.8), ("su·∫•t", 0.7),
                ("ƒë·ªì ƒÉn", 0.8), ("·∫©m th·ª±c", 0.7), ("ƒë·∫∑c s·∫£n", 0.7),
            ]
        },
        
        # EVENT_SUPPORT (h·ªó tr·ª£ ƒëo√†n)
        {
            "field": "event_support",
            "patterns": [
                (r'h·ªó tr·ª£.*g√¨|d·ªãch v·ª•.*k√®m theo|ƒëi k√®m', 0.8),
                (r'l·ª≠a tr·∫°i|giao l∆∞u vƒÉn h√≥a|ch·ª•p ·∫£nh', 0.9),
                (r'h∆∞·ªõng d·∫´n vi√™n|ƒëi·ªÅu ph·ªëi|t·ªï ch·ª©c', 0.7),
            ],
            "keywords": [
                ("h·ªó tr·ª£", 0.8), ("d·ªãch v·ª•", 0.6), ("l·ª≠a tr·∫°i", 0.9),
                ("giao l∆∞u", 0.8), ("ch·ª•p ·∫£nh", 0.7), ("h∆∞·ªõng d·∫´n", 0.7),
            ]
        },
    ]
    
    @staticmethod
    def detect_field_with_confidence(message: str) -> Tuple[Optional[str], float, Dict[str, float]]:
        """
        Detect which field user is asking about with confidence scores
        """
        if not message:
            return None, 0.0, {}
        
        message_lower = message.lower()
        scores = {}
        
        for rule in EnhancedFieldDetector.FIELD_DETECTION_RULES:
            field = rule["field"]
            field_score = 0.0
            
            for pattern, weight in rule["patterns"]:
                if re.search(pattern, message_lower):
                    field_score = max(field_score, weight)
            
            for keyword, weight in rule["keywords"]:
                if keyword in message_lower:
                    position = message_lower.find(keyword)
                    position_factor = 1.0 - (position / max(len(message_lower), 1))
                    adjusted_weight = weight * (0.7 + 0.3 * position_factor)
                    field_score = max(field_score, adjusted_weight)
            
            if field_score > 0:
                field_score = min(field_score * 1.1, 1.0)
            
            scores[field] = field_score
        
        best_field = None
        best_score = 0.0
        
        for field, score in scores.items():
            if score > best_score:
                best_score = score
                best_field = field
        
        if (best_score < 0.3 and 
            ("c√≥ g√¨" in message_lower or "th·∫ø n√†o" in message_lower) and
            "tour" in message_lower):
            best_field = "summary"
            best_score = 0.6
        
        logger.info(f"üîç Field detection: '{message}' ‚Üí {best_field} (confidence: {best_score:.2f})")
        return best_field, best_score, scores

# =========== UPGRADE 4: QUESTION PIPELINE (DATACLASS COMPATIBLE) ===========
class QuestionPipeline:
    """
    UPGRADE 4: Process different types of questions differently
    """
    
    @staticmethod
    def classify_question(message: str) -> Tuple[QuestionType, float, Dict]:
        """
        Classify question type with confidence and metadata
        """
        message_lower = message.lower()
        type_scores = defaultdict(float)
        metadata = {}
        
        # LISTING detection - CH·ªà khi y√™u c·∫ßu r√µ r√†ng li·ªát k√™ DANH S√ÅCH
        listing_patterns = [
            (r'li·ªát k√™.*t·∫•t c·∫£.*tour|danh s√°ch.*t·∫•t c·∫£.*tour|t·∫•t c·∫£.*tour', 0.95),
            (r'li·ªát k√™.*tour|danh s√°ch.*tour|list.*tour', 0.9),
            (r'k·ªÉ t√™n.*tour|n√™u t√™n.*tour', 0.9),
            (r'c√≥ nh·ªØng.*tour n√†o|c√≥ m·∫•y.*tour|m·∫•y.*tour', 0.7),
            (r'b√™n b·∫°n.*c√≥.*tour|hi·ªán c√≥.*tour', 0.75),
        ]
        
        for pattern, weight in listing_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.LISTING] = max(
                    type_scores[QuestionType.LISTING], weight
                )
        
        # COMPARISON detection
        comparison_patterns = [
            (r'so s√°nh.*v√†|ƒë·ªëi chi·∫øu.*v√†', 0.95),
            (r'kh√°c nhau.*n√†o|gi·ªëng nhau.*n√†o', 0.9),
            (r'n√™n ch·ªçn.*n√†o|t·ªët h∆°n.*n√†o|h∆°n k√©m.*n√†o', 0.85),
            (r'tour.*v√†.*tour', 0.8),
            (r's√°nh.*v·ªõi|ƒë·ªëi chi·∫øu.*v·ªõi', 0.8),
        ]
        
        for pattern, weight in comparison_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.COMPARISON] = max(
                    type_scores[QuestionType.COMPARISON], weight
                )
                metadata['comparison_type'] = 'direct'
        
        # RECOMMENDATION detection
        recommendation_patterns = [
            (r'ph√π h·ª£p.*v·ªõi|n√™n ƒëi.*n√†o|g·ª£i √Ω.*tour', 0.95),
            (r'tour n√†o.*ph√π h·ª£p|ph√π h·ª£p.*tour n√†o', 0.95),
            (r'tour.*t·ªët.*nh·∫•t|h√†nh tr√¨nh.*hay nh·∫•t|tour.*l√Ω t∆∞·ªüng', 0.9),
            (r'ƒë·ªÅ xu·∫•t.*tour|t∆∞ v·∫•n.*tour|ch·ªçn.*tour n√†o', 0.9),
            (r'tour n√†o.*cho.*gia ƒë√¨nh|tour.*gia ƒë√¨nh|gia ƒë√¨nh.*tour', 0.9),
            (r'tour n√†o.*cho|d√†nh cho.*tour|tour.*d√†nh cho', 0.85),
            (r'n√™n.*tour n√†o|n√™n ch·ªçn.*tour|tour.*n√™n', 0.85),
            (r'tour.*nh·∫π nh√†ng|tour.*d·ªÖ|tour.*ph√π h·ª£p.*ng∆∞·ªùi', 0.85),
            (r'tour.*tr·∫ª em|tour.*con n√≠t|tour.*b√©', 0.85),
            (r'tour.*ng∆∞·ªùi l·ªõn tu·ªïi|tour.*cao tu·ªïi|tour.*ngh·ªâ d∆∞·ª°ng', 0.85),
            (r'chi ph√≠.*v·ª´a ph·∫£i|gi√°.*ph√π h·ª£p|gi√°.*h·ª£p l√Ω', 0.8),
            (r'cho.*t√¥i|d√†nh cho.*t√¥i|h·ª£p v·ªõi.*t√¥i', 0.75),
            (r'n·∫øu.*th√¨.*n√™n.*tour|n√™n ch·ªçn.*tour', 0.8),
        ]
        
        for pattern, weight in recommendation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.RECOMMENDATION] = max(
                    type_scores[QuestionType.RECOMMENDATION], weight
                )
        
        # GREETING detection
        greeting_words = ['xin ch√†o', 'ch√†o', 'hello', 'hi', 'helo', 'chao']
        greeting_score = 0.0
        for word in greeting_words:
            if word in message_lower:
                if message_lower.startswith(word) or f" {word} " in message_lower or message_lower.endswith(f" {word}"):
                    greeting_score += 0.3
        
        other_intent_score = max([score for qtype, score in type_scores.items() 
                                 if qtype != QuestionType.GREETING], default=0.0)
        
        if greeting_score > 0.8 and other_intent_score < 0.3:
            type_scores[QuestionType.GREETING] = min(greeting_score, 1.0)
        
        # FAREWELL detection
        farewell_words = ['t·∫°m bi·ªát', 'c·∫£m ∆°n', 'thanks', 'thank you', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            type_scores[QuestionType.FAREWELL] = 0.95
        
        # CALCULATION detection
        calculation_patterns = [
            (r't√≠nh to√°n|t√≠nh.*bao nhi√™u|t·ªïng.*bao nhi√™u', 0.9),
            (r'c·ªông.*l·∫°i|nh√¢n.*l√™n|chia.*ra', 0.8),
            (r'bao nhi√™u.*ng∆∞·ªùi|m·∫•y.*ng∆∞·ªùi|s·ªë l∆∞·ª£ng.*ng∆∞·ªùi', 0.7),
        ]
        
        for pattern, weight in calculation_patterns:
            if re.search(pattern, message_lower):
                type_scores[QuestionType.CALCULATION] = max(
                    type_scores[QuestionType.CALCULATION], weight
                )
        
        # COMPLEX question detection
        complex_indicators = [
            ('v√†', 0.3), ('r·ªìi', 0.4), ('sau ƒë√≥', 0.5),
            ('ti·∫øp theo', 0.5), ('ngo√†i ra', 0.4), ('th√™m n·ªØa', 0.4),
        ]
        
        complex_score = 0.0
        for indicator, weight in complex_indicators:
            if indicator in message_lower:
                complex_score += weight
        
        if complex_score > 0.8:
            type_scores[QuestionType.COMPLEX] = min(complex_score / 2, 1.0)
            metadata['complex_parts'] = QuestionPipeline._split_complex_question(message)
        
        # DEFAULT: INFORMATION request
        if not type_scores:
            type_scores[QuestionType.INFORMATION] = 0.6
        else:
            info_keywords = ['l√† g√¨', 'bao nhi√™u', '·ªü ƒë√¢u', 'khi n√†o', 'th·∫ø n√†o', 'ai', 't·∫°i sao']
            if any(keyword in message_lower for keyword in info_keywords):
                type_scores[QuestionType.INFORMATION] = max(
                    type_scores.get(QuestionType.INFORMATION, 0),
                    0.5
                )
        
        # Determine best type
        best_type = QuestionType.INFORMATION
        best_score = 0.0
        
        for qtype, score in type_scores.items():
            if score > best_score:
                best_score = score
                best_type = qtype
        
        if best_score < 0.5:
            best_type = QuestionType.INFORMATION
            best_score = 0.5
        
        logger.info(f"üéØ Question classification: '{message}' ‚Üí {best_type.value} (score: {best_score:.2f})")
        return best_type, best_score, metadata
    
    @staticmethod
    def _split_complex_question(message: str) -> List[str]:
        """Split complex multi-part question into simpler parts"""
        split_patterns = [
            r'\s+v√†\s+',
            r'\s+r·ªìi\s+',
            r'\s+sau ƒë√≥\s+',
            r'\s+ti·∫øp theo\s+',
            r'\s+ngo√†i ra\s+',
            r'\s+th√™m n·ªØa\s+',
            r'\s+ƒë·ªìng th·ªùi\s+',
            r'\s+cu·ªëi c√πng\s+',
        ]
        
        parts = [message]
        
        for pattern in split_patterns:
            new_parts = []
            for part in parts:
                split_result = re.split(pattern, part, flags=re.IGNORECASE)
                new_parts.extend([p.strip() for p in split_result if p.strip()])
            parts = new_parts
        
        return parts
    
    @staticmethod
    def process_comparison_question(tour_indices: List[int], tours_db: Dict[int, Tour], 
                                  aspect: str = "", context: Dict = None) -> str:
        """
        Process comparison question between tours
        """
        if len(tour_indices) < 2:
            return "C·∫ßn √≠t nh·∫•t 2 tour ƒë·ªÉ so s√°nh."
        
        tours_to_compare = []
        for idx in tour_indices[:3]:
            tour = tours_db.get(idx)
            if tour:
                tours_to_compare.append((idx, tour))
        
        if len(tours_to_compare) < 2:
            return "Kh√¥ng t√¨m th·∫•y ƒë·ªß th√¥ng tin tour ƒë·ªÉ so s√°nh."
        
        if not aspect:
            aspect = 'price'
        
        result_lines = []
        
        headers = ["TI√äU CH√ç"]
        for idx, tour in tours_to_compare:
            tour_name = tour.name or f'Tour #{idx}'
            headers.append(tour_name[:25])
        
        result_lines.append(" | ".join(headers))
        result_lines.append("-" * (len(headers) * 30))
        
        comparison_fields = [
            ('duration', '‚è±Ô∏è Th·ªùi gian'),
            ('location', 'üìç ƒê·ªãa ƒëi·ªÉm'),
            ('price', 'üí∞ Gi√° tour'),
            ('accommodation', 'üè® Ch·ªó ·ªü'),
            ('meals', 'üçΩÔ∏è ƒÇn u·ªëng'),
            ('transport', 'üöó Di chuy·ªÉn'),
            ('summary', 'üìù M√¥ t·∫£'),
        ]
        
        for field, display_name in comparison_fields:
            if aspect and field != aspect and aspect not in ['all', 't·∫•t c·∫£']:
                continue
            
            row = [display_name]
            all_values = []
            
            for idx, tour in tours_to_compare:
                value = getattr(tour, field, 'N/A')
                if isinstance(value, list):
                    value = ', '.join(value[:2])
                row.append(str(value)[:30])
                all_values.append(str(value).lower())
            
            if len(set(all_values)) > 1 or aspect == field:
                result_lines.append(" | ".join(row))
        
        result_lines.append("\n" + "="*50)
        result_lines.append("**ƒê√ÅNH GI√Å & G·ª¢I √ù:**")
        
        durations = [tour.duration for _, tour in tours_to_compare]
        if any('1 ng√†y' in d for d in durations) and any('2 ng√†y' in d for d in durations):
            result_lines.append("‚Ä¢ N·∫øu b·∫°n c√≥ √≠t th·ªùi gian: Ch·ªçn tour 1 ng√†y")
            result_lines.append("‚Ä¢ N·∫øu mu·ªën tr·∫£i nghi·ªám s√¢u: Ch·ªçn tour 2 ng√†y")
        
        prices = []
        for _, tour in tours_to_compare:
            price_text = tour.price or ''
            price_nums = re.findall(r'\d[\d,\.]+', price_text)
            if price_nums:
                try:
                    price = int(price_nums[0].replace(',', '').replace('.', ''))
                    prices.append(price)
                except:
                    pass
        
        if len(prices) >= 2:
            min_price_idx = prices.index(min(prices))
            max_price_idx = prices.index(max(prices))
            
            if prices[max_price_idx] > prices[min_price_idx] * 1.5:
                result_lines.append(f"‚Ä¢ Ti·∫øt ki·ªám chi ph√≠: {headers[min_price_idx + 1]}")
                result_lines.append(f"‚Ä¢ Tr·∫£i nghi·ªám cao c·∫•p: {headers[max_price_idx + 1]}")
        
        result_lines.append("\nüí° *Li√™n h·ªá hotline 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt*")
        
        return "\n".join(result_lines)

# =========== UPGRADE 5: COMPLEX QUERY SPLITTER (DATACLASS COMPATIBLE) ===========
class ComplexQueryProcessor:
    """
    UPGRADE 5: Handle complex multi-condition queries
    """
    
    @staticmethod
    def split_query(query: str) -> List[Dict[str, Any]]:
        """
        Split complex query into sub-queries with priorities
        """
        sub_queries = []
        
        complexity_score = ComplexQueryProcessor._calculate_complexity(query)
        if complexity_score < 1.5:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': {},
                'focus': 'general'
            }]
        
        conditions = ComplexQueryProcessor._extract_conditions(query)
        
        if len(conditions) <= 1:
            return [{
                'query': query,
                'priority': 1.0,
                'filters': conditions[0] if conditions else {},
                'focus': 'general'
            }]
        
        sub_queries.append({
            'query': query,
            'priority': 1.0,
            'filters': ComplexQueryProcessor._merge_conditions(conditions),
            'focus': 'specific'
        })
        
        location_conds = [c for c in conditions if 'location' in c]
        other_conds = [c for c in conditions if 'location' not in c]
        
        if location_conds and other_conds:
            for other_cond in other_conds[:2]:
                merged = ComplexQueryProcessor._merge_conditions(location_conds + [other_cond])
                sub_queries.append({
                    'query': f"{query} (focus on location + {list(other_cond.keys())[0]})",
                    'priority': 0.8,
                    'filters': merged,
                    'focus': list(other_cond.keys())[0]
                })
        
        important_conds = ['price', 'duration', 'location']
        for cond_type in important_conds:
            conds_of_type = [c for c in conditions if cond_type in c]
            if conds_of_type:
                sub_queries.append({
                    'query': f"{query} (focus on {cond_type})",
                    'priority': 0.6,
                    'filters': conds_of_type[0],
                    'focus': cond_type
                })
        
        sub_queries.sort(key=lambda x: x['priority'], reverse=True)
        
        logger.info(f"üîÄ Split query into {len(sub_queries)} sub-queries")
        return sub_queries[:3]
    
    @staticmethod
    def _calculate_complexity(query: str) -> float:
        """Calculate how complex a query is"""
        complexity = 0.0
        
        aspects = {
            'price': ['gi√°', 'ti·ªÅn', 'chi ph√≠', 'ƒë·∫Øt', 'r·∫ª'],
            'duration': ['ng√†y', 'ƒë√™m', 'bao l√¢u', 'th·ªùi gian'],
            'location': ['·ªü', 't·∫°i', 'ƒë·∫øn', 'v·ªÅ', 'ƒë·ªãa ƒëi·ªÉm'],
            'quality': ['t·ªët', 'hay', 'ƒë·∫πp', 'h·∫•p d·∫´n', 'th√∫ v·ªã'],
            'type': ['thi·ªÅn', 'kh√≠ c√¥ng', 'retreat', 'ch·ªØa l√†nh'],
        }
        
        query_lower = query.lower()
        
        distinct_aspects = 0
        for aspect, keywords in aspects.items():
            if any(keyword in query_lower for keyword in keywords):
                distinct_aspects += 1
        
        complexity += distinct_aspects * 0.5
        complexity += min(len(query.split()) / 10, 1.0)
        
        conjunctions = ['v√†', 'v·ªõi', 'c√≥', 'cho', 'm√†', 'nh∆∞ng']
        for conj in conjunctions:
            if conj in query_lower:
                complexity += 0.3
        
        return complexity
    
    @staticmethod
    def _extract_conditions(query: str) -> List[Dict[str, Any]]:
        """Extract individual conditions from query"""
        conditions = []
        
        filters = MandatoryFilterSystem.extract_filters(query)
        
        if filters.price_min is not None or filters.price_max is not None:
            price_cond = {'price': {}}
            if filters.price_min is not None:
                price_cond['price']['min'] = filters.price_min
            if filters.price_max is not None:
                price_cond['price']['max'] = filters.price_max
            conditions.append(price_cond)
        
        if filters.duration_min is not None or filters.duration_max is not None:
            duration_cond = {'duration': {}}
            if filters.duration_min is not None:
                duration_cond['duration']['min'] = filters.duration_min
            if filters.duration_max is not None:
                duration_cond['duration']['max'] = filters.duration_max
            conditions.append(duration_cond)
        
        if filters.location:
            conditions.append({'location': filters.location})
        if filters.near_location:
            conditions.append({'near_location': filters.near_location})
        
        query_lower = query.lower()
        
        if any(word in query_lower for word in ['r·∫ª', 'gi√° r·∫ª', 'ti·∫øt ki·ªám']):
            conditions.append({'price_quality': 'budget'})
        if any(word in query_lower for word in ['cao c·∫•p', 'sang', 'premium']):
            conditions.append({'price_quality': 'premium'})
        
        if 'thi·ªÅn' in query_lower:
            conditions.append({'activity_type': 'meditation'})
        if 'kh√≠ c√¥ng' in query_lower:
            conditions.append({'activity_type': 'qigong'})
        if 'retreat' in query_lower:
            conditions.append({'activity_type': 'retreat'})
        if 'ch·ªØa l√†nh' in query_lower:
            conditions.append({'activity_type': 'healing'})
        
        tour_name_patterns = [
            r'tour\s+([^v√†\s,]+)\s+v√†\s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+v·ªõi\s+tour\s+([^\s,]+)',
            r'tour\s+([^\s,]+)\s+.*tour\s+([^\s,]+)',
        ]
        
        for pattern in tour_name_patterns:
            matches = re.finditer(pattern, query_lower)
            for match in matches:
                for i in range(1, 3):
                    if match.group(i):
                        tour_name = match.group(i).strip()
                        normalized_name = FuzzyMatcher.normalize_vietnamese(tour_name)
                        for name, idx in TOUR_NAME_TO_INDEX.items():
                            if normalized_name in name or name in normalized_name:
                                conditions.append({'specific_tour': idx})
                                logger.info(f"üîç Extracted tour name from complex query: {tour_name} ‚Üí index {idx}")
        
        return conditions
    
    @staticmethod
    def _merge_conditions(conditions: List[Dict]) -> Dict[str, Any]:
        """Merge multiple conditions into one filter dict"""
        merged = {}
        
        for condition in conditions:
            for key, value in condition.items():
                if key in merged:
                    if isinstance(merged[key], dict) and isinstance(value, dict):
                        merged[key].update(value)
                    elif isinstance(merged[key], list) and isinstance(value, list):
                        merged[key].extend(value)
                    else:
                        if isinstance(value, dict) or (isinstance(value, str) and len(value) > len(str(merged[key]))):
                            merged[key] = value
                else:
                    merged[key] = value
        
        return merged

# =========== UPGRADE 6: FUZZY MATCHING (DATACLASS COMPATIBLE) ===========
class FuzzyMatcher:
    """
    UPGRADE 6: Handle misspellings and variations in tour names
    """
    
    SIMILARITY_THRESHOLD = 0.75
    
    @staticmethod
    def normalize_vietnamese(text: str) -> str:
        """
        Normalize Vietnamese text for fuzzy matching
        """
        if not text:
            return ""
        
        text = text.lower()
        text = unicodedata.normalize('NFD', text)
        text = ''.join(c for c in text if unicodedata.category(c) != 'Mn')
        
        replacements = {
            'ƒë': 'd',
            'kh√¥ng': 'ko',
            'khong': 'ko',
            'r·ªìi': 'roi',
            'v·ªõi': 'voi',
            'ƒë∆∞·ª£c': 'duoc',
            'm·ªôt': 'mot',
            'hai': '2',
            'ba': '3',
            'b·ªën': '4',
            'nƒÉm': '5',
        }
        
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    @staticmethod
    def find_similar_tours(query: str, tour_names: Dict[str, int]) -> List[Tuple[int, float]]:
        """
        Find tours with names similar to query
        """
        if not query or not tour_names:
            return []
        
        query_norm = FuzzyMatcher.normalize_vietnamese(query)
        if not query_norm:
            return []
        
        matches = []
        
        for tour_name, tour_idx in tour_names.items():
            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name)
            if not tour_norm:
                continue
            
            similarity = SequenceMatcher(None, query_norm, tour_norm).ratio()
            
            if query_norm in tour_norm or tour_norm in query_norm:
                similarity = min(similarity + 0.2, 1.0)
            
            query_words = set(query_norm.split())
            tour_words = set(tour_norm.split())
            common_words = query_words.intersection(tour_words)
            
            if common_words:
                word_boost = len(common_words) * 0.1
                similarity = min(similarity + word_boost, 1.0)
            
            if similarity >= FuzzyMatcher.SIMILARITY_THRESHOLD:
                matches.append((tour_idx, similarity))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        logger.info(f"üîç Fuzzy matching: '{query}' ‚Üí {len(matches)} matches")
        return matches
    
    @staticmethod
    def find_tour_by_partial_name(partial_name: str, tours_db: Dict[int, Tour]) -> List[int]:
        """
        Find tours by partial name match
        """
        if not partial_name or not tours_db:
            return []
        
        partial_norm = FuzzyMatcher.normalize_vietnamese(partial_name)
        matches = []
        
        for tour_idx, tour in tours_db.items():
            tour_name = tour.name or ""
            if not tour_name:
                continue
            
            tour_norm = FuzzyMatcher.normalize_vietnamese(tour_name)
            
            if partial_norm in tour_norm:
                match_ratio = len(partial_norm) / len(tour_norm) if tour_norm else 0
                matches.append((tour_idx, match_ratio))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        return [idx for idx, _ in matches[:3]]

# =========== UPGRADE 7: STATE MACHINE (DATACLASS COMPATIBLE) ===========
class ConversationStateMachine:
    """
    UPGRADE 7: Track conversation state for better context
    """
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.state = ConversationState.INITIAL
        self.context = ConversationContext(session_id=session_id)
        self.transitions = []
        self.created_at = datetime.utcnow()
        self.last_updated = datetime.utcnow()
    
    def update(self, user_message: str, bot_response: str, tour_indices: List[int] = None):
        """Update state based on new interaction"""
        self.last_updated = datetime.utcnow()
        self.context.update(user_message, bot_response, tour_indices)
        
        new_state = self._determine_state(user_message, bot_response)
        
        self.transitions.append({
            'timestamp': datetime.utcnow().isoformat(),
            'from': self.state.value,
            'to': new_state.value,
            'message': user_message[:100]
        })
        
        self.state = new_state
        
        logger.info(f"üîÑ State update: {self.state.value} for session {self.session_id}")
    
    def _determine_state(self, user_message: str, bot_response: str) -> ConversationState:
        """Determine new state based on current interaction"""
        message_lower = user_message.lower()
        farewell_words = ['t·∫°m bi·ªát', 'c·∫£m ∆°n', 'thanks', 'bye', 'goodbye']
        if any(word in message_lower for word in farewell_words):
            return ConversationState.FAREWELL
        
        tour_ref_patterns = [
            r'tour n√†y', r'tour ƒë√≥', r'tour ƒëang n√≥i', r'c√°i tour',
            r'n√≥', r'c√°i ƒë√≥', r'c√°i n√†y', r'ƒë·∫•y'
        ]
        
        if any(re.search(pattern, message_lower) for pattern in tour_ref_patterns):
            if self.context.current_tours:
                return ConversationState.TOUR_SELECTED
            elif self.context.last_successful_tours:
                self.context.current_tours = self.context.last_successful_tours
                return ConversationState.TOUR_SELECTED
        
        if 'so s√°nh' in message_lower or 's√°nh' in message_lower:
            return ConversationState.COMPARING
        
        if any(word in message_lower for word in ['ph√π h·ª£p', 'g·ª£i √Ω', 'ƒë·ªÅ xu·∫•t', 't∆∞ v·∫•n', 'n√™n ch·ªçn']):
            return ConversationState.RECOMMENDATION
        
        if any(word in message_lower for word in ['ƒë·∫∑t', 'booking', 'ƒëƒÉng k√Ω', 'gi·ªØ ch·ªó']):
            return ConversationState.BOOKING
        
        if self.context.current_tours:
            return ConversationState.ASKING_DETAILS
        
        return ConversationState.INITIAL
    
    def get_context_hint(self) -> str:
        """Get hint about current context for LLM prompt"""
        hints = []
        
        if self.state == ConversationState.TOUR_SELECTED and self.context.current_tours:
            tour_indices = self.context.current_tours
            if len(tour_indices) == 1:
                hints.append(f"User is asking about tour index {tour_indices[0]}")
            else:
                hints.append(f"User is asking about tours {tour_indices}")
        
        if self.context.user_preferences:
            prefs = []
            for key, value in self.context.user_preferences.items():
                prefs.append(f"{key}: {value}")
            if prefs:
                hints.append(f"User preferences: {', '.join(prefs)}")
        
        return "; ".join(hints) if hints else "No specific context"
    
    def extract_reference(self, message: str) -> List[int]:
        """Extract tour reference from message using conversation context"""
        message_lower = message.lower()
        
        if self.context.current_tours:
            for tour_idx in self.context.current_tours:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"üîÑ State machine: Using current tour {tour_idx}")
                        return self.context.current_tours
        
        ref_patterns = [
            (r'tour n√†y', 1.0),
            (r'tour ƒë√≥', 0.9),
            (r'tour ƒëang n√≥i', 0.9),
            (r'c√°i tour', 0.8),
            (r'n√≥', 0.7),
            (r'ƒë·∫•y', 0.7),
            (r'c√°i ƒë√≥', 0.7),
        ]
        
        for pattern, confidence in ref_patterns:
            if re.search(pattern, message_lower):
                if self.context.current_tours:
                    logger.info(f"üîÑ State machine: Resolved reference to {self.context.current_tours}")
                    return self.context.current_tours
                elif self.context.last_successful_tours:
                    logger.info(f"üîÑ State machine: Using last successful tours {self.context.last_successful_tours}")
                    return self.context.last_successful_tours
        
        if self.context.mentioned_tours:
            recent_tours = list(self.context.mentioned_tours)
            for tour_idx in recent_tours[-3:]:
                tour = TOURS_DB.get(tour_idx)
                if not tour:
                    continue
                tour_name = (tour.name or "").lower()
                if tour_name:
                    tour_words = set(tour_name.split())
                    msg_words = set(message_lower.split())
                    common = tour_words.intersection(msg_words)
                    if common and len(common) >= 1:
                        logger.info(f"üîÑ State machine: Matched to recently mentioned tour {tour_idx}")
                        return [tour_idx]
        
        return []

# =========== UPGRADE 8: DEEP SEMANTIC ANALYSIS (DATACLASS COMPATIBLE) ===========
class SemanticAnalyzer:
    """
    UPGRADE 8: Deep understanding of user intent beyond keywords
    """
    
    USER_PROFILE_PATTERNS = {
        'age_group': [
            (r'ng∆∞·ªùi gi√†|ng∆∞·ªùi l·ªõn tu·ªïi|cao tu·ªïi', 'senior'),
            (r'thanh ni√™n|tr·∫ª|sinh vi√™n|h·ªçc sinh', 'young'),
            (r'trung ni√™n|trung tu·ªïi', 'middle_aged'),
            (r'gia ƒë√¨nh.*tr·∫ª em|tr·∫ª nh·ªè|con n√≠t', 'family_with_kids'),
        ],
        
        'group_type': [
            (r'm·ªôt m√¨nh|ƒëi l·∫ª|solo', 'solo'),
            (r'c·∫∑p ƒë√¥i|ƒë√¥i l·ª©a|ng∆∞·ªùi y√™u', 'couple'),
            (r'gia ƒë√¨nh|b·ªë m·∫π con', 'family'),
            (r'b·∫°n b√®|nh√≥m b·∫°n|h·ªôi b·∫°n', 'friends'),
            (r'c√¥ng ty|doanh nghi·ªáp|ƒë·ªìng nghi·ªáp', 'corporate'),
        ],
        
        'interest_type': [
            (r'thi√™n nhi√™n|r·ª´ng|c√¢y|c·∫£nh quan', 'nature'),
            (r'l·ªãch s·ª≠|di t√≠ch|chi·∫øn tranh|tri √¢n', 'history'),
            (r'vƒÉn h√≥a|c·ªông ƒë·ªìng|d√¢n t·ªôc|truy·ªÅn th·ªëng', 'culture'),
            (r'thi·ªÅn|t√¢m linh|tƒ©nh t√¢m|yoga', 'spiritual'),
            (r'kh√≠ c√¥ng|s·ª©c kh·ªèe|ch·ªØa l√†nh|wellness', 'wellness'),
            (r'·∫©m th·ª±c|ƒë·ªì ƒÉn|m√≥n ngon|ƒë·∫∑c s·∫£n', 'food'),
            (r'phi√™u l∆∞u|m·∫°o hi·ªÉm|kh√°m ph√°|tr·∫£i nghi·ªám', 'adventure'),
        ],
        
        'budget_level': [
            (r'kinh t·∫ø|ti·∫øt ki·ªám|r·∫ª|gi√° th·∫•p', 'budget'),
            (r'trung b√¨nh|v·ª´a ph·∫£i|ph·∫£i chƒÉng', 'midrange'),
            (r'cao c·∫•p|sang tr·ªçng|premium|ƒë·∫Øt', 'premium'),
        ],
        
        'physical_level': [
            (r'nh·∫π nh√†ng|d·ªÖ d√†ng|kh√¥ng m·ªát', 'easy'),
            (r'v·ª´a ph·∫£i|trung b√¨nh|b√¨nh th∆∞·ªùng', 'moderate'),
            (r'th·ª≠ th√°ch|kh√≥|m·ªát|leo n√∫i', 'challenging'),
        ],
    }
    
    @staticmethod
    def analyze_user_profile(message: str, current_context: ConversationContext = None) -> UserProfile:
        """
        Analyze message to build user profile
        """
        if current_context and hasattr(current_context, 'user_profile') and current_context.user_profile:
            profile = current_context.user_profile
        else:
            profile = UserProfile()
        
        message_lower = message.lower()
        
        for category, patterns in SemanticAnalyzer.USER_PROFILE_PATTERNS.items():
            for pattern, value in patterns:
                if re.search(pattern, message_lower):
                    if category == 'interests':
                        if value not in profile.interests:
                            profile.interests.append(value)
                            profile.confidence_scores[f'interest_{value}'] = 0.8
                    else:
                        setattr(profile, category, value)
                        profile.confidence_scores[category] = 0.8
        
        SemanticAnalyzer._infer_attributes(profile, message_lower)
        profile.overall_confidence = SemanticAnalyzer._calculate_confidence(profile)
        
        logger.info(f"üë§ User profile analysis: {profile}")
        return profile
    
    @staticmethod
    def _infer_attributes(profile: UserProfile, message_lower: str):
        """Infer additional attributes from context"""
        if not profile.age_group:
            if profile.group_type and 'family_with_kids' in profile.group_type:
                profile.age_group = 'middle_aged'
                profile.confidence_scores['age_group'] = 0.6
            elif 'senior' in message_lower or 'gi√†' in message_lower:
                profile.age_group = 'senior'
                profile.confidence_scores['age_group'] = 0.7
        
        if not profile.physical_level:
            if 'adventure' in profile.interests:
                profile.physical_level = 'challenging'
                profile.confidence_scores['physical_level'] = 0.6
            elif 'spiritual' in profile.interests or 'wellness' in profile.interests:
                profile.physical_level = 'easy'
                profile.confidence_scores['physical_level'] = 0.6
        
        if not profile.budget_level:
            budget_keywords = {
                'budget': ['r·∫ª', 'ti·∫øt ki·ªám', '√≠t ti·ªÅn', 'kinh t·∫ø'],
                'premium': ['cao c·∫•p', 'sang', 'ƒë·∫Øt', 'premium']
            }
            
            for level, keywords in budget_keywords.items():
                if any(keyword in message_lower for keyword in keywords):
                    profile.budget_level = level
                    profile.confidence_scores['budget_level'] = 0.7
                    break
    
    @staticmethod
    def _calculate_confidence(profile: UserProfile) -> float:
        """Calculate overall confidence in user profile"""
        if not profile.confidence_scores:
            return 0.0
        
        total = 0.0
        count = 0
        
        for key, score in profile.confidence_scores.items():
            total += score
            count += 1
        
        return total / max(count, 1)
    
    @staticmethod
    def match_tours_to_profile(profile: UserProfile, tours_db: Dict[int, Tour], 
                              max_results: int = 5) -> List[Tuple[int, float, List[str]]]:
        """
        Match tours to user profile with explanation
        """
        matches = []
        
        for tour_idx, tour in tours_db.items():
            score = 0.0
            reasons = []
            
            tour_tags = tour.tags or []
            
            if profile.age_group:
                if profile.age_group == 'senior':
                    if any('easy' in tag for tag in tour_tags):
                        score += 0.3
                        reasons.append("ph√π h·ª£p ng∆∞·ªùi l·ªõn tu·ªïi")
                    if any('nature' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("thi√™n nhi√™n nh·∫π nh√†ng")
            
            if profile.interests:
                for interest in profile.interests:
                    tour_summary = (tour.summary or "").lower()
                    if (interest in tour_summary or 
                        any(interest in tag for tag in tour_tags)):
                        score += 0.4
                        reasons.append(f"c√≥ y·∫øu t·ªë {interest}")
            
            if profile.budget_level:
                tour_price = tour.price or ""
                price_nums = re.findall(r'\d[\d,\.]+', tour_price)
                
                if price_nums:
                    try:
                        first_price = int(price_nums[0].replace(',', '').replace('.', ''))
                        
                        if profile.budget_level == 'budget' and first_price < 2000000:
                            score += 0.3
                            reasons.append("gi√° h·ª£p l√Ω")
                        elif profile.budget_level == 'premium' and first_price > 2500000:
                            score += 0.3
                            reasons.append("cao c·∫•p")
                        elif profile.budget_level == 'midrange' and 1500000 <= first_price <= 3000000:
                            score += 0.3
                            reasons.append("gi√° v·ª´a ph·∫£i")
                    except:
                        pass
            
            if profile.physical_level:
                if profile.physical_level == 'easy':
                    if any('easy' in tag or 'meditation' in tag for tag in tour_tags):
                        score += 0.2
                        reasons.append("ho·∫°t ƒë·ªông nh·∫π nh√†ng")
            
            if score > 0:
                matches.append((tour_idx, score, reasons))
        
        matches.sort(key=lambda x: x[1], reverse=True)
        
        return matches[:max_results]

# =========== UPGRADE 9: AUTO-VALIDATION SYSTEM (DATACLASS COMPATIBLE) ===========
class AutoValidator:
    """
    UPGRADE 9: Validate and correct information before returning
    """
    
    VALIDATION_RULES = {
        'duration': {
            'patterns': [
                r'(\d+)\s*ng√†y\s*(\d+)\s*ƒë√™m',
                r'(\d+)\s*ng√†y',
                r'(\d+)\s*ƒë√™m',
            ],
            'constraints': {
                'max_days': 7,
                'max_nights': 7,
                'valid_day_night_combos': [(1,0), (1,1), (2,1), (2,2), (3,2), (3,3)],
                'common_durations': ['1 ng√†y', '2 ng√†y 1 ƒë√™m', '3 ng√†y 2 ƒë√™m']
            }
        },
        
        'price': {
            'patterns': [
                r'(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)',
                r'(\d[\d,\.]*)\s*-\s*(\d[\d,\.]*)\s*(tri·ªáu|tr|k|ngh√¨n)?',
                r'(\d[\d,\.]*)\s*(ƒë·ªìng|vnƒë|vnd)',
            ],
            'constraints': {
                'min_tour_price': 500000,
                'max_tour_price': 10000000,
                'common_ranges': [
                    (800000, 1500000),
                    (1500000, 2500000),
                    (2500000, 4000000),
                ]
            }
        },
        
        'location': {
            'patterns': [
                r'·ªü\s+([^.,!?]+)',
                r't·∫°i\s+([^.,!?]+)',
                r'ƒë·∫øn\s+([^.,!?]+)',
            ],
            'constraints': {
                'valid_locations': ['Hu·∫ø', 'Qu·∫£ng Tr·ªã', 'B·∫°ch M√£', 'Tr∆∞·ªùng S∆°n', 'ƒê√¥ng H√†', 'Khe Sanh'],
                'max_length': 100
            }
        },
    }
    
    @staticmethod
    def validate_response(response: str) -> str:
        """
        Validate and correct response content
        """
        if not response:
            return response
        
        validated = response
        
        validated = AutoValidator._validate_duration(validated)
        validated = AutoValidator._validate_price(validated)
        validated = AutoValidator._validate_locations(validated)
        validated = AutoValidator._check_unrealistic_info(validated)
        
        if validated != response:
            validated = AutoValidator._add_validation_note(validated)
        
        return validated
    
    @staticmethod
    def _validate_duration(text: str) -> str:
        """Validate and correct duration information"""
        for pattern in AutoValidator.VALIDATION_RULES['duration']['patterns']:
            matches = list(re.finditer(pattern, text))
            for match in matches:
                try:
                    if match.lastindex == 2:
                        days = int(match.group(1))
                        nights = int(match.group(2))
                        
                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']
                        
                        valid_combos = constraints['valid_day_night_combos']
                        is_valid_combo = any(days == d2 and nights == n2 for d2, n2 in valid_combos)

                        
                        if days > constraints['max_days'] or nights > constraints['max_nights']:
                            replacement = random.choice(constraints['common_durations'])
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"‚ö†Ô∏è Corrected unrealistic duration: {days} ng√†y {nights} ƒë√™m ‚Üí {replacement}")
                        
                        elif not is_valid_combo:
                            valid_days = min(days, constraints['max_days'])
                            valid_nights = min(nights, constraints['max_nights'])
                            if abs(valid_days - valid_nights) > 1:
                                valid_nights = valid_days
                            
                            replacement = f"{valid_days} ng√†y {valid_nights} ƒë√™m"
                            text = text.replace(match.group(0), replacement)
                            logger.info(f"üîÑ Fixed duration combo: {replacement}")
                    
                    elif match.lastindex == 1:
                        num = int(match.group(1))
                        constraints = AutoValidator.VALIDATION_RULES['duration']['constraints']
                        
                        if num > constraints['max_days']:
                            replacement = f"{constraints['max_days']} ng√†y"
                            text = text.replace(match.group(0), replacement)
                            logger.warning(f"‚ö†Ô∏è Capped long duration: {num} ‚Üí {constraints['max_days']}")
                
                except (ValueError, IndexError):
                    continue
        
        return text
    
    @staticmethod
    def _validate_price(text: str) -> str:
        """Validate and correct price information"""
        for pattern in AutoValidator.VALIDATION_RULES['price']['patterns']:
            matches = list(re.finditer(pattern, text, re.IGNORECASE))
            for match in matches:
                try:
                    amount_str = match.group(1).replace(',', '').replace('.', '')
                    if not amount_str.isdigit():
                        continue
                    
                    amount = int(amount_str)
                    
                    unit = match.group(2).lower() if match.lastindex >= 2 else ''
                    
                    if unit in ['tri·ªáu', 'tr']:
                        amount = amount * 1000000
                    elif unit in ['k', 'ngh√¨n']:
                        amount = amount * 1000
                    
                    constraints = AutoValidator.VALIDATION_RULES['price']['constraints']
                    
                    if amount < constraints['min_tour_price']:
                        replacement = "gi√° h·ª£p l√Ω"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"‚ö†Ô∏è Corrected too-low price: {amount} ‚Üí {replacement}")
                    
                    elif amount > constraints['max_tour_price']:
                        replacement = "gi√° cao c·∫•p"
                        text = text.replace(match.group(0), replacement)
                        logger.warning(f"‚ö†Ô∏è Corrected too-high price: {amount} ‚Üí {replacement}")
                
                except (ValueError, IndexError, AttributeError):
                    continue
        
        return text
    
    @staticmethod
    def _validate_locations(text: str) -> str:
        """Validate location names"""
        wrong_locations = {
            'h√† n·ªôi': 'Hu·∫ø',
            'h·ªì ch√≠ minh': 'Qu·∫£ng Tr·ªã',
            'ƒë√† n·∫µng': 'B·∫°ch M√£',
            'nha trang': 'Tr∆∞·ªùng S∆°n',
        }
        
        for wrong, correct in wrong_locations.items():
            if wrong in text.lower():
                text = text.replace(wrong, correct)
                text = text.replace(wrong.capitalize(), correct)
                logger.info(f"üîÑ Corrected location: {wrong} ‚Üí {correct}")
        
        return text
    
    @staticmethod
    def _check_unrealistic_info(text: str) -> str:
        """Check for other unrealistic information"""
        unrealistic_patterns = [
            (r'\d+\s*gi·ªù\s*bay', "th·ªùi gian di chuy·ªÉn"),
            (r'\d+\s*sao', "ch·∫•t l∆∞·ª£ng d·ªãch v·ª•"),
            (r'\d+\s*t·∫ßng', "ch·ªó ·ªü"),
            (r'\d+\s*m\s*cao', "ƒë·ªãa h√¨nh"),
        ]
        
        for pattern, replacement in unrealistic_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
                logger.info(f"üîÑ Replaced unrealistic info with: {replacement}")
        
        return text
    
    @staticmethod
    def _add_validation_note(text: str) -> str:
        """Add note about information validation"""
        note = "\n\n*Th√¥ng tin ƒë∆∞·ª£c cung c·∫•p d·ª±a tr√™n d·ªØ li·ªáu hi·ªán c√≥. " \
               "Vui l√≤ng li√™n h·ªá hotline 0332510486 ƒë·ªÉ x√°c nh·∫≠n chi ti·∫øt ch√≠nh x√°c nh·∫•t.*"
        
        if note not in text:
            text += note
        
        return text

# =========== UPGRADE 10: TEMPLATE SYSTEM (DATACLASS COMPATIBLE) ===========
class TemplateSystem:
    """
    UPGRADE 10: Beautiful, structured responses for different question types
    """
    
    TEMPLATES = {
        'tour_list': {
            'header': "‚ú® **DANH S√ÅCH TOUR RUBY WINGS** ‚ú®\n\n",
            'item': "**{index}. {tour_name}** {emoji}\n"
                   "   üìÖ {duration}\n"
                   "   üìç {location}\n"
                   "   üí∞ {price}\n"
                   "   {summary}\n",
            'footer': "\nüìû **Li√™n h·ªá ƒë·∫∑t tour:** 0332510486\n"
                     "üìç **Ruby Wings Travel** - H√†nh tr√¨nh tr·∫£i nghi·ªám ƒë·∫∑c s·∫Øc\n"
                     "üí° *H·ªèi chi ti·∫øt v·ªÅ b·∫•t k·ª≥ tour n√†o b·∫±ng c√°ch nh·∫≠p t√™n tour*",
            'emoji_map': {
                '1 ng√†y': 'üåÖ',
                '2 ng√†y': 'üåÑ',
                '3 ng√†y': 'üèîÔ∏è',
                'default': '‚ú®'
            }
        },
        
        'tour_detail': {
            'header': "üéØ **{tour_name}**\n\n",
            'sections': {
                'overview': "üìã **TH√îNG TIN CH√çNH:**\n"
                          "   ‚è±Ô∏è Th·ªùi gian: {duration}\n"
                          "   üìç ƒê·ªãa ƒëi·ªÉm: {location}\n"
                          "   üí∞ Gi√° tour: {price}\n\n",
                'description': "üìñ **M√î T·∫¢ TOUR:**\n{summary}\n\n",
                'includes': "üé™ **L·ªäCH TR√åNH & D·ªäCH V·ª§:**\n{includes}\n\n",
                'accommodation': "üè® **CH·ªñ ·ªû:**\n{accommodation}\n\n",
                'meals': "üçΩÔ∏è **ƒÇN U·ªêNG:**\n{meals}\n\n",
                'transport': "üöó **DI CHUY·ªÇN:**\n{transport}\n\n",
                'notes': "üìù **GHI CH√ö:**\n{notes}\n\n",
            },
            'footer': "üìû **ƒê·∫∂T TOUR & T∆Ø V·∫æN:** 0332510486\n"
                     "‚≠ê *Tour ph√π h·ª£p cho: {suitable_for}*",
            'default_values': {
                'duration': 'ƒêang c·∫≠p nh·∫≠t',
                'location': 'ƒêang c·∫≠p nh·∫≠t',
                'price': 'Li√™n h·ªá ƒë·ªÉ bi·∫øt gi√°',
                'summary': 'H√†nh tr√¨nh tr·∫£i nghi·ªám ƒë·∫∑c s·∫Øc c·ªßa Ruby Wings',
                'includes': 'Chi ti·∫øt l·ªãch tr√¨nh li√™n h·ªá t∆∞ v·∫•n',
                'accommodation': 'ƒêang c·∫≠p nh·∫≠t',
                'meals': 'ƒêang c·∫≠p nh·∫≠t',
                'transport': 'ƒêang c·∫≠p nh·∫≠t',
                'notes': 'Vui l√≤ng li√™n h·ªá ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt',
                'suitable_for': 'm·ªçi ƒë·ªëi t∆∞·ª£ng',
            }
        },
        
        'comparison': {
            'header': "üìä **SO S√ÅNH TOUR**\n\n",
            'table_header': "| Ti√™u ch√≠ | {tour1} | {tour2} |\n|----------|----------|----------|\n",
            'table_row': "| {criterion} | {value1} | {value2} |\n",
            'recommendation': "\nüí° **G·ª¢I √ù L·ª∞A CH·ªåN:**\n{recommendations}\n",
            'footer': "\nüìû **T∆∞ v·∫•n chi ti·∫øt:** 0332510486\n"
                     "ü§î *C·∫ßn so s√°nh th√™m ti√™u ch√≠ n√†o?*",
        },
        
        'recommendation': {
            'header': "üéØ **ƒê·ªÄ XU·∫§T TOUR PH√ô H·ª¢P**\n\n",
            'top_recommendation': "üèÜ **PH√ô H·ª¢P NH·∫§T ({score}%)**\n"
                                "**{tour_name}**\n"
                                "   ‚úÖ {reasons}\n"
                                "   üìÖ {duration} | üìç {location} | üí∞ {price}\n\n",
            'other_recommendations': "üìã **L·ª∞A CH·ªåN KH√ÅC:**\n",
            'other_item': "   ‚Ä¢ **{tour_name}** ({score}%)\n"
                         "     üìÖ {duration} | üìç {location}\n",
            'criteria': "\nüîç **TI√äU CH√ç ƒê·ªÄ XU·∫§T:**\n{criteria}\n",
            'footer': "\nüìû **Li√™n h·ªá t∆∞ v·∫•n c√° nh√¢n h√≥a:** 0332510486\n"
                     "üí¨ *Cho t√¥i bi·∫øt th√™m s·ªü th√≠ch c·ªßa b·∫°n ƒë·ªÉ ƒë·ªÅ xu·∫•t ch√≠nh x√°c h∆°n*",
        },
        
        'information': {
            'header': "‚ÑπÔ∏è **TH√îNG TIN:**\n\n",
            'content': "{content}\n",
            'sources': "\nüìö *Ngu·ªìn th√¥ng tin t·ª´ d·ªØ li·ªáu Ruby Wings*",
            'footer': "\nüìû **Hotline h·ªó tr·ª£:** 0332510486",
        },
        
        'greeting': {
            'template': "üëã **Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI c·ªßa Ruby Wings**\n\n"
                       "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\n"
                       "‚Ä¢ T√¨m hi·ªÉu v·ªÅ c√°c tour tr·∫£i nghi·ªám\n"
                       "‚Ä¢ So s√°nh c√°c h√†nh tr√¨nh\n"
                       "‚Ä¢ ƒê·ªÅ xu·∫•t tour ph√π h·ª£p v·ªõi b·∫°n\n"
                       "‚Ä¢ Cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ tour\n\n"
                       "üí° **V√≠ d·ª• b·∫°n c√≥ th·ªÉ h·ªèi:**\n"
                       "- 'C√≥ nh·ªØng tour n√†o?'\n"
                       "- 'Tour B·∫°ch M√£ gi√° bao nhi√™u?'\n"
                       "- 'Tour n√†o ph√π h·ª£p cho gia ƒë√¨nh?'\n\n"
                       "H√£y cho t√¥i bi·∫øt b·∫°n c·∫ßn g√¨ nh√©! üòä",
        },
        
        'farewell': {
            'template': "üôè **C·∫£m ∆°n b·∫°n ƒë√£ tr√≤ chuy·ªán c√πng Ruby Wings!**\n\n"
                       "Ch√∫c b·∫°n m·ªôt ng√†y tr√†n ƒë·∫ßy nƒÉng l∆∞·ª£ng v√† b√¨nh an.\n"
                       "Hy v·ªçng s·ªõm ƒë∆∞·ª£c ƒë·ªìng h√†nh c√πng b·∫°n trong h√†nh tr√¨nh tr·∫£i nghi·ªám s·∫Øp t·ªõi!\n\n"
                       "üìû **Li√™n h·ªá ƒë·∫∑t tour:** 0332510486\n"
                       "üåê **Website:** rubywings.vn\n\n"
                       "H·∫πn g·∫∑p l·∫°i! ‚ú®",
        },
    }
    
    @staticmethod
    def render(template_name: str, **kwargs) -> str:
        """Render template with provided variables"""
        template_data = TemplateSystem.TEMPLATES.get(template_name)
        if not template_data:
            return kwargs.get('content', '')
        
        if template_name in ['greeting', 'farewell']:
            return template_data['template']
        
        response_parts = []
        
        if 'header' in template_data:
            header = template_data['header']
            for key, value in kwargs.items():
                header = header.replace(f'{{{key}}}', str(value))
            response_parts.append(header)
        
        if template_name == 'tour_list':
            response_parts.append(TemplateSystem._render_tour_list(template_data, kwargs))
        
        elif template_name == 'tour_detail':
            response_parts.append(TemplateSystem._render_tour_detail(template_data, kwargs))
        
        elif template_name == 'comparison':
            response_parts.append(TemplateSystem._render_comparison(template_data, kwargs))
        
        elif template_name == 'recommendation':
            response_parts.append(TemplateSystem._render_recommendation(template_data, kwargs))
        
        elif template_name == 'information':
            response_parts.append(TemplateSystem._render_information(template_data, kwargs))
        
        if 'footer' in template_data:
            footer = template_data['footer']
            for key, value in kwargs.items():
                footer = footer.replace(f'{{{key}}}', str(value))
            response_parts.append(footer)
        
        return '\n'.join(response_parts)
    
    @staticmethod
    def _render_tour_list(template_data: Dict, kwargs: Dict) -> str:
        """Render tour list template"""
        tours = kwargs.get('tours', [])
        if not tours:
            return "Hi·ªán ch∆∞a c√≥ th√¥ng tin tour."
        
        items = []
        for i, tour in enumerate(tours[:10], 1):
            duration = tour.duration or ''
            emoji = template_data['emoji_map'].get('default')
            for dur_pattern, dur_emoji in template_data['emoji_map'].items():
                if dur_pattern in duration.lower():
                    emoji = dur_emoji
                    break
            
            item_template = template_data['item']
            item = item_template.format(
                index=i,
                tour_name=tour.name or f'Tour #{i}',
                emoji=emoji or '‚ú®',
                duration=duration or 'ƒêang c·∫≠p nh·∫≠t',
                location=tour.location or 'ƒêang c·∫≠p nh·∫≠t',
                price=tour.price or 'Li√™n h·ªá ƒë·ªÉ bi·∫øt gi√°',
                summary=(tour.summary or 'Tour tr·∫£i nghi·ªám ƒë·∫∑c s·∫Øc')[:100] + '...'
            )
            items.append(item)
        
        return '\n'.join(items)
    
    @staticmethod
    def _render_tour_detail(template_data: Dict, kwargs: Dict) -> str:
        """Render tour detail template"""
        sections = []
        
        for section_name, section_template in template_data['sections'].items():
            value = kwargs.get(section_name, template_data['default_values'].get(section_name, ''))
            
            if value and value != template_data['default_values'].get(section_name):
                if isinstance(value, list):
                    if section_name == 'includes':
                        value = '\n'.join([f'   ‚Ä¢ {item}' for item in value[:5]])
                    else:
                        value = ', '.join(value[:3])
                
                section = section_template.format(**{section_name: value})
                sections.append(section)
        
        return '\n'.join(sections)
    
    @staticmethod
    def _render_comparison(template_data: Dict, kwargs: Dict) -> str:
        """Render comparison template"""
        comparison_table = []
        
        tour1_name = kwargs.get('tour1_name', 'Tour 1')[:20]
        tour2_name = kwargs.get('tour2_name', 'Tour 2')[:20]
        table_header = template_data['table_header'].format(tour1=tour1_name, tour2=tour2_name)
        comparison_table.append(table_header)
        
        criteria = kwargs.get('criteria', [])
        for criterion in criteria[:8]:
            row = template_data['table_row'].format(
                criterion=criterion.get('name', ''),
                value1=criterion.get('value1', 'N/A')[:20],
                value2=criterion.get('value2', 'N/A')[:20]
            )
            comparison_table.append(row)
        
        return '\n'.join(comparison_table)
    
    @staticmethod
    def _render_recommendation(template_data: Dict, kwargs: Dict) -> str:
        """Render recommendation template"""
        recommendation_text = []
        
        top_tour = kwargs.get('top_tour')
        if top_tour:
            top_text = template_data['top_recommendation'].format(
                score=int(top_tour.get('score', 0) * 100),
                tour_name=top_tour.get('name', ''),
                reasons=', '.join(top_tour.get('reasons', ['ph√π h·ª£p'])[:3]),
                duration=top_tour.get('duration', ''),
                location=top_tour.get('location', ''),
                price=top_tour.get('price', 'Li√™n h·ªá ƒë·ªÉ bi·∫øt gi√°')
            )
            recommendation_text.append(top_text)
        
        other_tours = kwargs.get('other_tours', [])
        if other_tours:
            recommendation_text.append(template_data['other_recommendations'])
            
            for tour in other_tours[:2]:
                other_item = template_data['other_item'].format(
                    tour_name=tour.get('name', ''),
                    score=int(tour.get('score', 0) * 100),
                    duration=tour.get('duration', ''),
                    location=tour.get('location', '')
                )
                recommendation_text.append(other_item)
        
        return '\n'.join(recommendation_text)
    
    @staticmethod
    def _render_information(template_data: Dict, kwargs: Dict) -> str:
        """Render information template"""
        content = kwargs.get('content', '')
        if not content:
            return ""
        
        info_text = template_data['content'].format(content=content)
        
        if kwargs.get('has_sources'):
            info_text += template_data['sources']
        
        return info_text

# =========== TOUR DATABASE BUILDER (USING Tour DATACLASS) ===========
def load_knowledge():
    """Load knowledge base from JSON file with fallback"""
    global KNOW, TOURS_DB, TOUR_NAME_TO_INDEX, FLAT_TEXTS
    
    try:
        # Multiple possible paths
        possible_paths = [
            "data/knowledge.json",
            "knowledge.json",
            "src/data/knowledge.json",
            "/opt/render/project/src/data/knowledge.json",
            os.path.join(os.path.dirname(__file__), "data/knowledge.json"),
        ]
        
        knowledge_path = None
        for path in possible_paths:
            if os.path.exists(path):
                knowledge_path = path
                logger.info(f"üìÇ Found knowledge.json at: {path}")
                break
        
        if not knowledge_path:
            logger.error("‚ùå Cannot find knowledge.json in any path")
            logger.error(f"   Current dir: {os.getcwd()}")
            logger.error(f"   Files in current dir: {os.listdir('.')}")
            if os.path.exists("data"):
                logger.error(f"   Files in data dir: {os.listdir('data')}")
            return
        
        # Load and parse JSON
        with open(knowledge_path, "r", encoding="utf-8") as f:
            KNOW = json.load(f)
        
        logger.info(f"üìä Knowledge loaded: {len(KNOW.get('tours', []))} tours")
        
        # Reset databases
        TOURS_DB.clear()
        TOUR_NAME_TO_INDEX.clear()
        FLAT_TEXTS.clear()
        
        # Process tours
        tours = KNOW.get("tours", [])
        for idx, tour_data in enumerate(tours):
            try:
                                # Debug: Log first tour structure
                if idx == 0:
                    logger.info(f"üè∑Ô∏è First tour data keys: {list(tour_data.keys())}")# Create Tour object
                               # Create Tour object v·ªõi tr∆∞·ªùng index
                tour = Tour(
                    index=idx,  # QUAN TR·ªåNG: Th√™m index
                    name=tour_data.get("tour_name", "").strip(),
                    summary=tour_data.get("summary", ""),
                    location=tour_data.get("location", ""),
                    duration=tour_data.get("duration", ""),
                    price=tour_data.get("price", ""),
                    includes=tour_data.get("includes", []),
                    notes=tour_data.get("notes", ""),
                    style=tour_data.get("style", ""),
                    transport=tour_data.get("transport", ""),
                    accommodation=tour_data.get("accommodation", ""),
                    meals=tour_data.get("meals", ""),
                    event_support=tour_data.get("event_support", ""),
                    tags=tour_data.get("tags", []),
                )
                
                # Store in databases
                TOURS_DB[idx] = tour
                
                # Create normalized name mapping using shared normalize function
                if tour.name:
                    norm_name = normalize_tour_key(tour.name)
                    TOUR_NAME_TO_INDEX[norm_name] = idx
                    logger.debug(f"üìå Indexed tour: '{norm_name}' -> idx {idx}")
                
                # Add to flat texts for FAISS
                flat_data = flatten_json({"tours": [tour_data]})
                if flat_data:
                    FLAT_TEXTS.extend([item["text"] for item in flat_data])
                    
            except Exception as e:
                logger.error(f"‚ùå Error processing tour {idx}: {e}")
                continue
        
        logger.info(f"‚úÖ Processed {len(TOURS_DB)} tours, {len(FLAT_TEXTS)} passages")
                # Log TOUR_NAME_TO_INDEX for debugging
        logger.info(f"‚úÖ TOUR_NAME_TO_INDEX initialized with {len(TOUR_NAME_TO_INDEX)} entries")
        # Log 5 t√™n ƒë·∫ßu ti√™n
        for i, (name, idx) in enumerate(list(TOUR_NAME_TO_INDEX.items())[:5]):
            logger.info(f"   {i+1}. '{name}' -> tour index {idx}")
        if len(TOURS_DB) == 0:
            logger.error("‚ùå NO tours loaded! Check knowledge.json structure")
            
    except Exception as e:
        logger.error(f"‚ùå load_knowledge error: {e}")
        traceback.print_exc()

def index_tour_names():
    """Build tour name to index mapping"""
    global TOUR_NAME_TO_INDEX
    TOUR_NAME_TO_INDEX = {}
    
    for m in MAPPING:
        if not isinstance(m, dict):
            continue  # defensive only
        
        path = m.get("path", "")
        if path.endswith(".tour_name"):
            txt = m.get("text", "") or ""
            norm = normalize_text_simple(txt)
            if not norm:
                continue
            
            match = re.search(r"\[(\d+)\]", path)
            if match:
                idx = int(match.group(1))
                prev = TOUR_NAME_TO_INDEX.get(norm)
                if prev is None:
                    TOUR_NAME_TO_INDEX[norm] = idx
                else:
                    # t√¨m tour_name c≈© ƒë·ªÉ so ƒë·ªô d√†i text
                    existing_txt = ""
                    for m2 in MAPPING:
                        if not isinstance(m2, dict):
                            continue
                        p2 = m2.get("path", "")
                        if (
                            re.search(rf"\[{prev}\]", p2)
                            and ".tour_name" in p2
                        ):
                            existing_txt = m2.get("text", "")
                            break
                    
                    if len(txt) > len(existing_txt):
                        TOUR_NAME_TO_INDEX[norm] = idx
    
    logger.info(f"üìù Indexed {len(TOUR_NAME_TO_INDEX)} tour names")


def build_tours_db():
    """Build structured tour database from MAPPING using Tour dataclass"""
    global TOURS_DB, TOUR_TAGS
    
    TOURS_DB.clear()
    TOUR_TAGS.clear()
    
    # First pass: collect all fields for each tour
    for m in MAPPING:
        if not isinstance(m, dict):
            continue  # defensive only
        
        path = m.get("path", "")
        text = m.get("text", "")
        
        if not path or not text:
            continue
        
        tour_match = re.search(r'tours\[(\d+)\]', path)
        if not tour_match:
            continue
        
        tour_idx = int(tour_match.group(1))
        
        field_match = re.search(
            r'tours\[\d+\]\.(\w+)(?:\[\d+\])?',
            path
        )
        if not field_match:
            continue
        
        field_name = field_match.group(1)

        
        # Initialize tour entry
        if tour_idx not in TOURS_DB:
            TOURS_DB[tour_idx] = Tour(index=tour_idx)
        
        # Update field in Tour object
        tour_obj = TOURS_DB[tour_idx]
        if field_name == 'tour_name':
            tour_obj.name = text
        elif field_name == 'duration':
            tour_obj.duration = text
        elif field_name == 'location':
            tour_obj.location = text
        elif field_name == 'price':
            tour_obj.price = text
        elif field_name == 'summary':
            tour_obj.summary = text
        elif field_name == 'includes':
            if isinstance(tour_obj.includes, list):
                tour_obj.includes.append(text)
            else:
                tour_obj.includes = [text]
        elif field_name == 'accommodation':
            tour_obj.accommodation = text
        elif field_name == 'meals':
            tour_obj.meals = text
        elif field_name == 'transport':
            tour_obj.transport = text
        elif field_name == 'notes':
            tour_obj.notes = text
        elif field_name == 'style':
            tour_obj.style = text
    
    # Second pass: generate tags and metadata
    for tour_idx, tour_obj in TOURS_DB.items():
        tags = []
        
        # Location tags
        if tour_obj.location:
            locations = [loc.strip() for loc in tour_obj.location.split(",") if loc.strip()]
            tags.extend([f"location:{loc}" for loc in locations[:2]])
        
        # Duration tags
        if tour_obj.duration:
            duration_lower = tour_obj.duration.lower()
            if "1 ng√†y" in duration_lower:
                tags.append("duration:1day")
            elif "2 ng√†y" in duration_lower:
                tags.append("duration:2day")
            elif "3 ng√†y" in duration_lower:
                tags.append("duration:3day")
            else:
                day_match = re.search(r'(\d+)\s*ng√†y', duration_lower)
                if day_match:
                    days = int(day_match.group(1))
                    tags.append(f"duration:{days}day")
        
        # Price tags
        if tour_obj.price:
            price_nums = re.findall(r'[\d,\.]+', tour_obj.price)
            if price_nums:
                try:
                    clean_nums = []
                    for p in price_nums[:2]:
                        p_clean = p.replace(',', '').replace('.', '')
                        if p_clean.isdigit():
                            clean_nums.append(int(p_clean))
                    
                    if clean_nums:
                        avg_price = sum(clean_nums) / len(clean_nums)
                        if avg_price < 1000000:
                            tags.append("price:budget")
                        elif avg_price < 2000000:
                            tags.append("price:midrange")
                        else:
                            tags.append("price:premium")
                except:
                    pass
        
        # Style/theme tags
        text_to_check = (tour_obj.style + " " + (tour_obj.summary or '')).lower()
        
        theme_keywords = {
            'meditation': ['thi·ªÅn', 'ch√°nh ni·ªám', 't√¢m linh'],
            'history': ['l·ªãch s·ª≠', 'di t√≠ch', 'chi·∫øn tranh', 'tri √¢n'],
            'nature': ['thi√™n nhi√™n', 'r·ª´ng', 'n√∫i', 'c√¢y'],
            'culture': ['vƒÉn h√≥a', 'c·ªông ƒë·ªìng', 'd√¢n t·ªôc'],
            'wellness': ['kh√≠ c√¥ng', 's·ª©c kh·ªèe', 'ch·ªØa l√†nh'],
            'adventure': ['phi√™u l∆∞u', 'm·∫°o hi·ªÉm', 'kh√°m ph√°'],
        }
        
        for theme, keywords in theme_keywords.items():
            if any(keyword in text_to_check for keyword in keywords):
                tags.append(f"theme:{theme}")
        
        # Destination tags from tour name
        if tour_obj.name:
            name_lower = tour_obj.name.lower()
            if "b·∫°ch m√£" in name_lower:
                tags.append("destination:bachma")
            if "tr∆∞·ªùng s∆°n" in name_lower:
                tags.append("destination:truongson")
            if "qu·∫£ng tr·ªã" in name_lower:
                tags.append("destination:quangtri")
            if "hu·∫ø" in name_lower:
                tags.append("destination:hue")
        
        # Update Tour object tags
        tour_obj.tags = list(set(tags))
        TOUR_TAGS[tour_idx] = tour_obj.tags
        
        # Calculate completeness score
        completeness = 0
        important_fields = ['name', 'duration', 'location', 'price', 'summary']
        for field in important_fields:
            if getattr(tour_obj, field, None):
                completeness += 1
        
        tour_obj.completeness_score = completeness / len(important_fields)
    
    logger.info(f"‚úÖ Built tours database: {len(TOURS_DB)} tours with tags")

def get_passages_by_field(field_name: str, limit: int = 50, 
                         tour_indices: Optional[List[int]] = None) -> List[Tuple[float, Dict]]:
    """
    Get passages for a specific field
    """
    exact_matches = []
    global_matches = []
    
    for m in MAPPING:
        if not isinstance(m, dict):
            continue  # defensive only

        path = m.get("path", "")
        if path.endswith(f".{field_name}") or f".{field_name}" in path:
            is_exact_match = False
            if tour_indices:
                for ti in tour_indices:
                    if f"[{ti}]" in path:
                        is_exact_match = True
                        break
            
            if is_exact_match:
                exact_matches.append((2.0, m))
            elif not tour_indices:
                global_matches.append((1.0, m))
    
    all_results = exact_matches + global_matches
    all_results.sort(key=lambda x: x[0], reverse=True)
    return all_results[:limit]


# =========== CACHE SYSTEM (DATACLASS COMPATIBLE) ===========
class CacheSystem:
    """Simple caching system for responses"""
    
    @staticmethod
    def get_cache_key(query: str, context_hash: str = "") -> str:
        """Generate cache key"""
        key_parts = [query]
        if context_hash:
            key_parts.append(context_hash)
        return hashlib.md5("|".join(key_parts).encode()).hexdigest()
    
    @staticmethod
    def get(key: str, ttl_seconds: int = 300):
        """Get item from cache"""
        with _cache_lock:
            if key in _response_cache:
                cache_entry = _response_cache[key]
                if not cache_entry.is_expired():
                    logger.info(f"üíæ Cache hit for key: {key[:20]}...")
                    return cache_entry.value
                else:
                    del _response_cache[key]
            return None
    
    @staticmethod
    def set(key: str, value: Any):
        """Set item in cache"""
        with _cache_lock:
            cache_entry = CacheEntry(
                key=key,
                value=value,
                created_at=datetime.utcnow(),
                ttl_seconds=UpgradeFlags.get_all_flags().get("CACHE_TTL_SECONDS", 300)
            )
            _response_cache[key] = cache_entry
            
            if len(_response_cache) > 1000:
                sorted_items = sorted(_response_cache.items(), 
                                     key=lambda x: x[1].created_at)
                for old_key in [k for k, _ in sorted_items[:200]]:
                    if old_key in _response_cache:
                        del _response_cache[old_key]

# =========== EMBEDDING FUNCTIONS (MEMORY OPTIMIZED) ===========
@lru_cache(maxsize=128 if IS_LOW_RAM else 1000)
def embed_text(text: str) -> Tuple[List[float], int]:
    """Embed text using OpenAI or fallback (with memory optimization)"""
    if not text:
        return [], 0
    
    text = text[:2000]
    
    if client:
        try:
            response = client.embeddings.create(
                model=EMBEDDING_MODEL,
                input=text
            )
            if response.data:
                embedding = response.data[0].embedding
                return embedding, len(embedding)
        except Exception as e:
            logger.error(f"OpenAI embedding error: {e}")
    
    # Fallback: deterministic hash-based embedding
    h = hash(text) % (10 ** 12)
    dim = 1536
    embedding = [(float((h >> (i % 32)) & 0xFF) + (i % 7)) / 255.0 
                 for i in range(dim)]
    
    return embedding, dim

def query_index(query: str, top_k: int = TOP_K) -> List[Tuple[float, Dict]]:
    """Query the index"""
    if not query or INDEX is None:
        return []
    
    emb, _ = embed_text(query)
    if not emb:
        return []
    
    vec = np.array(emb, dtype="float32").reshape(1, -1)
    vec = vec / (np.linalg.norm(vec) + 1e-12)
    
    try:
        if HAS_FAISS and isinstance(INDEX, faiss.Index):
            D, I = INDEX.search(vec, top_k)
        else:
            D, I = INDEX.search(vec, top_k)
        
        results = []
        for score, idx in zip(D[0], I[0]):
            if 0 <= idx < len(MAPPING):
                m = MAPPING[idx]
                if isinstance(m, dict):        # defensive only
                    results.append((float(score), m))
        
        return results
    except Exception as e:
        logger.error(f"Index search error: {e}")
        return []


class NumpyIndex:
    """Simple numpy-based index with safe numpy handling"""

    def __init__(self, mat=None):
        if NUMPY_AVAILABLE:
            if mat is None:
                self.mat = np.empty((0, 0), dtype="float32")
            else:
                # Force numpy float32 2D
                self.mat = np.asarray(mat, dtype="float32")
                if self.mat.ndim == 1:
                    self.mat = self.mat.reshape(1, -1)
        else:
            self.mat = mat if mat is not None else []

        # SAFE dimension detection (no numpy truth check)
        if NUMPY_AVAILABLE:
            if self.mat.shape[0] > 0 and self.mat.ndim == 2:
                self.dim = int(self.mat.shape[1])
            else:
                self.dim = 0
            self.size = int(self.mat.shape[0])
        else:
            self.size = len(self.mat)
            self.dim = len(self.mat[0]) if self.size > 0 else 0

    def is_empty(self):
        if NUMPY_AVAILABLE:
            return self.mat.shape[0] == 0
        return len(self.mat) == 0

    def search(self, query_vec, k=5):
        if self.is_empty():
            return [], []

        if NUMPY_AVAILABLE:
            q = np.asarray(query_vec, dtype="float32").reshape(1, -1)
            sims = np.dot(self.mat, q.T).reshape(-1)
            topk = np.argsort(-sims)[:k]
            return sims[topk].tolist(), topk.tolist()
        else:
            return [], []

    
    def search(self, qvec, k):
        if not self.mat or (NUMPY_AVAILABLE and self.mat.shape[0] == 0) or (not NUMPY_AVAILABLE and len(self.mat) == 0):
            # Return empty results
            return np.array([[]]), np.array([[]], dtype=np.int64)
        
        q = np.array(qvec).flatten()
        
        if NUMPY_AVAILABLE:
            # Use numpy if available
            q = q / (np.linalg.norm(q) + 1e-12)
            m = self.mat / (np.linalg.norm(self.mat, axis=1, keepdims=True) + 1e-12)
            sims = np.dot(q, m.T)
            idx = np.argsort(-sims)[:k]
            scores = sims[idx]
        else:
            # Fallback calculation
            q_norm = q / (sum(x*x for x in q)**0.5 + 1e-12)
            scores = []
            for i, row in enumerate(self.mat):
                row_norm = row / (sum(x*x for x in row)**0.5 + 1e-12)
                sim = sum(q_norm[j] * row_norm[j] for j in range(min(len(q_norm), len(row_norm))))
                scores.append((sim, i))
            
            scores.sort(key=lambda x: x[0], reverse=True)
            top_k = scores[:k]
            if top_k:
                scores_arr = np.array([s[0] for s in top_k])
                idx_arr = np.array([s[1] for s in top_k])
            else:
                scores_arr = np.array([])
                idx_arr = np.array([], dtype=np.int64)
            
            return scores_arr.reshape(1, -1), idx_arr.reshape(1, -1)
        
        return scores.reshape(1, -1), idx.reshape(1, -1)
    
    def save(self, path):
        if NUMPY_AVAILABLE:
            np.savez_compressed(path, mat=self.mat)
        else:
            logger.warning(f"‚ö†Ô∏è Cannot save index without NumPy: {path}")
    
    @classmethod
    def load(cls, path):
        if NUMPY_AVAILABLE:
            try:
                arr = np.load(path)
                return cls(arr['mat'])
            except Exception as e:
                logger.error(f"Failed to load numpy index: {e}")
                return cls()
        else:
            logger.warning(f"‚ö†Ô∏è Cannot load index without NumPy: {path}")
            return cls()

def build_index(force_rebuild: bool = False) -> bool:
    """Build or load FAISS/numpy index"""
    global INDEX, EMBEDDING_MODEL
    
    with INDEX_LOCK:
        # Try to load existing index
        if not force_rebuild:
            if FAISS_ENABLED and HAS_FAISS and os.path.exists(FAISS_INDEX_PATH):
                try:
                    INDEX = faiss.read_index(FAISS_INDEX_PATH)
                    logger.info(f"‚úÖ Loaded FAISS index from {FAISS_INDEX_PATH}")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load FAISS index: {e}")
            
            # Try numpy fallback
            if os.path.exists(FALLBACK_VECTORS_PATH):
                try:
                    arr = np.load(FALLBACK_VECTORS_PATH)
                    INDEX = NumpyIndex(arr['mat'])
                    logger.info("‚úÖ Loaded numpy index")
                    return True
                except Exception as e:
                    logger.warning(f"Failed to load numpy index: {e}")
        
        # Build new index
        if not FLAT_TEXTS:
            logger.warning("No texts to index")
            return False
        
        logger.info(f"üî® Building index for {len(FLAT_TEXTS)} passages...")
        
        # Generate embeddings
        vectors = []
        dims = None
        
        for text in FLAT_TEXTS:
            emb, d = embed_text(text)
            if emb:
                if dims is None:
                    dims = len(emb)
                vectors.append(np.array(emb, dtype="float32"))
        
        if not vectors:
            logger.error("No embeddings generated")
            return False
        
        # Create index
        mat = np.vstack(vectors)
        mat = mat / (np.linalg.norm(mat, axis=1, keepdims=True) + 1e-12)
        
        if FAISS_ENABLED and HAS_FAISS:
            INDEX = faiss.IndexFlatIP(dims)
            INDEX.add(mat)
            try:
                faiss.write_index(INDEX, FAISS_INDEX_PATH)
                logger.info(f"‚úÖ Saved FAISS index to {FAISS_INDEX_PATH}")
            except Exception as e:
                logger.error(f"Failed to save FAISS index: {e}")
        else:
            INDEX = NumpyIndex(mat)
            try:
                INDEX.save(FALLBACK_VECTORS_PATH)
                logger.info(f"‚úÖ Saved numpy index to {FALLBACK_VECTORS_PATH}")
            except Exception as e:
                logger.error(f"Failed to save numpy index: {e}")
        
        logger.info(f"‚úÖ Index built: {len(vectors)} vectors, {dims} dimensions")
        return True

# =========== HELPER FUNCTIONS ===========
def normalize_text_simple(s: str) -> str:
    """Basic text normalization"""
    if not s:
        return ""
    s = s.lower()
    s = unicodedata.normalize("NFD", s)
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
    s = re.sub(r"[^\w\s]", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def get_session_context(session_id: str) -> ConversationContext:
    """Get or create context for session using ConversationContext dataclass with auto-repair"""

    ctx = SESSION_CONTEXTS.get(session_id)

    if ctx is None:
        ctx = ConversationContext(session_id=session_id)
        SESSION_CONTEXTS[session_id] = ctx
        return ctx

    # ===== AUTO REPAIR FOR OLD CONTEXT OBJECTS =====
    if not hasattr(ctx, "last_tour_indices"):
        ctx.last_tour_indices = []

    if not hasattr(ctx, "current_tours"):
        ctx.current_tours = []

    if not hasattr(ctx, "mentioned_tours"):
        ctx.mentioned_tours = set()

    if not hasattr(ctx, "last_successful_tours"):
        ctx.last_successful_tours = []

    if not hasattr(ctx, "conversation_history"):
        ctx.conversation_history = []

    if not hasattr(ctx, "user_preferences"):
        ctx.user_preferences = {}

    return ctx


def extract_session_id(request_data: Dict, remote_addr: str) -> str:
    """Extract or create session ID"""
    session_id = request_data.get("session_id")
    if not session_id:
        ip = remote_addr or "0.0.0.0"
        current_hour = datetime.utcnow().strftime("%Y%m%d%H")
        unique_str = f"{ip}_{current_hour}"
        session_id = hashlib.md5(unique_str.encode()).hexdigest()[:12]
    return f"session_{session_id}"

def _prepare_llm_prompt(user_message: str, search_results: List, context: Dict) -> str:
    """Prepare prompt for LLM - TH√îNG MINH v·ªõi context & c√¢u h·ªèi chung"""
    
    message_lower = user_message.lower()
    
    # Ph√¢n lo·∫°i c√¢u h·ªèi
    is_general_question = any(keyword in message_lower for keyword in [
        'c√≥ bao g·ªìm', 'ƒë√£ bao g·ªìm', 'bao g·ªìm g√¨', 'bao g·ªìm nh·ªØng g√¨',
        'c√≥ g√¨', 'nh∆∞ th·∫ø n√†o', 'ra sao', 'th·∫ø n√†o', 'gi√° tour'
    ])
    
    has_specific_tour = context.get('current_tours') and len(context.get('current_tours', [])) > 0
    tour_count = len(context.get('current_tours', []))
    
    # Ph√°t hi·ªán c√¢u h·ªèi ti·∫øp theo (followup)
    is_followup = (
        context.get('last_action') == 'chat_response' and 
        (has_specific_tour or context.get('last_tour_name'))
    )
    
    # Ph√°t hi·ªán r√†ng bu·ªôc ƒë·ªãa l√Ω
    has_location_constraint = False
    location_constraint = None
    filters = context.get('filters', {})
    if filters:
        if filters.get('location'):
            has_location_constraint = True
            location_constraint = filters.get('location')
        elif filters.get('near_location'):
            has_location_constraint = True
            location_constraint = filters.get('near_location')
    
    prompt_parts = [
        "B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n du l·ªãch Ruby Wings - CHUY√äN NGHI·ªÜP, TH√îNG MINH, NHI·ªÜT T√åNH.",
        "",
        "‚ö†Ô∏è QUY T·∫ÆC NGHI√äM NG·∫∂T:",
    ]
    
    # RULE 1: C√¢u h·ªèi CHUNG (kh√¥ng c√≥ tour c·ª• th·ªÉ)
    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "",
            "üéØ ƒê√ÇY L√Ä C√ÇU H·ªéI CHUNG - KH√îNG C√ì TOUR C·ª§ TH·ªÇ:",
            "‚Ä¢ TR·∫¢ L·ªúI NG·∫ÆN G·ªåN (2-4 c√¢u) d·ª±a tr√™n ki·∫øn th·ª©c chung v·ªÅ tour du l·ªãch",
            "‚Ä¢ S·ª¨ D·ª§NG OPENAI ƒë·ªÉ tr·∫£ l·ªùi t·ª± nhi√™n, kh√¥ng n√≥i 'kh√¥ng c√≥ d·ªØ li·ªáu'",
            "‚Ä¢ K·∫æT TH√öC b·∫±ng c√¢u h·ªèi: 'B·∫°n quan t√¢m tour n√†o ƒë·ªÉ t√¥i t∆∞ v·∫•n chi ti·∫øt?'",
            "‚Ä¢ KH√îNG li·ªát k√™ tour, KH√îNG dump d·ªØ li·ªáu",
            "",
            "V√ç D·ª§ ƒê√öNG:",
            "Q: 'Gi√° tour bao g·ªìm g√¨?'",
            "A: 'Gi√° tour Ruby Wings th∆∞·ªùng bao g·ªìm: xe ƒë∆∞a ƒë√≥n, ƒÉn u·ªëng theo ch∆∞∆°ng tr√¨nh, kh√°ch s·∫°n, h∆∞·ªõng d·∫´n vi√™n v√† b·∫£o hi·ªÉm. T√πy tour c·ª• th·ªÉ c√≥ th·ªÉ c√≥ th√™m v√© tham quan ho·∫∑c ho·∫°t ƒë·ªông ƒë·∫∑c bi·ªát. B·∫°n quan t√¢m tour n√†o ƒë·ªÉ t√¥i t∆∞ v·∫•n chi ti·∫øt? üòä'",
            "",
            "Q: 'Tour c√≥ ph√π h·ª£p gia ƒë√¨nh kh√¥ng?'",
            "A: 'Ruby Wings c√≥ nhi·ªÅu tour ph√π h·ª£p gia ƒë√¨nh v·ªõi ho·∫°t ƒë·ªông nh·∫π nh√†ng, an to√†n cho tr·∫ª em v√† ng∆∞·ªùi l·ªõn tu·ªïi. Gia ƒë√¨nh b·∫°n c√≥ bao nhi√™u ng∆∞·ªùi v√† th√≠ch lo·∫°i h√¨nh n√†o (thi√™n nhi√™n, l·ªãch s·ª≠, ngh·ªâ d∆∞·ª°ng) ƒë·ªÉ t√¥i t∆∞ v·∫•n tour ph√π h·ª£p nh·∫•t?'",
        ])
    
    # RULE 2: C√¢u h·ªèi TI·∫æP THEO (followup)
    elif is_followup:
        prompt_parts.extend([
            "",
            "üí≠ ƒê√ÇY L√Ä C√ÇU H·ªéI TI·∫æP THEO - S·ª¨ D·ª§NG CONTEXT:",
            f"‚Ä¢ ƒê√£ b√†n v·ªÅ {tour_count} tour: {context.get('last_tour_name', '')}",
            "‚Ä¢ PH·∫¢I d·ª±a v√†o context c≈© - KH√îNG reset",
            "‚Ä¢ TR·∫¢ L·ªúI TI·∫æP theo ng·ªØ c·∫£nh ƒë√£ c√≥",
            "‚Ä¢ KH√îNG li·ªát k√™ l·∫°i to√†n b·ªô tour",
            "‚Ä¢ N·∫øu h·ªèi v·ªÅ gi√°/th·ªùi gian ‚Üí Ch·ªâ n√≥i v·ªÅ tour ƒëang b√†n",
            "‚Ä¢ N·∫øu h·ªèi th√™m ƒëi·ªÅu ki·ªán ‚Üí G·ª£i √Ω tour t·ª´ context ho·∫∑c h·ªèi l·∫°i",
            "",
            "V√ç D·ª§ ƒê√öNG:",
            "Context: ƒê√£ n√≥i v·ªÅ 'Tour B·∫°ch M√£'",
            "Q: 'Tour n√†y c√≥ ph√π h·ª£p nh√≥m 10 ng∆∞·ªùi kh√¥ng?'",
            "A: 'Tour B·∫°ch M√£ r·∫•t ph√π h·ª£p cho nh√≥m 10 ng∆∞·ªùi! Ch√∫ng t√¥i c√≥ th·ªÉ t·ªï ch·ª©c ri√™ng v·ªõi gi√° ∆∞u ƒë√£i. Nh√≥m b·∫°n th√≠ch ho·∫°t ƒë·ªông n√†o: trekking, thi·ªÅn tƒ©nh t√¢m hay c·∫£ hai? T√¥i s·∫Ω t∆∞ v·∫•n l·ªãch tr√¨nh chi ti·∫øt.'",
        ])
    
    # RULE 3: Location constraint
    if has_location_constraint:
        prompt_parts.extend([
            "",
            "üö® R√ÄNG BU·ªòC ƒê·ªäA L√ù - NGHI√äM NG·∫∂T:",
            f"‚Ä¢ Y√™u c·∫ßu tour g·∫ßn/t·∫°i: {location_constraint or 'khu v·ª±c c·ª• th·ªÉ'}",
            "‚Ä¢ CH·ªà ƒë·ªÅ xu·∫•t tour trong khu v·ª±c n√†y",
            "‚Ä¢ N·∫æU kh√¥ng c√≥ tour ph√π h·ª£p:",
            "  ‚Üí 'Hi·ªán Ruby Wings ch∆∞a c√≥ tour t·∫°i [ƒë·ªãa ƒëi·ªÉm]. Tuy nhi√™n, ch√∫ng t√¥i c√≥ tour g·∫ßn nh·∫•t t·∫°i [X].'",
            "  ‚Üí H·ªèi: 'B·∫°n c√≥ mu·ªën xem tour ·ªü khu v·ª±c l√¢n c·∫≠n kh√¥ng?'",
        ])
    
    # RULE 4: Gi·ªõi h·∫°n tour
    prompt_parts.extend([
        "",
        "üìä GI·ªöI H·∫†N TOUR (B·∫ÆT BU·ªòC):",
        "‚Ä¢ T·ªëi ƒëa 2-3 tour/c√¢u tr·∫£ l·ªùi",
        "‚Ä¢ M·ªñI tour ph·∫£i c√≥ L√ù DO r√µ r√†ng",
        "‚Ä¢ KH√îNG li·ªát k√™ >3 tour",
        "‚Ä¢ N·∫øu c√≥ nhi·ªÅu tour ph√π h·ª£p:",
        "  ‚Üí Ch·ªçn 2-3 TI√äU BI·ªÇU nh·∫•t",
        "  ‚Üí T√≥m t·∫Øt: 'C√≤n X tour kh√°c...'",
        "  ‚Üí H·ªèi: 'B·∫°n mu·ªën xem th√™m lo·∫°i n√†o?'",
    ])
    
    # CONTEXT INFO
    prompt_parts.extend([
        "",
        "üìö TH√îNG TIN NG·ªÆ C·∫¢NH:",
    ])
    
    if context.get('user_preferences'):
        prefs = []
        for k, v in context['user_preferences'].items():
            prefs.append(f"{k}: {v}")
        if prefs:
            prompt_parts.append(f"- S·ªü th√≠ch: {'; '.join(prefs)}")
    
    if context.get('current_tours'):
        tours_info = [f"{t['name']}" for t in context['current_tours'][:3]]
        if tours_info:
            prompt_parts.append(f"- Tour ƒë√£ b√†n: {', '.join(tours_info)}")
    
    if filters:
        filter_strs = []
        if filters.get('price_max'):
            filter_strs.append(f"gi√° <{filters['price_max']:,}ƒë")
        if filters.get('location'):
            filter_strs.append(f"V·ªä TR√ç: {filters['location']}")
        if filter_strs:
            prompt_parts.append(f"- R√†ng bu·ªôc: {'; '.join(filter_strs)}")
    
    # SEARCH RESULTS
    prompt_parts.append("")
    prompt_parts.append("üìù D·ªÆ LI·ªÜU T·ª™ H·ªÜ TH·ªêNG:")
    
    if search_results:
        for i, (score, passage) in enumerate(search_results[:5], 1):
            text = passage.get('text', '')[:250]
            prompt_parts.append(f"[{i}] {text}")
    else:
        prompt_parts.append("(Kh√¥ng c√≥ d·ªØ li·ªáu c·ª• th·ªÉ - s·ª≠ d·ª•ng ki·∫øn th·ª©c chung)")
    
    # Y√äU C·∫¶U TR·∫¢ L·ªúI
    prompt_parts.append("")
    prompt_parts.append("üí¨ Y√äU C·∫¶U TR·∫¢ L·ªúI:")
    
    if is_general_question and not has_specific_tour:
        prompt_parts.extend([
            "1. Tr·∫£ l·ªùi NG·∫ÆN G·ªåN (2-4 c√¢u) d·ª±a OpenAI",
            "2. KH√îNG n√≥i 'kh√¥ng c√≥ d·ªØ li·ªáu'",
            "3. K·∫øt th√∫c: H·ªèi l·∫°i ƒë·ªÉ x√°c ƒë·ªãnh tour",
        ])
    elif is_followup:
        prompt_parts.extend([
            "1. D·ª±a v√†o CONTEXT (tour ƒë√£ b√†n)",
            "2. Tr·∫£ l·ªùi TI·∫æP, KH√îNG reset",
            "3. T·ªëi ƒëa nh·∫Øc 1-2 tour t·ª´ context",
        ])
    else:
        prompt_parts.extend([
            "1. Ch·ªçn 2-3 tour v·ªõi L√ù DO r√µ",
            "2. KH√îNG >3 tour",
            "3. N·∫øu nhi·ªÅu: t√≥m t·∫Øt + h·ªèi ti·∫øp",
        ])
    
    prompt_parts.append("4. Lu√¥n k·∫øt th√∫c: C√¢u h·ªèi d·∫´n d·∫Øt ho·∫∑c 'üìû G·ªçi 0332510486'")
    
    return "\n".join(prompt_parts)

def _generate_fallback_response(user_message: str, search_results: List, tour_indices: List[int] = None) -> str:
    """Generate SMART fallback response - D√πng OpenAI khi c√≥, context-aware"""
    message_lower = user_message.lower()
    
    # ===== S·ª¨ D·ª§NG OPENAI N·∫æU C√ì =====
    if client and HAS_OPENAI:
        try:
            # Chu·∫©n b·ªã context
            context_parts = []
            
            # Th√¥ng tin tour n·∫øu c√≥
            if tour_indices and TOURS_DB:
                for idx in tour_indices[:2]:
                    tour = TOURS_DB.get(idx)
                    if tour:
                        context_parts.append(f"Tour: {tour.name}")
                        if tour.duration:
                            context_parts.append(f"Th·ªùi gian: {tour.duration}")
                        if tour.price:
                            context_parts.append(f"Gi√°: {tour.price}")
                        if tour.summary:
                            context_parts.append(f"M√¥ t·∫£: {tour.summary[:150]}")
            
            # D·ªØ li·ªáu search
            if search_results:
                for i, (score, passage) in enumerate(search_results[:3], 1):
                    text = passage.get('text', '')[:200]
                    if text:
                        context_parts.append(f"Th√¥ng tin {i}: {text}")
            
            # T·∫°o prompt th√¥ng minh
            context_str = "\n".join(context_parts) if context_parts else "Kh√¥ng c√≥ d·ªØ li·ªáu c·ª• th·ªÉ"
            
            prompt = f"""B·∫°n l√† t∆∞ v·∫•n vi√™n Ruby Wings chuy√™n nghi·ªáp.

TH√îNG TIN C√ì S·∫¥N:
{context_str}

Y√äU C·∫¶U TR·∫¢ L·ªúI:
1. N·∫øu c√≥ th√¥ng tin tour c·ª• th·ªÉ ‚Üí T∆∞ v·∫•n d·ª±a tr√™n ƒë√≥
2. N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu ‚Üí Tr·∫£ l·ªùi d·ª±a ki·∫øn th·ª©c chung v·ªÅ tour du l·ªãch
3. LU√îN k·∫øt th√∫c b·∫±ng c√¢u h·ªèi d·∫´n d·∫Øt ho·∫∑c "G·ªçi 0332510486"
4. Ng·∫Øn g·ªçn 2-4 c√¢u, nhi·ªát t√¨nh, t·ª± nhi√™n
5. KH√îNG n√≥i "kh√¥ng c√≥ d·ªØ li·ªáu", "xin l·ªói kh√¥ng t√¨m th·∫•y"

C√¢u h·ªèi c·ªßa kh√°ch: {user_message}"""

            response = client.chat.completions.create(
                model=CHAT_MODEL,
                messages=[
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.6,
                max_tokens=300
            )
            
            if response.choices:
                reply = response.choices[0].message.content or ""
                # ƒê·∫£m b·∫£o c√≥ hotline
                if "0332510486" not in reply:
                    reply += "\n\nüìû Li√™n h·ªá 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt!"
                return reply
        
        except Exception as e:
            logger.error(f"OpenAI fallback error: {e}")
            # R∆°i xu·ªëng logic template b√™n d∆∞·ªõi
    
    # ===== FALLBACK KHI KH√îNG C√ì OPENAI =====
    
    # C√≥ tour c·ª• th·ªÉ ‚Üí Tr·∫£ th√¥ng tin tour
    if tour_indices and TOURS_DB:
        response_parts = []
        for idx in tour_indices[:2]:
            tour = TOURS_DB.get(idx)
            if tour:
                response_parts.append(f"**{tour.name}**")
                if tour.duration:
                    response_parts.append(f"‚è±Ô∏è {tour.duration}")
                if tour.location:
                    response_parts.append(f"üìç {tour.location}")
                if tour.price:
                    response_parts.append(f"üí∞ {tour.price}")
                if tour.summary:
                    response_parts.append(f"üìù {tour.summary[:150]}...")
        
        if response_parts:
            return "\n".join(response_parts) + "\n\nüìû G·ªçi 0332510486 ƒë·ªÉ bi·∫øt th√™m!"
    
    # C√≥ search results ‚Üí T√≥m t·∫Øt
    if search_results:
        top_results = search_results[:2]
        response_parts = ["Th√¥ng tin li√™n quan:"]
        
        for i, (score, passage) in enumerate(top_results, 1):
            text = passage.get('text', '')[:150]
            if text:
                response_parts.append(f"\n{i}. {text}...")
        
        response_parts.append("\n\nüìû Li√™n h·ªá 0332510486 ƒë·ªÉ bi·∫øt chi ti·∫øt!")
        return "".join(response_parts)
    
    # C√¢u h·ªèi chung ‚Üí Template th√¥ng minh theo keyword
    general_qa = {
        'bao g·ªìm': "Gi√° tour Ruby Wings th∆∞·ªùng bao g·ªìm: xe ƒë∆∞a ƒë√≥n, ƒÉn u·ªëng theo ch∆∞∆°ng tr√¨nh, kh√°ch s·∫°n, h∆∞·ªõng d·∫´n vi√™n v√† b·∫£o hi·ªÉm. T√πy tour c·ª• th·ªÉ c√≥ th√™m ho·∫°t ƒë·ªông ƒë·∫∑c bi·ªát. B·∫°n quan t√¢m tour n√†o ƒë·ªÉ t√¥i t∆∞ v·∫•n chi ti·∫øt? üòä",
        
        'ph√π h·ª£p gia ƒë√¨nh': "Ruby Wings c√≥ nhi·ªÅu tour ph√π h·ª£p gia ƒë√¨nh v·ªõi ho·∫°t ƒë·ªông nh·∫π nh√†ng, an to√†n cho tr·∫ª em v√† ng∆∞·ªùi l·ªõn tu·ªïi. Gia ƒë√¨nh b·∫°n bao nhi√™u ng∆∞·ªùi v√† th√≠ch lo·∫°i tour n√†o (thi√™n nhi√™n, l·ªãch s·ª≠, ngh·ªâ d∆∞·ª°ng)?",
        
        'ph√π h·ª£p': "Ruby Wings c√≥ tour cho m·ªçi ƒë·ªëi t∆∞·ª£ng! B·∫°n ƒëi nh√≥m bao nhi√™u ng∆∞·ªùi v√† c√≥ s·ªü th√≠ch g√¨ ƒë·∫∑c bi·ªát kh√¥ng?",
        
        'gi√°': "Gi√° tour Ruby Wings t·ª´ 800.000ƒë - 3.000.000ƒë t√πy lo·∫°i. B·∫°n c√≥ ng√¢n s√°ch kho·∫£ng bao nhi√™u v√† mu·ªën ƒëi m·∫•y ng√†y ƒë·ªÉ t√¥i t∆∞ v·∫•n ph√π h·ª£p?",
        
        'th·ªùi gian': "Ruby Wings c√≥ tour 1 ng√†y, 2 ng√†y 1 ƒë√™m, 3 ng√†y 2 ƒë√™m. B·∫°n c√≥ kho·∫£ng bao nhi√™u th·ªùi gian r·∫£nh?",
        
        'ƒë·ªãa ƒëi·ªÉm': "Ruby Wings t·ªï ch·ª©c tour t·∫°i Hu·∫ø, Qu·∫£ng Tr·ªã, B·∫°ch M√£, Tr∆∞·ªùng S∆°n v√† nhi·ªÅu n∆°i kh√°c. B·∫°n mu·ªën kh√°m ph√° khu v·ª±c n√†o?",
        
        'nh√≥m': "Tour nh√≥m c·ªßa Ruby Wings r·∫•t ph√π h·ª£p! Nh√≥m b·∫°n bao nhi√™u ng∆∞·ªùi v√† th√≠ch ho·∫°t ƒë·ªông g√¨ (teambuilding, ngh·ªâ d∆∞·ª°ng, kh√°m ph√°)?",
        
        'retreat': "Ruby Wings chuy√™n tour retreat k·∫øt h·ª£p thi·ªÅn, kh√≠ c√¥ng v√† thi√™n nhi√™n. B·∫°n mu·ªën tour bao nhi√™u ng√†y v√† m·ª©c ƒë·ªô ho·∫°t ƒë·ªông nh∆∞ n√†o?",
    }
    
    # T√¨m keyword match
    for keyword, response in general_qa.items():
        if keyword in message_lower:
            return response
    
    # Default - D·∫´n d·∫Øt h·ªèi l·∫°i
    return "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n t√¨m tour ph√π h·ª£p! B·∫°n c√≥ th·ªÉ cho t√¥i bi·∫øt:\n" \
           "‚Ä¢ Mu·ªën ƒëi ƒë√¢u?\n" \
           "‚Ä¢ Th·ªùi gian bao l√¢u?\n" \
           "‚Ä¢ Ng√¢n s√°ch kho·∫£ng bao nhi√™u?\n" \
           "‚Ä¢ ƒêi bao nhi√™u ng∆∞·ªùi?\n\n" \
           "Ho·∫∑c g·ªçi ngay 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt! üòä"

@app.route("/chat", methods=["POST"])
def chat_endpoint_ultimate():
    """
    Main chat endpoint v·ªõi x·ª≠ l√Ω AI th√¥ng minh, context-aware m·∫°nh m·∫Ω
    X·ª≠ l√Ω m·ªçi lo·∫°i c√¢u h·ªèi t·ª´ ƒë∆°n gi·∫£n ƒë·∫øn ph·ª©c t·∫°p
    """
    start_time = time.time()
    
    try:
        # ================== INITIALIZATION ==================
        data = request.get_json() or {}
        user_message = (data.get("message") or "").strip()
        
        # FIX: KH·ªûI T·∫†O BI·∫æN TR∆Ø·ªöC KHI LOG
        tour_indices = []
        direct_tour_matches = []
        detected_intents = []
        
        # LOG - CH·ªà LOG NH·ªÆNG TH√îNG TIN ƒê√É C√ì S·∫¥N
        # logger.info(f"üîç Chat request: '{user_message}'")
        # logger.info(f"üìä TOURS_DB count: {len(TOURS_DB)}")
        # logger.info(f"üìä FAISS index count: {len(FLAT_TEXTS) if FLAT_TEXTS else 0}")
        
        session_id = extract_session_id(data, request.remote_addr)
        
        if not user_message:
            return jsonify({
                "reply": "üëã **Xin ch√†o! T√¥i l√† tr·ª£ l√Ω AI c·ªßa Ruby Wings Travel**\n\n"
                        "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\n"
                        "‚Ä¢ T√¨m hi·ªÉu v·ªÅ 32 tour tr·∫£i nghi·ªám ƒë·∫∑c s·∫Øc\n"
                        "‚Ä¢ So s√°nh c√°c tour ƒë·ªÉ ch·ªçn ph√π h·ª£p nh·∫•t\n"
                        "‚Ä¢ T∆∞ v·∫•n tour theo nhu c·∫ßu gia ƒë√¨nh, nh√≥m, c√° nh√¢n\n"
                        "‚Ä¢ Cung c·∫•p th√¥ng tin chi ti·∫øt v·ªÅ gi√°, l·ªãch tr√¨nh, ƒë·ªãa ƒëi·ªÉm\n\n"
                        "üìû **Hotline t∆∞ v·∫•n 24/7:** 0332510486\n"
                        "üí° **H·ªèi ngay:** 'Tour n√†o ph√π h·ª£p cho gia ƒë√¨nh?', 'Tour B·∫°ch M√£ gi√° bao nhi√™u?'",
                "sources": [],
                "context": {},
                "processing_time": 0
            })
        
        # ================== CONTEXT MANAGEMENT SYSTEM ==================
        context = get_session_context(session_id)
        
        # Kh·ªüi t·∫°o context n·∫øu ch∆∞a c√≥
        if not hasattr(context, 'conversation_history'):
            context.conversation_history = []
        if not hasattr(context, 'current_tour'):
            context.current_tour = None
        if not hasattr(context, 'user_profile'):
            context.user_profile = {}
        
        # L∆∞u user message v√†o history
        context.conversation_history.append({
            'role': 'user',
            'message': user_message,
            'timestamp': datetime.utcnow().isoformat()
        })
        
        # Gi·ªõi h·∫°n history (gi·ªØ 10 tin nh·∫Øn g·∫ßn nh·∫•t)
        if len(context.conversation_history) > 20:
            context.conversation_history = context.conversation_history[-10:]
        
        # ================== AI-POWERED CONTEXT ANALYSIS ==================
        message_lower = user_message.lower()
        message_norm = normalize_tour_key(user_message)
        # FOLLOW-UP CONTEXT MEMORY
        followup_keywords = [
            'gi√° tour', 'gi√°', 'ch∆∞∆°ng tr√¨nh', 'l·ªãch tr√¨nh', 'chi ti·∫øt tour',
            'tour n√†y', 'tour do', 'gi√° tour n√†y'
        ]
        is_followup_tour_question = any(k in message_lower for k in followup_keywords)
        

        # L∆∞u √Ω: tour_indices ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o [] ·ªü ƒë·∫ßu h√†m.
        if is_followup_tour_question and not tour_indices:
            last_tour_idx = getattr(context, 'current_tour', None)
            if isinstance(last_tour_idx, int) and last_tour_idx in TOURS_DB:
                tour_indices = [last_tour_idx]
                logger.info(f"üß† Reuse context.current_tour={last_tour_idx} for follow-up")
        # Ph√¢n t√≠ch c·∫•p ƒë·ªô ph·ª©c t·∫°p
        complexity_score = 0
        complexity_indicators = {
            'v√†': 1, 'cho': 1, 'v·ªõi': 1, 'nh∆∞ng': 2, 'tuy nhi√™n': 2,
            'n·∫øu': 2, 'khi': 1, 'ƒë·ªÉ': 1, 'm√†': 1, 'ho·∫∑c': 1
        }
        
        for indicator, weight in complexity_indicators.items():
            if indicator in message_lower:
                complexity_score += weight
        
        # ================== SMART INTENT DETECTION ==================
        intent_categories = {
            'tour_listing': ['c√≥ nh·ªØng tour n√†o','co nhung tour nao','co tour nao','danh s√°ch tour','li·ªát k√™ tour','tour n√†o c√≥','c√°c tour hi·ªán c√≥','t·ªïng h·ª£p tour','to√†n b·ªô tour','tour ƒëang m·ªü','tour ƒëang c√≥','c√≥ tour g√¨','hi·ªán c√≥ tour g√¨','xem danh s√°ch tour','cho xem tour','c√°c ch∆∞∆°ng tr√¨nh tour','c√°c h√†nh tr√¨nh ƒëang ch·∫°y','tour ruby wings c√≥ g√¨'],
            'price_inquiry': ['gi√° bao nhi√™u','gia bao nhieu','bao nhi√™u ti·ªÅn','bao nhieu tien','chi ph√≠','chi phi','gi√° tour','gia tour','gi√° ch∆∞∆°ng tr√¨nh','gia chuong trinh','gi√° h√†nh tr√¨nh','gia hanh trinh','gi√° ƒëi','gia di','m·ª©c gi√°','muc gia','gi√° nh∆∞ th·∫ø n√†o','gia nhu the nao','gi√° kho·∫£ng bao nhi√™u','gia khoang bao nhieu','t·ªën bao nhi√™u','ton bao nhieu'],
            'tour_detail': ['chi ti·∫øt tour','chi tiet tour','l·ªãch tr√¨nh','lich trinh','ch∆∞∆°ng tr√¨nh','chuong trinh','tour c√≥ g√¨','c√≥ nh·ªØng g√¨','bao g·ªìm g√¨','bao gom gi','trong tour c√≥ g√¨','n·ªôi dung tour','noi dung tour','c√°c ho·∫°t ƒë·ªông','hoat dong gi','ƒëi nh·ªØng ƒë√¢u','di nhung dau','tham quan nh·ªØng ƒë√¢u','tham quan gi','tour g·ªìm nh·ªØng g√¨'],
            'comparison': ['so s√°nh','so sanh','kh√°c nhau','khac nhau','so v·ªõi','so voi','so s√°nh gi·ªØa','so sanh giua','ƒëi·ªÉm kh√°c nhau','diem khac nhau','kh√°c g√¨','khac gi','so s√°nh tour','so sanh tour','so s√°nh ch∆∞∆°ng tr√¨nh','so sanh chuong trinh'],
            'recommendation': ['ph√π h·ª£p','phu hop','g·ª£i √Ω','goi y','ƒë·ªÅ xu·∫•t','de xuat','t∆∞ v·∫•n','tu van','n√™n ƒëi','nen di','n√™n ch·ªçn tour n√†o','nen chon tour nao','t∆∞ v·∫•n gi√∫p','tu van giup','g·ª£i √Ω gi√∫p','goi y giup','ph√π h·ª£p v·ªõi t√¥i','phu hop voi toi','tour n√†o ph√π h·ª£p','tour nao phu hop'],
            'booking_info': ['ƒë·∫∑t tour','dat tour','ƒëƒÉng k√Ω','dang ky','booking','gi·ªØ ch·ªó','giu cho','ƒë·∫∑t ch·ªó','dat cho','ƒëƒÉng k√Ω tour','dang ky tour','booking tour','gi·ªØ su·∫•t','giu suat','ƒë·∫∑t l·ªãch ƒëi','dat lich di','c√°ch ƒë·∫∑t tour','cach dat tour','ƒëƒÉng k√Ω nh∆∞ th·∫ø n√†o','dang ky nhu the nao'],
            'policy': ['ch√≠nh s√°ch','chinh sach','gi·∫£m gi√°','giam gia','∆∞u ƒë√£i','uu dai','khuy·∫øn m√£i','khuyen mai','ch√≠nh s√°ch tour','chinh sach tour','ch√≠nh s√°ch h·ªßy','chinh sach huy','ch√≠nh s√°ch ho√†n','chinh sach hoan','ƒëi·ªÅu kho·∫£n','dieu khoan','ƒëi·ªÅu ki·ªán √°p d·ª•ng','dieu kien ap dung','∆∞u ƒë√£i hi·ªán c√≥','uu dai hien co','ch∆∞∆°ng tr√¨nh khuy·∫øn m√£i','chuong trinh khuyen mai'],
            'general_info': ['gi·ªõi thi·ªáu','gioi thieu','l√† g√¨','la gi','th·∫ø n√†o','the nao','ra sao','th√¥ng tin chung','thong tin chung','n√≥i v·ªÅ','noi ve','t√¨m hi·ªÉu','tim hieu','gi·ªõi thi·ªáu chung','gioi thieu chung','th√¥ng tin c∆° b·∫£n','thong tin co ban','cho bi·∫øt th√™m','cho biet them'],
            'location_info': ['·ªü ƒë√¢u','ƒë·ªãa ƒëi·ªÉm','ƒë·∫øn ƒë√¢u','v·ªã tr√≠','Qu·∫£ng Tr·ªã','Th·ªã x√£ Qu·∫£ng Tr·ªã','Th√†nh c·ªï Qu·∫£ng Tr·ªã','ƒê√¥ng H√†','Vƒ©nh Linh','Gio Linh','Hi·ªÅn L∆∞∆°ng','B·∫øn H·∫£i','Vƒ© tuy·∫øn 17','H∆∞·ªõng H√≥a','Khe Sanh','Lao B·∫£o','Tr∆∞·ªùng S∆°n','T√¢y Tr∆∞·ªùng S∆°n','Nghƒ©a trang Li·ªát sƒ© Tr∆∞·ªùng S∆°n','Nghƒ©a trang Li·ªát sƒ© Qu·ªëc gia Tr∆∞·ªùng S∆°n','Nh√† t√π Lao B·∫£o','S√¢n bay T√† C∆°n','B·∫£o t√†ng Khe Sanh','R√†o Qu√°n','H·ªì R√†o Qu√°n','ƒêakr√¥ng','La Vang','DMZ','V·ªãnh M·ªëc','ƒê·ªãa ƒë·∫°o V·ªãnh M·ªëc','C·ª≠a Vi·ªát','C·∫£ng C·ª≠a Vi·ªát','ƒê·∫£o C·ªìn C·ªè','C·ªìn C·ªè','Vƒ©nh M·ªëc','Hu·∫ø','Th√†nh ph·ªë Hu·∫ø','ƒê·∫°i N·ªôi Hu·∫ø','Ch√πa Thi√™n M·ª•','Ch√πa T·ª´ Hi·∫øu','R√∫ Ch√°','ƒê·∫ßm Chu·ªìn','Ph√° Tam Giang','Qu·∫£ng B√¨nh','ƒê·ªìng H·ªõi','Phong Nha','ƒê·ªông Phong Nha','V≈©ng Ch√πa','Nh·∫≠t L·ªá','H√† N·ªôi','Ninh B√¨nh','Tr√†ng An','Tam C·ªëc','B√°i ƒê√≠nh','H·∫° Long','B√£i Ch√°y','Qu·∫£ng Nam','H·ªôi An','R·ª´ng d·ª´a B·∫£y M·∫´u','ƒê√† N·∫µng','Ng≈© H√†nh S∆°n','Sa Pa','Fansipan','L√†o Cai','Ph√∫ Th·ªç','ƒê·ªÅn H√πng','TP.HCM','Th√†nh ph·ªë H·ªì Ch√≠ Minh','B√¨nh D∆∞∆°ng','ƒê·∫°i Nam','C·∫ßn Th∆°','S√≥c TrƒÉng','C√† Mau','ƒê·∫•t M≈©i','ƒê·ªìng Th√°p','Nha Trang','ƒê√† L·∫°t','Bu√¥n Ma Thu·ªôt','Quy Nh∆°n','Ph√∫ Y√™n','Tuy H√≤a','Tam ƒê·∫£o','M·ªôc Ch√¢u','S∆°n La','Ph√∫ Qu·ªëc','H√≤n Th∆°m'],
            'time_info': ['khi n√†o','th·ªùi gian','bao l√¢u','m·∫•y ng√†y','m·∫•y ƒë√™m','ƒëi m·∫•y ng√†y','ƒëi bao l√¢u','th·ªùi l∆∞·ª£ng','ng√†y n√†o','bao gi·ªù','m·∫•y h√¥m','th·ªùi gian ƒëi','th·ªùi gian tour','k√©o d√†i bao l√¢u'],
            'weather_info': ['th·ªùi ti·∫øt','thoi tiet','kh√≠ h·∫≠u','khi hau','n·∫Øng m∆∞a','nang mua','th·ªùi ti·∫øt th·∫ø n√†o','thoi tiet the nao','tr·ªùi c√≥ m∆∞a kh√¥ng','troi co mua khong','th·ªùi ti·∫øt c√≥ t·ªët kh√¥ng','thoi tiet co tot khong','m√πa n√†o ƒë·∫πp','mua nao dep','th·ªùi ti·∫øt khi ƒëi','thoi tiet khi di','ƒëi m√πa n√†o','di mua nao'],
            'food_info': ['·∫©m th·ª±c','am thuc','m√≥n ƒÉn','mon an','ƒë·∫∑c s·∫£n','dac san','ƒë·ªì ƒÉn','do an','ƒÉn g√¨','an gi','ƒÉn u·ªëng','an uong','·∫©m th·ª±c ƒë·ªãa ph∆∞∆°ng','am thuc dia phuong','ƒë·∫∑c s·∫£n v√πng','dac san vung','b·ªØa ƒÉn trong tour','bua an trong tour','tour ƒÉn g√¨','tour an gi'],
            'culture_info': ['vƒÉn h√≥a','van hoa','l·ªãch s·ª≠','lich su','truy·ªÅn th·ªëng','truyen thong','di t√≠ch','di tich','gi√° tr·ªã vƒÉn h√≥a','gia tri van hoa','gi√° tr·ªã l·ªãch s·ª≠','gia tri lich su','vƒÉn h√≥a ƒë·ªãa ph∆∞∆°ng','van hoa dia phuong','√Ω nghƒ©a l·ªãch s·ª≠','y nghia lich su','di s·∫£n','di san'],
            'wellness_info': ['thi·ªÅn','thien','yoga','ch·ªØa l√†nh','chua lanh','s·ª©c kh·ªèe','suc khoe','chƒÉm s√≥c s·ª©c kh·ªèe','cham soc suc khoe','thi·ªÅn ƒë·ªãnh','thien dinh','kh√≠ c√¥ng','khi cong','retreat','tr·ªã li·ªáu','tri lieu','ph·ª•c h·ªìi nƒÉng l∆∞·ª£ng','phuc hoi nang luong'],
            'group_info': ['nh√≥m','nhom','ƒëo√†n','doan','c√¥ng ty','cong ty','gia ƒë√¨nh','gia dinh','ƒëi theo nh√≥m','di theo nhom','ƒëi theo ƒëo√†n','di theo doan','ƒëo√†n ƒë√¥ng','doan dong','tour cho nh√≥m','tour cho doan','tour gia ƒë√¨nh','tour cong ty','ƒëo√†n bao nhi√™u ng∆∞·ªùi','doan bao nhieu nguoi'],
            'custom_request': ['t√πy ch·ªânh','tuy chinh','ri√™ng','tour ri√™ng','ca nhan hoa','c√° nh√¢n h√≥a','theo y√™u c·∫ßu','theo yeu cau','thi·∫øt k·∫ø ri√™ng','thiet ke rieng','l√†m tour ri√™ng','lam tour rieng','tour thi·∫øt k·∫ø','tour thiet ke','ch·ªânh theo nhu c·∫ßu','chinh theo nhu cau'],
}

        
        detected_intents = []
        for intent, keywords in intent_categories.items():
            for keyword in keywords:
                kw_norm = normalize_tour_key(keyword)
                if keyword in message_lower or (kw_norm and kw_norm in message_norm):
                    detected_intents.append(intent)
                    break
        
                # ================== TOUR RESOLUTION ENGINE ==================
        # FIX: KH·ªûI T·∫†O L·∫†I ƒê·ªÇ ƒê·∫¢M B·∫¢O S·∫†CH
        tour_indices = []
        direct_tour_matches = []
        
        # Strategy 1: Direct tour name matching (normalized resolver)
        logger.info(f"üîé Calling resolve_best_tour_indices with message: '{user_message}'")
        direct_tour_matches = resolve_best_tour_indices(user_message, top_k=5)
        logger.info(f"üìå direct_tour_matches = {direct_tour_matches}")
        if direct_tour_matches:
            tour_indices = direct_tour_matches[:3]
            logger.info(f"üéØ Direct tour matches found: {tour_indices}")

        # N·∫øu kh√¥ng match ƒë∆∞·ª£c tour m·ªõi, d√πng tour g·∫ßn nh·∫•t trong context cho follow-up
        if is_followup_tour_question and not tour_indices:
            last_tour_idx = getattr(context, 'current_tour', None)
            if isinstance(last_tour_idx, int) and last_tour_idx in TOURS_DB:
                tour_indices = [last_tour_idx]
                logger.info(f"üß† Reuse context.current_tour={last_tour_idx} for follow-up")
        # Strategy 3: Filter-based search
        mandatory_filters = FilterSet()
        if UpgradeFlags.is_enabled("1_MANDATORY_FILTER"):
            mandatory_filters = MandatoryFilterSystem.extract_filters(user_message)
            
            if not mandatory_filters.is_empty():
                filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                if filtered_indices:
                    if tour_indices:
                        # K·∫øt h·ª£p k·∫øt qu·∫£
                        combined = list(set(tour_indices) & set(filtered_indices))
                        tour_indices = combined if combined else filtered_indices[:3]
                    else:
                        tour_indices = filtered_indices[:5]  # Gi·ªõi h·∫°n 5 tour
                    logger.info(f"üéØ Filter-based search: {len(tour_indices)} tours")
        
    
        
        # LOG K·∫æT QU·∫¢ SAU KHI ƒê√É X·ª¨ L√ù XONG
        logger.info(f"üéØ Direct tour matches: {direct_tour_matches}")
        logger.info(f"üéØ Final tour indices: {tour_indices}")
        logger.info(f"üéØ Detected intents: {detected_intents}")


        
                # ================== INTELLIGENT RESPONSE GENERATION ==================
        reply = ""
        sources = []
        response_locked = False
                # ================== PRIORITY PRICE HANDLER ==================
        # X·ª≠ l√Ω tr·ª±c ti·∫øp c√¢u h·ªèi v·ªÅ gi√° tour khi ƒë√£ x√°c ƒë·ªãnh ƒë∆∞·ª£c tour c·ª• th·ªÉ
        if not response_locked and tour_indices:
            price_keywords = ['gi√° bao nhi√™u', 'bao nhi√™u ti·ªÅn', 'gi√° tour', 'gi√°', 'chi ph√≠']
            if any(kw in message_lower for kw in price_keywords):
                tour = TOURS_DB.get(tour_indices[0])
                if tour and tour.price:
                    reply = f"üí∞ **GI√Å TOUR: {tour.name}** üí∞\n\n{tour.price}"
                    reply += "\n\nüìû **Hotline t∆∞ v·∫•n 24/7:** 0332510486"
                    response_locked = True
                    logger.info(f"üí∞ PRIORITY PRICE HANDLER: tr·∫£ gi√° cho tour index {tour_indices[0]}")
        # ================== FIELD-SPECIFIC RESPONSE (UPGRADE 3) ==================
        # ∆Øu ti√™n tr·∫£ l·ªùi ch√≠nh x√°c tr∆∞·ªùng d·ªØ li·ªáu kh√°ch ƒëang h·ªèi
        if UpgradeFlags.is_enabled("3_ENHANCED_FIELDS") and tour_indices:
            field_name, confidence, _ = EnhancedFieldDetector.detect_field_with_confidence(user_message)
            if field_name and confidence >= 0.6:
                tour = TOURS_DB.get(tour_indices[0])
                if tour:
                    formatter_map = {
                        'price': format_tour_price_response,
                        'location': format_tour_location_response,
                        'duration': format_tour_duration_response,
                        'includes': format_tour_includes_response,
                        'notes': format_tour_notes_response,
                        'style': format_tour_style_response,
                        'transport': format_tour_transport_response,
                        'accommodation': format_tour_accommodation_response,
                        'meals': format_tour_meals_response,
                        'event_support': format_tour_event_support_response,
                        'summary': format_tour_program_response,
                    }
                    if field_name in formatter_map:
                        formatted = formatter_map[field_name](tour)
                        if formatted:
                            reply = formatted
                            if "0332510486" not in reply:
                                reply += "\n\nüìû **Hotline t∆∞ v·∫•n 24/7:** 0332510486"
                            response_locked = True
                            logger.info(f"üéØ Field-specific response for '{field_name}' (confidence: {confidence:.2f})")
                        else:
                            # Tr∆∞·ªùng h·ª£p kh√¥ng c√≥ d·ªØ li·ªáu cho field n√†y
                            tour_name = getattr(tour, 'name', 'tour n√†y')
                            reply = f"‚ùå **Hi·ªán t·∫°i t√¥i ch∆∞a c√≥ th√¥ng tin v·ªÅ {field_name} c·ªßa {tour_name}.**\n\nüìû Vui l√≤ng li√™n h·ªá hotline **0332510486** ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ chi ti·∫øt."
                            response_locked = True
                            logger.warning(f"‚ö†Ô∏è No data for field '{field_name}' of tour index {tour_indices[0]}")
        # ================== INTELLIGENT RESPONSE GENERATION ==================
        reply = ""
        sources = []
        response_locked = False
        if any(k in message_lower for k in ['ch∆∞∆°ng tr√¨nh', 'l·ªãch tr√¨nh', 'chi ti·∫øt tour']) and tour_indices:
            selected_tour = TOURS_DB.get(tour_indices[0])
            if selected_tour:
                reply = format_tour_program_response(selected_tour)
                response_locked = True
        
        # üîπ CASE 1: LISTING TOURS
        if (not response_locked) and ('tour_listing' in detected_intents or any(keyword in message_lower for keyword in ['c√≥ nh·ªØng tour n√†o', 'danh s√°ch tour', 'li·ªát k√™ tour', 'tour n√†o c√≥'])):
            
            # T·∫ÆT T·∫†M MANDATORY FILTER ƒê·ªÇ TEST
            # use_filters = UpgradeFlags.is_enabled("1_MANDATORY_FILTER") and not mandatory_filters.is_empty()
            use_filters = False  # T·∫Øt filter t·∫°m th·ªùi
            
            if use_filters:
                # S·ª≠ d·ª•ng filter n·∫øu c√≥
                filtered_indices = MandatoryFilterSystem.apply_filters(TOURS_DB, mandatory_filters)
                all_tours = [TOURS_DB[idx] for idx in filtered_indices if idx in TOURS_DB]
                logger.info(f"üéØ Filter-based search: {len(all_tours)} tours")
            else:
                # L·∫•y T·∫§T C·∫¢ tours t·ª´ database
                all_tours = list(TOURS_DB.values())
                logger.info(f"üéØ Getting ALL tours: {len(all_tours)} tours")
            
            # Apply deduplication (normalized)
            if UpgradeFlags.is_enabled("2_DEDUPLICATION") and all_tours:
                seen_keys = set()
                unique_tours = []
                for tour in all_tours:
                    try:
                        key = normalize_tour_key(getattr(tour, "name", ""))
                    except Exception:
                        key = (getattr(tour, "name", "") or "").strip().lower()
                    if key and key not in seen_keys:
                        seen_keys.add(key)
                        unique_tours.append(tour)
                all_tours = unique_tours
            
            total_tours = len(all_tours)
            
            # Debug log
            logger.info(f"üìä Total tours after processing: {total_tours}")
            
            if total_tours == 0:
                # Fallback: hi·ªÉn th·ªã 5 tour ƒë·∫ßu ti√™n t·ª´ database
                all_tours = list(TOURS_DB.values())[:5]
                total_tours = len(all_tours)
                logger.warning(f"‚ö†Ô∏è No tours found, using fallback: {total_tours} tours")
            
            # GI·ªöI H·∫†N: Ch·ªâ hi·ªÉn th·ªã 5 tour + th√¥ng b√°o c√≤n l·∫°i
            display_tours = all_tours[:5]
            
            if display_tours:
                # Format response v·ªõi emoji theo lo·∫°i tour
                reply = "‚ú® **DANH S√ÅCH TOUR RUBY WINGS** ‚ú®\n\n"
                
                for i, tour in enumerate(display_tours, 1):
                    # X√°c ƒë·ªãnh emoji ph√π h·ª£p
                    emoji = "‚ú®"
                    if tour.tags:
                        if any('nature' in tag for tag in tour.tags):
                            emoji = "üåø"
                        elif any('history' in tag for tag in tour.tags):
                            emoji = "üèõÔ∏è"
                        elif any('meditation' in tag for tag in tour.tags):
                            emoji = "üïâÔ∏è"
                        elif any('family' in tag for tag in tour.tags):
                            emoji = "üë®‚Äçüë©‚Äçüëß‚Äçüë¶"
                    
                    reply += f"{emoji} **{tour.name}**\n"
                    if tour.duration:
                        reply += f"   ‚è±Ô∏è {tour.duration}\n"
                    if tour.location:
                        reply += f"   üìç {tour.location}\n"
                    if tour.price and i <= 3:  # Ch·ªâ hi·ªán gi√° 3 tour ƒë·∫ßu
                        price_text = tour.price[:50] + "..." if len(tour.price) > 50 else tour.price
                        reply += f"   üí∞ {price_text}\n"
                    reply += "\n"
                
                if total_tours > 5:
                    reply += f"üìä **C√≤n {total_tours - 5} tour kh√°c!**\n\n"
                
                reply += "üí° **B·∫°n mu·ªën t√¨m hi·ªÉu chi ti·∫øt tour n√†o?**\n"
                reply += "‚Ä¢ G·ªçi t√™n tour c·ª• th·ªÉ (v√≠ d·ª•: 'Tour B·∫°ch M√£')\n"
                reply += "‚Ä¢ Ho·∫∑c m√¥ t·∫£ nhu c·∫ßu ƒë·ªÉ t√¥i t∆∞ v·∫•n ph√π h·ª£p\n\n"
                reply += "üìû **Hotline t∆∞ v·∫•n nhanh:** 0332510486"
            else:
                reply = "‚ú® **DANH S√ÅCH TOUR RUBY WINGS** ‚ú®\n\n"
                reply += "Hi·ªán t·∫°i Ruby Wings c√≥ 33 tour ƒë·∫∑c s·∫Øc ph·ª•c v·ª• nhi·ªÅu nhu c·∫ßu:\n\n"
                reply += "üåø **Tour Thi√™n Nhi√™n:** B·∫°ch M√£, Tr∆∞·ªùng S∆°n, ƒë·∫°i ng√†n\n"
                reply += "üèõÔ∏è **Tour L·ªãch S·ª≠:** Di s·∫£n Hu·∫ø, chi·∫øn tr∆∞·ªùng x∆∞a\n"
                reply += "üïâÔ∏è **Tour Retreat:** Thi·ªÅn, yoga, ch·ªØa l√†nh\n"
                reply += "üë®‚Äçüë©‚Äçüëß‚Äçüë¶ **Tour Gia ƒê√¨nh:** Ph√π h·ª£p m·ªçi l·ª©a tu·ªïi\n"
                reply += "üéØ **Tour Nh√≥m:** Teambuilding, c√¥ng ty, b·∫°n b√®\n\n"
                reply += "üí° **ƒê·ªÉ xem tour c·ª• th·ªÉ, h√£y h·ªèi:**\n"
                reply += "‚Ä¢ 'Tour B·∫°ch M√£ c√≥ g√¨?'\n"
                reply += "‚Ä¢ 'Tour gia ƒë√¨nh 2 ng√†y'\n"
                reply += "‚Ä¢ 'Tour l·ªãch s·ª≠ ·ªü Hu·∫ø'\n\n"
                reply += "üìû **Hotline t∆∞ v·∫•n 24/7:** 0332510486"
        
        # üîπ CASE 2: PRICE INQUIRY
        elif 'price_inquiry' in detected_intents or any(keyword in message_lower for keyword in ['gi√° bao nhi√™u', 'bao nhi√™u ti·ªÅn', 'gi√° tour', 'gi√° tour n√†y', 'gi√° tout', 'g√≠a tour']):
            if not response_locked:
                logger.info("üí∞ Processing price inquiry")
                
                if tour_indices:
                    # C√≥ tour c·ª• th·ªÉ
                    price_responses = []
                    for idx in tour_indices[:2]:  # Ch·ªâ 2 tour ƒë·∫ßu
                        tour = TOURS_DB.get(idx)
                        if tour and tour.price:
                            price_text = tour.price
                            # L√†m ƒë·∫πp price text
                            if 'ngh√¨n' in price_text.lower():
                                price_text = price_text.replace('ngh√¨n', 'k').replace('Ngh√¨n', 'k')
                            
                            price_responses.append(f"**{tour.name}:** {price_text}")
                    
                    if price_responses:
                        reply = "üí∞ **TH√îNG TIN GI√Å TOUR** üí∞\n\n"
                        reply += "\n".join(price_responses)
                        reply += "\n\nüìû **Gi√° ∆∞u ƒë√£i cho nh√≥m & ƒë·∫∑t s·ªõm:** 0332510486"
                        response_locked = True
                else:
                    # D√πng AI ƒë·ªÉ tr·∫£ l·ªùi th√¥ng minh
                    if client and HAS_OPENAI:
                        try:
                            prompt = f"""B·∫°n l√† t∆∞ v·∫•n vi√™n Ruby Wings. Kh√°ch h·ªèi v·ªÅ gi√° tour nh∆∞ng ch∆∞a ch·ªâ ƒë·ªãnh tour c·ª• th·ªÉ.

                                        TH√îNG TIN CHUNG V·ªÄ GI√Å TOUR RUBY WINGS:
                                        - Tour 1 ng√†y: t·ª´ 500.000ƒë - 1.500.000ƒë
                                        - Tour 2 ng√†y 1 ƒë√™m: t·ª´ 1.500.000ƒë - 3.000.000ƒë  
                                        - Tour 3 ng√†y 2 ƒë√™m: t·ª´ 2.500.000ƒë - 5.000.000ƒë
                                        - Tour nh√≥m: c√≥ ch√≠nh s√°ch gi·∫£m gi√° theo s·ªë l∆∞·ª£ng
                                        - Tour cao c·∫•p: gi√° theo y√™u c·∫ßu

                                        Y√äU C·∫¶U:
                                        1. Gi·∫£i th√≠ch ph·∫°m vi gi√° tour c·ªßa Ruby Wings
                                        2. H·ªèi l·∫°i kh√°ch v·ªÅ lo·∫°i tour c·ª• th·ªÉ
                                        3. ƒê·ªÅ ngh·ªã li√™n h·ªá hotline ƒë·ªÉ b√°o gi√° chi ti·∫øt

                                        Tr·∫£ l·ªùi ng·∫Øn g·ªçn, chuy√™n nghi·ªáp."""

                            response = client.chat.completions.create(
                                model=CHAT_MODEL,
                                messages=[
                                    {"role": "system", "content": prompt},
                                    {"role": "user", "content": user_message}
                                ],
                                temperature=0.5,
                                max_tokens=250
                            )
                            
                            if response.choices:
                                reply = response.choices[0].message.content or ""
                            else:
                                reply = "Gi√° tour Ruby Wings dao ƒë·ªông t·ª´ 500.000ƒë - 5.000.000ƒë t√πy lo·∫°i tour v√† d·ªãch v·ª•. B·∫°n quan t√¢m tour n√†o c·ª• th·ªÉ ƒë·ªÉ t√¥i b√°o gi√° chi ti·∫øt?"
                        
                        except Exception as e:
                            logger.error(f"OpenAI price inquiry error: {e}")
                            reply = "Gi√° tour t√πy thu·ªôc v√†o lo·∫°i tour, th·ªùi gian v√† s·ªë l∆∞·ª£ng ng∆∞·ªùi. Vui l√≤ng cho bi·∫øt b·∫°n quan t√¢m tour n√†o ƒë·ªÉ t√¥i b√°o gi√° c·ª• th·ªÉ."
                    else:
                        reply = "Gi√° tour Ruby Wings r·∫•t ƒëa d·∫°ng, t·ª´ tour 1 ng√†y gi√° 500.000ƒë ƒë·∫øn tour cao c·∫•p 5.000.000ƒë. B·∫°n mu·ªën bi·∫øt gi√° tour c·ª• th·ªÉ n√†o?"
            # B·∫£o hi·ªÉm context l·∫ßn cu·ªëi tr∆∞·ªõc khi r∆°i v·ªÅ b·∫£ng gi√° chung
            if not tour_indices:
                last_tour_idx = getattr(context, 'current_tour', None)
                if isinstance(last_tour_idx, int) and last_tour_idx in TOURS_DB:
                    tour_indices = [last_tour_idx]
            else:
                # Kh√¥ng c√≥ tour c·ª• th·ªÉ
                reply = "üí∞ **B·∫¢NG GI√Å THAM KH·∫¢O RUBY WINGS** üí∞\n\n"
                reply += "üè∑Ô∏è **Tour 1 ng√†y:** 500.000ƒë - 1.500.000ƒë\n"
                reply += "   ‚Ä¢ Thi√™n nhi√™n, vƒÉn h√≥a, ·∫©m th·ª±c\n\n"
                reply += "üè∑Ô∏è **Tour 2 ng√†y 1 ƒë√™m:** 1.500.000ƒë - 3.000.000ƒë\n"
                reply += "   ‚Ä¢ Tr·∫£i nghi·ªám s√¢u, retreat, l·ªãch s·ª≠\n\n"
                reply += "üè∑Ô∏è **Tour 3+ ng√†y:** 2.500.000ƒë - 5.000.000ƒë\n"
                reply += "   ‚Ä¢ Cao c·∫•p, c√° nh√¢n h√≥a, nh√≥m ƒë·∫∑c bi·ªát\n\n"
                reply += "üéØ **∆Øu ƒë√£i ƒë·∫∑c bi·ªát:**\n"
                reply += "‚Ä¢ Nh√≥m 10+ ng∆∞·ªùi: Gi·∫£m 10-20%\n"
                reply += "‚Ä¢ ƒê·∫∑t tr∆∞·ªõc 30 ng√†y: Gi·∫£m 5%\n"
                reply += "‚Ä¢ C·ª±u chi·∫øn binh: ∆Øu ƒë√£i ƒë·∫∑c bi·ªát\n\n"
                reply += "üìû **Li√™n h·ªá ngay 0332510486 ƒë·ªÉ nh·∫≠n b√°o gi√° chi ti·∫øt!**"
        
        # üîπ CASE 3: TOUR COMPARISON
        elif 'comparison' in detected_intents:
            # logger.info("‚öñÔ∏è Processing tour comparison request")
            
            # T√¨m c√°c tour ƒë·ªÉ so s√°nh
            comparison_tours = []
            
            # Extract tour names t·ª´ c√¢u h·ªèi
            import re
            tour_patterns = [
                r'tour\s+["\']?(.+?)["\']?\s+v√†\s+tour\s+["\']?(.+?)["\']?',
                r'tour\s+["\']?(.+?)["\']?\s+v·ªõi\s+tour\s+["\']?(.+?)["\']?',
                r'tour\s+["\']?(.+?)["\']?\s+so\s+s√°nh\s+v·ªõi\s+tour\s+["\']?(.+?)["\']?',
            ]
            
            for pattern in tour_patterns:
                matches = re.findall(pattern, message_lower, re.IGNORECASE)
                for match in matches:
                    for tour_name in match:
                        if tour_name.strip():
                            # T√¨m tour index
                            for norm_name, idx in TOUR_NAME_TO_INDEX.items():
                                if tour_name.lower() in norm_name.lower():
                                    comparison_tours.append(idx)
                                    break
            
            # N·∫øu kh√¥ng extract ƒë∆∞·ª£c, d√πng tour_indices
            if not comparison_tours and tour_indices:
                comparison_tours = tour_indices[:3]  # T·ªëi ƒëa 3 tour
            
            if len(comparison_tours) >= 2:
                # T·∫°o b·∫£ng so s√°nh chi ti·∫øt
                reply = "üìä **SO S√ÅNH CHI TI·∫æT TOUR** üìä\n\n"
                
                # Header
                headers = ["TI√äU CH√ç"]
                tour_data = []
                
                for idx in comparison_tours[:3]:  # T·ªëi ƒëa 3 tour
                    tour = TOURS_DB.get(idx)
                    if tour:
                        headers.append(tour.name[:20])
                        tour_data.append(tour)
                
                # C√°c ti√™u ch√≠ so s√°nh
                comparison_criteria = [
                    ('‚è±Ô∏è Th·ªùi gian', lambda t: t.duration or 'N/A'),
                    ('üìç ƒê·ªãa ƒëi·ªÉm', lambda t: t.location or 'N/A'),
                    ('üí∞ Gi√°', lambda t: t.price[:30] + '...' if t.price and len(t.price) > 30 else t.price or 'Li√™n h·ªá'),
                    ('üéØ Lo·∫°i h√¨nh', lambda t: ', '.join([tag.split(':')[1] for tag in (t.tags or []) if ':' in tag][:2]) or 'ƒêa d·∫°ng'),
                    ('üìù ƒê·ªô ph√π h·ª£p', lambda t: 'Gia ƒë√¨nh' if any('family' in tag for tag in (t.tags or [])) else 'Nh√≥m/Ng∆∞·ªùi l·ªõn'),
                ]
                
                for criterion_name, get_value in comparison_criteria:
                    row = [criterion_name]
                    for tour in tour_data:
                        value = get_value(tour)
                        row.append(value[:20] if value else 'N/A')
                    
                    # Format row
                    row_formatted = " | ".join([cell.ljust(20) for cell in row])
                    reply += f"{row_formatted}\n"
                    reply += "-" * (len(row) * 22) + "\n"
                
                # G·ª£i √Ω l·ª±a ch·ªçn
                reply += "\nüí° **G·ª¢I √ù L·ª∞A CH·ªåN:**\n"
                
                if tour_data:
                    # Ph√¢n t√≠ch gi√°
                    prices = []
                    for tour in tour_data:
                        if tour.price:
                            # Extract s·ªë t·ª´ price
                            nums = re.findall(r'\d[\d,\.]+', tour.price)
                            if nums:
                                try:
                                    price_num = int(nums[0].replace(',', '').replace('.', ''))
                                    prices.append(price_num)
                                except:
                                    pass
                    
                    if len(prices) >= 2:
                        min_price = min(prices)
                        max_price = max(prices)
                        if max_price > min_price * 1.5:
                            reply += "‚Ä¢ Ti·∫øt ki·ªám: Ch·ªçn tour gi√° th·∫•p h∆°n\n"
                            reply += "‚Ä¢ Tr·∫£i nghi·ªám ƒë·∫ßy ƒë·ªß: Ch·ªçn tour gi√° cao h∆°n\n"
                    
                    # Ph√¢n t√≠ch th·ªùi gian
                    durations = [tour.duration.lower() if tour.duration else '' for tour in tour_data]
                    if any('1 ng√†y' in d for d in durations) and any('2 ng√†y' in d for d in durations):
                        reply += "‚Ä¢ √çt th·ªùi gian: Tour 1 ng√†y\n"
                        reply += "‚Ä¢ Tr·∫£i nghi·ªám s√¢u: Tour 2 ng√†y\n"
                
                reply += "\nüìû **T∆∞ v·∫•n ch·ªçn tour ph√π h·ª£p:** 0332510486"
            
            else:
                reply = "ƒê·ªÉ so s√°nh tour, vui l√≤ng cho bi·∫øt t√™n 2-3 tour c·ª• th·ªÉ. V√≠ d·ª•: 'So s√°nh tour B·∫°ch M√£ v√† tour Tr∆∞·ªùng S∆°n'"
        
        # üîπ CASE 4: TOUR RECOMMENDATION
        elif 'recommendation' in detected_intents or any(keyword in message_lower for keyword in ['ph√π h·ª£p', 'g·ª£i √Ω', 'ƒë·ªÅ xu·∫•t']):
            logger.info("üéØ Processing recommendation request")
            
            # Ph√¢n t√≠ch y√™u c·∫ßu chi ti·∫øt
            requirements = {
                'family': any(word in message_lower for word in ['gia ƒë√¨nh', 'tr·∫ª em', 'con nh·ªè', 'b·ªë m·∫π']),
                'senior': any(word in message_lower for word in ['ng∆∞·ªùi l·ªõn tu·ªïi', 'cao tu·ªïi', '√¥ng b√†']),
                'group': any(word in message_lower for word in ['nh√≥m', 'ƒëo√†n', 'c√¥ng ty', 'b·∫°n b√®']),
                'couple': any(word in message_lower for word in ['c·∫∑p ƒë√¥i', 'ƒë√¥i l·ª©a', 'ng∆∞·ªùi y√™u']),
                'solo': any(word in message_lower for word in ['m·ªôt m√¨nh', 'ƒëi l·∫ª', 'solo']),
                'nature': any(word in message_lower for word in ['thi√™n nhi√™n', 'r·ª´ng', 'n√∫i', 'c√¢y']),
                'history': any(word in message_lower for word in ['l·ªãch s·ª≠', 'di t√≠ch', 'chi·∫øn tranh']),
                'meditation': any(word in message_lower for word in ['thi·ªÅn', 'tƒ©nh t√¢m', 'yoga']),
                'relax': any(word in message_lower for word in ['ngh·ªâ ng∆°i', 'th∆∞ gi√£n', 'nh·∫π nh√†ng']),
                'adventure': any(word in message_lower for word in ['phi√™u l∆∞u', 'm·∫°o hi·ªÉm', 'kh√°m ph√°']),
                'budget': any(word in message_lower for word in ['gi√° r·∫ª', 'ti·∫øt ki·ªám', 'kinh t·∫ø']),
                'premium': any(word in message_lower for word in ['cao c·∫•p', 'sang tr·ªçng', 'premium']),
            }
            
            # T√¨m tour ph√π h·ª£p
            matching_tours = []
            
            for idx, tour in TOURS_DB.items():
                score = 0
                reasons = []
                
                # Ki·ªÉm tra tags
                tour_tags = [tag.lower() for tag in (tour.tags or [])]
                
                # Ph√π h·ª£p gia ƒë√¨nh
                if requirements['family']:
                    if any('family' in tag for tag in tour_tags):
                        score += 3
                        reasons.append("ph√π h·ª£p gia ƒë√¨nh")
                    elif 'history' in tour_tags and not requirements['history']:
                        score -= 1  # Tr·ª´ ƒëi·ªÉm n·∫øu tour l·ªãch s·ª≠ nh∆∞ng kh√¥ng y√™u c·∫ßu
                
                # Ng∆∞·ªùi l·ªõn tu·ªïi
                if requirements['senior']:
                    if any('nature' in tag for tag in tour_tags) or any('meditation' in tag for tag in tour_tags):
                        score += 2
                        reasons.append("nh·∫π nh√†ng cho ng∆∞·ªùi l·ªõn tu·ªïi")
                
                # Thi√™n nhi√™n
                if requirements['nature']:
                    if any('nature' in tag for tag in tour_tags):
                        score += 2
                        reasons.append("tr·∫£i nghi·ªám thi√™n nhi√™n")
                
                # Thi·ªÅn/tƒ©nh t√¢m
                if requirements['meditation']:
                    if any('meditation' in tag for tag in tour_tags):
                        score += 3
                        reasons.append("c√≥ ho·∫°t ƒë·ªông thi·ªÅn")
                
                # Ngh·ªâ ng∆°i
                if requirements['relax']:
                    if any('nature' in tag for tag in tour_tags) or any('meditation' in tag for tag in tour_tags):
                        score += 2
                        reasons.append("t·∫≠p trung ngh·ªâ ng∆°i")
                
                # Budget
                if requirements['budget']:
                    if tour.price:
                        # T√¨m s·ªë trong price
                        nums = re.findall(r'\d[\d,\.]+', tour.price)
                        if nums:
                            try:
                                price_num = int(nums[0].replace(',', '').replace('.', ''))
                                if price_num < 2000000:
                                    score += 2
                                    reasons.append("gi√° h·ª£p l√Ω")
                            except:
                                pass
                
                if score > 0:
                    matching_tours.append((idx, score, reasons))
            
            # S·∫Øp x·∫øp theo ƒëi·ªÉm
            matching_tours.sort(key=lambda x: x[1], reverse=True)
            
            if matching_tours:
                reply = "üéØ **ƒê·ªÄ XU·∫§T TOUR PH√ô H·ª¢P** üéØ\n\n"
                
                # Top recommendation
                top_idx, top_score, top_reasons = matching_tours[0]
                top_tour = TOURS_DB.get(top_idx)
                
                if top_tour:
                    reply += f"üèÜ **PH√ô H·ª¢P NH·∫§T ({int(top_score/10*100)}%)**\n"
                    reply += f"**{top_tour.name}**\n"
                    reply += f"‚úÖ L√Ω do: {', '.join(top_reasons[:3])}\n"
                    if top_tour.duration:
                        reply += f"‚è±Ô∏è Th·ªùi gian: {top_tour.duration}\n"
                    if top_tour.location:
                        reply += f"üìç ƒê·ªãa ƒëi·ªÉm: {top_tour.location}\n"
                    if top_tour.price:
                        reply += f"üí∞ Gi√°: {top_tour.price[:80]}\n"
                    reply += "\n"
                
                # Other recommendations (t·ªëi ƒëa 2 tour)
                other_tours = matching_tours[1:3]
                if other_tours:
                    reply += "üìã **L·ª∞A CH·ªåN KH√ÅC:**\n"
                    for idx, score, reasons in other_tours:
                        tour = TOURS_DB.get(idx)
                        if tour:
                            reply += f"‚Ä¢ **{tour.name}** ({int(score/10*100)}%)\n"
                            if tour.duration:
                                reply += f"  ‚è±Ô∏è {tour.duration}"
                            if tour.location:
                                reply += f" | üìç {tour.location[:30]}"
                            reply += "\n"
                
                reply += "\nüí° **C·∫¶N T∆Ø V·∫§N CHI TI·∫æT?**\n"
                reply += "üìû G·ªçi ngay 0332510486 ƒë·ªÉ:\n"
                reply += "‚Ä¢ Nh·∫≠n l·ªãch tr√¨nh chi ti·∫øt\n"
                reply += "‚Ä¢ B√°o gi√° ch√≠nh x√°c\n"
                reply += "‚Ä¢ ƒê·∫∑t tour ∆∞u ƒë√£i\n"
            
            else:
                # D√πng AI ƒë·ªÉ ƒë·ªÅ xu·∫•t th√¥ng minh
                if client and HAS_OPENAI:
                    try:
                        prompt = f"""B·∫°n l√† t∆∞ v·∫•n vi√™n Ruby Wings chuy√™n nghi·ªáp. Kh√°ch h√†ng c·∫ßn t∆∞ v·∫•n tour nh∆∞ng ch∆∞a t√¨m th·∫•y tour ph√π h·ª£p.

Y√äU C·∫¶U KH√ÅCH: {user_message}

TH√îNG TIN RUBY WINGS:
- Chuy√™n tour tr·∫£i nghi·ªám: l·ªãch s·ª≠, thi√™n nhi√™n, retreat
- ƒêa d·∫°ng tour t·ª´ 1 ng√†y ƒë·∫øn 4 ng√†y
- Ph√π h·ª£p m·ªçi ƒë·ªëi t∆∞·ª£ng: gia ƒë√¨nh, nh√≥m, c√° nh√¢n

Y√äU C·∫¶U:
1. Th·ª´a nh·∫≠n ch∆∞a t√¨m th·∫•y tour ph√π h·ª£p ngay
2. ƒê·ªÅ ngh·ªã cung c·∫•p th√™m th√¥ng tin ƒë·ªÉ t∆∞ v·∫•n t·ªët h∆°n
3. G·ª£i √Ω m·ªôt s·ªë lo·∫°i tour ph·ªï bi·∫øn
4. Khuy·∫øn kh√≠ch li√™n h·ªá hotline

Tr·∫£ l·ªùi th√¢n thi·ªán, chuy√™n nghi·ªáp."""

                        response = client.chat.completions.create(
                            model=CHAT_MODEL,
                            messages=[
                                {"role": "system", "content": prompt},
                                {"role": "user", "content": user_message}
                            ],
                            temperature=0.6,
                            max_tokens=300
                        )
                        
                        if response.choices:
                            reply = response.choices[0].message.content or ""
                        else:
                            reply = "ƒê·ªÉ t√¥i t∆∞ v·∫•n tour ph√π h·ª£p nh·∫•t, b·∫°n c√≥ th·ªÉ cho bi·∫øt th√™m:\n‚Ä¢ S·ªë ng∆∞·ªùi tham gia\n‚Ä¢ ƒê·ªô tu·ªïi c√°c th√†nh vi√™n\n‚Ä¢ S·ªü th√≠ch ch√≠nh (thi√™n nhi√™n, l·ªãch s·ª≠, ngh·ªâ d∆∞·ª°ng)\n‚Ä¢ Ng√¢n s√°ch d·ª± ki·∫øn\n‚Ä¢ Th·ªùi gian c√≥ th·ªÉ ƒëi"
                    
                    except Exception as e:
                        logger.error(f"OpenAI recommendation error: {e}")
                        reply = "Ruby Wings c√≥ nhi·ªÅu tour ƒëa d·∫°ng ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa b·∫°n. Vui l√≤ng li√™n h·ªá hotline 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt v√† ƒë·ªÅ xu·∫•t tour ri√™ng."
                else:
                    reply = "ƒê·ªÉ t∆∞ v·∫•n tour ph√π h·ª£p nh·∫•t, vui l√≤ng cung c·∫•p th√™m th√¥ng tin ho·∫∑c li√™n h·ªá tr·ª±c ti·∫øp hotline 0332510486."
        
        # üîπ CASE 5: GENERAL INFORMATION (gi·ªõi thi·ªáu, tri·∫øt l√Ω, vƒÉn h√≥a)
        elif 'general_info' in detected_intents or any(keyword in message_lower for keyword in ['gi·ªõi thi·ªáu', 'l√† g√¨', 'th·∫ø n√†o', 'tri·∫øt l√Ω']):
            # logger.info("üèõÔ∏è Processing general information request")
            
            # X√°c ƒë·ªãnh lo·∫°i th√¥ng tin c·∫ßn
            if 'ruby wings' in message_lower or 'c√¥ng ty' in message_lower:
                reply = "üèõÔ∏è **GI·ªöI THI·ªÜU RUBY WINGS TRAVEL** üèõÔ∏è\n\n"
                reply += "Ruby Wings l√† ƒë∆°n v·ªã t·ªï ch·ª©c tour du l·ªãch tr·∫£i nghi·ªám ƒë·∫∑c s·∫Øc, chuy√™n s√¢u v·ªÅ:\n\n"
                reply += "üéØ **3 TR·ª§ C·ªòT CH√çNH:**\n"
                reply += "1. **Tour L·ªãch S·ª≠ - Tri √Çn:** H√†nh tr√¨nh v·ªÅ ngu·ªìn, k·∫øt n·ªëi qu√° kh·ª©\n"
                reply += "2. **Tour Retreat - Ch·ªØa L√†nh:** Thi·ªÅn, kh√≠ c√¥ng, tƒ©nh t√¢m gi·ªØa thi√™n nhi√™n\n"
                reply += "3. **Tour Tr·∫£i Nghi·ªám - Kh√°m Ph√°:** VƒÉn h√≥a, ·∫©m th·ª±c, ƒë·ªùi s·ªëng ƒë·ªãa ph∆∞∆°ng\n\n"
                reply += "‚ú® **TRI·∫æT L√ù HO·∫†T ƒê·ªòNG:**\n"
                reply += "‚Ä¢ Chu·∫©n m·ª±c trong d·ªãch v·ª•\n"
                reply += "‚Ä¢ Ch√¢n th√†nh trong k·∫øt n·ªëi\n"
                reply += "‚Ä¢ Chi·ªÅu s√¢u trong tr·∫£i nghi·ªám\n\n"
                reply += "üåø **GI√Å TR·ªä C·ªêT L√ïI:**\n"
                reply += "‚Ä¢ T√¥n vinh l·ªãch s·ª≠ d√¢n t·ªôc\n"
                reply += "‚Ä¢ B·∫£o t·ªìn vƒÉn h√≥a b·∫£n ƒë·ªãa\n"
                reply += "‚Ä¢ Lan t·ªèa nƒÉng l∆∞·ª£ng t√≠ch c·ª±c\n\n"
                reply += "üìû **K·∫øt n·ªëi v·ªõi ch√∫ng t√¥i:** 0332510486"
            
            elif 'tri·∫øt l√Ω' in message_lower or 'chu·∫©n m·ª±c' in message_lower:
                reply = "‚ú® **TRI·∫æT L√ù 'CHU·∫®N M·ª∞C - CH√ÇN TH√ÄNH - C√ì CHI·ªÄU S√ÇU'** ‚ú®\n\n"
                reply += "Tri·∫øt l√Ω n√†y ƒë∆∞·ª£c th·ªÉ hi·ªán trong m·ªçi tour c·ªßa Ruby Wings:\n\n"
                reply += "üèÜ **CHU·∫®N M·ª∞C:**\n"
                reply += "‚Ä¢ Ti√™u chu·∫©n d·ªãch v·ª• cao nh·∫•t\n"
                reply += "‚Ä¢ An to√†n tuy·ªát ƒë·ªëi cho kh√°ch h√†ng\n"
                reply += "‚Ä¢ Chuy√™n nghi·ªáp trong t·ª´ng chi ti·∫øt\n\n"
                reply += "‚ù§Ô∏è **CH√ÇN TH√ÄNH:**\n"
                reply += "‚Ä¢ K·∫øt n·ªëi th·∫≠t v·ªõi con ng∆∞·ªùi, vƒÉn h√≥a\n"
                reply += "‚Ä¢ ƒê·ªìng h√†nh ch√¢n th√†nh c√πng kh√°ch h√†ng\n"
                reply += "‚Ä¢ T∆∞ v·∫•n trung th·ª±c, minh b·∫°ch\n\n"
                reply += "üåå **C√ì CHI·ªÄU S√ÇU:**\n"
                reply += "‚Ä¢ Tr·∫£i nghi·ªám c√≥ √Ω nghƒ©a, gi√° tr·ªã\n"
                reply += "‚Ä¢ Kh√°m ph√° b·∫£n ch·∫•t, kh√¥ng ch·ªâ b·ªÅ n·ªïi\n"
                reply += "‚Ä¢ ƒê·ªçng l·∫°i b√†i h·ªçc, c·∫£m x√∫c s√¢u s·∫Øc\n\n"
                reply += "üìû **Tr·∫£i nghi·ªám tri·∫øt l√Ω n√†y trong tour:** 0332510486"
            
            else:
                # D√πng AI cho c√°c c√¢u h·ªèi chung kh√°c
                if client and HAS_OPENAI:
                    try:
                        prompt = f"""B·∫°n l√† ƒë·∫°i di·ªán Ruby Wings Travel. Tr·∫£ l·ªùi c√¢u h·ªèi chung v·ªÅ c√¥ng ty.

C√ÇU H·ªéI: {user_message}

TH√îNG TIN C√îNG TY:
- T√™n: Ruby Wings Travel
- Chuy√™n: Tour tr·∫£i nghi·ªám l·ªãch s·ª≠, retreat, vƒÉn h√≥a
- Tri·∫øt l√Ω: Chu·∫©n m·ª±c - Ch√¢n th√†nh - C√≥ chi·ªÅu s√¢u
- Hotline: 0332510486

Y√äU C·∫¶U:
1. Tr·∫£ l·ªùi ƒë√∫ng tr·ªçng t√¢m c√¢u h·ªèi
2. Gi·ªõi thi·ªáu ng·∫Øn g·ªçn v·ªÅ Ruby Wings n·∫øu ph√π h·ª£p
3. K·∫øt th√∫c b·∫±ng l·ªùi m·ªùi t√¨m hi·ªÉu tour c·ª• th·ªÉ
4. Gi·ªçng vƒÉn chuy√™n nghi·ªáp, th√¢n thi·ªán

Tr·∫£ l·ªùi trong 150-200 t·ª´."""

                        response = client.chat.completions.create(
                            model=CHAT_MODEL,
                            messages=[
                                {"role": "system", "content": prompt},
                                {"role": "user", "content": user_message}
                            ],
                            temperature=0.5,
                            max_tokens=300
                        )
                        
                        if response.choices:
                            reply = response.choices[0].message.content or ""
                            if "0332510486" not in reply:
                                reply += "\n\nüìû **Li√™n h·ªá t∆∞ v·∫•n tour:** 0332510486"
                        else:
                            reply = "Ruby Wings l√† c√¥ng ty t·ªï ch·ª©c tour tr·∫£i nghi·ªám ƒë·∫∑c s·∫Øc v·ªõi tri·∫øt l√Ω 'Chu·∫©n m·ª±c - Ch√¢n th√†nh - C√≥ chi·ªÅu s√¢u'. Ch√∫ng t√¥i chuy√™n v·ªÅ c√°c tour l·ªãch s·ª≠, retreat thi·ªÅn ƒë·ªãnh, v√† kh√°m ph√° vƒÉn h√≥a."
                    
                    except Exception as e:
                        logger.error(f"OpenAI general info error: {e}")
                        reply = "Ruby Wings Travel chuy√™n t·ªï ch·ª©c c√°c tour tr·∫£i nghi·ªám √Ω nghƒ©a. ƒê·ªÉ bi·∫øt th√™m chi ti·∫øt, vui l√≤ng li√™n h·ªá hotline 0332510486."
                else:
                    reply = "Ruby Wings Travel - ƒê·ªìng h√†nh c√πng b·∫°n trong nh·ªØng h√†nh tr√¨nh √Ω nghƒ©a. üìû Hotline: 0332510486"
        
        # üîπ CASE 6: LOCATION & WEATHER INFO
        elif 'location_info' in detected_intents or 'weather_info' in detected_intents:
            logger.info("üå§Ô∏è Processing location/weather inquiry")
            
            # X√°c ƒë·ªãnh ƒë·ªãa ƒëi·ªÉm ƒë∆∞·ª£c h·ªèi
            locations = ['hu·∫ø', 'qu·∫£ng tr·ªã', 'b·∫°ch m√£', 'tr∆∞·ªùng s∆°n', 'ƒë√¥ng h√†']
            mentioned_location = None
            
            for loc in locations:
                if loc in message_lower:
                    mentioned_location = loc
                    break
            
            if mentioned_location:
                if 'weather' in message_lower or 'th·ªùi ti·∫øt' in message_lower:
                    # X·ª≠ l√Ω c√¢u h·ªèi th·ªùi ti·∫øt
                    reply = f"üå§Ô∏è **TH√îNG TIN TH·ªúI TI·∫æT {mentioned_location.upper()}** üå§Ô∏è\n\n"
                    
                    if mentioned_location == 'hu·∫ø':
                        reply += "**Th√°ng 12 t·∫°i Hu·∫ø:**\n"
                        reply += "‚Ä¢ Nhi·ªát ƒë·ªô: 18-24¬∞C (m√°t m·∫ª)\n"
                        reply += "‚Ä¢ Th·ªùi ti·∫øt: √çt m∆∞a, nhi·ªÅu n·∫Øng nh·∫π\n"
                        reply += "‚Ä¢ ƒê·∫∑c ƒëi·ªÉm: Se l·∫°nh v·ªÅ ƒë√™m v√† s√°ng\n"
                        reply += "‚Ä¢ L∆∞u √Ω: Mang theo √°o kho√°c nh·∫π\n\n"
                    elif mentioned_location == 'b·∫°ch m√£':
                        reply += "**Th·ªùi ti·∫øt B·∫°ch M√£:**\n"
                        reply += "‚Ä¢ Nhi·ªát ƒë·ªô: 15-22¬∞C (m√°t l·∫°nh)\n"
                        reply += "‚Ä¢ ƒê·∫∑c ƒëi·ªÉm: S∆∞∆°ng m√π bu·ªïi s√°ng\n"
                        reply += "‚Ä¢ L∆∞u √Ω: Mang gi√†y trekking, √°o ·∫•m\n\n"
                    else:
                        reply += f"**Th·ªùi ti·∫øt {mentioned_location.title()}:**\n"
                        reply += "‚Ä¢ Mi·ªÅn Trung: Kh√≠ h·∫≠u nhi·ªát ƒë·ªõi gi√≥ m√πa\n"
                        reply += "‚Ä¢ M√πa kh√¥: T·ª´ th√°ng 1-8 (√≠t m∆∞a)\n"
                        reply += "‚Ä¢ M√πa m∆∞a: T·ª´ th√°ng 9-12 (m∆∞a nhi·ªÅu)\n\n"
                    
                    reply += "üìÖ **Th·ªùi ƒëi·ªÉm l√Ω t∆∞·ªüng ƒë·ªÉ ƒëi tour:**\n"
                    reply += "‚Ä¢ Th√°ng 1-4: Th·ªùi ti·∫øt ƒë·∫πp nh·∫•t\n"
                    reply += "‚Ä¢ Th√°ng 5-8: N·∫Øng ƒë·∫πp, ph√π h·ª£p trekking\n"
                    reply += "‚Ä¢ Th√°ng 9-12: M∆∞a nhi·ªÅu, check k·ªπ d·ª± b√°o\n\n"
                    reply += "üìû **T∆∞ v·∫•n tour ph√π h·ª£p th·ªùi ti·∫øt:** 0332510486"
                
                else:
                    # X·ª≠ l√Ω c√¢u h·ªèi ƒë·ªãa ƒëi·ªÉm chung
                    reply = f"üìç **TH√îNG TIN {mentioned_location.upper()}** üìç\n\n"
                    
                    if mentioned_location == 'hu·∫ø':
                        reply += "**Hu·∫ø - Kinh ƒë√¥ c·ªï c·ªßa Vi·ªát Nam:**\n"
                        reply += "‚Ä¢ Di s·∫£n vƒÉn h√≥a UNESCO\n"
                        reply += "‚Ä¢ N·ªïi ti·∫øng: ƒê·∫°i N·ªôi, LƒÉng t·∫©m, S√¥ng H∆∞∆°ng\n"
                        reply += "‚Ä¢ ·∫®m th·ª±c: B√∫n b√≤ Hu·∫ø, b√°nh b√®o, c∆°m h·∫øn\n"
                        reply += "‚Ä¢ Tour ph·ªï bi·∫øn: Di s·∫£n Hu·∫ø, ·∫©m th·ª±c Hu·∫ø\n\n"
                    elif mentioned_location == 'b·∫°ch m√£':
                        reply += "**B·∫°ch M√£ - V∆∞·ªùn qu·ªëc gia:**\n"
                        reply += "‚Ä¢ ƒê·ªô cao: 1.450m so v·ªõi m·ª±c n∆∞·ªõc bi·ªÉn\n"
                        reply += "‚Ä¢ H·ªá sinh th√°i: R·ª´ng nguy√™n sinh ƒëa d·∫°ng\n"
                        reply += "‚Ä¢ Ho·∫°t ƒë·ªông: Trekking, thi·ªÅn, ng·∫Øm c·∫£nh\n"
                        reply += "‚Ä¢ Tour ph·ªï bi·∫øn: Retreat B·∫°ch M√£ 1 ng√†y\n\n"
                    elif mentioned_location == 'tr∆∞·ªùng s∆°n':
                        reply += "**Tr∆∞·ªùng S∆°n - D√£y n√∫i h√πng vƒ©:**\n"
                        "‚Ä¢ √ù nghƒ©a l·ªãch s·ª≠: ƒê∆∞·ªùng H·ªì Ch√≠ Minh huy·ªÅn tho·∫°i\n"
                        reply += "‚Ä¢ VƒÉn h√≥a: C·ªông ƒë·ªìng V√¢n Ki·ªÅu - Pa K√¥\n"
                        reply += "‚Ä¢ Ho·∫°t ƒë·ªông: T√¨m hi·ªÉu l·ªãch s·ª≠, vƒÉn h√≥a\n"
                        reply += "‚Ä¢ Tour ph·ªï bi·∫øn: M∆∞a ƒê·ªè v√† Tr∆∞·ªùng S∆°n\n\n"
                    
                    reply += "üéØ **TOUR PH√ô H·ª¢P T·∫†I ƒê√ÇY:**\n"
                    # T√¨m tour t·∫°i ƒë·ªãa ƒëi·ªÉm n√†y
                    location_tours = []
                    for idx, tour in TOURS_DB.items():
                        if tour.location and mentioned_location in tour.location.lower():
                            location_tours.append(tour)
                    
                    if location_tours:
                        for tour in location_tours[:3]:
                            reply += f"‚Ä¢ **{tour.name}**"
                            if tour.duration:
                                reply += f" ({tour.duration})"
                            reply += "\n"
                    else:
                        reply += "‚Ä¢ Tour thi√™n nhi√™n B·∫°ch M√£\n"
                        reply += "‚Ä¢ Tour l·ªãch s·ª≠ Tr∆∞·ªùng S∆°n\n"
                        reply += "‚Ä¢ Tour di s·∫£n Hu·∫ø\n"
                    
                    reply += "\nüìû **ƒê·∫∑t tour kh√°m ph√°:** 0332510486"
            
            else:
                reply = "Ruby Wings t·ªï ch·ª©c tour t·∫°i nhi·ªÅu ƒë·ªãa ƒëi·ªÉm: Hu·∫ø, Qu·∫£ng Tr·ªã, B·∫°ch M√£, Tr∆∞·ªùng S∆°n. B·∫°n quan t√¢m tour t·∫°i khu v·ª±c n√†o?"
        
        # üîπ CASE 7: FOOD & CULTURE INFO
        elif 'food_info' in detected_intents or 'culture_info' in detected_intents:
            logger.info("üçú Processing food/culture inquiry")
            
            if 'b√°nh b√®o' in message_lower or '·∫©m th·ª±c hu·∫ø' in message_lower:
                reply = "üçú **B√ÅNH B√àO HU·∫æ - ƒê·∫∂C S·∫¢N N·ªîI TI·∫æNG** üçú\n\n"
                reply += "**ƒê·∫∑c ƒëi·ªÉm:**\n"
                reply += "‚Ä¢ L√†m t·ª´ b·ªôt g·∫°o, h·∫•p trong ch√©n nh·ªè\n"
                reply += "‚Ä¢ Nh√¢n: T√¥m ch√°y, th·ªãt xay, m·ª° h√†nh\n"
                reply += "‚Ä¢ N∆∞·ªõc ch·∫•m: M·∫Øm n√™m Hu·∫ø ƒë·∫∑c tr∆∞ng\n"
                reply += "‚Ä¢ ƒÇn k√®m: Rau s·ªëng, ·ªõt xanh\n\n"
                reply += "üéØ **TR·∫¢I NGHI·ªÜM TRONG TOUR:**\n"
                reply += "‚Ä¢ Tour ·∫®m th·ª±c Hu·∫ø: H·ªçc l√†m b√°nh b√®o\n"
                reply += "‚Ä¢ Tour VƒÉn h√≥a: ThƒÉm l√†ng ngh·ªÅ truy·ªÅn th·ªëng\n"
                reply += "‚Ä¢ Tour ƒê√™m Hu·∫ø: Th∆∞·ªüng th·ª©c ƒë·∫∑c s·∫£n\n\n"
                reply += "üìû **ƒê·∫∑t tour ·∫©m th·ª±c Hu·∫ø:** 0332510486"
            
            elif 'vƒÉn h√≥a' in message_lower or 'l·ªãch s·ª≠' in message_lower:
                reply = "üèõÔ∏è **VƒÇN H√ìA & L·ªäCH S·ª¨ MI·ªÄN TRUNG** üèõÔ∏è\n\n"
                reply += "**ƒêi·ªÉm n·ªïi b·∫≠t:**\n"
                reply += "‚Ä¢ Di s·∫£n Hu·∫ø: C·ªë ƒë√¥ tri·ªÅu Nguy·ªÖn\n"
                reply += "‚Ä¢ Chi·∫øn tranh: ƒê·ªãa ƒë·∫°o V·ªãnh M·ªëc, Th√†nh c·ªï Qu·∫£ng Tr·ªã\n"
                reply += "‚Ä¢ VƒÉn h√≥a b·∫£n ƒë·ªãa: D√¢n t·ªôc V√¢n Ki·ªÅu, Pa K√¥\n"
                reply += "‚Ä¢ Ki·∫øn tr√∫c: Nh√† r∆∞·ªùng, ƒë√¨nh l√†ng\n\n"
                reply += "üéØ **TOUR VƒÇN H√ìA N·ªîI B·∫¨T:**\n"
                
                # T√¨m tour vƒÉn h√≥a
                culture_tours = []
                for idx, tour in TOURS_DB.items():
                    if tour.tags and any('history' in tag or 'culture' in tag for tag in tour.tags):
                        culture_tours.append(tour)
                
                if culture_tours:
                    for tour in culture_tours[:3]:
                        reply += f"‚Ä¢ **{tour.name}**\n"
                        if tour.summary:
                            reply += f"  {tour.summary[:80]}...\n"
                else:
                    reply += "‚Ä¢ M∆∞a ƒê·ªè v√† Tr∆∞·ªùng S∆°n\n"
                    reply += "‚Ä¢ K√Ω ·ª©c - L·ªãch S·ª≠ v√† ƒê·∫°i Ng√†n\n"
                    reply += "‚Ä¢ Di s·∫£n Hu·∫ø & ƒê·∫ßm Chu·ªìn\n\n"
                
                reply += "\nüìû **T∆∞ v·∫•n tour vƒÉn h√≥a:** 0332510486"
            
            else:
                reply = "Mi·ªÅn Trung Vi·ªát Nam n·ªïi ti·∫øng v·ªõi ·∫©m th·ª±c phong ph√∫ v√† vƒÉn h√≥a ƒëa d·∫°ng. Ruby Wings c√≥ nhi·ªÅu tour kh√°m ph√° ·∫©m th·ª±c v√† vƒÉn h√≥a ƒë·∫∑c s·∫Øc."
        
        # üîπ CASE 8: WELLNESS & MEDITATION INFO
        elif 'wellness_info' in detected_intents:
            logger.info("üïâÔ∏è Processing wellness/meditation inquiry")
            
            if 'thi·ªÅn' in message_lower or 'meditation' in message_lower:
                reply = "üïâÔ∏è **THI·ªÄN & L·ª¢I √çCH S·ª®C KH·ªéE** üïâÔ∏è\n\n"
                reply += "**L·ª£i √≠ch ch√≠nh:**\n"
                reply += "1. **Gi·∫£m cƒÉng th·∫≥ng:** Gi·∫£m cortisol, tƒÉng serotonin\n"
                reply += "2. **C·∫£i thi·ªán t·∫≠p trung:** TƒÉng kh·∫£ nƒÉng ch√∫ √Ω\n"
                reply += "3. **TƒÉng c∆∞·ªùng s·ª©c kh·ªèe:** H·∫° huy·∫øt √°p, c·∫£i thi·ªán tim m·∫°ch\n"
                reply += "4. **C√¢n b·∫±ng c·∫£m x√∫c:** Ki·ªÉm so√°t lo √¢u, tr·∫ßm c·∫£m\n"
                reply += "5. **N√¢ng cao nh·∫≠n th·ª©c:** Hi·ªÉu r√µ b·∫£n th√¢n h∆°n\n\n"
                reply += "üéØ **TOUR THI·ªÄN & RETREAT RUBY WINGS:**\n"
                
                # T√¨m tour thi·ªÅn
                meditation_tours = []
                for idx, tour in TOURS_DB.items():
                    if tour.tags and any('meditation' in tag or 'retreat' in tag for tag in tour.tags):
                        meditation_tours.append(tour)
                
                if meditation_tours:
                    for tour in meditation_tours[:3]:
                        reply += f"‚Ä¢ **{tour.name}**\n"
                        if tour.duration:
                            reply += f"  ‚è±Ô∏è {tour.duration}"
                        if tour.location:
                            reply += f" | üìç {tour.location[:30]}"
                        reply += "\n"
                else:
                    reply += "‚Ä¢ Non n∆∞·ªõc B·∫°ch M√£ - 1 ng√†y thi·ªÅn\n"
                    reply += "‚Ä¢ Retreat Tr∆∞·ªùng S∆°n - 2 ng√†y 1 ƒë√™m\n"
                    reply += "‚Ä¢ Kh√≠ c√¥ng gi·ªØa ƒë·∫°i ng√†n\n\n"
                
                reply += "\nüí° **Ph√π h·ª£p cho:** Ng∆∞·ªùi stress, c·∫ßn c√¢n b·∫±ng, mu·ªën tƒ©nh t√¢m\n"
                reply += "üìû **ƒê·∫∑t retreat thi·ªÅn:** 0332510486"
            
            else:
                reply = "Ruby Wings chuy√™n t·ªï ch·ª©c c√°c tour retreat k·∫øt h·ª£p thi·ªÅn, kh√≠ c√¥ng v√† tr·ªã li·ªáu thi√™n nhi√™n. Li√™n h·ªá 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n."
        
        # üîπ CASE 9: GROUP & CUSTOM REQUEST
        elif 'group_info' in detected_intents or 'custom_request' in detected_intents:
            logger.info("üë• Processing group/custom request")
            
            if 'nh√≥m' in message_lower or 'ƒëo√†n' in message_lower:
                reply = "üë• **TOUR NH√ìM & ∆ØU ƒê√ÉI ƒê·∫∂C BI·ªÜT** üë•\n\n"
                reply += "**Ch√≠nh s√°ch ∆∞u ƒë√£i nh√≥m:**\n"
                reply += "‚Ä¢ Nh√≥m 10-15 ng∆∞·ªùi: Gi·∫£m 10%\n"
                reply += "‚Ä¢ Nh√≥m 16-20 ng∆∞·ªùi: Gi·∫£m 15%\n"
                reply += "‚Ä¢ Nh√≥m 21+ ng∆∞·ªùi: Gi·∫£m 20% + qu√† t·∫∑ng\n"
                reply += "‚Ä¢ C·ª±u chi·∫øn binh: ∆Øu ƒë√£i th√™m 5%\n\n"
                reply += "üéØ **TOUR PH√ô H·ª¢P NH√ìM:**\n"
                reply += "1. **Teambuilding c√¥ng ty:** Tour k·∫øt h·ª£p ho·∫°t ƒë·ªông nh√≥m\n"
                reply += "2. **Gia ƒë√¨nh ƒëa th·∫ø h·ªá:** Tour nh·∫π nh√†ng, ƒëa d·∫°ng ho·∫°t ƒë·ªông\n"
                reply += "3. **Nh√≥m b·∫°n:** Tour kh√°m ph√°, phi√™u l∆∞u\n"
                reply += "4. **Nh√≥m h·ªçc sinh/sinh vi√™n:** Tour gi√°o d·ª•c, tr·∫£i nghi·ªám\n\n"
                reply += "‚ú® **D·ªäCH V·ª§ ƒê·∫∂C BI·ªÜT CHO NH√ìM:**\n"
                reply += "‚Ä¢ Thi·∫øt k·∫ø tour ri√™ng theo y√™u c·∫ßu\n"
                reply += "‚Ä¢ H∆∞·ªõng d·∫´n vi√™n chuy√™n bi·ªát\n"
                reply += "‚Ä¢ Ph∆∞∆°ng ti·ªán ri√™ng, linh ho·∫°t l·ªãch tr√¨nh\n"
                reply += "‚Ä¢ H·ªó tr·ª£ quay phim, ch·ª•p ·∫£nh\n\n"
                reply += "üìû **T∆∞ v·∫•n tour nh√≥m:** 0332510486"
            
            elif 'c√° nh√¢n h√≥a' in message_lower or 'ri√™ng' in message_lower or 'theo y√™u c·∫ßu' in message_lower:
                reply = "‚ú® **TOUR C√Å NH√ÇN H√ìA - THEO Y√äU C·∫¶U** ‚ú®\n\n"
                reply += "Ruby Wings chuy√™n thi·∫øt k·∫ø tour ri√™ng bi·ªát:\n\n"
                reply += "üéØ **QUY TR√åNH THI·∫æT K·∫æ TOUR RI√äNG:**\n"
                reply += "1. **Ti·∫øp nh·∫≠n y√™u c·∫ßu:** Hi·ªÉu r√µ nhu c·∫ßu, s·ªü th√≠ch\n"
                reply += "2. **Thi·∫øt k·∫ø l·ªãch tr√¨nh:** Ph√π h·ª£p th·ªùi gian, ng√¢n s√°ch\n"
                reply += "3. **B√°o gi√° chi ti·∫øt:** Minh b·∫°ch, c·∫°nh tranh\n"
                reply += "4. **Ch·ªânh s·ª≠a & ho√†n thi·ªán:** Theo feedback c·ªßa b·∫°n\n"
                reply += "5. **Tri·ªÉn khai tour:** Chuy√™n nghi·ªáp, t·∫≠n t√¢m\n\n"
                reply += "üèÜ **TOUR RI√äNG N·ªîI B·∫¨T ƒê√É TH·ª∞C HI·ªÜN:**\n"
                reply += "‚Ä¢ Tour gia ƒë√¨nh 3 th·∫ø h·ªá (t·ª´ 6-70 tu·ªïi)\n"
                reply += "‚Ä¢ Tour teambuilding c√¥ng ty (50 ng∆∞·ªùi)\n"
                reply += "‚Ä¢ Tour retreat thi·ªÅn 7 ng√†y\n"
                reply += "‚Ä¢ Tour nhi·∫øp ·∫£nh chuy√™n nghi·ªáp\n\n"
                reply += "üí° **Y√äU C·∫¶U TOUR RI√äNG C·∫¶N C√ì:**\n"
                reply += "‚Ä¢ S·ªë l∆∞·ª£ng ng∆∞·ªùi tham gia\n"
                reply += "‚Ä¢ Th·ªùi gian d·ª± ki·∫øn\n"
                reply += "‚Ä¢ Ng√¢n s√°ch ∆∞·ªõc t√≠nh\n"
                reply += "‚Ä¢ S·ªü th√≠ch, y√™u c·∫ßu ƒë·∫∑c bi·ªát\n\n"
                reply += "üìû **Li√™n h·ªá thi·∫øt k·∫ø tour ri√™ng:** 0332510486"
            
            else:
                reply = "Ruby Wings c√≥ ch√≠nh s√°ch ∆∞u ƒë√£i ƒë·∫∑c bi·ªát cho nh√≥m v√† d·ªãch v·ª• thi·∫øt k·∫ø tour theo y√™u c·∫ßu. Li√™n h·ªá hotline ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt."
        
        # üîπ CASE 10: BOOKING & POLICY INFO
        elif 'booking_info' in detected_intents or 'policy' in detected_intents:
            logger.info("üìù Processing booking/policy inquiry")
            
            if 'ƒë·∫∑t tour' in message_lower or 'booking' in message_lower:
                reply = "üìù **QUY TR√åNH ƒê·∫∂T TOUR RUBY WINGS** üìù\n\n"
                reply += "**B∆∞·ªõc 1: T∆∞ v·∫•n & ch·ªçn tour**\n"
                reply += "‚Ä¢ Li√™n h·ªá hotline 0332510486\n"
                reply += "‚Ä¢ Nh·∫≠n t∆∞ v·∫•n tour ph√π h·ª£p\n"
                reply += "‚Ä¢ X√°c nh·∫≠n l·ªãch tr√¨nh, gi√° c·∫£\n\n"
                reply += "**B∆∞·ªõc 2: ƒê·∫∑t c·ªçc & x√°c nh·∫≠n**\n"
                reply += "‚Ä¢ ƒê·∫∑t c·ªçc 30% gi√° tr·ªã tour\n"
                reply += "‚Ä¢ K√Ω h·ª£p ƒë·ªìng d·ªãch v·ª•\n"
                reply += "‚Ä¢ Nh·∫≠n x√°c nh·∫≠n booking\n\n"
                reply += "**B∆∞·ªõc 3: Chu·∫©n b·ªã & thanh to√°n**\n"
                reply += "‚Ä¢ Thanh to√°n 70% c√≤n l·∫°i tr∆∞·ªõc 7 ng√†y\n"
                reply += "‚Ä¢ Nh·∫≠n th√¥ng tin chi ti·∫øt tour\n"
                reply += "‚Ä¢ Chu·∫©n b·ªã h√†nh l√Ω, gi·∫•y t·ªù\n\n"
                reply += "**B∆∞·ªõc 4: Kh·ªüi h√†nh & tr·∫£i nghi·ªám**\n"
                reply += "‚Ä¢ ƒê√≥n kh√°ch t·∫°i ƒëi·ªÉm h·∫πn\n"
                reply += "‚Ä¢ Tr·∫£i nghi·ªám tour tuy·ªát v·ªùi\n"
                reply += "‚Ä¢ Feedback sau tour\n\n"
                reply += "üìû **ƒê·∫∑t tour ngay:** 0332510486"
            
            elif 'gi·∫£m gi√°' in message_lower or '∆∞u ƒë√£i' in message_lower:
                reply = "üéÅ **CH√çNH S√ÅCH ∆ØU ƒê√ÉI & KHUY·∫æN M√ÉI** üéÅ\n\n"
                reply += "**1. ∆Øu ƒë√£i nh√≥m:**\n"
                reply += "‚Ä¢ 10-15 ng∆∞·ªùi: Gi·∫£m 10%\n"
                reply += "‚Ä¢ 16-20 ng∆∞·ªùi: Gi·∫£m 15%\n"
                reply += "‚Ä¢ 21+ ng∆∞·ªùi: Gi·∫£m 20%\n\n"
                reply += "**2. ∆Øu ƒë√£i ƒë·∫∑t s·ªõm:**\n"
                reply += "‚Ä¢ ƒê·∫∑t tr∆∞·ªõc 30 ng√†y: Gi·∫£m 5%\n"
                reply += "‚Ä¢ ƒê·∫∑t tr∆∞·ªõc 60 ng√†y: Gi·∫£m 8%\n\n"
                reply += "**3. ∆Øu ƒë√£i ƒë·∫∑c bi·ªát:**\n"
                reply += "‚Ä¢ C·ª±u chi·∫øn binh: Th√™m 5%\n"
                reply += "‚Ä¢ H·ªçc sinh/sinh vi√™n: Gi·∫£m 10%\n"
                reply += "‚Ä¢ Kh√°ch quay l·∫°i: Gi·∫£m 5%\n\n"
                reply += "**4. Ch∆∞∆°ng tr√¨nh t√≠ch ƒëi·ªÉm:**\n"
                reply += "‚Ä¢ M·ªói tour: T√≠ch 1 ƒëi·ªÉm\n"
                reply += "‚Ä¢ 5 ƒëi·ªÉm: Gi·∫£m 10% tour ti·∫øp theo\n"
                reply += "‚Ä¢ 10 ƒëi·ªÉm: T·∫∑ng 1 tour 1 ng√†y\n\n"
                reply += "üìû **Nh·∫≠n ∆∞u ƒë√£i t·ªët nh·∫•t:** 0332510486"
            
            else:
                reply = "Ruby Wings c√≥ ch√≠nh s√°ch ∆∞u ƒë√£i h·∫•p d·∫´n v√† quy tr√¨nh ƒë·∫∑t tour chuy√™n nghi·ªáp. Li√™n h·ªá hotline ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n chi ti·∫øt."
        if (not response_locked) and ('pha tam giang' in message_norm or 'ƒë·∫ßm chu·ªìn' in message_lower):
            exact_hits = resolve_best_tour_indices('Di s·∫£n Hu·∫ø ƒê·∫ßm Chu·ªìn Ho√†ng h√¥n ph√° Tam Giang', top_k=1)
            if exact_hits:
                t = TOURS_DB.get(exact_hits[0])
                if t:
                    reply = format_tour_program_response(t)
                    response_locked = True
        # üîπ CASE 11: OUT OF SCOPE QUESTIONS (x·ª≠ l√Ω b·∫±ng AI)
        else:
            logger.info("ü§ñ Processing with general search")
            
            # 1. Th·ª≠ FAISS search tr∆∞·ªõc
            search_results = query_index(user_message, TOP_K)
            
            # 2. N·∫øu kh√¥ng c√≥ k·∫øt qu·∫£, d√πng fallback
            if not search_results or len(search_results) < 2:
                logger.warning(f"‚ö†Ô∏è FAISS returned {len(search_results) if search_results else 0} results, using fallback")
                
                # L·∫•y c√°c tour ph√π h·ª£p v·ªõi t·ª´ kh√≥a
                fallback_tours = get_fallback_tours(user_message, limit=3)
                
                if fallback_tours:
                    # T·∫°o response t·ª´ fallback tours
                    reply = f"üîç **T√åM TH·∫§Y {len(fallback_tours)} TOUR PH√ô H·ª¢P**\n\n"
                    
                    for i, tour in enumerate(fallback_tours, 1):
                        reply += f"{i}. **{tour.name}**\n"
                        if tour.duration:
                            reply += f"   ‚è±Ô∏è {tour.duration}\n"
                        if tour.location:
                            reply += f"   üìç {tour.location}\n"
                        if tour.summary:
                            summary = tour.summary[:100] + "..." if len(tour.summary) > 100 else tour.summary
                            reply += f"   üìù {summary}\n"
                        reply += "\n"
                    
                    reply += "üí° **B·∫°n mu·ªën bi·∫øt th√™m v·ªÅ tour n√†o?**\n"
                    reply += "üìû **T∆∞ v·∫•n chi ti·∫øt:** 0332510486"
                    
                    # C·∫≠p nh·∫≠t tour_indices
                    for tour in fallback_tours:
                        for idx, db_tour in TOURS_DB.items():
                            if db_tour.name == tour.name:
                                tour_indices.append(idx)
                                break
                else:
                    # D√πng AI ƒë·ªÉ tr·∫£ l·ªùi
                    if client and HAS_OPENAI:
                        try:
                            prompt = f"""B·∫°n l√† t∆∞ v·∫•n vi√™n Ruby Wings Travel. Kh√°ch h·ªèi: "{user_message}"

        TH√îNG TIN C√îNG TY:
        - C√≥ 33 tour ƒëa d·∫°ng: thi√™n nhi√™n, l·ªãch s·ª≠, retreat, gia ƒë√¨nh
        - Khu v·ª±c: Hu·∫ø, Qu·∫£ng Tr·ªã, B·∫°ch M√£, Tr∆∞·ªùng S∆°n
        - Gi√° t·ª´ 500.000ƒë - 5.000.000ƒë

        Y√äU C·∫¶U:
        1. Gi·ªõi thi·ªáu t·ªïng quan v·ªÅ Ruby Wings
        2. G·ª£i √Ω m·ªôt s·ªë lo·∫°i tour ph·ªï bi·∫øn
        3. M·ªùi li√™n h·ªá hotline ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt

        Tr·∫£ l·ªùi th√¢n thi·ªán, chuy√™n nghi·ªáp."""

                            response = client.chat.completions.create(
                                model=CHAT_MODEL,
                                messages=[
                                    {"role": "system", "content": prompt},
                                    {"role": "user", "content": user_message}
                                ],
                                temperature=0.6,
                                max_tokens=300
                            )
                            
                            if response.choices:
                                reply = response.choices[0].message.content or ""
                            else:
                                reply = "Ruby Wings c√≥ 33 tour ƒëa d·∫°ng ph·ª•c v·ª• nhi·ªÅu nhu c·∫ßu. B·∫°n quan t√¢m lo·∫°i tour n√†o: thi√™n nhi√™n, l·ªãch s·ª≠, retreat hay gia ƒë√¨nh?"
                        
                        except Exception as e:
                            logger.error(f"OpenAI error: {e}")
                            reply = "Ruby Wings Travel - ƒê·ªìng h√†nh c√πng b·∫°n trong nh·ªØng h√†nh tr√¨nh √Ω nghƒ©a. üìû Hotline: 0332510486"
                    else:
                        reply = "‚ú® **RUBY WINGS TRAVEL** ‚ú®\n\n"
                        reply += "Ch√∫ng t√¥i c√≥ 33 tour ƒë·∫∑c s·∫Øc t·∫°i mi·ªÅn Trung:\n\n"
                        reply += "üåø **Tour Thi√™n Nhi√™n:** B·∫°ch M√£, Tr∆∞·ªùng S∆°n, r·ª´ng nguy√™n sinh\n"
                        reply += "üèõÔ∏è **Tour L·ªãch S·ª≠:** Di s·∫£n Hu·∫ø, ƒë·ªãa ƒë·∫°o V·ªãnh M·ªëc, Th√†nh c·ªï\n"
                        reply += "üïâÔ∏è **Tour Retreat:** Thi·ªÅn, yoga, ch·ªØa l√†nh gi·ªØa thi√™n nhi√™n\n"
                        reply += "üë®‚Äçüë©‚Äçüëß‚Äçüë¶ **Tour Gia ƒê√¨nh:** Ph√π h·ª£p t·ª´ tr·∫ª nh·ªè ƒë·∫øn ng∆∞·ªùi l·ªõn tu·ªïi\n"
                        reply += "üéØ **Tour Nh√≥m:** Teambuilding, c√¥ng ty, b·∫°n b√®\n\n"
                        reply += "üìû **Li√™n h·ªá ngay 0332510486 ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n tour ph√π h·ª£p!**"
         
            else:
                # Default: Semantic search + AI
                search_results = query_index(user_message, TOP_K)
                
                if UpgradeFlags.is_enabled("2_DEDUPLICATION") and search_results:
                    search_results = DeduplicationEngine.deduplicate_passages(search_results)
                
                # Chu·∫©n b·ªã context cho AI
                context_info = {
                    'user_message': user_message,
                    'tour_indices': tour_indices,
                    'detected_intents': detected_intents,
                    'filters': mandatory_filters.to_dict() if mandatory_filters else {}
                }
                
                # T·∫°o prompt th√¥ng minh
                prompt = _prepare_llm_prompt(user_message, search_results, context_info)
                
                # G·ªçi AI
                if client and HAS_OPENAI:
                    try:
                        messages = [
                            {"role": "system", "content": prompt},
                            {"role": "user", "content": user_message}
                        ]
                        
                        response = client.chat.completions.create(
                            model=CHAT_MODEL,
                            messages=messages,
                            temperature=0.6,
                            max_tokens=500,
                            top_p=0.9,
                            frequency_penalty=0.2,
                            presence_penalty=0.1
                        )
                        
                        if response.choices:
                            reply = response.choices[0].message.content or ""
                        else:
                            reply = _generate_fallback_response(user_message, search_results, tour_indices)
                    
                    except Exception as e:
                        logger.error(f"OpenAI general error: {e}")
                        reply = _generate_fallback_response(user_message, search_results, tour_indices)
                else:
                    reply = _generate_fallback_response(user_message, search_results, tour_indices)
                
                sources = [m for _, m in search_results]
        
        # ================== ENHANCE RESPONSE QUALITY ==================
        # ƒê·∫£m b·∫£o m·ªçi response ƒë·ªÅu c√≥ hotline
        if "0332510486" not in reply and "hotline" not in reply.lower():
            reply += "\n\nüìû **Hotline t∆∞ v·∫•n 24/7:** 0332510486"
        
        # Gi·ªõi h·∫°n ƒë·ªô d√†i response
        if len(reply) > 2000:
            reply = reply[:2000] + "...\n\nüí° ƒê·ªÉ bi·∫øt th√™m chi ti·∫øt, vui l√≤ng li√™n h·ªá hotline 0332510486"
        
        # ================== UPDATE CONTEXT ==================
        # C·∫≠p nh·∫≠t tour context n·∫øu c√≥ tour ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p
        if tour_indices and len(tour_indices) > 0:
            context.current_tour = tour_indices[0]
            context.current_tour_updated_at = datetime.utcnow().isoformat()
            tour = TOURS_DB.get(tour_indices[0])
            if tour:
                context.last_tour_name = tour.name
        
        # L∆∞u reply v√†o history
        context.conversation_history.append({
            'role': 'assistant',
            'message': reply,
            'timestamp': datetime.utcnow().isoformat(),
            'tour_indices': tour_indices
        })
        
        # ================== FINAL RESPONSE ==================
        processing_time = time.time() - start_time
        
        chat_response = ChatResponse(
            reply=reply,
            sources=sources,
            context={
                "session_id": session_id,
                "current_tour": getattr(context, 'current_tour', None),
                "last_tour_name": getattr(context, 'last_tour_name', None),
                "user_preferences": getattr(context, 'user_profile', {}),
                "detected_intents": detected_intents,
                "processing_time_ms": int(processing_time * 1000),
                "tours_found": len(tour_indices),
                "complexity_score": complexity_score
            },
            tour_indices=tour_indices,
            processing_time_ms=int(processing_time * 1000),
            from_memory=False
        )
        
        # Cache response
        if UpgradeFlags.get_all_flags().get("ENABLE_CACHING", True):
            context_hash = hashlib.md5(json.dumps({
                'tour_indices': tour_indices,
                'detected_intents': detected_intents,
                'complexity': complexity_score
            }, sort_keys=True).encode()).hexdigest()
            
            cache_key = CacheSystem.get_cache_key(user_message, context_hash)
            CacheSystem.set(cache_key, chat_response.to_dict())
        
        logger.info(f"‚úÖ Processed in {processing_time:.2f}s | "
                   f"Intents: {detected_intents} | "
                   f"Tours: {len(tour_indices)} | "
                   f"Complexity: {complexity_score}")
        
        return jsonify(chat_response.to_dict())
    
    except Exception as e:
        logger.error(f"‚ùå Chat endpoint error: {e}\n{traceback.format_exc()}")
        
        processing_time = time.time() - start_time
        
        # Smart error response
        error_response = ChatResponse(
            reply="‚ö° **C√≥ ch√∫t tr·ª•c tr·∫∑c k·ªπ thu·∫≠t, nh∆∞ng ƒë·ªôi ng≈© Ruby Wings v·∫´n s·∫µn s√†ng h·ªó tr·ª£ b·∫°n!**\n\n"
                  "üîß **C√°ch gi·∫£i quy·∫øt nhanh:**\n"
                  "1. **G·ªçi ngay:** üìû 0332510486 (t∆∞ v·∫•n tr·ª±c ti·∫øp)\n"
                  "2. **Th·ª≠ l·∫°i:** G√µ c√¢u h·ªèi ng·∫Øn g·ªçn h∆°n\n"
                  "3. **Ch·ªçn tour:** 'Tour 1 ng√†y Hu·∫ø', 'Tour gia ƒë√¨nh 2 ng√†y'\n\n"
                  "‚è∞ **Ch√∫ng t√¥i ho·∫°t ƒë·ªông 24/7 ƒë·ªÉ ph·ª•c v·ª• b·∫°n!** üòä",
            sources=[],
            context={
                "error": str(e),
                "processing_time_ms": int(processing_time * 1000)
            },
            tour_indices=[],
            processing_time_ms=int(processing_time * 1000),
            from_memory=False
        )
        
        return jsonify(error_response.to_dict()), 500





# =========== OTHER ENDPOINTS ===========
@app.route("/")
def home():
    """Home endpoint"""
    return jsonify({
        "status": "ok",
        "version": "4.0",
        "upgrades": UpgradeFlags.get_all_flags(),
        "services": {
            "openai": "available" if client else "unavailable",
            "faiss": "available" if HAS_FAISS else "unavailable",
            "google_sheets": "available" if HAS_GOOGLE_SHEETS else "unavailable",
            "meta_capi": "available" if HAS_META_CAPI else "unavailable",
        },
        "counts": {
            "tours": len(TOURS_DB),
            "passages": len(FLAT_TEXTS),
            "tour_names": len(TOUR_NAME_TO_INDEX),
        }
    })

@app.route("/reindex", methods=["POST"])
def reindex():
    """Rebuild index endpoint"""
    secret = request.headers.get("X-RBW-ADMIN", "")
    if not secret and os.environ.get("RBW_ALLOW_REINDEX", "") != "1":
        return jsonify({"error": "reindex not allowed"}), 403
    
    load_knowledge()
    build_index(force_rebuild=True)
    
    return jsonify({
        "ok": True,
        "count": len(FLAT_TEXTS),
        "tours": len(TOURS_DB)
    })

# =========== GOOGLE SHEETS INTEGRATION ===========
_gsheet_client = None
_gsheet_client_lock = threading.Lock()

def get_gspread_client(force_refresh: bool = False):
    """Get Google Sheets client"""
    global _gsheet_client
    
    if not GOOGLE_SERVICE_ACCOUNT_JSON:
        logger.error("GOOGLE_SERVICE_ACCOUNT_JSON not set")
        return None
    
    with _gsheet_client_lock:
        if _gsheet_client is not None and not force_refresh:
            return _gsheet_client
        
        try:
            info = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
            scopes = [
                "https://www.googleapis.com/auth/spreadsheets",
                "https://www.googleapis.com/auth/drive",
            ]
            creds = Credentials.from_service_account_info(info, scopes=scopes)
            _gsheet_client = gspread.authorize(creds)
            logger.info("‚úÖ Google Sheets client initialized")
            return _gsheet_client
        except Exception as e:
            logger.error(f"‚ùå Google Sheets client failed: {e}")
            return None

# ===============================
# API: SAVE LEAD (Website / Call / Zalo)
# ===============================
@app.route('/api/save-lead', methods=['POST', 'OPTIONS'])
def save_lead():
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200

    try:
        data = request.get_json() or {}

        # =====================================================
        # 1. EXTRACT & VALIDATE (GI·ªÆ NGUY√äN LOGIC C≈®)
        # =====================================================
        phone = (data.get('phone') or '').strip()
        name = (data.get('name') or '').strip()
        email = (data.get('email') or '').strip()
        tour_interest = (data.get('tour_interest') or '').strip()
        page_url = (data.get('page_url') or '').strip()
        note = (data.get('note') or '').strip()

        # üîë FE ‚Üí BE event_id (KH√îNG t·ª± sinh)
        event_id = data.get('event_id')
        # üîí HARD DEDUP: CAPI ch·ªâ ch·∫°y khi c√≥ event_id t·ª´ FE
        if not event_id:
            logger.info("‚ÑπÔ∏è Lead without event_id ‚Üí Pixel only, skip CAPI")
        if not phone and not data.get('event_id'):
            return jsonify({'error': 'Phone number is required'}), 400

        phone_clean = re.sub(r'\D', '', phone)
        if phone_clean and not re.match(r'^0\d{9,10}$', phone_clean):
            return jsonify({'error': 'Invalid phone number format'}), 400

        timestamp = datetime.now().strftime("%d/%m/%Y %H:%M:%S")


        lead_data = {
            'timestamp': timestamp,
            'phone': phone_clean,
            'name': name,
            'email': email,
            'tour_interest': tour_interest,
            'page_url': page_url,
            'note': note,
            'source': 'Website Lead Form'
        }

        # =====================================================
        # 2. SAVE GOOGLE SHEETS (CH·ªà GHI KHI C√ì LEAD TH·∫¨T)
        # =====================================================
        if ENABLE_GOOGLE_SHEETS and phone_clean:
            try:
                import gspread
                from google.oauth2.service_account import Credentials

                creds_json = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
                creds = Credentials.from_service_account_info(
                    creds_json,
                    scopes=['https://www.googleapis.com/auth/spreadsheets']
                )

                gc = gspread.authorize(creds)
                sh = gc.open_by_key(GOOGLE_SHEET_ID)
                ws = sh.worksheet(GOOGLE_SHEET_NAME)

                ws.append_row(
                    [
                        timestamp,
                        'Website - Lead Form',
                        'Form Submission',
                        page_url or '',
                        name or '',
                        int(phone_clean) if phone_clean else '',
                        tour_interest or '',
                        note or email or '',
                        'New'
                    ],
                    value_input_option='USER_ENTERED'
                )

                logger.info('‚úÖ Lead saved to Google Sheets')

            except Exception as e:
                logger.error(f'‚ùå Google Sheets error: {e}')

        # =====================================================
        # 3. FALLBACK STORAGE (KH√îNG ƒê·ª§NG)
        # =====================================================
        if ENABLE_FALLBACK_STORAGE:
            try:
                if os.path.exists(FALLBACK_STORAGE_PATH):
                    with open(FALLBACK_STORAGE_PATH, 'r', encoding='utf-8') as f:
                        leads = json.load(f)
                else:
                    leads = []

                leads.append(lead_data)
                leads = leads[-1000:]

                with open(FALLBACK_STORAGE_PATH, 'w', encoding='utf-8') as f:
                    json.dump(leads, f, ensure_ascii=False, indent=2)

            except Exception as e:
                logger.error(f'‚ùå Fallback storage error: {e}')

        # =====================================================
        # 4. META PARAM BUILDER (FBP / FBC ‚Äì FALLBACK DEDUP)
        # =====================================================
        meta = MetaParamService()
        meta.process_request(request)

        fbp = meta.get_fbp()
        fbc = meta.get_fbc()

        # Chu·∫©n Meta: event_source_url
        event_source_url = (
            page_url
            or request.headers.get("Referer")
            or request.url
        )
        
        # =====================================================
        # 5. META CAPI ‚Äì LEAD (CHU·∫®N META, DEDUP 100%)
        # =====================================================
        if ENABLE_META_CAPI_LEAD and HAS_META_CAPI:

            test_code = os.environ.get("META_TEST_EVENT_CODE", "").strip()
            is_test_mode = bool(test_code)

            # ===== PROD: b·∫Øt bu·ªôc c√≥ event_id ƒë·ªÉ dedup =====
            if not event_id and not is_test_mode:
                logger.warning(
                    "‚ö†Ô∏è Lead submitted without event_id "
                    "(PROD mode ‚Üí Pixel only, CAPI skipped)"
                )
            else:
                try:
                    # ================= LEAD ‚Äì META CAPI (CH·ªà FORM TH·∫¨T) =================
                    phone_clean = re.sub(r'\D', '', phone or '')

                    if phone_clean and re.match(r'^0\d{9,10}$', phone_clean) and event_id:
                        send_meta_lead(
                            request=request,
                            event_name="Contact",
                            event_id=event_id,          # üîí B·∫ÆT BU·ªòC t·ª´ FE
                            phone=phone_clean,
                            fbp=fbp,
                            fbc=fbc,
                            event_source_url=event_source_url,
                            content_name=(
                                f"Tour: {tour_interest}"
                                if tour_interest else "Website Lead Form"
                            )
                        )

                        increment_stat("meta_capi_leads")
                        logger.info(
                            f"üì© Meta CAPI Lead sent | "
                            f"mode=PROD | event_id={event_id}"
                        )
                    else:
                        logger.warning(
                            "‚ö†Ô∏è Meta CAPI Lead b·ªã b·ªè qua: thi·∫øu event_id ho·∫∑c ch∆∞a ph·∫£i lead th·∫≠t"
                        )


                except Exception as e:
                    increment_stat("meta_capi_errors")
                    logger.error(f"‚ùå Meta CAPI Lead error: {e}")

        increment_stat("leads")


        # =====================================================
        # 6. RESPONSE
        # =====================================================
        return jsonify({
            'success': True,
            'message': 'Lead ƒë√£ ƒë∆∞·ª£c l∆∞u',
            'data': {
                'phone': phone_clean[:3] + '***' + phone_clean[-2:],
                'timestamp': timestamp
            }
        })

    except Exception as e:
        logger.error(f'‚ùå Save lead fatal error: {e}')
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500



# ===============================
# API: CALL / ZALO CLICK (Meta CAPI - CallButtonClick)
# ===============================
# =========================================================
# API: CONTACT CLICK (ALIAS ‚Äì FIX 404, SAFE)
# =========================================================
ALLOWED_ORIGINS = [
    "https://rubywings.vn",
    "https://www.rubywings.vn",
    "http://localhost:3000",  # local dev
]

def cors_origin():
    """
    CORS production-safe:
    - Cho ph√©p Origin trong whitelist
    - Same-origin / server-side ‚Üí cho qua
    - Origin l·∫° ‚Üí v·∫´n tr·∫£ v·ªÅ Origin ƒë·ªÉ KH√îNG l√†m ch·∫øt h·ªá
    - Kh√¥ng d√πng "*" cho browser-origin (tr√°nh l·ªói credentials)
    """
    origin = request.headers.get("Origin")

    # Same-origin / server-side / tool (no Origin header)
    if not origin:
        return "https://www.rubywings.vn"

    # Whitelist chu·∫©n
    if origin in ALLOWED_ORIGINS:
        return origin

    # Fallback an to√†n: KH√îNG ch·∫∑n POST, nh∆∞ng KH√îNG m·ªü wildcard
    return origin



@app.route("/api/track-contact", methods=["POST", "OPTIONS"])
def track_contact():
    logger.warning(f"[CORS AUDIT] Origin={request.headers.get('Origin')}")
    # ===== CORS PREFLIGHT =====
    if request.method == 'OPTIONS':
        response = jsonify({'status': 'ok'})
        response.headers.add("Access-Control-Allow-Origin", cors_origin())
        response.headers.add("Access-Control-Allow-Methods", "POST, OPTIONS")
        response.headers.add(
            "Access-Control-Allow-Headers",
            "Content-Type, X-RW-EVENT-ID"
        )
        response.headers.add("Access-Control-Max-Age", "86400")
        return response, 200

    try:
        data = request.get_json() or {}
        event_id = data.get('event_id')
        phone = data.get('phone')
        source = data.get('source', 'Contact')

        logger.info(f"üìû Track contact: source={source}, event_id={event_id[:8] if event_id else 'None'}")

        # üîí 1. CHECK EVENT_ID (b·∫Øt bu·ªôc cho CAPI)
        if not event_id:
            logger.warning(f"‚ö†Ô∏è Missing event_id ‚Üí Pixel only ({source})")
            response = jsonify({'success': True, 'message': 'Pixel only (no CAPI)'})
            response.headers.add("Access-Control-Allow-Origin", cors_origin())
            return response

        # üîí 2. CHECK META CAPI AVAILABILITY
        if not ENABLE_META_CAPI_LEAD or not HAS_META_CAPI:
            logger.info(f"‚ÑπÔ∏è Meta CAPI disabled: ENABLE_META_CAPI_LEAD={ENABLE_META_CAPI_LEAD}, HAS_META_CAPI={HAS_META_CAPI}")
            response = jsonify({'success': True, 'message': 'CAPI disabled'})
            response.headers.add("Access-Control-Allow-Origin", cors_origin())
            return response

        # üîí 3. EXTRACT META PARAMS
        meta = MetaParamService()
        meta.process_request(request)

        # üîí 4. SEND META CAPI
        send_meta_lead(
            request=request,
            event_name="Lead",  # Chu·∫©n Meta: "Lead" thay v√¨ "Contact"
            event_id=event_id,
            phone=phone or "",
            fbp=meta.get_fbp(),
            fbc=meta.get_fbc(),
            content_name=f"Contact: {source}"
        )
        increment_stat('meta_capi_leads')
        logger.info(f"‚úÖ Meta CAPI Lead sent: {source}")

        response = jsonify({'success': True})
        response.headers.add("Access-Control-Allow-Origin", cors_origin())
        return response

    except Exception as e:
        increment_stat('meta_capi_errors')
        logger.error(f"‚ùå Track contact error: {e}", exc_info=True)
        response = jsonify({'error': 'Internal server error'})
        response.headers.add("Access-Control-Allow-Origin", cors_origin())
        return response, 500


@app.route('/api/track-call', methods=['POST', 'OPTIONS'])
def track_call():
    if request.method == 'OPTIONS':
        return jsonify({'status': 'ok'}), 200

    try:
        data = request.get_json() or {}

        event_id = data.get('event_id')
        phone = data.get('phone')
        action = data.get('action', 'Call/Zalo Click')

        # ===== META PARAM BUILDER =====
        meta = MetaParamService()
        meta.process_request(request)

        fbp = meta.get_fbp()
        fbc = meta.get_fbc()

        if ENABLE_META_CAPI_CALL and HAS_META_CAPI:
            send_meta_lead(
                request=request,
                event_name="CallButtonClick",  # KH√îNG ƒë·ªïi
                event_id=event_id,             # t·ª´ FE
                phone=phone,
                fbp=fbp,                       # fallback dedup
                fbc=fbc,                       # fallback dedup
                content_name=action
            )
            increment_stat('meta_capi_calls')
            logger.info("üìû CallButtonClick Meta CAPI sent")

        return jsonify({'success': True})

    except Exception as e:
        increment_stat('meta_capi_errors')
        logger.error(f'‚ùå Track call error: {e}')
        return jsonify({'error': str(e)}), 500







@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    try:
        return jsonify({
            "status": "healthy",
            "timestamp": datetime.utcnow().isoformat(),
            "services": {
                "chatbot": "running",
                "openai": "available" if client else "unavailable",
                "faiss": "available" if INDEX else "unavailable",
                "tours_db": len(TOURS_DB),
                "upgrades": {k: v for k, v in UpgradeFlags.get_all_flags().items() 
                           if k.startswith("UPGRADE_")}
            },
            "memory_profile": {
                "ram_profile": RAM_PROFILE,
                "is_low_ram": IS_LOW_RAM,
                "is_high_ram": IS_HIGH_RAM,
                "tour_count": len(TOURS_DB),
                "context_count": len(SESSION_CONTEXTS)
            }
        })
    except Exception as e:
        return jsonify({
            "status": "unhealthy",
            "error": str(e)
        }), 500

# =========== INITIALIZATION ===========
def initialize_app():
    """Initialize the application"""
    logger.info("üöÄ Starting Ruby Wings Chatbot v4.0 (Dataclass Rewrite)...")
    
    # Apply memory optimizations
    optimize_for_memory_profile()
    
    # Load knowledge base
    load_knowledge()
    
    # Load or build tours database (SAFE)
    if os.path.exists(FAISS_MAPPING_PATH):
        try:
            with open(FAISS_MAPPING_PATH, 'r', encoding='utf-8') as f:
                loaded = json.load(f)

            # Defensive: ch·ªâ ch·∫•p nh·∫≠n list[dict]
            if isinstance(loaded, list):
                safe_mapping = [m for m in loaded if isinstance(m, dict)]
                MAPPING[:] = safe_mapping
                FLAT_TEXTS[:] = [m.get('text', '') for m in safe_mapping]
                logger.info(f"üìÅ Loaded {len(MAPPING)} mappings from disk (safe)")
            else:
                MAPPING[:] = []
                FLAT_TEXTS[:] = []
                logger.warning(
                    "‚ö†Ô∏è FAISS_MAPPING_PATH is not list, skip loading mappings"
                )

        except Exception as e:
            MAPPING[:] = []
            FLAT_TEXTS[:] = []
            logger.error(f"‚ùå Failed to load mappings safely: {e}")
    
    # Build tour databases
    # index_tour_names()
    # build_tours_db()
    
    # Build index in background
    def build_index_background():
        time.sleep(2)
        success = build_index(force_rebuild=False)
        if success:
            logger.info("‚úÖ Index ready")
        else:
            logger.warning("‚ö†Ô∏è Index building failed")
    
    threading.Thread(target=build_index_background, daemon=True).start()
    
    # Initialize Google Sheets client
    if ENABLE_GOOGLE_SHEETS:
        threading.Thread(target=get_gspread_client, daemon=True).start()
    
    # Log active upgrades
    active_upgrades = [
        name for name, enabled in UpgradeFlags.get_all_flags().items()
        if enabled and name.startswith("UPGRADE_")
    ]
    logger.info(f"üîß Active upgrades: {len(active_upgrades)}")
    for upgrade in active_upgrades:
        logger.info(f"   ‚Ä¢ {upgrade}")
    
    # Log memory profile
    logger.info(
        f"üß† Memory Profile: {RAM_PROFILE}MB | "
        f"Low RAM: {IS_LOW_RAM} | High RAM: {IS_HIGH_RAM}"
    )
    logger.info(f"üìä Tours Database: {len(TOURS_DB)} tours loaded")
    
    logger.info("‚úÖ Application initialized successfully with dataclasses")


# =========== APPLICATION START ===========
# ================== INITIALIZE ON STARTUP ==================
# ================== ƒê·∫¢M B·∫¢O KH·ªûI T·∫†O KHI ·ª®NG D·ª§NG CH·∫†Y ==================
def initialize_on_start():
    """Kh·ªüi t·∫°o d·ªØ li·ªáu khi ·ª©ng d·ª•ng b·∫Øt ƒë·∫ßu"""
    try:
        logger.info("üöÄ Kh·ªüi ƒë·ªông Ruby Wings Chatbot v4...")
        
        # ƒê·∫£m b·∫£o th∆∞ m·ª•c data t·ªìn t·∫°i
        if not os.path.exists("data"):
            os.makedirs("data")
            logger.info("üìÅ T·∫°o th∆∞ m·ª•c data")
        
        # T·∫£i knowledge base
        load_knowledge()
        logger.info(f"‚úÖ ƒê√£ t·∫£i {len(TOURS_DB)} tours, {len(TOUR_NAME_TO_INDEX)} t√™n tour")
        
        if len(TOURS_DB) == 0:
            logger.error("‚ùå KH√îNG t·∫£i ƒë∆∞·ª£c tours n√†o t·ª´ knowledge.json!")
            logger.error(f"   Current directory: {os.getcwd()}")
            logger.error(f"   Files: {os.listdir('.')}")
            if os.path.exists("data"):
                logger.error(f"   Data files: {os.listdir('data')}")
        
        # X√¢y d·ª±ng FAISS index n·∫øu c√≥
        if HAS_FAISS and len(FLAT_TEXTS) > 0:
            build_index()
            logger.info(f"‚úÖ ƒê√£ x√¢y d·ª±ng FAISS index v·ªõi {len(FLAT_TEXTS)} passages")
        else:
            logger.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ x√¢y d·ª±ng FAISS index, s·ª≠ d·ª•ng fallback search")
            
    except Exception as e:
        logger.error(f"‚ùå L·ªói kh·ªüi t·∫°o: {e}")
        traceback.print_exc()

# CH·ªà ch·∫°y khi ·ª©ng d·ª•ng th·ª±c s·ª± kh·ªüi ƒë·ªông
if not os.environ.get('RENDER'):  # Tr√™n Render, kh·ªüi t·∫°o qua before_request
    initialize_on_start()
else:
    logger.info("üîÑ Render mode - Kh·ªüi t·∫°o qua before_request")
    pass
@app.route("/api/debug", methods=["GET"])
def debug_endpoint():
    """Debug endpoint to check loaded data"""
    debug_info = {
        "status": "healthy" if len(TOURS_DB) > 0 else "no_data",
        "app_initialized": APP_INITIALIZED,
        "counts": {
            "tours_db": len(TOURS_DB),
            "tour_name_to_index": len(TOUR_NAME_TO_INDEX),
            "flat_texts": len(FLAT_TEXTS),
            "knowledge_tours": len(KNOW.get("tours", [])) if KNOW else 0
        },
        "sample_tours": [],
        "file_info": {
            "current_directory": os.getcwd(),
            "data_directory_exists": os.path.exists("data"),
            "files_in_current_dir": os.listdir("."),
        }
    }
    
    # Th√™m th√¥ng tin v·ªÅ 3 tour ƒë·∫ßu ti√™n
    for i, (idx, tour) in enumerate(list(TOURS_DB.items())[:3]):
        debug_info["sample_tours"].append({
            "id": idx,
            "name": tour.name,
            "location": tour.location,
            "duration": tour.duration,
            "price": tour.price[:50] if tour.price else ""
        })
    
    # Th√™m th√¥ng tin v·ªÅ c√°c file trong th∆∞ m·ª•c data n·∫øu c√≥
    if os.path.exists("data"):
        debug_info["file_info"]["files_in_data_dir"] = os.listdir("data")
        # Ki·ªÉm tra knowledge.json
        knowledge_paths = [
            "data/knowledge.json",
            "knowledge.json",
            "src/data/knowledge.json"
        ]
        for path in knowledge_paths:
            if os.path.exists(path):
                debug_info["file_info"]["knowledge_json_found"] = path
                # ƒê·ªçc k√≠ch th∆∞·ªõc file
                try:
                    size = os.path.getsize(path)
                    debug_info["file_info"]["knowledge_json_size"] = f"{size} bytes"
                except:
                    pass
                break
    
    # Th√™m th√¥ng tin v·ªÅ upgrades
    debug_info["upgrades"] = UpgradeFlags.get_all_flags()
    
    # Th√™m th√¥ng tin v·ªÅ c√°c services
    debug_info["services"] = {
        "openai": "available" if client else "unavailable",
        "faiss": "available" if HAS_FAISS else "unavailable",
        "google_sheets": "available" if HAS_GOOGLE_SHEETS else "unavailable",
        "meta_capi": "available" if HAS_META_CAPI else "unavailable",
    }
    
    return jsonify(debug_info)
# Run initialization
initialize_app()
if __name__ == "__main__":
# ================== ƒê·∫¢M B·∫¢O KH·ªûI T·∫†O KHI ·ª®NG D·ª§NG CH·∫†Y ==================
    def initialize_on_start():
        """Kh·ªüi t·∫°o d·ªØ li·ªáu khi ·ª©ng d·ª•ng b·∫Øt ƒë·∫ßu"""
        try:
            logger.info("üöÄ Kh·ªüi ƒë·ªông Ruby Wings Chatbot v4...")
            
            # ƒê·∫£m b·∫£o th∆∞ m·ª•c data t·ªìn t·∫°i
            if not os.path.exists("data"):
                os.makedirs("data")
                logger.info("üìÅ T·∫°o th∆∞ m·ª•c data")
            
            # T·∫£i knowledge base
            load_knowledge()
            logger.info(f"‚úÖ ƒê√£ t·∫£i {len(TOURS_DB)} tours, {len(TOUR_NAME_TO_INDEX)} t√™n tour")
            
            if len(TOURS_DB) == 0:
                logger.error("‚ùå KH√îNG t·∫£i ƒë∆∞·ª£c tours n√†o t·ª´ knowledge.json!")
                logger.error(f"   Current directory: {os.getcwd()}")
                logger.error(f"   Files: {os.listdir('.')}")
                if os.path.exists("data"):
                    logger.error(f"   Data files: {os.listdir('data')}")
            
            # X√¢y d·ª±ng FAISS index n·∫øu c√≥
            if HAS_FAISS and len(FLAT_TEXTS) > 0:
                build_index()
                logger.info(f"‚úÖ ƒê√£ x√¢y d·ª±ng FAISS index v·ªõi {len(FLAT_TEXTS)} passages")
            else:
                logger.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ x√¢y d·ª±ng FAISS index, s·ª≠ d·ª•ng fallback search")
                
        except Exception as e:
            logger.error(f"‚ùå L·ªói kh·ªüi t·∫°o: {e}")
            traceback.print_exc()

# CH·ªà ch·∫°y khi ·ª©ng d·ª•ng th·ª±c s·ª± kh·ªüi ƒë·ªông
if not os.environ.get('RENDER'):  # Tr√™n Render, kh·ªüi t·∫°o qua before_request
    initialize_on_start()
else:
    logger.info("üîÑ Render mode - Kh·ªüi t·∫°o qua before_request")
def get_fallback_tours(query=None, limit=5):
    """Fallback khi FAISS kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£"""
    try:
        all_tours = list(TOURS_DB.values())
        
        if query:
            # Simple keyword matching
            query_lower = query.lower()
            matched_tours = []
            
            for tour in all_tours:
                score = 0
                
                # Check name
                if tour.name and query_lower in tour.name.lower():
                    score += 3
                
                # Check location
                if tour.location and query_lower in tour.location.lower():
                    score += 2
                
                # Check tags
                if tour.tags:
                    for tag in tour.tags:
                        if query_lower in tag.lower():
                            score += 1
                
                if score > 0:
                    matched_tours.append((score, tour))
            
            # Sort by score
            matched_tours.sort(key=lambda x: x[0], reverse=True)
            return [tour for _, tour in matched_tours[:limit]]
        
        # Return first N tours if no query
        return all_tours[:limit]
        
    except Exception as e:
        logger.error(f"Fallback tour error: {e}")
        return list(TOURS_DB.values())[:min(limit, len(TOURS_DB))]