#!/usr/bin/env python3
# build_index.py ‚Äî build embeddings/faiss index + mapping + tour_entities.json (compatible with app.py v5.2 & entities.py v5.2)
# Usage:
#   pip install -r requirements.txt
#   export OPENAI_API_KEY="sk-..."
#   python build_index.py

import os
import sys
import json
import time
import datetime
import re
from typing import Any, List, Optional, Tuple, Dict
import numpy as np

# try imports with helpful fallbacks
try:
    import faiss  # type: ignore
    HAS_FAISS = True
except Exception:
    faiss = None
    HAS_FAISS = False

# New OpenAI SDK
try:
    from openai import OpenAI
except Exception:
    OpenAI = None

# =========== NEW: C√ÅC H√ÄM X·ª¨ L√ù M·ªöI CHO C·∫§U TR√öC TOUR_ENTITIES ===========

def extract_region(location_text: str) -> str:
    """
    Tr√≠ch xu·∫•t region (Mi·ªÅn B·∫Øc/Trung/Nam) t·ª´ location string
    """
    if not location_text:
        return "Kh√¥ng x√°c ƒë·ªãnh"
    
    location_lower = location_text.lower()
    
    # Mapping c√°c keyword cho t·ª´ng mi·ªÅn (ƒë·ªìng b·ªô v·ªõi entities.py)
    north_keywords = ["h√† n·ªôi", "sapa", "h·∫° long", "ninh b√¨nh", "tam ƒë·∫£o", "m·ªôc ch√¢u", "ph√∫ th·ªç"]
    central_keywords = [
        "ƒë√† n·∫µng", "hu·∫ø", "qu·∫£ng tr·ªã", "nha trang", "h·ªôi an", "ƒë√¥ng h√†", 
        "c·ª≠a vi·ªát", "c·ªìn c·ªè", "qu·∫£ng b√¨nh", "b·∫°ch m√£", "hi·ªÅn l∆∞∆°ng", "khe sanh",
        "h∆∞·ªõng h√≥a", "h∆∞·ªõng ho√°", "vƒ© tuy·∫øn 17", "ƒë√¥i b·ªù hi·ªÅn l∆∞∆°ng", 
        "v∆∞·ªùn qu·ªëc gia b·∫°ch m√£", "vƒ©nh linh", "gio linh", "th·ªã x√£ qu·∫£ng tr·ªã",
        "ng≈© h·ªì", "th√°c ƒë·ªó quy√™n"
    ]
    south_keywords = [
        "ph√∫ qu·ªëc", "c·∫ßn th∆°", "c√† mau", "s√†i g√≤n", "th√†nh ph·ªë h·ªì ch√≠ minh", 
        "v≈©ng t√†u", "ƒë√† l·∫°t", "bu√¥n ma thu·ªôt", "nha trang", "phan thi·∫øt"
    ]
    
    # ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa t·ª´ng mi·ªÅn
    north_count = sum(1 for kw in north_keywords if kw in location_lower)
    central_count = sum(1 for kw in central_keywords if kw in location_lower)
    south_count = sum(1 for kw in south_keywords if kw in location_lower)
    
    # Ch·ªçn mi·ªÅn c√≥ s·ªë l·∫ßn xu·∫•t hi·ªán nhi·ªÅu nh·∫•t
    counts = {"Mi·ªÅn B·∫Øc": north_count, "Mi·ªÅn Trung": central_count, "Mi·ªÅn Nam": south_count}
    region = max(counts, key=counts.get)
    
    return region if counts[region] > 0 else "Mi·ªÅn Trung"  # Default Mi·ªÅn Trung cho Ruby Wings

def extract_tags(tour_data: Dict[str, Any]) -> List[str]:
    """
    Tr√≠ch xu·∫•t tags t·ª´ style, includes, notes c·ªßa tour
    """
    tags = []
    
    # L·∫•y c√°c field c·∫ßn thi·∫øt - X·ª¨ L√ù C·∫¢ STRING V√Ä LIST
    style = tour_data.get("style", "")
    if isinstance(style, str):
        style = style.lower()
    else:
        style = str(style).lower()
    
    # X·ª≠ l√Ω includes - c√≥ th·ªÉ l√† list ho·∫∑c string
    includes_raw = tour_data.get("includes", [])
    if isinstance(includes_raw, list):
        includes = " ".join(str(item) for item in includes_raw).lower()
    else:
        includes = str(includes_raw).lower()
    
    # X·ª≠ l√Ω notes - C√ì TH·ªÇ L√Ä LIST HO·∫∂C STRING
    notes_raw = tour_data.get("notes", "")
    if isinstance(notes_raw, list):
        notes = " ".join(str(item) for item in notes_raw).lower()
    else:
        notes = str(notes_raw).lower()
    
    summary = tour_data.get("summary", "")
    if isinstance(summary, str):
        summary = summary.lower()
    else:
        summary = str(summary).lower()
    
    tour_name = tour_data.get("tour_name", "")
    if isinstance(tour_name, str):
        tour_name = tour_name.lower()
    else:
        tour_name = str(tour_name).lower()
    
    # Danh s√°ch keyword mapping theo knowledge.json th·ª±c t·∫ø
    keyword_mapping = {
        "retreat": ["retreat", "ngh·ªâ d∆∞·ª°ng", "th∆∞ gi√£n", "tƒ©nh t√¢m", "ch·ªØa l√†nh", "t√°i t·∫°o nƒÉng l∆∞·ª£ng", "tƒ©nh t·∫°i"],
        "t√¢m_linh": ["t√¢m linh", "thi·ªÅn", "ch√°nh ni·ªám", "t·ªãnh t√¢m", "c·∫ßu nguy·ªán", "n·ªôi t√¢m", "thi·ªÅn ƒë·ªãnh"],
        "l·ªãch_s·ª≠": ["l·ªãch s·ª≠", "tri √¢n", "di t√≠ch", "chi·∫øn tranh", "c·ª±u chi·∫øn binh", "k√Ω ·ª©c", "kh√°ng chi·∫øn", "kh√°t v·ªçng"],
        "bi·ªÉn_ƒë·∫£o": ["bi·ªÉn", "ƒë·∫£o", "b√£i bi·ªÉn", "c·ªìn c·ªè", "c·ª≠a vi·ªát", "ven bi·ªÉn", "b·ªù bi·ªÉn"],
        "vƒÉn_h√≥a": ["vƒÉn h√≥a", "b·∫£n ƒë·ªãa", "d√¢n t·ªôc", "c·ªông ƒë·ªìng", "v√¢n ki·ªÅu", "pa k√¥", "c·ªìng chi√™ng", "ƒë√†n ta l∆∞"],
        "team_building": ["team building", "c√¥ng ty", "doanh nghi·ªáp", "t·∫≠p th·ªÉ", "corporate", "ƒëo√†n vi√™n"],
        "gia_ƒë√¨nh": ["gia ƒë√¨nh", "tr·∫ª em", "tr·∫ª nh·ªè", "ph√π h·ª£p gia ƒë√¨nh"],
        "thanh_ni√™n": ["thanh ni√™n", "h·ªçc sinh", "sinh vi√™n", "ƒëo√†n vi√™n", "tr·∫ª trung"],
        "ng∆∞·ªùi_l·ªõn_tu·ªïi": ["ng∆∞·ªùi l·ªõn tu·ªïi", "ng∆∞·ªùi gi√†", "senior", "ng∆∞·ªùi cao tu·ªïi"],
        "thi·ªÅn": ["thi·ªÅn", "kh√≠ c√¥ng", "ch√°nh ni·ªám", "yoga", "t·∫≠p luy·ªán tinh th·∫ßn", "th·ª±c h√†nh thi·ªÅn"],
        "thi√™n_nhi√™n": ["r·ª´ng", "n√∫i", "su·ªëi", "thi√™n nhi√™n", "b·∫°ch m√£", "nguy√™n sinh", "c√¢y c·ªè", "r·ª´ng nguy√™n sinh", "ng≈© h·ªì"],
        "m·∫°o_hi·ªÉm": ["trekking", "leo n√∫i", "kh√°m ph√°", "m·∫°o hi·ªÉm", "th·ª≠ th√°ch"],
        "tr·∫£i_nghi·ªám": ["tr·∫£i nghi·ªám", "h√†nh tr√¨nh", "kh√°m ph√°", "th·ª±c t·∫ø", "g·∫Øn k·∫øt"],
        "du_l·ªãch_xanh": ["xanh", "b·ªÅn v·ªØng", "m√¥i tr∆∞·ªùng", "sinh th√°i", "h√†nh tr√¨nh xanh"],
        "l·ª≠a_tr·∫°i": ["l·ª≠a tr·∫°i", "ƒë·ªët l·ª≠a", "giao l∆∞u ƒë√™m", "c·ªìng chi√™ng"],
        "picnic": ["picnic", "ƒÉn ngo√†i tr·ªùi", "thu·∫ßn chay"],
        "1_ng√†y": ["1 ng√†y", "m·ªôt ng√†y"],
        "2_ng√†y": ["2 ng√†y", "hai ng√†y", "1 ƒë√™m"],
        "gi√°_r·∫ª": ["890.000", "d∆∞·ªõi 1 tri·ªáu", "ti·∫øt ki·ªám"],
        "cao_c·∫•p": ["cao c·∫•p", "premium", "ch·∫•t l∆∞·ª£ng cao", "n√¢ng cao"]
    }
    
    # Ki·ªÉm tra t·ª´ng keyword
    all_text = f"{tour_name} {style} {includes} {notes} {summary}"
    for tag, keywords in keyword_mapping.items():
        if any(keyword in all_text for keyword in keywords):
            tags.append(tag)
    
    # ƒê·∫£m b·∫£o unique tags
    return list(set(tags))

def parse_duration(duration_text: str) -> int:
    """
    Parse duration text th√†nh s·ªë ng√†y
    V√≠ d·ª•: "2 ng√†y 1 ƒë√™m" ‚Üí 2, "1 ng√†y" ‚Üí 1
    """
    if not duration_text:
        return 1
    
    duration_lower = duration_text.lower().strip()
    
    # T√¨m s·ªë trong text (∆∞u ti√™n s·ªë ƒë·∫ßu ti√™n tr∆∞·ªõc "ng√†y")
    # Pattern: "2 ng√†y", "1 ng√†y", etc.
    day_match = re.search(r'(\d+)\s*ng√†y', duration_lower)
    if day_match:
        try:
            return int(day_match.group(1))
        except:
            pass
    
    # Fallback: t√¨m s·ªë b·∫•t k·ª≥
    numbers = re.findall(r'\d+', duration_text)
    if numbers:
        try:
            return int(numbers[0])
        except:
            pass
    
    return 1  # M·∫∑c ƒë·ªãnh 1 ng√†y

def parse_price(price_text: str) -> Tuple[int, int, int]:
    """
    Parse price text th√†nh min_price, max_price, avg_price
    V√≠ d·ª•: 
    - "1.700.000 ‚Äì 2.300.000 VNƒê/ng∆∞·ªùi" ‚Üí (1700000, 2300000, 2000000)
    - "890.000 VNƒê/kh√°ch" ‚Üí (890000, 890000, 890000)
    """
    if not price_text:
        return 1000000, 2000000, 1500000
    
    price_lower = price_text.lower().replace(',', '').replace(' ', '')
    
    # T√¨m t·∫•t c·∫£ s·ªë (b·ªè d·∫•u ch·∫•m ph√¢n c√°ch ng√†n)
    # Pattern: 1.700.000, 890.000, etc.
    numbers_raw = re.findall(r'[\d\.]+', price_text)
    
    clean_numbers = []
    for num_str in numbers_raw:
        try:
            # Lo·∫°i b·ªè d·∫•u ch·∫•m ph√¢n c√°ch ng√†n
            clean_num_str = num_str.replace('.', '')
            clean_num = int(clean_num_str)
            
            # Ch·ªâ l·∫•y s·ªë >= 1000 (tr√°nh s·ªë nh·ªè nh∆∞ nƒÉm, s·ªë ng∆∞·ªùi)
            if clean_num >= 1000:
                clean_numbers.append(clean_num)
        except:
            continue
    
    if len(clean_numbers) >= 2:
        # C√≥ kho·∫£ng gi√°: l·∫•y min, max
        min_price = min(clean_numbers)
        max_price = max(clean_numbers)
        avg_price = (min_price + max_price) // 2
    elif len(clean_numbers) == 1:
        # Ch·ªâ c√≥ 1 gi√°: gi·∫£ s·ª≠ ƒë√≥ l√† gi√° c∆° b·∫£n
        base_price = clean_numbers[0]
        
        # N·∫øu trong text c√≥ "g√≥i" ho·∫∑c "theo ƒëo√†n" th√¨ c√≥ th·ªÉ c√≥ range
        if any(word in price_lower for word in ["g√≥i", "theo", "tu·ª≥", "chi ti·∫øt"]):
            # ∆Ø·ªõc l∆∞·ª£ng range: ¬±30%
            min_price = int(base_price * 0.7)
            max_price = int(base_price * 1.3)
            avg_price = base_price
        else:
            # Gi√° c·ªë ƒë·ªãnh
            min_price = base_price
            max_price = base_price
            avg_price = base_price
    else:
        # Kh√¥ng parse ƒë∆∞·ª£c: ∆∞·ªõc l∆∞·ª£ng t·ª´ text
        if "tri·ªáu" in price_lower:
            # T√¨m s·ªë tri·ªáu
            million_match = re.search(r'(\d+)\s*tri·ªáu', price_lower)
            if million_match:
                try:
                    million_val = int(million_match.group(1))
                    base_price = million_val * 1000000
                    min_price = base_price
                    max_price = int(base_price * 1.5)
                    avg_price = int((min_price + max_price) / 2)
                except:
                    min_price, max_price, avg_price = 2000000, 3000000, 2500000
            else:
                min_price, max_price, avg_price = 2000000, 3000000, 2500000
        elif any(word in price_lower for word in ["ngh√¨n", "k"]):
            min_price, max_price, avg_price = 500000, 1500000, 1000000
        else:
            # Default cho Ruby Wings
            min_price, max_price, avg_price = 1000000, 2000000, 1500000
    
    return int(min_price), int(max_price), int(avg_price)

def create_embedding_text(tour_data: Dict[str, Any]) -> str:
    """
    T·∫°o text cho embedding t·ª´ c√°c field quan tr·ªçng
    """
    def safe_str(val):
        if val is None:
            return ""
        if isinstance(val, list):
            return " ".join(str(item) for item in val)
        if isinstance(val, dict):
            return " ".join(f"{k}: {v}" for k, v in val.items())
        return str(val)
    
    fields = [
        safe_str(tour_data.get("tour_name", "")),
        safe_str(tour_data.get("summary", "")),
        safe_str(tour_data.get("location", "")),
        safe_str(tour_data.get("style", "")),
        safe_str(tour_data.get("includes", "")),
        safe_str(tour_data.get("notes", "")),
        safe_str(tour_data.get("duration", "")),
        safe_str(tour_data.get("price", "")),
        safe_str(tour_data.get("accommodation", "")),
        safe_str(tour_data.get("meals", "")),
        safe_str(tour_data.get("transport", "")),
        safe_str(tour_data.get("event_support", ""))
    ]
    return " ".join([field for field in fields if field and field.strip()])

def calculate_popularity_score(tour_index: int, total_tours: int) -> float:
    """
    T√≠nh popularity score d·ª±a tr√™n v·ªã tr√≠ tour (gi·∫£ ƒë·ªãnh tour ƒë·∫ßu popular h∆°n)
    """
    if total_tours <= 1:
        return 0.8
    
    # Tour ƒë·∫ßu ti√™n c√≥ score cao nh·∫•t, gi·∫£m d·∫ßn
    base_score = 0.7
    position_factor = (total_tours - tour_index) / total_tours  # t·ª´ 1 ƒë·∫øn 0
    return base_score + (0.3 * position_factor)

def calculate_value_score(min_price: int, max_price: int, duration_days: int) -> float:
    """
    T√≠nh value score d·ª±a tr√™n gi√° v√† s·ªë ng√†y (gi√° th·∫•p + ng√†y nhi·ªÅu = value cao)
    """
    if duration_days == 0 or max_price == 0:
        return 0.5
    
    avg_price = (min_price + max_price) / 2
    price_per_day = avg_price / duration_days
    
    # Normalize: gi√° m·ªói ng√†y d∆∞·ªõi 1 tri·ªáu -> score cao
    if price_per_day < 1000000:
        return 0.8
    elif price_per_day < 2000000:
        return 0.6
    else:
        return 0.4

# =========== H√ÄM FLATTEN JSON (C·∫¨P NH·∫¨T) ===========

def flatten_json(path: str) -> List[dict]:
    """
    Flatten knowledge.json th√†nh list of passages cho FAISS
    M·ªói tour = 1 passage duy nh·∫•t v·ªõi t·∫•t c·∫£ th√¥ng tin
    """
    if not os.path.exists(path):
        raise FileNotFoundError(f"{path} not found")
    
    with open(path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    mapping = []
    
    # 1. X·ª≠ l√Ω about_company
    about = data.get("about_company", {})
    for key, value in about.items():
        if isinstance(value, str) and value.strip():
            mapping.append({
                "path": f"root.about_company.{key}",
                "text": value
            })
    
    # 2. X·ª≠ l√Ω tours - M·ªñI TOUR L√Ä 1 PASSAGE DUY NH·∫§T
    tours = data.get("tours", [])
    for i, tour in enumerate(tours):
        tour_text_parts = []
        
        # C√°c tr∆∞·ªùng quan tr·ªçng c·∫ßn index
        fields_to_include = [
            ("tour_name", "T√™n tour"),
            ("summary", "T√≥m t·∫Øt"),
            ("location", "ƒê·ªãa ƒëi·ªÉm"),
            ("duration", "Th·ªùi l∆∞·ª£ng"),
            ("price", "Gi√°"),
            ("notes", "L∆∞u √Ω"),
            ("style", "Phong c√°ch"),
            ("transport", "Ph∆∞∆°ng ti·ªán"),
            ("accommodation", "Ch·ªó ·ªü"),
            ("meals", "B·ªØa ƒÉn"),
            ("event_support", "H·ªó tr·ª£ s·ª± ki·ªán")
        ]
        
        for field_key, field_label in fields_to_include:
            if field_key in tour:
                value = tour[field_key]
                if isinstance(value, list):
                    tour_text_parts.append(f"{field_label}: {', '.join(str(v) for v in value)}")
                elif value and str(value).strip():
                    tour_text_parts.append(f"{field_label}: {value}")
        
        # X·ª≠ l√Ω includes
        if "includes" in tour and tour["includes"]:
            includes_text = "D·ªãch v·ª• bao g·ªìm: " + "; ".join(str(item) for item in tour["includes"])
            tour_text_parts.append(includes_text)
        
        # G·ªôp th√†nh 1 passage
        full_tour_text = "\n".join(tour_text_parts)
        
        mapping.append({
            "path": f"root.tours[{i}]",
            "text": full_tour_text
        })
    
    # 3. X·ª≠ l√Ω FAQ (n·∫øu c√≥)
    faq = data.get("faq", {})
    for key, value in faq.items():
        if isinstance(value, str) and value.strip():
            mapping.append({
                "path": f"root.faq.{key}",
                "text": value
            })
    
    # 4. X·ª≠ l√Ω contact (n·∫øu c√≥)
    contact = data.get("contact", {})
    for key, value in contact.items():
        if isinstance(value, str) and value.strip():
            mapping.append({
                "path": f"root.contact.{key}",
                "text": value
            })
    
    return mapping

# =========== H√ÄM T·∫†O TOUR_ENTITIES ===========

def create_tour_entities(tours_data: List[Dict[str, Any]], mapping: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    T·∫°o tour_entities.json v·ªõi c·∫•u tr√∫c v5.2
    ƒê·ªìng b·ªô v·ªõi entities.py v√† app.py
    """
    tour_entities = {}
    total_tours = len(tours_data)
    
    for i, tour in enumerate(tours_data):
        tour_id = f"tour_{i:03d}"
        
        # Parse c√°c th√¥ng tin c∆° b·∫£n
        tour_name = tour.get("tour_name", "")
        location = tour.get("location", "")
        duration_text = tour.get("duration", "")
        price_text = tour.get("price", "")
        
        # Extract metadata
        region = extract_region(location)
        tags = extract_tags(tour)
        duration_days = parse_duration(duration_text)
        min_price, max_price, avg_price = parse_price(price_text)
        
        # T·∫°o embedding text
        embedding_text = create_embedding_text(tour)
        
        # T√≠nh c√°c score
        popularity_score = calculate_popularity_score(i, total_tours)
        value_score = calculate_value_score(min_price, max_price, duration_days)
        
        # Ki·ªÉm tra c√°c flag
        family_friendly = "gia_ƒë√¨nh" in tags
        senior_friendly = "ng∆∞·ªùi_l·ªõn_tu·ªïi" in tags or (
            "m·∫°o_hi·ªÉm" not in tags and 
            "trekking" not in embedding_text.lower() and
            duration_days <= 2
        )
        corporate_friendly = "team_building" in tags or "thanh_ni√™n" in tags
        
        # T·∫°o tour entity
        tour_entities[tour_id] = {
            "tour_id": tour_id,
            "index": i,
            "tour_name": tour_name,
            "location": location,
            "region": region,
            
            "tags": tags,
            
            "duration": duration_text,
            "duration_days": duration_days,
            
            "price_text": price_text,
            "min_price": min_price,
            "max_price": max_price,
            "avg_price": avg_price,
            
            "embedding_text": embedding_text,
            
            # Metadata cho ranking
            "popularity_score": round(popularity_score, 2),
            "value_score": round(value_score, 2),
            "family_friendly": family_friendly,
            "senior_friendly": senior_friendly,
            "corporate_friendly": corporate_friendly,
            
            # C√°c field t·ª´ knowledge.json
            "summary": tour.get("summary", ""),
            "style": tour.get("style", ""),
            "includes": tour.get("includes", []),
            "notes": tour.get("notes", ""),
            "transport": tour.get("transport", ""),
            "accommodation": tour.get("accommodation", ""),
            "meals": tour.get("meals", ""),
            "event_support": tour.get("event_support", ""),
            
            # Timestamps
            "created_at": datetime.datetime.utcnow().isoformat() + "Z",
            "last_updated": datetime.datetime.utcnow().isoformat() + "Z"
        }
    
    return tour_entities

# =========== EMBEDDING FUNCTIONS ===========

def synthetic_embedding(text: str, dim: int = 1536) -> List[float]:
    """Generate synthetic embedding for fallback"""
    h = abs(hash(text)) % (10 ** 12)
    return [(float((h >> (i % 32)) & 0xFF) + (i % 7)) / 255.0 for i in range(dim)]

def call_embeddings_with_retry(inputs: List[str], model: str) -> List[List[float]]:
    """Call OpenAI embeddings API with retry logic"""
    if not OPENAI_KEY or OpenAI is None:
        print("‚ö†Ô∏è OpenAI API key not found, using synthetic embeddings", file=sys.stderr)
        dim = 1536 if "3-small" in model else 3072
        return [synthetic_embedding(t, dim) for t in inputs]

    client = OpenAI(api_key=OPENAI_KEY)
    attempt = 0
    
    while attempt <= RETRY_LIMIT:
        try:
            resp = client.embeddings.create(model=model, input=inputs)
            if getattr(resp, "data", None):
                out = [r.embedding for r in resp.data]
                print(f"‚úÖ Generated {len(out)} embeddings (model={model})", flush=True)
                return out
            else:
                raise ValueError("Empty response from OpenAI embeddings API")
        except Exception as e:
            attempt += 1
            if attempt > RETRY_LIMIT:
                print(f"‚ùå Embedding API failed after {RETRY_LIMIT} attempts: {e}", file=sys.stderr)
                print("‚ö†Ô∏è Falling back to synthetic embeddings", file=sys.stderr)
                dim = 1536 if "3-small" in model else 3072
                return [synthetic_embedding(t, dim) for t in inputs]
            
            delay = RETRY_BASE * (2 ** (attempt - 1))
            print(f"‚ö†Ô∏è Embedding API error (attempt {attempt}/{RETRY_LIMIT}): {e}. Retrying in {delay:.1f}s...", file=sys.stderr)
            time.sleep(delay)
    
    # Final fallback
    dim = 1536 if "3-small" in model else 3072
    return [synthetic_embedding(t, dim) for t in inputs]

# =========== CONFIG ===========

OPENAI_KEY = os.environ.get("OPENAI_API_KEY", "").strip()

KNOW_PATH = os.environ.get("KNOWLEDGE_PATH", "knowledge.json")
FAISS_INDEX_PATH = os.environ.get("FAISS_INDEX_PATH", "faiss_index.bin")
FAISS_MAPPING_PATH = os.environ.get("FAISS_MAPPING_PATH", "faiss_mapping.json")
FALLBACK_VECTORS_PATH = os.environ.get("FALLBACK_VECTORS_PATH", "vectors.npz")
META_PATH = os.environ.get("FAISS_META_PATH", "faiss_index_meta.json")
TOUR_ENTITIES_PATH = os.environ.get("TOUR_ENTITIES_PATH", "tour_entities.json")

EMBEDDING_MODEL = os.environ.get("OPENAI_EMBEDDING_MODEL", "text-embedding-3-small")
BATCH_SIZE = int(os.environ.get("BUILD_BATCH_SIZE", "8"))
RETRY_LIMIT = int(os.environ.get("RETRY_LIMIT", "5"))
RETRY_BASE = float(os.environ.get("RETRY_BASE_DELAY", "1.0"))

TMP_EMB_FILE = "emb_tmp.bin"

# =========== MAIN BUILD FLOW ===========

def build_index():
    print("=" * 60)
    print("BUILDING INDEX FOR RUBY WINGS v5.2")
    print("=" * 60)
    
    # 1. ƒê·ªçc knowledge.json
    print(f"\nüìö Reading knowledge from {KNOW_PATH}...")
    if not os.path.exists(KNOW_PATH):
        print(f"‚ùå Error: {KNOW_PATH} not found", file=sys.stderr)
        sys.exit(1)
    
    with open(KNOW_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    tours_data = data.get("tours", [])
    print(f"‚úÖ Found {len(tours_data)} tours")
    
    if len(tours_data) == 0:
        print("‚ùå No tours found in knowledge.json", file=sys.stderr)
        sys.exit(1)
    
    # 2. Flatten knowledge.json th√†nh mapping cho FAISS
    print("\nüîÑ Flattening knowledge.json for FAISS mapping...")
    mapping = flatten_json(KNOW_PATH)
    texts = [m.get("text", "") for m in mapping]
    n = len(texts)
    print(f"‚úÖ Created {n} passages for FAISS indexing")
    
    if n == 0:
        print("‚ùå No passages to index -> exit", file=sys.stderr)
        sys.exit(1)
    
    # 3. T·∫°o tour_entities.json
    print("\nüèóÔ∏è  Creating tour_entities.json with enhanced structure...")
    tour_entities = create_tour_entities(tours_data, mapping)
    
    # L∆∞u tour_entities.json
    try:
        with open(TOUR_ENTITIES_PATH, "w", encoding="utf-8") as f:
            json.dump(tour_entities, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ Saved enhanced tour_entities.json to {TOUR_ENTITIES_PATH}")
        print(f"   - Contains {len(tour_entities)} tours with fields:")
        print(f"     ‚Ä¢ region, tags, duration_days, min/max/avg_price")
        print(f"     ‚Ä¢ popularity_score, value_score")
        print(f"     ‚Ä¢ family_friendly, senior_friendly, corporate_friendly")
    except Exception as e:
        print(f"‚ùå Failed to save tour_entities.json: {e}", file=sys.stderr)
        sys.exit(1)
    
    # 4. T·∫°o embeddings
    print("\nüß† Creating embeddings for FAISS index...")
    print(f"   Using model: {EMBEDDING_MODEL}")
    print(f"   Batch size: {BATCH_SIZE}")
    
    # Remove tmp if exists
    if os.path.exists(TMP_EMB_FILE):
        try:
            os.remove(TMP_EMB_FILE)
        except Exception:
            pass

    dim: Optional[int] = None
    total_rows = 0
    batches = (n + BATCH_SIZE - 1) // BATCH_SIZE

    for start in range(0, n, BATCH_SIZE):
        batch = texts[start:start+BATCH_SIZE]
        inputs = [t if (t and str(t).strip()) else " " for t in batch]
        print(f"   Embedding batch {start//BATCH_SIZE + 1}/{batches} ({len(inputs)} texts)...", flush=True)
        vecs = call_embeddings_with_retry(inputs, EMBEDDING_MODEL)

        # Ensure no None entries
        for j, v in enumerate(vecs):
            if v is None:
                vecs[j] = synthetic_embedding(inputs[j], 1536 if "3-small" in EMBEDDING_MODEL else 3072)

        if dim is None and vecs:
            dim = len(vecs[0])

        arr = np.array(vecs, dtype="float32")
        norms = np.linalg.norm(arr, axis=1, keepdims=True)
        norms[norms == 0] = 1.0
        arr = arr / (norms + 1e-12)

        with open(TMP_EMB_FILE, "ab") as f:
            f.write(arr.tobytes())

        total_rows += arr.shape[0]

    if total_rows == 0 or dim is None:
        print("‚ùå No embeddings created -> exit", file=sys.stderr)
        sys.exit(1)

    print(f"‚úÖ Generated {total_rows} embeddings with dimension {dim}")
    
    # 5. Load embeddings v√† build FAISS index
    print("\nüîç Building FAISS index...")
    try:
        emb = np.memmap(TMP_EMB_FILE, dtype="float32", mode="r", shape=(total_rows, dim))
    except Exception:
        # Fallback: load entire array into memory
        raw = np.fromfile(TMP_EMB_FILE, dtype="float32")
        emb = raw.reshape((total_rows, dim))

    # Build FAISS index if available
    HAS_FAISS_local = False
    if HAS_FAISS:
        try:
            index = faiss.IndexFlatIP(dim)
            index.add(np.asarray(emb))
            try:
                faiss.write_index(index, FAISS_INDEX_PATH)
                print(f"‚úÖ Saved FAISS index to {FAISS_INDEX_PATH}")
                HAS_FAISS_local = True
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to persist FAISS index: {e}", file=sys.stderr)
                HAS_FAISS_local = False
        except Exception as e:
            print(f"‚ö†Ô∏è FAISS index build failed: {e}", file=sys.stderr)
            HAS_FAISS_local = False
    else:
        print("‚ö†Ô∏è FAISS not available, skipping FAISS index creation")

    # 6. Lu√¥n l∆∞u fallback vectors (npz) cho numpy fallback
    try:
        np.savez_compressed(FALLBACK_VECTORS_PATH, mat=np.asarray(emb))
        print(f"‚úÖ Saved fallback vectors to {FALLBACK_VECTORS_PATH}")
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to save fallback vectors: {e}", file=sys.stderr)

    # 7. L∆∞u mapping (list of {"path","text"}) expected by app.py
    print(f"\nüóÇÔ∏è  Saving mapping to {FAISS_MAPPING_PATH}...")
    try:
        with open(FAISS_MAPPING_PATH, "w", encoding="utf-8") as f:
            json.dump(mapping, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ Saved {len(mapping)} mapping entries")
    except Exception as e:
        print(f"‚ùå Failed to save mapping: {e}", file=sys.stderr)
        sys.exit(1)

    # 8. Write metadata
    meta = {
        "created_at": datetime.datetime.utcnow().isoformat() + "Z",
        "num_passages": int(total_rows),
        "num_tours": len(tours_data),
        "embedding_model": EMBEDDING_MODEL,
        "dimension": int(dim),
        "faiss_available": bool(HAS_FAISS_local),
        "system_version": "v5.2",
        "notes": "Built with enhanced tour_entities.json structure for Ruby Wings v5.2",
        "features": {
            "region_extraction": True,
            "tags_extraction": True,
            "price_parsing": True,
            "duration_parsing": True,
            "popularity_scoring": True,
            "value_scoring": True,
            "event_support_field": True
        }
    }
    try:
        with open(META_PATH, "w", encoding="utf-8") as f:
            json.dump(meta, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ Saved metadata to {META_PATH}")
    except Exception:
        print(f"‚ö†Ô∏è Failed to save metadata", file=sys.stderr)

    # 9. Cleanup temp file
    try:
        os.remove(TMP_EMB_FILE)
        print(f"‚úÖ Cleaned up temporary file: {TMP_EMB_FILE}")
    except Exception:
        pass

    # 10. Summary
    print("\n" + "=" * 60)
    print("üéâ BUILD COMPLETE")
    print("=" * 60)
    print(f"\nüìä Summary:")
    print(f"   ‚Ä¢ Tours processed: {len(tours_data)}")
    print(f"   ‚Ä¢ FAISS passages: {total_rows}")
    print(f"   ‚Ä¢ Embedding dimension: {dim}")
    print(f"   ‚Ä¢ Embedding model: {EMBEDDING_MODEL}")
    print(f"\nüìÅ Files created:")
    print(f"   1. tour_entities.json: {TOUR_ENTITIES_PATH}")
    print(f"      - Enhanced structure with region, tags, pricing, scores")
    print(f"   2. FAISS index: {FAISS_INDEX_PATH if HAS_FAISS_local else '(skipped - FAISS not available)'}")
    print(f"   3. FAISS mapping: {FAISS_MAPPING_PATH}")
    print(f"   4. Fallback vectors: {FALLBACK_VECTORS_PATH}")
    print(f"   5. Metadata: {META_PATH}")
    
    # Hi·ªÉn th·ªã sample c·ªßa tour ƒë·∫ßu ti√™n
    if tour_entities:
        sample_id = list(tour_entities.keys())[0]
        sample_tour = tour_entities[sample_id]
        print(f"\nüìù Sample tour structure (first tour):")
        print(f"   ‚Ä¢ Tour ID: {sample_id}")
        print(f"   ‚Ä¢ Name: {sample_tour.get('tour_name', 'N/A')[:60]}...")
        print(f"   ‚Ä¢ Location: {sample_tour.get('location', 'N/A')[:60]}")
        print(f"   ‚Ä¢ Region: {sample_tour.get('region', 'N/A')}")
        print(f"   ‚Ä¢ Tags: {', '.join(sample_tour.get('tags', [])[:5])}")
        if len(sample_tour.get('tags', [])) > 5:
            print(f"            (and {len(sample_tour.get('tags', [])) - 5} more...)")
        print(f"   ‚Ä¢ Duration: {sample_tour.get('duration', 'N/A')} ({sample_tour.get('duration_days', 'N/A')} days)")
        print(f"   ‚Ä¢ Price range: {sample_tour.get('min_price', 0):,} - {sample_tour.get('max_price', 0):,} VND")
        print(f"   ‚Ä¢ Avg price: {sample_tour.get('avg_price', 0):,} VND")
        print(f"   ‚Ä¢ Popularity score: {sample_tour.get('popularity_score', 0)}")
        print(f"   ‚Ä¢ Value score: {sample_tour.get('value_score', 0)}")
        print(f"   ‚Ä¢ Family friendly: {sample_tour.get('family_friendly', False)}")
        print(f"   ‚Ä¢ Senior friendly: {sample_tour.get('senior_friendly', False)}")
        print(f"   ‚Ä¢ Corporate friendly: {sample_tour.get('corporate_friendly', False)}")
    
    # Hi·ªÉn th·ªã th·ªëng k√™ tags
    if tour_entities:
        all_tags = []
        for tour_id, tour in tour_entities.items():
            all_tags.extend(tour.get('tags', []))
        
        from collections import Counter
        tag_counts = Counter(all_tags)
        print(f"\nüè∑Ô∏è  Tag statistics (top 10):")
        for tag, count in tag_counts.most_common(10):
            print(f"   ‚Ä¢ {tag}: {count} tours")
    
    # Hi·ªÉn th·ªã th·ªëng k√™ regions
    if tour_entities:
        regions = {}
        for tour_id, tour in tour_entities.items():
            region = tour.get('region', 'Kh√¥ng x√°c ƒë·ªãnh')
            regions[region] = regions.get(region, 0) + 1
        
        print(f"\nüó∫Ô∏è  Region distribution:")
        for region, count in sorted(regions.items(), key=lambda x: x[1], reverse=True):
            print(f"   ‚Ä¢ {region}: {count} tours")
    
    print("\n‚úÖ Index ready for Ruby Wings v5.2 system!")
    print("=" * 60)

if __name__ == "__main__":
    try:
        build_index()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Build interrupted by user", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå ERROR building index: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)